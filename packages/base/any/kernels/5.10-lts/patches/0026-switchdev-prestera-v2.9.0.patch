diff --git a/drivers/net/ethernet/marvell/prestera/Makefile b/drivers/net/ethernet/marvell/prestera/Makefile
index 29093e4..db531db 100644
--- a/drivers/net/ethernet/marvell/prestera/Makefile
+++ b/drivers/net/ethernet/marvell/prestera/Makefile
@@ -1,11 +1,16 @@
 # SPDX-License-Identifier: GPL-2.0
-obj-$(CONFIG_PRESTERA)	+= prestera.o
-prestera-objs		:= prestera_main.o \
-			   prestera_hw.o prestera_switchdev.o prestera_devlink.o prestera_fw_log.o \
-			   prestera_rxtx.o prestera_rxtx_sdma.o prestera_dsa.o prestera_router.o \
-			   prestera_acl.o prestera_flower.o prestera_debugfs.o
+#
+# Makefile for the Marvell Switch driver.
+#
 
-obj-$(CONFIG_PRESTERA_PCI)	+= prestera_pci.o
+obj-$(CONFIG_PRESTERA) += prestera.o
+prestera-objs := prestera_main.o \
+	prestera_hw.o prestera_switchdev.o prestera_devlink.o prestera_fw_log.o \
+	prestera_rxtx.o prestera_dsa.o prestera_router.o \
+	prestera_acl.o prestera_flow.o prestera_flower.o prestera_matchall.o prestera_debugfs.o \
+	prestera_storm_control.o prestera_ct.o
 
-prestera-$(CONFIG_MRVL_PRESTERA_DEBUG) += prestera_log.o
-ccflags-$(CONFIG_MRVL_PRESTERA_DEBUG) += -DCONFIG_MRVL_PRESTERA_DEBUG
+prestera-$(CONFIG_PRESTERA_DEBUG) += prestera_log.o
+ccflags-$(CONFIG_PRESTERA_DEBUG) += -DCONFIG_MRVL_PRESTERA_DEBUG
+
+obj-$(CONFIG_PRESTERA_PCI) += prestera_pci.o
diff --git a/drivers/net/ethernet/marvell/prestera/prestera.h b/drivers/net/ethernet/marvell/prestera/prestera.h
index 87acd30..6228cfa 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera.h
@@ -18,7 +18,8 @@
 
 #define PRESTERA_DRV_NAME       "prestera"
 
-#define MVSW_MSG_MAX_SIZE 1500
+#define PRESTERA_MSG_MAX_SIZE 1500
+#define MVSW_MSG_CHUNK_SIZE 1024
 
 #define MVSW_PR_DEFAULT_VID 1
 
@@ -28,6 +29,8 @@
 
 #define MVSW_PR_NHGR_SIZE_MAX 4
 
+#define PRESTERA_SPAN_INVALID_ID -1
+
 struct prestera_fw_rev {
 	u16 maj;
 	u16 min;
@@ -35,14 +38,36 @@ struct prestera_fw_rev {
 };
 
 struct mvsw_pr_bridge_port;
+struct mvsw_pr_kern_neigh_cache;
 struct prestera_acl;
-struct prestera_acl_block;
 struct prestera_acl_rule;
 struct prestera_acl_ruleset;
+struct prestera_acl_nat_port;
+struct prestera_span;
+struct prestera_span_entry;
+struct prestera_storm_control;
+
+struct prestera_flow_block_binding {
+	struct list_head list;
+	struct prestera_port *port;
+	int span_id;
+};
+
+struct prestera_flow_block {
+	struct list_head binding_list;
+	struct prestera_switch *sw;
+	unsigned int rule_count;
+	unsigned int disable_count;
+	struct net *net;
+	struct prestera_acl_ruleset *ruleset;
+	struct flow_block_cb *block_cb;
+	u32 mall_prio;
+	u32 flower_min_prio;
+};
 
 struct mvsw_pr_port_vlan {
 	struct list_head list;
-	struct mvsw_pr_port *mvsw_pr_port;
+	struct prestera_port *mvsw_pr_port;
 	u16 vid;
 	struct mvsw_pr_bridge_port *bridge_port;
 	struct list_head bridge_vlan_node;
@@ -88,10 +113,10 @@ struct mvsw_pr_port_caps {
 	u8 transceiver;
 };
 
-struct mvsw_pr_port {
+struct prestera_port {
 	struct devlink_port dl_port;
 	struct net_device *net_dev;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	u32 id;
 	u32 hw_id;
 	u32 dev_id;
@@ -111,20 +136,20 @@ struct mvsw_pr_port {
 		struct mvsw_pr_port_stats stats;
 		struct delayed_work caching_dw;
 	} cached_hw_stats;
-	struct prestera_acl_block *acl_block;
+	struct prestera_flow_block *flow_block;
 
 	struct phylink_config phy_config;
 	struct phylink *phy_link;
 };
 
 struct prestera_switchdev {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct notifier_block swdev_n;
 	struct notifier_block swdev_blocking_n;
 };
 
 struct mvsw_pr_fib {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct notifier_block fib_nb;
 	struct notifier_block netevent_nb;
 };
@@ -136,6 +161,10 @@ struct prestera_device {
 	u8 __iomem *pp_regs;
 	void *priv;
 
+	struct delayed_work keepalive_wdog_work;
+	atomic_t keepalive_wdog_counter;
+	bool running;
+
 	/* called by device driver to handle received packets */
 	void (*recv_pkt)(struct prestera_device *dev);
 
@@ -143,8 +172,9 @@ struct prestera_device {
 	int (*recv_msg)(struct prestera_device *dev, u8 *msg, size_t size);
 
 	/* called by higher layer to send request to the firmware */
-	int (*send_req)(struct prestera_device *dev, u8 *in_msg,
-			size_t in_size, u8 *out_msg, size_t out_size,
+	int (*send_req)(struct prestera_device *dev, int qid,
+			u8 *in_msg, size_t in_size,
+			u8 *out_msg, size_t out_size,
 			unsigned int wait);
 };
 
@@ -154,6 +184,7 @@ enum mvsw_pr_event_type {
 	MVSW_EVENT_TYPE_FDB,
 	MVSW_EVENT_TYPE_RXTX,
 	MVSW_EVENT_TYPE_FW_LOG,
+	MVSW_EVENT_TYPE_PULSE,
 
 	MVSW_EVENT_TYPE_MAX,
 };
@@ -224,7 +255,7 @@ struct mvsw_pr_event {
 
 struct prestera_lag_member {
 	struct list_head list;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 };
 
 struct prestera_lag {
@@ -259,8 +290,10 @@ struct mvsw_pr_iface {
 struct mvsw_pr_bridge;
 struct mvsw_pr_router;
 struct mvsw_pr_rif;
+struct prestera_trap_data;
+struct prestera_rxtx;
 
-struct mvsw_pr_switch {
+struct prestera_switch {
 	struct list_head list;
 	struct prestera_device *dev;
 	struct list_head event_handlers;
@@ -272,17 +305,22 @@ struct mvsw_pr_switch {
 	u8 id;
 	u8 lag_max;
 	u8 lag_member_max;
+	u32 size_tbl_router_nexthop;
+	struct prestera_storm_control *storm_control;
 	struct prestera_acl *acl;
+	struct prestera_span *span;
 	struct mvsw_pr_bridge *bridge;
 	struct prestera_switchdev *switchdev;
 	struct mvsw_pr_router *router;
 	struct prestera_lag *lags;
 	struct notifier_block netdevice_nb;
 	struct device_node *np;
+	struct prestera_trap_data *trap_data;
+	struct prestera_rxtx *rxtx;
 };
 
 struct mvsw_pr_router {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct list_head rif_list;	/* list of mvsw_pr_rif */
 	struct list_head vr_list;	/* list of mvsw_pr_vr */
 	struct rhashtable nh_neigh_ht;
@@ -290,6 +328,8 @@ struct mvsw_pr_router {
 	struct rhashtable fib_ht;
 	struct rhashtable kern_fib_cache_ht;
 	struct rhashtable kern_neigh_cache_ht;
+	u8 *nhgrp_hw_state_cache; /* Bitmap cached hw state of nhs */
+	unsigned long nhgrp_hw_cache_kick; /* jiffies */
 	struct {
 		struct delayed_work dw;
 		unsigned int interval;	/* ms */
@@ -307,6 +347,24 @@ enum mvsw_pr_fdb_flush_mode {
 				   | MVSW_PR_FDB_FLUSH_MODE_STATIC,
 };
 
+struct mvsw_pr_ip_addr {
+	enum {
+		MVSW_PR_IPV4 = 0,
+		MVSW_PR_IPV6
+	} v;
+	union {
+		__be32 ipv4;
+		struct in6_addr ipv6;
+	} u;
+};
+
+/* Used for hw call */
+struct mvsw_pr_neigh_info {
+	struct mvsw_pr_iface iface;
+	unsigned char ha[ETH_ALEN];
+	bool connected; /* indicate, if mac/oif valid */
+};
+
 enum prestera_acl_rule_match_entry_type {
 	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE = 1,
 	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC,
@@ -329,11 +387,14 @@ enum prestera_acl_rule_action {
 	MVSW_ACL_RULE_ACTION_ACCEPT,
 	MVSW_ACL_RULE_ACTION_DROP,
 	MVSW_ACL_RULE_ACTION_TRAP,
-	MVSW_ACL_RULE_ACTION_POLICE
+	MVSW_ACL_RULE_ACTION_POLICE,
+	MVSW_ACL_RULE_ACTION_NAT,
+	MVSW_ACL_RULE_ACTION_JUMP,
+	MVSW_ACL_RULE_ACTION_MANGLE
 };
 
-struct prestera_acl_rule_match_entry {
-	struct list_head list;
+/* Used for hw call */
+struct prestera_acl_hw_match_info {
 	enum prestera_acl_rule_match_entry_type type;
 	union {
 		struct {
@@ -352,28 +413,50 @@ struct prestera_acl_rule_match_entry {
 			u8 key[ETH_ALEN];
 			u8 mask[ETH_ALEN];
 		} mac;
-	} keymask;
+	};
 };
 
-struct prestera_acl_rule_action_entry {
-	struct list_head list;
+/* Used for hw call */
+struct prestera_acl_hw_action_info {
 	enum prestera_acl_rule_action id;
 	union {
 		struct {
-			u64 rate, burst;
+			u64 rate;
+			u64 burst;
 		} police;
+		struct {
+			u8 l4_src_valid:1, l4_dst_valid:1,
+			   sip_valid:1, dip_valid:1;
+			__be16 l4_src;
+			__be16 l4_dst;
+			struct mvsw_pr_ip_addr sip;
+			struct mvsw_pr_ip_addr dip;
+			struct mvsw_pr_neigh_info n;
+		} mangle;
+		struct {
+			__be32 old_addr;
+			__be32 new_addr;
+			u32 port;
+			u32 dev;
+			u32 flags;
+		} nat;
+		struct {
+			u32 chain;
+		} jump;
 	};
 };
 
-struct mvsw_pr_ip_addr {
-	enum {
-		MVSW_PR_IPV4 = 0,
-		MVSW_PR_IPV6
-	} v;
-	union {
-		__be32 ipv4;
-		struct in6_addr ipv6;
-	} u;
+/* TODO: match/action entries will be refactored to provide tie with neigh */
+
+struct prestera_acl_rule_match_entry {
+	struct list_head list;
+	struct prestera_acl_hw_match_info info;
+};
+
+struct prestera_acl_rule_action_entry {
+	struct list_head list;
+	struct prestera_acl_rule *rule;
+	struct prestera_acl_hw_action_info info;
 };
 
 struct mvsw_pr_fib_key {
@@ -399,13 +482,6 @@ struct mvsw_pr_fib_info {
 	struct mvsw_pr_nexthop_group *nh_grp;
 };
 
-/* Used for hw call */
-struct mvsw_pr_neigh_info {
-	struct mvsw_pr_iface iface;
-	unsigned char ha[ETH_ALEN];
-	bool connected; /* indicate, if mac/oif valid */
-};
-
 struct mvsw_pr_nh_neigh_key {
 	struct mvsw_pr_ip_addr addr;
 	struct mvsw_pr_rif *rif;
@@ -419,105 +495,130 @@ struct mvsw_pr_nh_neigh {
 	struct list_head nexthop_group_list;
 };
 
-int mvsw_pr_switch_ageing_set(struct mvsw_pr_switch *sw, u32 ageing_time);
+struct mvsw_pr_nexthop_group_key {
+	struct mvsw_pr_nh_neigh_key neigh[MVSW_PR_NHGR_SIZE_MAX];
+};
+
+struct prestera_port *dev_to_prestera_port(struct device *dev);
+
+int prestera_switch_ageing_set(struct prestera_switch *sw, u32 ageing_time);
 
-int mvsw_pr_port_learning_set(struct mvsw_pr_port *mvsw_pr_port,
-			      bool learn_enable);
-int mvsw_pr_port_uc_flood_set(struct mvsw_pr_port *mvsw_pr_port, bool flood);
-int mvsw_pr_port_mc_flood_set(struct mvsw_pr_port *mvsw_pr_port, bool flood);
-int mvsw_pr_port_pvid_set(struct mvsw_pr_port *mvsw_pr_port, u16 vid);
-int mvsw_pr_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state);
+int prestera_port_learning_set(struct prestera_port *port, bool learn_enable);
+int prestera_port_uc_flood_set(struct prestera_port *port, bool flood);
+int prestera_port_mc_flood_set(struct prestera_port *port, bool flood);
+int prestera_port_pvid_set(struct prestera_port *port, u16 vid);
+int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state);
 struct mvsw_pr_port_vlan *
-mvsw_pr_port_vlan_create(struct mvsw_pr_port *mvsw_pr_port, u16 vid,
-			 bool untagged);
-void mvsw_pr_port_vlan_destroy(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan);
-int mvsw_pr_port_vlan_set(struct mvsw_pr_port *mvsw_pr_port, u16 vid,
-			  bool is_member, bool untagged);
+prestera_port_vlan_create(struct prestera_port *port, u16 vid, bool untagged);
+void prestera_port_vlan_destroy(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan);
+int prestera_port_vlan_set(struct prestera_port *port, u16 vid,
+			   bool is_member, bool untagged);
 
 struct mvsw_pr_bridge_device *
 mvsw_pr_bridge_device_find(const struct mvsw_pr_bridge *bridge,
 			   const struct net_device *br_dev);
 u16 mvsw_pr_vlan_dev_vlan_id(struct mvsw_pr_bridge *bridge,
 			     struct net_device *dev);
-int mvsw_pr_8021d_bridge_create(struct mvsw_pr_switch *sw, u16 *bridge_id);
-int mvsw_pr_8021d_bridge_delete(struct mvsw_pr_switch *sw, u16 bridge_id);
-int mvsw_pr_8021d_bridge_port_add(struct mvsw_pr_port *mvsw_pr_port,
-				  u16 bridge_id);
-int mvsw_pr_8021d_bridge_port_delete(struct mvsw_pr_port *mvsw_pr_port,
-				     u16 bridge_id);
-
-int mvsw_pr_fdb_add(struct mvsw_pr_port *mvsw_pr_port, const unsigned char *mac,
-		    u16 vid, bool dynamic);
-int mvsw_pr_fdb_del(struct mvsw_pr_port *mvsw_pr_port, const unsigned char *mac,
-		    u16 vid);
-int mvsw_pr_fdb_flush_vlan(struct mvsw_pr_switch *sw, u16 vid,
-			   enum mvsw_pr_fdb_flush_mode mode);
-int mvsw_pr_fdb_flush_port_vlan(struct mvsw_pr_port *port, u16 vid,
-				enum mvsw_pr_fdb_flush_mode mode);
-int mvsw_pr_fdb_flush_port(struct mvsw_pr_port *port,
-			   enum mvsw_pr_fdb_flush_mode mode);
-int mvsw_pr_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid);
-int mvsw_pr_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid);
-
-int prestera_lag_member_add(struct mvsw_pr_port *port,
+int prestera_8021d_bridge_create(struct prestera_switch *sw, u16 *bridge_id);
+int prestera_8021d_bridge_delete(struct prestera_switch *sw, u16 bridge_id);
+int prestera_8021d_bridge_port_add(struct prestera_port *port, u16 bridge_id);
+int prestera_8021d_bridge_port_delete(struct prestera_port *port,
+				      u16 bridge_id);
+
+int prestera_fdb_add(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid, bool dynamic);
+int prestera_fdb_del(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid);
+int prestera_fdb_flush_vlan(struct prestera_switch *sw, u16 vid,
+			    enum mvsw_pr_fdb_flush_mode mode);
+int prestera_fdb_flush_port_vlan(struct prestera_port *port, u16 vid,
+				 enum mvsw_pr_fdb_flush_mode mode);
+int prestera_fdb_flush_port(struct prestera_port *port,
+			    enum mvsw_pr_fdb_flush_mode mode);
+int prestera_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid);
+int prestera_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid);
+
+int prestera_lag_member_add(struct prestera_port *port,
 			    struct net_device *lag_dev, u16 lag_id);
-int prestera_lag_member_del(struct mvsw_pr_port *port);
-int prestera_lag_member_enable(struct mvsw_pr_port *port, bool enable);
-bool mvsw_pr_port_is_lag_member(const struct mvsw_pr_port *port);
-int prestera_lag_id_find(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
+int prestera_lag_member_del(struct prestera_port *port);
+int prestera_lag_member_enable(struct prestera_port *port, bool enable);
+bool prestera_port_is_lag_member(const struct prestera_port *port);
+int prestera_lag_id_find(struct prestera_switch *sw, struct net_device *lag_dev,
 			 u16 *lag_id);
-void prestera_lag_member_rif_leave(const struct mvsw_pr_port *port,
+void prestera_lag_member_rif_leave(const struct prestera_port *port,
 				   u16 lag_id, u16 vr_id);
 
-int mvsw_pr_dev_if_type(const struct net_device *dev);
+/* SPAN */
+int prestera_span_get(struct prestera_port *port, u8 *span_id);
+int prestera_span_put(const struct prestera_switch *sw, u8 span_id);
+
+int prestera_dev_if_type(const struct net_device *dev);
 
 /* prestera_flower.c */
-int mvsw_pr_flower_replace(struct mvsw_pr_switch *sw,
-			   struct prestera_acl_block *block,
+int mvsw_pr_flower_replace(struct prestera_switch *sw,
+			   struct prestera_flow_block *block,
 			   struct flow_cls_offload *f);
-void mvsw_pr_flower_destroy(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
+void mvsw_pr_flower_destroy(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
 			    struct flow_cls_offload *f);
-int mvsw_pr_flower_stats(struct mvsw_pr_switch *sw,
-			 struct prestera_acl_block *block,
+int mvsw_pr_flower_stats(struct prestera_switch *sw,
+			 struct prestera_flow_block *block,
 			 struct flow_cls_offload *f);
+int prestera_flower_prio_get(struct prestera_flow_block *block,
+			     u32 *prio);
+
+/* prestera_matchall.c */
+int prestera_mall_replace(struct prestera_flow_block *block,
+			  struct tc_cls_matchall_offload *f);
+void prestera_mall_destroy(struct prestera_flow_block *block);
+int prestera_mall_prio_get(struct prestera_flow_block *block,
+			   u32 *prio);
+
+/* prestera_flow.c */
+int prestera_setup_tc_block(struct prestera_port *port,
+			    struct flow_block_offload *f);
 
 /* prestera_acl.c */
-int prestera_acl_init(struct mvsw_pr_switch *sw);
-void prestera_acl_fini(struct mvsw_pr_switch *sw);
-struct prestera_acl_block *
-prestera_acl_block_create(struct mvsw_pr_switch *sw, struct net *net);
-void prestera_acl_block_destroy(struct prestera_acl_block *block);
-struct net *prestera_acl_block_net(struct prestera_acl_block *block);
-struct mvsw_pr_switch *prestera_acl_block_sw(struct prestera_acl_block *block);
-unsigned int prestera_acl_block_rule_count(struct prestera_acl_block *block);
-void prestera_acl_block_disable_inc(struct prestera_acl_block *block);
-void prestera_acl_block_disable_dec(struct prestera_acl_block *block);
-bool prestera_acl_block_disabled(const struct prestera_acl_block *block);
-int prestera_acl_block_bind(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
-			    struct mvsw_pr_port *port);
-int prestera_acl_block_unbind(struct mvsw_pr_switch *sw,
-			      struct prestera_acl_block *block,
-			      struct mvsw_pr_port *port);
+int prestera_acl_init(struct prestera_switch *sw);
+void prestera_acl_fini(struct prestera_switch *sw);
+struct prestera_flow_block *
+prestera_acl_block_create(struct prestera_switch *sw, struct net *net);
+void prestera_acl_block_destroy(struct prestera_flow_block *block);
+struct net *prestera_acl_block_net(struct prestera_flow_block *block);
+struct prestera_switch *
+prestera_acl_block_sw(struct prestera_flow_block *block);
+unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block);
+void prestera_acl_block_disable_inc(struct prestera_flow_block *block);
+void prestera_acl_block_disable_dec(struct prestera_flow_block *block);
+bool prestera_acl_block_disabled(const struct prestera_flow_block *block);
+int prestera_acl_block_bind(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
+			    struct prestera_port *port);
+int prestera_acl_block_unbind(struct prestera_switch *sw,
+			      struct prestera_flow_block *block,
+			      struct prestera_port *port);
 struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_acl_block *block);
+prestera_acl_block_ruleset_get(struct prestera_flow_block *block);
 struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_acl_block *block,
-			 unsigned long cookie);
+prestera_acl_rule_create(struct prestera_flow_block *block,
+			 unsigned long cookie, u32 chain_index);
 u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule);
 void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
 				    u32 priority);
 u8 prestera_acl_rule_hw_tc_get(struct prestera_acl_rule *rule);
 void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc);
 u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule);
+u8 prestera_acl_rule_hw_chain_id_get(const struct prestera_acl_rule *rule);
 struct list_head *
 prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule);
+u32 prestera_acl_rule_chain_get(struct prestera_acl_rule *rule);
 u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule);
-void prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				  struct prestera_acl_rule_action_entry *entry);
+u8 prestera_acl_rule_match_len(struct prestera_acl_rule *rule);
+int prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
+				 struct prestera_acl_rule_action_entry *entry);
+
 struct list_head *
 prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule);
 void prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
@@ -526,67 +627,86 @@ void prestera_acl_rule_destroy(struct prestera_acl_rule *rule);
 struct prestera_acl_rule *
 prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
 			 unsigned long cookie);
-int prestera_acl_rule_add(struct mvsw_pr_switch *sw,
+int prestera_acl_rule_add(struct prestera_switch *sw,
 			  struct prestera_acl_rule *rule);
-void prestera_acl_rule_del(struct mvsw_pr_switch *sw,
+void prestera_acl_rule_del(struct prestera_switch *sw,
 			   struct prestera_acl_rule *rule);
-int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
+int prestera_acl_rule_get_stats(struct prestera_switch *sw,
 				struct prestera_acl_rule *rule,
 				u64 *packets, u64 *bytes, u64 *last_use);
+void prestera_acl_block_prio_update(struct prestera_switch *sw,
+				    struct prestera_flow_block *block);
+
+/* ACL-NAT */
+struct prestera_acl_nat_port *
+prestera_acl_nat_port_get(struct prestera_acl *acl, u32 port_hw_id,
+			  u32 port_dev_id);
+void prestera_acl_nat_port_put(struct prestera_acl_nat_port *nat_port);
+struct prestera_port *
+prestera_acl_nat_port_to_port(struct prestera_acl_nat_port *nat_port);
 
 /* VLAN API */
 struct mvsw_pr_port_vlan *
-mvsw_pr_port_vlan_find_by_vid(const struct mvsw_pr_port *mvsw_pr_port, u16 vid);
+prestera_port_vlan_find_by_vid(const struct prestera_port *port, u16 vid);
 void
 mvsw_pr_port_vlan_bridge_leave(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan);
 
-int prestera_switchdev_register(struct mvsw_pr_switch *sw);
-void prestera_switchdev_unregister(struct mvsw_pr_switch *sw);
+int prestera_switchdev_register(struct prestera_switch *sw);
+void prestera_switchdev_unregister(struct prestera_switch *sw);
 
 int prestera_device_register(struct prestera_device *dev);
 void prestera_device_unregister(struct prestera_device *dev);
 
-bool mvsw_pr_netdev_check(const struct net_device *dev);
-struct mvsw_pr_switch *mvsw_pr_switch_get(struct net_device *dev);
-struct mvsw_pr_port *mvsw_pr_port_dev_lower_find(struct net_device *dev);
+bool prestera_netdev_check(const struct net_device *dev);
+struct prestera_switch *prestera_switch_get(struct net_device *dev);
+struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev);
 
-const struct mvsw_pr_port *mvsw_pr_port_find(u32 dev_hw_id, u32 port_hw_id);
-int mvsw_pr_schedule_dw(struct delayed_work *dwork, unsigned long delay);
+struct prestera_port *prestera_port_find(u32 dev_hw_id, u32 port_hw_id);
 
 /* prestera_router.c */
-int mvsw_pr_router_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_router_fini(struct mvsw_pr_switch *sw);
+int mvsw_pr_router_init(struct prestera_switch *sw);
+void mvsw_pr_router_fini(struct prestera_switch *sw);
 int mvsw_pr_netdevice_router_port_event(struct net_device *dev,
 					unsigned long event, void *ptr);
 int mvsw_pr_inetaddr_valid_event(struct notifier_block *unused,
 				 unsigned long event, void *ptr);
 int mvsw_pr_netdevice_vrf_event(struct net_device *dev, unsigned long event,
 				struct netdev_notifier_changeupper_info *info);
-void mvsw_pr_port_router_leave(struct mvsw_pr_port *mvsw_pr_port);
-int mvsw_pr_lpm_add(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len, u32 grp_id);
-int mvsw_pr_lpm_del(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len);
-int mvsw_pr_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 *grp_id);
-int mvsw_pr_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 grp_id);
-int mvsw_pr_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy);
-
-void mvsw_pr_rif_enable(struct mvsw_pr_switch *sw, struct net_device *dev,
+void mvsw_pr_port_router_leave(struct prestera_port *port);
+int prestera_lpm_add(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct mvsw_pr_ip_addr *addr, u32 prefix_len, u32 grp_id);
+int prestera_lpm_del(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct mvsw_pr_ip_addr *addr, u32 prefix_len);
+int prestera_nh_entries_set(const struct prestera_switch *sw, int count,
+			    struct mvsw_pr_neigh_info *nhs, u32 grp_id);
+int prestera_nh_entries_get(const struct prestera_switch *sw, int count,
+			    struct mvsw_pr_neigh_info *nhs, u32 grp_id);
+int prestera_nhgrp_blk_get(const struct prestera_switch *sw, u8 *hw_state,
+			   u32 buf_size);
+int prestera_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+			     u32 *grp_id);
+int prestera_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+			     u32 grp_id);
+int prestera_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy);
+
+struct mvsw_pr_nh_neigh *
+mvsw_pr_nh_neigh_find(struct prestera_switch *sw,
+		      struct mvsw_pr_nh_neigh_key *key);
+int prestera_util_kern_dip2nh_grp_key(struct prestera_switch *sw,
+				      u32 tb_id, struct mvsw_pr_ip_addr *addr,
+				      struct mvsw_pr_nexthop_group_key *res);
+void mvsw_pr_rif_enable(struct prestera_switch *sw, struct net_device *dev,
 			bool enable);
-bool mvsw_pr_rif_exists(const struct mvsw_pr_switch *sw,
+bool mvsw_pr_rif_exists(const struct prestera_switch *sw,
 			const struct net_device *dev);
-void mvsw_pr_router_lag_member_leave(const struct mvsw_pr_port *port,
+void mvsw_pr_router_lag_member_leave(const struct prestera_port *port,
 				     const struct net_device *dev);
-void prestera_lag_router_leave(struct mvsw_pr_switch *sw,
+void prestera_lag_router_leave(struct prestera_switch *sw,
 			       struct net_device *lag_dev);
 
-void mvsw_pr_bridge_device_rifs_destroy(struct mvsw_pr_switch *sw,
+void mvsw_pr_bridge_device_rifs_destroy(struct prestera_switch *sw,
 					struct net_device *bridge_dev);
+struct mvsw_pr_neigh_info *
+prestera_kern_neigh_cache_to_neigh_info(struct mvsw_pr_kern_neigh_cache *nc);
 
 #endif /* _MVSW_PRESTERA_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.c b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
index 143df72..6dc7d75 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_acl.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
@@ -7,47 +7,17 @@
 
 #include "prestera.h"
 #include "prestera_hw.h"
+#include "prestera_log.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
 
-#define MVSW_ACL_RULE_DEF_HW_TC		3
-
-struct prestera_acl {
-	struct mvsw_pr_switch *sw;
-	struct list_head rules;
-};
-
-struct prestera_acl_block_binding {
-	struct list_head list;
-	struct mvsw_pr_port *port;
-};
 
 struct prestera_acl_ruleset {
 	struct rhashtable rule_ht;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	u16 id;
 };
 
-struct prestera_acl_block {
-	struct list_head binding_list;
-	struct mvsw_pr_switch *sw;
-	unsigned int rule_count;
-	unsigned int disable_count;
-	struct net *net;
-	struct prestera_acl_ruleset *ruleset;
-};
-
-struct prestera_acl_rule {
-	struct rhash_head ht_node; /* Member of acl HT */
-	struct list_head list;
-	struct list_head match_list;
-	struct list_head action_list;
-	struct prestera_acl_block *block;
-	unsigned long cookie;
-	u32 priority;
-	u8 n_actions;
-	u8 hw_tc;
-	u32 id;
-};
-
 static const struct rhashtable_params prestera_acl_rule_ht_params = {
 	.key_len = sizeof(unsigned long),
 	.key_offset = offsetof(struct prestera_acl_rule, cookie),
@@ -55,8 +25,59 @@ static const struct rhashtable_params prestera_acl_rule_ht_params = {
 	.automatic_shrinking = true,
 };
 
+struct prestera_acl_nat_port *
+prestera_acl_nat_port_get(struct prestera_acl *acl, u32 port_hw_id,
+			  u32 port_dev_id)
+{
+	struct prestera_acl_nat_port *nat_port;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &acl->nat_port_list) {
+		nat_port = list_entry(pos, typeof(*nat_port), list);
+		if (nat_port->port->hw_id == port_hw_id &&
+		    nat_port->port->dev_id == port_dev_id) {
+			refcount_inc(&nat_port->refcount);
+			return nat_port;
+		}
+	}
+
+	return NULL;
+}
+
+void prestera_acl_nat_port_put(struct prestera_acl_nat_port *nat_port)
+{
+	if (!refcount_dec_and_test(&nat_port->refcount))
+		return;
+
+	list_del(&nat_port->list);
+	kfree(nat_port);
+}
+
+struct prestera_port *
+prestera_acl_nat_port_to_port(struct prestera_acl_nat_port *nat_port)
+{
+	return nat_port->port;
+}
+
+static struct prestera_acl_nat_port *
+prestera_acl_nat_port_create(struct prestera_acl *acl,
+			     struct prestera_port *port)
+{
+	struct prestera_acl_nat_port *nat_port;
+
+	nat_port = kzalloc(sizeof(*nat_port), GFP_KERNEL);
+	if (!nat_port)
+		return ERR_PTR(-ENOMEM);
+
+	nat_port->port = port;
+	refcount_set(&nat_port->refcount, 1);
+	list_add(&nat_port->list, &acl->nat_port_list);
+
+	return nat_port;
+}
+
 static struct prestera_acl_ruleset *
-prestera_acl_ruleset_create(struct mvsw_pr_switch *sw)
+prestera_acl_ruleset_create(struct prestera_switch *sw)
 {
 	int err;
 	struct prestera_acl_ruleset *ruleset;
@@ -91,10 +112,27 @@ static void prestera_acl_ruleset_destroy(struct prestera_acl_ruleset *ruleset)
 	kfree(ruleset);
 }
 
-struct prestera_acl_block *
-prestera_acl_block_create(struct mvsw_pr_switch *sw, struct net *net)
+void prestera_acl_block_prio_update(struct prestera_switch *sw,
+				    struct prestera_flow_block *block)
+{
+	struct prestera_acl *acl = sw->acl;
+	struct prestera_acl_rule *rule;
+	u32 new_prio = UINT_MAX;
+	u32 prio;
+
+	list_for_each_entry(rule, &acl->rules, list) {
+		prio = prestera_acl_rule_priority_get(rule);
+		if (prio < new_prio)
+			new_prio = prio;
+	}
+
+	block->flower_min_prio = new_prio;
+}
+
+struct prestera_flow_block *
+prestera_acl_block_create(struct prestera_switch *sw, struct net *net)
 {
-	struct prestera_acl_block *block;
+	struct prestera_flow_block *block;
 
 	block = kzalloc(sizeof(*block), GFP_KERNEL);
 	if (!block)
@@ -102,6 +140,8 @@ prestera_acl_block_create(struct mvsw_pr_switch *sw, struct net *net)
 	INIT_LIST_HEAD(&block->binding_list);
 	block->net = net;
 	block->sw = sw;
+	block->mall_prio = UINT_MAX;
+	block->flower_min_prio = UINT_MAX;
 
 	block->ruleset = prestera_acl_ruleset_create(sw);
 	if (IS_ERR(block->ruleset)) {
@@ -112,18 +152,18 @@ prestera_acl_block_create(struct mvsw_pr_switch *sw, struct net *net)
 	return block;
 }
 
-void prestera_acl_block_destroy(struct prestera_acl_block *block)
+void prestera_acl_block_destroy(struct prestera_flow_block *block)
 {
 	prestera_acl_ruleset_destroy(block->ruleset);
 	WARN_ON(!list_empty(&block->binding_list));
 	kfree(block);
 }
 
-static struct prestera_acl_block_binding *
-prestera_acl_block_lookup(struct prestera_acl_block *block,
-			  struct mvsw_pr_port *port)
+static struct prestera_flow_block_binding *
+prestera_acl_block_lookup(struct prestera_flow_block *block,
+			  struct prestera_port *port)
 {
-	struct prestera_acl_block_binding *binding;
+	struct prestera_flow_block_binding *binding;
 
 	list_for_each_entry(binding, &block->binding_list, list)
 		if (binding->port == port)
@@ -132,33 +172,33 @@ prestera_acl_block_lookup(struct prestera_acl_block *block,
 	return NULL;
 }
 
-unsigned int prestera_acl_block_rule_count(struct prestera_acl_block *block)
+unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block)
 {
 	return block ? block->rule_count : 0;
 }
 
-void prestera_acl_block_disable_inc(struct prestera_acl_block *block)
+void prestera_acl_block_disable_inc(struct prestera_flow_block *block)
 {
 	if (block)
 		block->disable_count++;
 }
 
-void prestera_acl_block_disable_dec(struct prestera_acl_block *block)
+void prestera_acl_block_disable_dec(struct prestera_flow_block *block)
 {
 	if (block)
 		block->disable_count--;
 }
 
-bool prestera_acl_block_disabled(const struct prestera_acl_block *block)
+bool prestera_acl_block_disabled(const struct prestera_flow_block *block)
 {
 	return block->disable_count;
 }
 
-int prestera_acl_block_bind(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
-			    struct mvsw_pr_port *port)
+int prestera_acl_block_bind(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
+			    struct prestera_port *port)
 {
-	struct prestera_acl_block_binding *binding;
+	struct prestera_flow_block_binding *binding;
 	int err;
 
 	if (WARN_ON(prestera_acl_block_lookup(block, port)))
@@ -167,6 +207,7 @@ int prestera_acl_block_bind(struct mvsw_pr_switch *sw,
 	binding = kzalloc(sizeof(*binding), GFP_KERNEL);
 	if (!binding)
 		return -ENOMEM;
+	binding->span_id = PRESTERA_SPAN_INVALID_ID;
 	binding->port = port;
 
 	err = mvsw_pr_hw_acl_port_bind(port, block->ruleset->id);
@@ -181,11 +222,11 @@ int prestera_acl_block_bind(struct mvsw_pr_switch *sw,
 	return err;
 }
 
-int prestera_acl_block_unbind(struct mvsw_pr_switch *sw,
-			      struct prestera_acl_block *block,
-			      struct mvsw_pr_port *port)
+int prestera_acl_block_unbind(struct prestera_switch *sw,
+			      struct prestera_flow_block *block,
+			      struct prestera_port *port)
 {
-	struct prestera_acl_block_binding *binding;
+	struct prestera_flow_block_binding *binding;
 
 	binding = prestera_acl_block_lookup(block, port);
 	if (!binding)
@@ -200,7 +241,7 @@ int prestera_acl_block_unbind(struct mvsw_pr_switch *sw,
 }
 
 struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_acl_block *block)
+prestera_acl_block_ruleset_get(struct prestera_flow_block *block)
 {
 	return block->ruleset;
 }
@@ -210,12 +251,12 @@ u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule)
 	return rule->block->ruleset->id;
 }
 
-struct net *prestera_acl_block_net(struct prestera_acl_block *block)
+struct net *prestera_acl_block_net(struct prestera_flow_block *block)
 {
 	return block->net;
 }
 
-struct mvsw_pr_switch *prestera_acl_block_sw(struct prestera_acl_block *block)
+struct prestera_switch *prestera_acl_block_sw(struct prestera_flow_block *block)
 {
 	return block->sw;
 }
@@ -229,8 +270,8 @@ prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
 }
 
 struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_acl_block *block,
-			 unsigned long cookie)
+prestera_acl_rule_create(struct prestera_flow_block *block,
+			 unsigned long cookie, u32 chain_index)
 {
 	struct prestera_acl_rule *rule;
 
@@ -242,7 +283,8 @@ prestera_acl_rule_create(struct prestera_acl_block *block,
 	INIT_LIST_HEAD(&rule->action_list);
 	rule->cookie = cookie;
 	rule->block = block;
-	rule->hw_tc = MVSW_ACL_RULE_DEF_HW_TC;
+	rule->chain_index = chain_index;
+	rule->hw_tc = PRESTERA_ACL_RULE_DEF_HW_TC;
 
 	return rule;
 }
@@ -253,17 +295,40 @@ prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule)
 	return &rule->match_list;
 }
 
+static struct prestera_acl_rule_action_entry *
+prestera_acl_rule_action_lookup(struct prestera_acl_rule *rule,
+				enum prestera_acl_rule_action action)
+{
+	struct prestera_acl_rule_action_entry *a_entry;
+
+	list_for_each_entry(a_entry, &rule->action_list, list)
+		if (a_entry->info.id == action)
+			return a_entry;
+
+	return NULL;
+}
+
 struct list_head *
 prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule)
 {
 	return &rule->action_list;
 }
 
-void prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				  struct prestera_acl_rule_action_entry *entry)
+int prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
+				 struct prestera_acl_rule_action_entry *entry)
 {
-	list_add(&entry->list, &rule->action_list);
+	struct prestera_acl_rule_action_entry *a_entry;
+
+	a_entry = kmalloc(sizeof(*a_entry), GFP_KERNEL);
+	if (!a_entry)
+		return -ENOMEM;
+
+	memcpy(a_entry, entry, sizeof(*entry));
+	list_add(&a_entry->list, &rule->action_list);
+	a_entry->rule = rule;
+
 	rule->n_actions++;
+	return 0;
 }
 
 u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule)
@@ -271,6 +336,19 @@ u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule)
 	return rule->n_actions;
 }
 
+void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
+				unsigned long flag)
+{
+	set_bit(flag, &rule->attr.flags);
+}
+
+bool
+prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
+			    unsigned long flag)
+{
+	return test_bit(flag, &rule->attr.flags);
+}
+
 u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule)
 {
 	return rule->priority;
@@ -291,11 +369,49 @@ void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc)
 {
 	rule->hw_tc = hw_tc;
 }
-
 void prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
 				 struct prestera_acl_rule_match_entry *entry)
 {
 	list_add(&entry->list, &rule->match_list);
+	rule->n_matches++;
+}
+
+u8 prestera_acl_rule_match_len(struct prestera_acl_rule *rule)
+{
+	return rule->n_matches;
+}
+
+u32 prestera_acl_rule_chain_get(struct prestera_acl_rule *rule)
+{
+	/* TODO: chain (rule->chain_index) is not supported for user now */
+	return 0;
+}
+
+static int prestera_acl_nat_port_neigh_lookup(struct prestera_port *port,
+					      struct mvsw_pr_neigh_info *ni)
+{
+	struct mvsw_pr_kern_neigh_cache *n_cache;
+	struct mvsw_pr_neigh_info *n_info;
+	struct rhashtable_iter iter;
+	int err = -ENOENT;
+
+	rhashtable_walk_enter(&port->sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while ((n_cache = rhashtable_walk_next(&iter)) != NULL) {
+		if (IS_ERR(n_cache))
+			continue;
+		n_info = prestera_kern_neigh_cache_to_neigh_info(n_cache);
+		if (n_info->iface.type == MVSW_IF_PORT_E &&
+		    n_info->iface.dev_port.port_num == port->hw_id &&
+		    n_info->iface.dev_port.hw_dev_num == port->dev_id) {
+			memcpy(ni, n_info, sizeof(*n_info));
+			err = 0;
+			break;
+		}
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+	return err;
 }
 
 void prestera_acl_rule_destroy(struct prestera_acl_rule *rule)
@@ -314,14 +430,24 @@ void prestera_acl_rule_destroy(struct prestera_acl_rule *rule)
 		list_del(pos);
 		kfree(a_entry);
 	}
+	if (rule->nat_port)
+		prestera_acl_nat_port_put(rule->nat_port);
 	kfree(rule);
 }
 
-int prestera_acl_rule_add(struct mvsw_pr_switch *sw,
+int prestera_acl_rule_add(struct prestera_switch *sw,
 			  struct prestera_acl_rule *rule)
 {
 	int err;
 	u32 rule_id;
+	struct prestera_acl_hw_match_info *matches = NULL;
+	struct prestera_acl_hw_action_info *actions = NULL;
+	struct prestera_flow_block_binding *binding;
+	struct prestera_acl_nat_port *nat_port;
+	struct mvsw_pr_neigh_info n_info;
+	u8 n_matches, n_actions, i;
+	struct prestera_acl_rule_action_entry *a_entry;
+	struct prestera_acl_rule_match_entry *m_entry;
 
 	/* try to add rule to hash table first */
 	err = rhashtable_insert_fast(&rule->block->ruleset->rule_ht,
@@ -330,35 +456,121 @@ int prestera_acl_rule_add(struct mvsw_pr_switch *sw,
 	if (err)
 		return err;
 
-	/* add rule to hw */
-	err = mvsw_pr_hw_acl_rule_add(sw, rule, &rule_id);
+	if (rule_flag_test(rule, CT)) {
+		err = prestera_ct_ft_offload_add_cb(sw, rule);
+		if (err)
+			goto err_rule_add;
+
+		goto hw_handled;
+	}
+
+	if (rule_flag_test(rule, GOTO))
+		goto err_rule_add;
+
+	n_actions = prestera_acl_rule_action_len(rule);
+	n_matches = prestera_acl_rule_match_len(rule);
+	matches = kcalloc(n_matches, sizeof(*matches), GFP_KERNEL);
+	actions = kcalloc(n_actions, sizeof(*actions), GFP_KERNEL);
+	if (!matches || !actions)
+		goto err_rule_add;
+
+	i = 0;
+	list_for_each_entry(m_entry, prestera_acl_rule_match_list_get(rule),
+			    list) {
+		matches[i] = m_entry->info;
+		i++;
+	}
+
+	i = 0;
+	list_for_each_entry(a_entry, prestera_acl_rule_action_list_get(rule),
+			    list) {
+		actions[i] = a_entry->info;
+		i++;
+	}
+
+	err = mvsw_pr_hw_acl_rule_add(sw,
+				      prestera_acl_rule_ruleset_id_get(rule),
+				      prestera_acl_rule_chain_get(rule),
+				      prestera_acl_rule_priority_get(rule),
+				      prestera_acl_rule_hw_tc_get(rule),
+				      n_matches, matches, n_actions, actions,
+				      &rule_id);
 	if (err)
 		goto err_rule_add;
 
 	rule->id = rule_id;
 
+	if (!prestera_acl_rule_action_lookup
+	    (rule, MVSW_ACL_RULE_ACTION_NAT))
+		goto nat_port_neigh_not_found;
+
+	/* TODO: assign port to NAT here instead of doing this in
+	 * flower action.
+	 *
+	 * Get first interface bound to the block same as
+	 * in NAT action for now
+	 */
+	binding = list_first_entry(&rule->block->binding_list,
+				   struct prestera_flow_block_binding, list);
+	nat_port = prestera_acl_nat_port_get(sw->acl, binding->port->hw_id,
+					     binding->port->dev_id);
+	if (!nat_port) {
+		nat_port = prestera_acl_nat_port_create(sw->acl, binding->port);
+		MVSW_LOG_INFO("NAT port created");
+		if (!nat_port)
+			goto err_rule_add_nat;
+	}
+	rule->nat_port = nat_port;
+
+	/* try to lookup neigh for this port and update HW */
+	err = prestera_acl_nat_port_neigh_lookup(nat_port->port, &n_info);
+	if (err == -ENOENT) {
+		MVSW_LOG_INFO("Neighbour for NAT port not found");
+		goto nat_port_neigh_not_found;
+	}
+	if (err)
+		goto err_rule_add_nat;
+
+	MVSW_LOG_INFO("Found a neighbour for NAT port");
+	err = prestera_hw_nat_port_neigh_update(nat_port->port, n_info.ha);
+	if (err)
+		goto err_rule_add_nat;
+
+hw_handled:
+nat_port_neigh_not_found:
 	list_add_tail(&rule->list, &sw->acl->rules);
 	rule->block->rule_count++;
 
 	return 0;
 
+err_rule_add_nat:
+	mvsw_pr_hw_acl_rule_del(sw, rule->chain_index, rule->id);
 err_rule_add:
+	kfree(matches);
+	kfree(actions);
 	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
 	return err;
 }
 
-void prestera_acl_rule_del(struct mvsw_pr_switch *sw,
+void prestera_acl_rule_del(struct prestera_switch *sw,
 			   struct prestera_acl_rule *rule)
 {
 	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
 	rule->block->rule_count--;
 	list_del(&rule->list);
-	mvsw_pr_hw_acl_rule_del(sw, rule->id);
+
+	if (rule_flag_test(rule, CT)) {
+		prestera_ct_ft_offload_del_cb(sw, rule);
+	} else {
+		/* TODO: use prestera_acl_rule_chain_get ? */
+		mvsw_pr_hw_acl_rule_del(sw, rule->chain_index, rule->id);
+		prestera_acl_block_prio_update(sw, rule->block);
+	}
 }
 
-int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
+int prestera_acl_rule_get_stats(struct prestera_switch *sw,
 				struct prestera_acl_rule *rule,
 				u64 *packets, u64 *bytes, u64 *last_use)
 {
@@ -366,6 +578,13 @@ int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
 	u64 current_bytes;
 	int err;
 
+	if (rule_flag_test(rule, CT)) {
+		*last_use = jiffies;
+		*packets = 0;
+		*bytes = 0;
+		return 0;
+	}
+
 	err = mvsw_pr_hw_acl_rule_stats_get(sw, rule->id, &current_packets,
 					    &current_bytes);
 	if (err)
@@ -378,7 +597,7 @@ int prestera_acl_rule_get_stats(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-int prestera_acl_init(struct mvsw_pr_switch *sw)
+int prestera_acl_init(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl;
 
@@ -386,17 +605,26 @@ int prestera_acl_init(struct mvsw_pr_switch *sw)
 	if (!acl)
 		return -ENOMEM;
 
+	acl->ct_priv = prestera_ct_init(sw);
+	if (IS_ERR(acl->ct_priv)) {
+		kfree(acl);
+		return PTR_ERR(acl->ct_priv);
+	}
+
 	INIT_LIST_HEAD(&acl->rules);
+	INIT_LIST_HEAD(&acl->nat_port_list);
 	sw->acl = acl;
 	acl->sw = sw;
 
 	return 0;
 }
 
-void prestera_acl_fini(struct mvsw_pr_switch *sw)
+void prestera_acl_fini(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl = sw->acl;
 
+	WARN_ON(!list_empty(&acl->nat_port_list));
 	WARN_ON(!list_empty(&acl->rules));
+	prestera_ct_clean(acl->ct_priv);
 	kfree(acl);
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.h b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
new file mode 100644
index 0000000..a76ae1e
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
@@ -0,0 +1,67 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+ *
+ * Copyright (c) 2021 Marvell International Ltd. All rights reserved.
+ *
+ */
+
+#ifndef _PRESTERA_ACL_H_
+#define _PRESTERA_ACL_H_
+
+#include <linux/types.h>
+
+#define PRESTERA_ACL_RULE_DEF_HW_TC		3
+#define PRESTERA_ACL_RULE_DEF_HW_CHAIN_ID	0
+#define PRESTERA_ACL_RULESET_ALL		0xff
+
+#define rule_flag_set(rule, flag) \
+	prestera_acl_rule_flag_set(rule, PRESTERA_ACL_RULE_FLAG_##flag)
+#define rule_flag_test(rule, flag) \
+	prestera_acl_rule_flag_test(rule, PRESTERA_ACL_RULE_FLAG_##flag)
+
+enum {
+	PRESTERA_ACL_RULE_FLAG_CT,
+	PRESTERA_ACL_RULE_FLAG_GOTO
+};
+
+struct prestera_acl {
+	struct prestera_switch *sw;
+	struct list_head nat_port_list;
+	struct list_head rules;
+	struct prestera_ct_priv *ct_priv;
+};
+
+struct prestera_acl_nat_port {
+	struct list_head list;
+	struct prestera_port *port;
+	refcount_t refcount;
+};
+
+struct prestera_acl_rule_attr {
+	struct prestera_ct_attr ct_attr;
+	unsigned long flags;
+};
+
+struct prestera_acl_rule {
+	struct rhash_head ht_node; /* Member of acl HT */
+	struct list_head list;
+	struct list_head match_list;
+	struct list_head action_list;
+	struct prestera_flow_block *block;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_acl_rule_attr attr;
+	unsigned long cookie;
+	u32 chain_index;
+	u32 priority;
+	u8 n_actions;
+	u8 n_matches;
+	u8 hw_tc;
+	u32 id;
+};
+
+void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
+				unsigned long flag);
+bool
+prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
+			    unsigned long flag);
+
+#endif /* _PRESTERA_ACL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.c b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
new file mode 100644
index 0000000..ea05aae
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
@@ -0,0 +1,687 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+//
+// Copyright (c) 2021 Marvell International Ltd. All rights reserved.
+//
+
+#include <linux/rhashtable.h>
+#include <net/netfilter/nf_flow_table.h>
+#include <net/tc_act/tc_ct.h>
+#include <linux/bitops.h>
+
+#include "prestera.h"
+#include "prestera_log.h"
+#include "prestera_hw.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
+
+#define PRESTERA_ACL_CT_CHAIN 1
+#define PRESTERA_ACL_CT_TRAP_PRIO 0xfffffffe
+#define PRESTERA_ACL_CT_MATCHES 4
+
+enum mangle_act_mask {
+	MANGLE_ACT_IP4_SRC_BIT = BIT(0),
+	MANGLE_ACT_IP4_DST_BIT = BIT(1),
+	MANGLE_ACT_PORT_SRC_BIT = BIT(2),
+	MANGLE_ACT_PORT_DST_BIT = BIT(3)
+};
+
+struct prestera_ct_tuple {
+	u16 zone;
+	u16 ruleset;
+	u32 prio;
+	u8 n_matches;
+	struct prestera_acl_hw_match_info match[PRESTERA_ACL_CT_MATCHES];
+	struct prestera_acl_hw_action_info act;
+	u32 rule_id;
+};
+
+struct prestera_ct_priv {
+	struct prestera_switch *sw;
+	struct rhashtable zone_ht;
+	u32 trap_hw_rule_id;
+	u32 access_hw_rule_id;
+};
+
+struct prestera_ct_entry {
+	struct rhash_head node;
+	unsigned long cookie;
+	struct prestera_ct_tuple tuple;
+};
+
+struct prestera_ct_ft {
+	struct rhash_head node;
+	u16 zone;
+	struct net *net;
+	refcount_t refcount;
+	struct prestera_ct_priv *ct_priv;
+	struct nf_flowtable *nf_ft;
+	struct rhashtable ct_entries_ht;
+};
+
+static const struct rhashtable_params ct_entry_ht_params = {
+	.head_offset = offsetof(struct prestera_ct_entry, node),
+	.key_offset = offsetof(struct prestera_ct_entry, cookie),
+	.key_len = sizeof(((struct prestera_ct_entry *)0)->cookie),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params ct_zone_ht_params = {
+	.head_offset = offsetof(struct prestera_ct_ft, node),
+	.key_offset = offsetof(struct prestera_ct_ft, zone),
+	.key_len = sizeof(((struct prestera_ct_ft *)0)->zone),
+	.automatic_shrinking = true,
+};
+
+static int __prestera_ct_hw_chain_init(struct prestera_ct_priv *priv)
+{
+	int err;
+	struct prestera_acl_hw_action_info action_info;
+
+	action_info.id = MVSW_ACL_RULE_ACTION_TRAP;
+	err = mvsw_pr_hw_acl_rule_add(priv->sw, PRESTERA_ACL_RULESET_ALL,
+				      PRESTERA_ACL_CT_CHAIN,
+				      PRESTERA_ACL_CT_TRAP_PRIO,
+				      PRESTERA_ACL_RULE_DEF_HW_TC,
+				      0, NULL, 1, &action_info,
+				      &priv->trap_hw_rule_id);
+	if (err)
+		goto err_hw_acl_add_trap;
+
+	action_info.id = MVSW_ACL_RULE_ACTION_ACCEPT;
+	err = mvsw_pr_hw_acl_rule_add(priv->sw, PRESTERA_ACL_RULESET_ALL,
+				      0, PRESTERA_ACL_CT_TRAP_PRIO,
+				      PRESTERA_ACL_RULE_DEF_HW_TC,
+				      0, NULL, 1, &action_info,
+				      &priv->access_hw_rule_id);
+	if (err)
+		goto err_hw_acl_add_access;
+
+	return 0;
+
+err_hw_acl_add_access:
+	mvsw_pr_hw_acl_rule_del(priv->sw, PRESTERA_ACL_CT_CHAIN,
+				priv->trap_hw_rule_id);
+err_hw_acl_add_trap:
+	return -EINVAL;
+}
+
+struct prestera_ct_priv *prestera_ct_init(struct prestera_switch *sw)
+{
+	struct prestera_ct_priv *ct_priv;
+
+	ct_priv = kzalloc(sizeof(*ct_priv), GFP_KERNEL);
+	if (!ct_priv)
+		return ERR_PTR(-ENOMEM);
+
+	rhashtable_init(&ct_priv->zone_ht, &ct_zone_ht_params);
+	ct_priv->sw = sw;
+
+	if (__prestera_ct_hw_chain_init(ct_priv))
+		return ERR_PTR(-EINVAL);
+
+	return ct_priv;
+}
+
+void prestera_ct_clean(struct prestera_ct_priv *ct_priv)
+{
+	if (!ct_priv)
+		return;
+
+	rhashtable_destroy(&ct_priv->zone_ht);
+	kfree(ct_priv);
+}
+
+int prestera_ct_match_parse(struct flow_cls_offload *f,
+			    struct netlink_ext_ack *extack)
+{
+	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
+	struct flow_dissector_key_ct *mask, *key;
+	bool trk, est, untrk, unest, new;
+	u16 ct_state_on, ct_state_off;
+	u16 ct_state, ct_state_mask;
+	struct flow_match_ct match;
+
+	if (!flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_CT))
+		return 0;
+
+	flow_rule_match_ct(f_rule, &match);
+
+	key = match.key;
+	mask = match.mask;
+
+	ct_state = key->ct_state;
+	ct_state_mask = mask->ct_state;
+
+	if (ct_state_mask & ~(TCA_FLOWER_KEY_CT_FLAGS_TRACKED |
+			      TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED |
+			      TCA_FLOWER_KEY_CT_FLAGS_NEW)) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "only ct_state trk, est and new are supported for offload");
+		return -EOPNOTSUPP;
+	}
+
+	ct_state_on = ct_state & ct_state_mask;
+	ct_state_off = (ct_state & ct_state_mask) ^ ct_state_mask;
+
+	trk = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	new = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_NEW;
+	est = ct_state_on & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+
+	untrk = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_TRACKED;
+	unest = ct_state_off & TCA_FLOWER_KEY_CT_FLAGS_ESTABLISHED;
+
+	MVSW_LOG_INFO("trk=%d new=%d est=%d untrk=%d unest=%d",
+		      trk, new, est, untrk, unest);
+
+	if (new) {
+		NL_SET_ERR_MSG_MOD(extack,
+				   "matching on ct_state +new isn't supported");
+		return -EOPNOTSUPP;
+	}
+
+	return 0;
+}
+
+int prestera_ct_parse_action(const struct flow_action_entry *act,
+			     struct prestera_acl_rule *rule,
+			     struct netlink_ext_ack *extack)
+
+{
+	struct prestera_ct_attr *ct_attr;
+
+	ct_attr = &rule->attr.ct_attr;
+
+	ct_attr->zone = act->ct.zone;
+	ct_attr->ct_action = act->ct.action;
+	ct_attr->nf_ft = act->ct.flow_table;
+
+	return 0;
+}
+
+static struct flow_action_entry *
+prestera_ct_get_ct_metadata_action(struct flow_rule *flow_rule)
+{
+	struct flow_action *flow_action = &flow_rule->action;
+	struct flow_action_entry *act;
+	int i;
+
+	flow_action_for_each(i, act, flow_action) {
+		if (act->id == FLOW_ACTION_CT_METADATA)
+			return act;
+	}
+
+	return NULL;
+}
+
+static int
+prestera_ct_flow_rule_to_tuple(struct flow_rule *rule, struct net *net,
+			       struct prestera_ct_tuple *tuple)
+{
+	struct flow_match_ipv4_addrs ipv4_match;
+	struct flow_match_ports ports_match;
+	struct flow_match_control control;
+	struct flow_match_basic basic;
+	u16 addr_type;
+	u8 ip_proto;
+
+	flow_rule_match_basic(rule, &basic);
+	flow_rule_match_control(rule, &control);
+
+	ip_proto = basic.key->ip_proto;
+	addr_type = control.key->addr_type;
+
+	if (addr_type != FLOW_DISSECTOR_KEY_IPV4_ADDRS)
+		return -EOPNOTSUPP;
+
+	flow_rule_match_ipv4_addrs(rule, &ipv4_match);
+	tuple->match[0].type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC;
+	tuple->match[0].u32.mask = -1;
+	memcpy(&tuple->match[0].u32.key, &ipv4_match.key->src, sizeof(u32));
+	/* Match 1 must be dst ! */
+	tuple->match[1].type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST;
+	tuple->match[1].u32.mask = -1;
+	memcpy(&tuple->match[1].u32.key, &ipv4_match.key->dst, sizeof(u32));
+	tuple->n_matches = 2;
+
+	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS))
+		return -EOPNOTSUPP;
+
+	flow_rule_match_ports(rule, &ports_match);
+	switch (ip_proto) {
+	case IPPROTO_TCP:
+	case IPPROTO_UDP:
+		tuple->match[2].type =
+			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC;
+		tuple->match[2].u16.mask = -1;
+		tuple->match[2].u16.key = ntohs(ports_match.key->src);
+		tuple->match[3].type =
+			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST;
+		tuple->match[3].u16.mask = -1;
+		tuple->match[3].u16.key = ntohs(ports_match.key->dst);
+		tuple->n_matches = 4;
+		break;
+	default:
+		return -EOPNOTSUPP;
+	}
+
+	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_META))
+		return -EOPNOTSUPP;
+
+	/* metadata match is set but not information is present.
+	 * Issue? Need to investigate on kernel side.
+	 */
+	return 0;
+}
+
+static int
+prestera_ct_flow_rule_to_tuple_nat(struct flow_rule *rule,
+				   struct prestera_ct_tuple *tuple)
+{
+	struct flow_action *flow_action = &rule->action;
+	struct flow_action_entry *act;
+	u32 offset, val;
+	int i;
+
+	tuple->act.id = MVSW_ACL_RULE_ACTION_MANGLE;
+	flow_action_for_each(i, act, flow_action) {
+		if (act->id != FLOW_ACTION_MANGLE)
+			continue;
+
+		offset = act->mangle.offset;
+		val = act->mangle.val;
+		switch (act->mangle.htype) {
+		case FLOW_ACT_MANGLE_HDR_TYPE_IP4:
+			if (offset == offsetof(struct iphdr, saddr)) {
+				tuple->act.mangle.sip.u.ipv4 = cpu_to_be32(val);
+				tuple->act.mangle.sip_valid = true;
+			} else if (offset == offsetof(struct iphdr, daddr)) {
+				tuple->act.mangle.dip.u.ipv4 = cpu_to_be32(val);
+				tuple->act.mangle.dip_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		case FLOW_ACT_MANGLE_HDR_TYPE_TCP:
+			if (offset == offsetof(struct tcphdr, source)) {
+				tuple->act.mangle.l4_src = cpu_to_be16(val);
+				tuple->act.mangle.l4_src_valid = true;
+			} else if (offset == offsetof(struct tcphdr, dest)) {
+				tuple->act.mangle.l4_dst = cpu_to_be16(val);
+				tuple->act.mangle.l4_dst_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		case FLOW_ACT_MANGLE_HDR_TYPE_UDP:
+			if (offset == offsetof(struct udphdr, source)) {
+				tuple->act.mangle.l4_src = cpu_to_be16(val);
+				tuple->act.mangle.l4_src_valid = true;
+			} else if (offset == offsetof(struct udphdr, dest)) {
+				tuple->act.mangle.l4_dst = cpu_to_be16(val);
+				tuple->act.mangle.l4_dst_valid = true;
+			} else {
+				return -EOPNOTSUPP;
+			}
+			break;
+		default:
+			return -EOPNOTSUPP;
+		}
+	}
+
+	return 0;
+}
+
+static int __prestera_ct_tuple_get_nh(struct prestera_switch *sw,
+				      struct prestera_ct_tuple *tuple)
+{
+	struct mvsw_pr_ip_addr ip;
+	struct mvsw_pr_nexthop_group_key nh_grp_key;
+	struct mvsw_pr_nh_neigh *n;
+
+	/* Match 1 must be dst ! See prestera_ct_flow_rule_to_tuple() */
+	memset(&ip, 0, sizeof(ip));
+	memcpy(&ip.u.ipv4,
+	       tuple->act.mangle.sip_valid ?
+	       (void *)&tuple->match[1].u32.key :
+	       (void *)&tuple->act.mangle.dip.u.ipv4,
+	       sizeof(ip.u.ipv4));
+
+	/* TODO: VRF */
+	/* TODO: ECMP */
+	if (prestera_util_kern_dip2nh_grp_key(sw, RT_TABLE_MAIN, &ip,
+					      &nh_grp_key) != 1)
+		return -ENOTSUPP;
+
+	n = mvsw_pr_nh_neigh_find(sw, &nh_grp_key.neigh[0]);
+	if (!n) {
+		memset(&tuple->act.mangle.n, 0, sizeof(tuple->act.mangle.n));
+		return 0;
+	}
+
+	tuple->act.mangle.n = n->info;
+
+	return 0;
+}
+
+static int __prestera_ct_tuple2acl_add(struct prestera_switch *sw,
+				       struct prestera_ct_tuple *tuple)
+{
+	return mvsw_pr_hw_acl_rule_add(sw,
+				       tuple->ruleset,
+				       PRESTERA_ACL_CT_CHAIN,
+				       tuple->prio,
+				       PRESTERA_ACL_RULE_DEF_HW_TC,
+				       tuple->n_matches, &tuple->match[0], 1,
+				       &tuple->act, &tuple->rule_id);
+}
+
+static int
+prestera_ct_block_flow_offload_add(struct prestera_ct_ft *ft,
+				   struct flow_cls_offload *flow)
+{
+	struct flow_rule *flow_rule = flow_cls_offload_flow_rule(flow);
+	struct flow_action_entry *meta_action;
+	unsigned long cookie = flow->cookie;
+	struct prestera_ct_entry *entry;
+	int err;
+
+	meta_action = prestera_ct_get_ct_metadata_action(flow_rule);
+	if (!meta_action)
+		return -EOPNOTSUPP;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (entry)
+		return 0;
+
+	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+	if (!entry)
+		return -ENOMEM;
+
+	entry->tuple.zone = ft->zone;
+	entry->cookie = flow->cookie;
+	entry->tuple.prio = flow->common.prio;
+	/* Match everyting for CT lookup. FIXME */
+	entry->tuple.ruleset = PRESTERA_ACL_RULESET_ALL;
+
+	err = prestera_ct_flow_rule_to_tuple(flow_rule, ft->net, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	err = prestera_ct_flow_rule_to_tuple_nat(flow_rule, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	err = __prestera_ct_tuple_get_nh(ft->ct_priv->sw, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	/* HW offload */
+	err = __prestera_ct_tuple2acl_add(ft->ct_priv->sw, &entry->tuple);
+	if (err)
+		goto err_set;
+
+	err = rhashtable_insert_fast(&ft->ct_entries_ht, &entry->node,
+				     ct_entry_ht_params);
+	if (err)
+		goto err_insert;
+
+	return 0;
+
+err_insert:
+	/* HW remove*/
+
+err_set:
+	kfree(entry);
+	return err;
+}
+
+static int
+prestera_ct_block_flow_offload_del(struct prestera_ct_ft *ft,
+				   struct flow_cls_offload *flow)
+{
+	int err;
+	unsigned long cookie = flow->cookie;
+	struct prestera_ct_entry *entry;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (!entry)
+		return -ENOENT;
+
+	err = mvsw_pr_hw_acl_rule_del(ft->ct_priv->sw, PRESTERA_ACL_CT_CHAIN,
+				      entry->tuple.rule_id);
+	if (err)
+		MVSW_LOG_ERROR("mvsw_pr_hw_acl_rule_del failed err = %d", err);
+
+	rhashtable_remove_fast(&ft->ct_entries_ht,
+			       &entry->node, ct_entry_ht_params);
+	kfree(entry);
+	return 0;
+}
+
+static void
+prestera_ct_flow_stats_query_cached(u64 *bytes, u64 *packets, u64 *lastuse)
+{
+	/* TODO: add HW stats instead */
+	*bytes = 128;
+	*packets = 1;
+	*lastuse = jiffies;
+}
+
+static int
+prestera_ct_block_flow_offload_stats(struct prestera_ct_ft *ft,
+				     struct flow_cls_offload *f)
+{
+	unsigned long cookie = f->cookie;
+	struct prestera_ct_entry *entry;
+	u64 lastuse, packets, bytes;
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (!entry)
+		return -ENOENT;
+
+	prestera_ct_flow_stats_query_cached(&bytes, &packets, &lastuse);
+	flow_stats_update(&f->stats, bytes, packets, 0, lastuse,
+			  FLOW_ACTION_HW_STATS_DELAYED);
+
+	return 0;
+}
+
+static int
+prestera_ct_block_flow_offload(enum tc_setup_type type, void *type_data,
+			       void *cb_priv)
+{
+	struct flow_cls_offload *f = type_data;
+	struct prestera_ct_ft *ft = cb_priv;
+
+	if (type != TC_SETUP_CLSFLOWER)
+		return -EOPNOTSUPP;
+
+	switch (f->command) {
+	case FLOW_CLS_REPLACE:
+		return prestera_ct_block_flow_offload_add(ft, f);
+	case FLOW_CLS_DESTROY:
+		return prestera_ct_block_flow_offload_del(ft, f);
+	case FLOW_CLS_STATS:
+		return prestera_ct_block_flow_offload_stats(ft, f);
+	default:
+		break;
+	}
+
+	return -EOPNOTSUPP;
+}
+
+static struct prestera_ct_ft *
+__prestera_ct_ft_offload_add_cb(struct prestera_ct_priv *ct_priv,
+				u16 zone, struct nf_flowtable *nf_ft,
+				struct net *net)
+{
+	struct prestera_ct_ft *ft;
+	int err;
+
+	ft = rhashtable_lookup_fast(&ct_priv->zone_ht, &zone,
+				    ct_zone_ht_params);
+	if (ft) {
+		refcount_inc(&ft->refcount);
+		return ft;
+	}
+
+	ft = kzalloc(sizeof(*ft), GFP_KERNEL);
+	if (!ft)
+		return ERR_PTR(-ENOMEM);
+
+	/* ft->net = read_pnet(&nf_ft->net); */
+	ft->net = net;
+	ft->zone = zone;
+	ft->nf_ft = nf_ft;
+	ft->ct_priv = ct_priv;
+	refcount_set(&ft->refcount, 1);
+
+	err = rhashtable_init(&ft->ct_entries_ht, &ct_entry_ht_params);
+	if (err)
+		goto err_init;
+
+	err = rhashtable_insert_fast(&ct_priv->zone_ht, &ft->node,
+				     ct_zone_ht_params);
+	if (err)
+		goto err_insert;
+
+	err = nf_flow_table_offload_add_cb(ft->nf_ft,
+					   prestera_ct_block_flow_offload, ft);
+	if (err)
+		goto err_add_cb;
+
+	return ft;
+
+err_add_cb:
+	rhashtable_remove_fast(&ct_priv->zone_ht, &ft->node, ct_zone_ht_params);
+err_insert:
+	rhashtable_destroy(&ft->ct_entries_ht);
+err_init:
+	kfree(ft);
+	return ERR_PTR(err);
+}
+
+/* Add gateway rule in def chain and add TRAP rule in CT chain */
+static int __prestera_ct_rule2gateway(struct prestera_switch *sw,
+				      struct prestera_acl_rule *rule)
+{
+	int err;
+	u8 n_matches, i;
+	struct prestera_acl_rule_match_entry *m_entry;
+	struct prestera_acl_hw_match_info *match_info;
+	struct prestera_acl_hw_action_info action_info;
+
+	n_matches = prestera_acl_rule_match_len(rule);
+	match_info = kcalloc(n_matches, sizeof(*match_info), GFP_KERNEL);
+	if (!match_info)
+		goto err_kzalloc_match;
+
+	i = 0;
+	list_for_each_entry(m_entry,
+			    prestera_acl_rule_match_list_get(rule),
+			    list) {
+		match_info[i] = m_entry->info;
+		i++;
+	}
+
+	action_info.id = MVSW_ACL_RULE_ACTION_JUMP;
+	action_info.jump.chain = PRESTERA_ACL_CT_CHAIN;
+
+	err = mvsw_pr_hw_acl_rule_add(sw,
+				      prestera_acl_rule_ruleset_id_get(rule),
+				      prestera_acl_rule_chain_get(rule),
+				      prestera_acl_rule_priority_get(rule),
+				      prestera_acl_rule_hw_tc_get(rule),
+				      n_matches, match_info, 1, &action_info,
+				      &rule->id);
+	if (err)
+		goto err_hw_acl_add_gw;
+
+	return 0;
+
+err_hw_acl_add_gw:
+	kfree(match_info);
+err_kzalloc_match:
+	return -EINVAL;
+}
+
+int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
+				  struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_attr *ct_attr;
+	struct prestera_ct_ft *ct_ft;
+	int err;
+
+	ct_attr = &rule->attr.ct_attr;
+
+	if (ct_attr->ct_action & TCA_CT_ACT_CLEAR)
+		return -EOPNOTSUPP;
+
+	ct_ft = __prestera_ct_ft_offload_add_cb(sw->acl->ct_priv, ct_attr->zone,
+						ct_attr->nf_ft,
+						rule->block->net);
+	if (IS_ERR(ct_ft))
+		return PTR_ERR(ct_ft);
+
+	err = __prestera_ct_rule2gateway(sw, rule);
+	if (err) {
+		prestera_ct_ft_offload_del_cb(sw, rule);
+		return err;
+	}
+
+	ct_attr->ft = ct_ft;
+	return 0;
+}
+
+static void
+prestera_ct_del_ft_entry(struct prestera_ct_priv *ct_priv,
+			 struct prestera_ct_entry *entry)
+{
+	int err;
+
+	err = mvsw_pr_hw_acl_rule_del(ct_priv->sw, PRESTERA_ACL_CT_CHAIN,
+				      entry->tuple.rule_id);
+	if (err)
+		MVSW_LOG_ERROR("mvsw_pr_hw_acl_rule_del failed err = %d", err);
+}
+
+static void prestera_ct_flush_ft_entry(void *ptr, void *arg)
+{
+	struct prestera_ct_priv *ct_priv = arg;
+	struct prestera_ct_entry *entry = ptr;
+
+	prestera_ct_del_ft_entry(ct_priv, entry);
+	kfree(entry);
+}
+
+void prestera_ct_ft_offload_del_cb(struct prestera_switch *sw,
+				   struct prestera_acl_rule *rule)
+{
+	struct prestera_ct_attr *ct_attr;
+	struct prestera_ct_ft *ft;
+	struct prestera_ct_priv *ct_priv;
+	int err;
+
+	ct_attr = &rule->attr.ct_attr;
+	ft = ct_attr->ft;
+	ct_priv = sw->acl->ct_priv;
+
+	err = mvsw_pr_hw_acl_rule_del(sw, prestera_acl_rule_chain_get(rule),
+				      rule->id);
+	if (err)
+		MVSW_LOG_ERROR("mvsw_pr_hw_acl_rule_del failed err = %d", err);
+
+	if (!refcount_dec_and_test(&ft->refcount))
+		return;
+
+	nf_flow_table_offload_del_cb(ft->nf_ft,
+				     prestera_ct_block_flow_offload, ft);
+	rhashtable_free_and_destroy(&ft->ct_entries_ht,
+				    prestera_ct_flush_ft_entry, ct_priv);
+	rhashtable_remove_fast(&ct_priv->zone_ht, &ft->node, ct_zone_ht_params);
+
+	kfree(ft);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.h b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
new file mode 100644
index 0000000..c86c9a4
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
@@ -0,0 +1,42 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+ *
+ * Copyright (c) 2021 Marvell International Ltd. All rights reserved.
+ *
+ */
+
+#ifndef _PRESTERA_CT_H_
+#define _PRESTERA_CT_H_
+
+#include <linux/types.h>
+#include <linux/netlink.h>
+#include <net/flow_offload.h>
+
+struct prestera_switch;
+struct prestera_ct_ft;
+struct prestera_ct_priv;
+
+struct prestera_ct_attr {
+	u16 zone;
+	u16 ct_action;
+	struct net *net;
+	struct prestera_ct_ft *ft;
+	struct nf_flowtable *nf_ft;
+};
+
+struct prestera_ct_priv *prestera_ct_init(struct prestera_switch *sw);
+void prestera_ct_clean(struct prestera_ct_priv *ct_priv);
+
+/* match & action */
+int prestera_ct_match_parse(struct flow_cls_offload *f,
+			    struct netlink_ext_ack *extack);
+int prestera_ct_parse_action(const struct flow_action_entry *act,
+			     struct prestera_acl_rule *rule,
+			     struct netlink_ext_ack *extack);
+
+/* flowtable */
+int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
+				  struct prestera_acl_rule *rule);
+void prestera_ct_ft_offload_del_cb(struct prestera_switch *sw,
+				   struct prestera_acl_rule *rule);
+
+#endif /* _PRESTERA_CT_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
index 1b4b855..8e4ae0b 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.c
@@ -13,148 +13,277 @@
 #include "prestera_log.h"
 #include "prestera_fw_log.h"
 #include "prestera_rxtx.h"
+#include "prestera_hw.h"
 
-#define DEBUGFS_ROOTDIR	"prestera"
+#define PRESTERA_DEBUGFS_ROOTDIR	"prestera"
 
-#define CPU_CODE_SUBDIR_NAME	"traps"
-#define CPU_CODE_MAX_BUF_SIZE	(MVSW_PR_RXTX_CPU_CODE_MAX_NUM * 32)
+#define CPU_CODE_HW_CNT_SUBDIR_NAME	"hw_counters"
+#define CPU_CODE_SW_CNT_SUBDIR_NAME	"sw_counters"
 
-static ssize_t cpu_code_stats_read(struct file *file,
-				   char __user *ubuf,
-				   size_t count, loff_t *ppos);
+#define CPU_CODE_CNT_SUBDIR_TRAP_NAME	"traps"
+#define CPU_CODE_CNT_SUBDIR_DROP_NAME	"drops"
 
-struct mvsw_pr_debugfs {
+#define CPU_CODE_CNT_BUF_MAX_SIZE	(MVSW_PR_RXTX_CPU_CODE_MAX_NUM * 32)
+
+static ssize_t prestera_cnt_read(struct file *file, char __user *ubuf,
+				 size_t count, loff_t *ppos);
+
+struct prestera_debugfs {
 	struct dentry *root_dir;
-	struct dentry *cpu_code_subdir;
-	const struct file_operations cpu_code_stats_fops;
-	char *cpu_code_stats_buf;
-	/* serialize access to cpu_code_stats_buf */
-	struct mutex cpu_code_stats_mtx;
+	const struct file_operations cpu_code_cnt_fops;
+	char *cpu_code_cnt_buf;
+	/* serialize access to cpu_code_cnt_buf */
+	struct mutex cpu_code_cnt_buf_mtx;
+	struct prestera_switch *sw;
 };
 
-static struct mvsw_pr_debugfs prestera_debugfs = {
-	.cpu_code_stats_fops = {
-		.read = cpu_code_stats_read,
+struct prestera_cpu_code_data {
+	union {
+		long data;
+		struct {
+			u16 cpu_code;
+			u8 cpu_code_cnt_type;
+		} __packed __aligned(4);
+	};
+} __packed __aligned(4);
+
+static struct prestera_debugfs prestera_debugfs = {
+	.cpu_code_cnt_fops = {
+		.read = prestera_cnt_read,
 		.open = simple_open,
 		.llseek = default_llseek,
 	},
 };
 
-int mvsw_pr_debugfs_init(struct mvsw_pr_switch *sw)
+enum {
+	CPU_CODE_CNT_TYPE_HW_DROP = PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP,
+	CPU_CODE_CNT_TYPE_HW_TRAP = PRESTERA_HW_CPU_CODE_CNT_TYPE_TRAP,
+	CPU_CODE_CNT_TYPE_SW_TRAP = CPU_CODE_CNT_TYPE_HW_TRAP + 1,
+};
+
+int prestera_debugfs_init(struct prestera_switch *sw)
 {
-	const struct file_operations *fops =
-		&prestera_debugfs.cpu_code_stats_fops;
+	struct prestera_debugfs *debugfs = &prestera_debugfs;
+	struct dentry *cpu_code_hw_cnt_trap_subdir;
+	struct dentry *cpu_code_hw_cnt_drop_subdir;
+	struct dentry *cpu_code_sw_cnt_trap_subdir;
+	struct dentry *cpu_code_sw_cnt_subdir;
+	struct dentry *cpu_code_hw_counters_subdir;
 	char file_name[] = "cpu_code_XXX_stats";
+	const struct file_operations *fops =
+		&prestera_debugfs.cpu_code_cnt_fops;
+	struct prestera_cpu_code_data f_data;
+	struct dentry *debugfs_file;
 	int err;
 	int i;
 
-	mutex_init(&prestera_debugfs.cpu_code_stats_mtx);
+	mutex_init(&debugfs->cpu_code_cnt_buf_mtx);
 
-	prestera_debugfs.cpu_code_stats_buf =
-		kzalloc(CPU_CODE_MAX_BUF_SIZE, GFP_KERNEL);
+	debugfs->sw = sw;
 
-	if (!prestera_debugfs.cpu_code_stats_buf)
+	debugfs->cpu_code_cnt_buf = kzalloc(CPU_CODE_CNT_BUF_MAX_SIZE,
+					    GFP_KERNEL);
+	if (!debugfs->cpu_code_cnt_buf)
 		return -ENOMEM;
 
 	err = mvsw_pr_fw_log_init(sw);
 	if (err)
-		return err;
+		goto err_fw_log_init;
 
-	prestera_debugfs.root_dir = debugfs_create_dir(DEBUGFS_ROOTDIR, NULL);
-	if (!prestera_debugfs.root_dir) {
-		err = -ENOMEM;
-		goto root_dir_alloc_failed;
+	debugfs->root_dir = debugfs_create_dir(PRESTERA_DEBUGFS_ROOTDIR, NULL);
+	if (PTR_ERR_OR_ZERO(debugfs->root_dir)) {
+		err = (int)PTR_ERR(debugfs->root_dir);
+		goto err_root_dir_alloc;
 	}
 
-	prestera_debugfs.cpu_code_subdir =
-		debugfs_create_dir(CPU_CODE_SUBDIR_NAME,
-				   prestera_debugfs.root_dir);
-	if (!prestera_debugfs.cpu_code_subdir) {
-		err = -ENOMEM;
-		goto cpu_code_subdir_alloc_failed;
+	cpu_code_sw_cnt_subdir = debugfs_create_dir(CPU_CODE_SW_CNT_SUBDIR_NAME,
+						    debugfs->root_dir);
+	if (PTR_ERR_OR_ZERO(cpu_code_sw_cnt_subdir)) {
+		err = (int)PTR_ERR(debugfs->root_dir);
+		goto err_subdir_alloc;
 	}
 
-	for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
-		snprintf(file_name, sizeof(file_name), "cpu_code_%d_stats", i);
-		if (!debugfs_create_file(file_name, 0644,
-					 prestera_debugfs.cpu_code_subdir,
-					 (void *)(long)i, fops)) {
-			err = -ENOMEM;
-			goto cpu_code_single_file_creation_failed;
-		}
+	cpu_code_sw_cnt_trap_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_TRAP_NAME,
+				   cpu_code_sw_cnt_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_sw_cnt_trap_subdir)) {
+		err = (int)PTR_ERR(cpu_code_sw_cnt_trap_subdir);
+		goto err_subdir_alloc;
+	}
+
+	cpu_code_hw_counters_subdir =
+		debugfs_create_dir(CPU_CODE_HW_CNT_SUBDIR_NAME,
+				   debugfs->root_dir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_counters_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_counters_subdir);
+		goto err_subdir_alloc;
 	}
 
-	strncpy(file_name, "cpu_code_stats", sizeof(file_name));
+	cpu_code_hw_cnt_trap_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_TRAP_NAME,
+				   cpu_code_hw_counters_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_cnt_trap_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_cnt_trap_subdir);
+		goto err_subdir_alloc;
+	}
 
-	if (!debugfs_create_file(file_name, 0644,
-				 prestera_debugfs.cpu_code_subdir,
-				 (void *)(long)MVSW_PR_RXTX_CPU_CODE_MAX_NUM,
-				 fops)) {
-		err = -ENOMEM;
-		goto cpu_code_single_file_creation_failed;
+	cpu_code_hw_cnt_drop_subdir =
+		debugfs_create_dir(CPU_CODE_CNT_SUBDIR_DROP_NAME,
+				   cpu_code_hw_counters_subdir);
+	if (PTR_ERR_OR_ZERO(cpu_code_hw_cnt_drop_subdir)) {
+		err = (int)PTR_ERR(cpu_code_hw_cnt_trap_subdir);
+		goto err_subdir_alloc;
 	}
 
+	for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
+		f_data.cpu_code = i;
+
+		snprintf(file_name, sizeof(file_name), "cpu_code_%d_stats", i);
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_SW_TRAP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_sw_cnt_trap_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_TRAP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_hw_cnt_trap_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+
+		f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_DROP;
+		debugfs_file = debugfs_create_file(file_name, 0644,
+						   cpu_code_hw_cnt_drop_subdir,
+						   (void *)f_data.data,
+						   fops);
+		if (PTR_ERR_OR_ZERO(debugfs_file))
+			goto err_single_file_creation;
+	}
+
+	f_data.cpu_code = MVSW_PR_RXTX_CPU_CODE_MAX_NUM;
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_SW_TRAP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_sw_cnt_trap_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_TRAP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_hw_cnt_trap_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
+	f_data.cpu_code_cnt_type = CPU_CODE_CNT_TYPE_HW_DROP;
+	debugfs_file = debugfs_create_file("cpu_code_stats", 0644,
+					   cpu_code_hw_cnt_drop_subdir,
+					   (void *)f_data.data,
+					   fops);
+	if (PTR_ERR_OR_ZERO(debugfs_file))
+		goto err_single_file_creation;
+
 	return 0;
 
-cpu_code_single_file_creation_failed:
-	debugfs_remove(prestera_debugfs.cpu_code_subdir);
-cpu_code_subdir_alloc_failed:
-	debugfs_remove(prestera_debugfs.root_dir);
-root_dir_alloc_failed:
+err_single_file_creation:
+	err = (int)PTR_ERR(debugfs_file);
+err_subdir_alloc:
+	/*
+	 * Removing root directory would result in recursive
+	 * subdirectories / files cleanup of all child nodes;
+	 */
+	debugfs_remove(debugfs->root_dir);
+err_root_dir_alloc:
 	mvsw_pr_fw_log_fini(sw);
-
+err_fw_log_init:
+	kfree(debugfs->cpu_code_cnt_buf);
 	return err;
 }
 
-void mvsw_pr_debugfs_fini(struct mvsw_pr_switch *sw)
+void prestera_debugfs_fini(struct prestera_switch *sw)
 {
 	mvsw_pr_fw_log_fini(sw);
-
-	debugfs_remove(prestera_debugfs.cpu_code_subdir);
 	debugfs_remove(prestera_debugfs.root_dir);
+	mutex_destroy(&prestera_debugfs.cpu_code_cnt_buf_mtx);
+	kfree(prestera_debugfs.cpu_code_cnt_buf);
+}
 
-	mutex_destroy(&prestera_debugfs.cpu_code_stats_mtx);
-
-	kfree(prestera_debugfs.cpu_code_stats_buf);
+/*
+ * Software: only TRAP counters are present
+ * Hardware: counters can be either TRAP or drops
+ */
+static int prestera_cpu_code_cnt_get(u64 *stats, u8 cpu_code, u8 cnt_type)
+{
+	switch (cnt_type) {
+	case CPU_CODE_CNT_TYPE_HW_DROP:
+	case CPU_CODE_CNT_TYPE_HW_TRAP:
+		/* fall through */
+		return prestera_hw_cpu_code_counters_get(prestera_debugfs.sw,
+							 cpu_code, cnt_type,
+							 stats);
+	case CPU_CODE_CNT_TYPE_SW_TRAP:
+		*stats = mvsw_pr_rxtx_get_cpu_code_stats(cpu_code);
+		return 0;
+	default:
+		return -EINVAL;
+	}
 }
 
-static ssize_t cpu_code_stats_read(struct file *file,
-				   char __user *ubuf,
-				   size_t count, loff_t *ppos)
+static ssize_t prestera_cnt_read(struct file *file, char __user *ubuf,
+				 size_t count, loff_t *ppos)
 {
-	char *buf = prestera_debugfs.cpu_code_stats_buf;
-	u16 cpu_code = (u16)(long)file->private_data;
+	char *buf = prestera_debugfs.cpu_code_cnt_buf;
+	struct prestera_cpu_code_data f_data = {
+		.data = (long)file->private_data,
+	};
 	u64 cpu_code_stats;
 	/* as the snprintf doesn't count for \0, start with 1 */
 	int buf_len = 1;
 	int ret;
 
-	mutex_lock(&prestera_debugfs.cpu_code_stats_mtx);
+	mutex_lock(&prestera_debugfs.cpu_code_cnt_buf_mtx);
 
-	if (cpu_code == MVSW_PR_RXTX_CPU_CODE_MAX_NUM) {
+	if (f_data.cpu_code == MVSW_PR_RXTX_CPU_CODE_MAX_NUM) {
 		int i;
 
-		memset(buf, 0, CPU_CODE_MAX_BUF_SIZE);
+		memset(buf, 0, CPU_CODE_CNT_BUF_MAX_SIZE);
 
 		for (i = 0; i < MVSW_PR_RXTX_CPU_CODE_MAX_NUM; ++i) {
-			cpu_code_stats = mvsw_pr_rxtx_get_cpu_code_stats(i);
+			ret = prestera_cpu_code_cnt_get
+				(&cpu_code_stats, (u8)i,
+				 f_data.cpu_code_cnt_type);
+			if (ret)
+				goto err_get_stats;
 
 			if (!cpu_code_stats)
 				continue;
 
 			buf_len += snprintf(buf + buf_len,
-					    CPU_CODE_MAX_BUF_SIZE - buf_len,
+					    CPU_CODE_CNT_BUF_MAX_SIZE - buf_len,
 					    "%u:%llu\n", i, cpu_code_stats);
 		}
 
 	} else {
-		cpu_code_stats = mvsw_pr_rxtx_get_cpu_code_stats((u8)cpu_code);
+		ret = prestera_cpu_code_cnt_get(&cpu_code_stats,
+						(u8)f_data.cpu_code,
+						f_data.cpu_code_cnt_type);
+		if (ret)
+			goto err_get_stats;
 
 		buf_len += sprintf(buf, "%llu\n", cpu_code_stats);
 	}
 
 	ret = simple_read_from_buffer(ubuf, count, ppos, buf, buf_len);
-	mutex_unlock(&prestera_debugfs.cpu_code_stats_mtx);
+
+err_get_stats:
+	mutex_unlock(&prestera_debugfs.cpu_code_cnt_buf_mtx);
 
 	return ret;
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
index b3ce1a4..389421e 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_debugfs.h
@@ -6,9 +6,9 @@
 #ifndef _MVSW_PRESTERA_DEBUGFS_H_
 #define _MVSW_PRESTERA_DEBUGFS_H_
 
-struct mvsw_pr_switch;
+struct prestera_switch;
 
-int mvsw_pr_debugfs_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_debugfs_fini(struct mvsw_pr_switch *sw);
+int prestera_debugfs_init(struct prestera_switch *sw);
+void prestera_debugfs_fini(struct prestera_switch *sw);
 
 #endif /* _MVSW_PRESTERA_DEBUGFS_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
index 7a9d5f4..fa7a46f 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
@@ -2,14 +2,297 @@
 /* Copyright (c) 2020 Marvell International Ltd. All rights reserved */
 
 #include <net/devlink.h>
+#include <linux/version.h>
 
 #include "prestera_devlink.h"
 
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+/* All driver-specific traps must be documented in
+ * Documentation/networking/devlink/prestera.rst
+ */
+enum {
+	DEVLINK_PRESTERA_TRAP_ID_BASE = DEVLINK_TRAP_GENERIC_ID_MAX,
+	DEVLINK_PRESTERA_TRAP_ID_ARP_BC,
+	DEVLINK_PRESTERA_TRAP_ID_IS_IS,
+	DEVLINK_PRESTERA_TRAP_ID_OSPF,
+	DEVLINK_PRESTERA_TRAP_ID_IP_BC_MAC,
+	DEVLINK_PRESTERA_TRAP_ID_ROUTER_MC,
+	DEVLINK_PRESTERA_TRAP_ID_VRRP,
+	DEVLINK_PRESTERA_TRAP_ID_DHCP,
+	DEVLINK_PRESTERA_TRAP_ID_MAC_TO_ME,
+	DEVLINK_PRESTERA_TRAP_ID_IPV4_OPTIONS,
+	DEVLINK_PRESTERA_TRAP_ID_IP_DEFAULT_ROUTE,
+	DEVLINK_PRESTERA_TRAP_ID_IP_TO_ME,
+	DEVLINK_PRESTERA_TRAP_ID_IPV4_ICMP_REDIRECT,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_0,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_1,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_2,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_3,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_4,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_5,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_6,
+	DEVLINK_PRESTERA_TRAP_ID_ACL_CODE_7,
+	DEVLINK_PRESTERA_TRAP_ID_BGP,
+	DEVLINK_PRESTERA_TRAP_ID_SSH,
+	DEVLINK_PRESTERA_TRAP_ID_TELNET,
+	DEVLINK_PRESTERA_TRAP_ID_ICMP,
+};
+
+#define DEVLINK_PRESTERA_TRAP_NAME_ARP_BC \
+	"arp_bc"
+#define DEVLINK_PRESTERA_TRAP_NAME_IS_IS \
+	"is_is"
+#define DEVLINK_PRESTERA_TRAP_NAME_OSPF \
+	"ospf"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_BC_MAC \
+	"ip_bc_mac"
+#define DEVLINK_PRESTERA_TRAP_NAME_ROUTER_MC \
+	"router_mc"
+#define DEVLINK_PRESTERA_TRAP_NAME_VRRP \
+	"vrrp"
+#define DEVLINK_PRESTERA_TRAP_NAME_DHCP \
+	"dhcp"
+#define DEVLINK_PRESTERA_TRAP_NAME_MAC_TO_ME \
+	"mac_to_me"
+#define DEVLINK_PRESTERA_TRAP_NAME_IPV4_OPTIONS \
+	"ipv4_options"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_DEFAULT_ROUTE \
+	"ip_default_route"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_TO_ME \
+	"ip_to_me"
+#define DEVLINK_PRESTERA_TRAP_NAME_IPV4_ICMP_REDIRECT \
+	"ipv4_icmp_redirect"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_0 \
+	"acl_code_0"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_1 \
+	"acl_code_1"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_2 \
+	"acl_code_2"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_3 \
+	"acl_code_3"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_4 \
+	"acl_code_4"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_5 \
+	"acl_code_5"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_6 \
+	"acl_code_6"
+#define DEVLINK_PRESTERA_TRAP_NAME_ACL_CODE_7 \
+	"acl_code_7"
+#define DEVLINK_PRESTERA_TRAP_NAME_BGP \
+	"bgp"
+#define DEVLINK_PRESTERA_TRAP_NAME_SSH \
+	"ssh"
+#define DEVLINK_PRESTERA_TRAP_NAME_TELNET \
+	"telnet"
+#define DEVLINK_PRESTERA_TRAP_NAME_ICMP \
+	"icmp"
+
+struct prestera_trap {
+	struct devlink_trap trap;
+	u8 cpu_code;
+};
+
+struct prestera_trap_item {
+	enum devlink_trap_action action;
+	void *trap_ctx;
+};
+
+struct prestera_trap_data {
+	struct prestera_switch *sw;
+	struct prestera_trap_item *trap_items_arr;
+	u32 traps_count;
+};
+
+#define PRESTERA_TRAP_METADATA DEVLINK_TRAP_METADATA_TYPE_F_IN_PORT
+
+#define PRESTERA_TRAP_CONTROL(_id, _group_id, _action)			      \
+	DEVLINK_TRAP_GENERIC(CONTROL, _action, _id,			      \
+			     DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			     PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_TRAP_DRIVER_CONTROL(_id, _group_id)			      \
+	DEVLINK_TRAP_DRIVER(CONTROL, TRAP, DEVLINK_PRESTERA_TRAP_ID_##_id,    \
+			    DEVLINK_PRESTERA_TRAP_NAME_##_id,		      \
+			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			    PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_TRAP_EXCEPTION(_id, _group_id)				      \
+	DEVLINK_TRAP_GENERIC(EXCEPTION, TRAP, _id,			      \
+			     DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			     PRESTERA_TRAP_METADATA)
+
+#define PRESTERA_TRAP_DRIVER_EXCEPTION(_id, _group_id)			      \
+	DEVLINK_TRAP_DRIVER(EXCEPTION, TRAP, DEVLINK_PRESTERA_TRAP_ID_##_id,  \
+			    DEVLINK_PRESTERA_TRAP_NAME_##_id,		      \
+			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			    PRESTERA_TRAP_METADATA)
+
+static const struct devlink_trap_group prestera_trap_groups_arr[] = {
+	/* No policer is associated with following groups (policerid == 0)*/
+	DEVLINK_TRAP_GROUP_GENERIC(L2_DROPS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(L3_DROPS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(L3_EXCEPTIONS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(NEIGH_DISCOVERY, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(ACL_TRAP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(ACL_DROPS, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(ACL_SAMPLE, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(OSPF, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(STP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(LACP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(LLDP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(VRRP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(DHCP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(BGP, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(LOCAL_DELIVERY, 0),
+};
+
+/* Initialize trap list, as well as associate CPU code with them. */
+static struct prestera_trap prestera_trap_items_arr[] = {
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ARP_BC, NEIGH_DISCOVERY),
+		.cpu_code = 5,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(IS_IS, LOCAL_DELIVERY),
+		.cpu_code = 13,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(OSPF, OSPF),
+		.cpu_code = 16,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(IP_BC_MAC, LOCAL_DELIVERY),
+		.cpu_code = 19,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(STP, STP, TRAP),
+		.cpu_code = 26,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(LACP, LACP, TRAP),
+		.cpu_code = 27,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(LLDP, LLDP, TRAP),
+		.cpu_code = 28,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ROUTER_MC, LOCAL_DELIVERY),
+		.cpu_code = 29,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(VRRP, VRRP),
+		.cpu_code = 30,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(DHCP, DHCP),
+		.cpu_code = 33,
+	},
+	{
+		.trap = PRESTERA_TRAP_EXCEPTION(MTU_ERROR, L3_EXCEPTIONS),
+		.cpu_code = 63,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(MAC_TO_ME, LOCAL_DELIVERY),
+		.cpu_code = 65,
+	},
+	{
+		.trap = PRESTERA_TRAP_EXCEPTION(TTL_ERROR, L3_EXCEPTIONS),
+		.cpu_code = 133,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_EXCEPTION(IPV4_OPTIONS,
+						       L3_EXCEPTIONS),
+		.cpu_code = 141,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(IP_DEFAULT_ROUTE,
+						     LOCAL_DELIVERY),
+		.cpu_code = 160,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(LOCAL_ROUTE, LOCAL_DELIVERY,
+					      TRAP),
+		.cpu_code = 161,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_EXCEPTION(IPV4_ICMP_REDIRECT,
+						       L3_EXCEPTIONS),
+		.cpu_code = 180,
+	},
+	{
+		.trap = PRESTERA_TRAP_CONTROL(ARP_RESPONSE, NEIGH_DISCOVERY,
+					      TRAP),
+		.cpu_code = 188,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_0, ACL_TRAP),
+		.cpu_code = 192,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_1, ACL_TRAP),
+		.cpu_code = 193,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_2, ACL_TRAP),
+		.cpu_code = 194,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_3, ACL_TRAP),
+		.cpu_code = 195,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_4, ACL_TRAP),
+		.cpu_code = 196,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_5, ACL_TRAP),
+		.cpu_code = 197,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_6, ACL_TRAP),
+		.cpu_code = 198,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ACL_CODE_7, ACL_TRAP),
+		.cpu_code = 199,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(BGP, BGP),
+		.cpu_code = 206,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(SSH, LOCAL_DELIVERY),
+		.cpu_code = 207,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(TELNET, LOCAL_DELIVERY),
+		.cpu_code = 208,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ICMP, LOCAL_DELIVERY),
+		.cpu_code = 209,
+	},
+};
+#endif
+
+static void prestera_devlink_traps_fini(struct prestera_switch *sw);
+
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx);
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack);
+
+static int prestera_devlink_traps_register(struct prestera_switch *sw);
+
 static int prestera_dl_info_get(struct devlink *dl,
 				struct devlink_info_req *req,
 				struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_switch *sw = devlink_priv(dl);
+	struct prestera_switch *sw = devlink_priv(dl);
 	char buf[16];
 	int err;
 
@@ -29,50 +312,65 @@ static int prestera_dl_info_get(struct devlink *dl,
 
 static const struct devlink_ops prestera_dl_ops = {
 	.info_get = prestera_dl_info_get,
+	.trap_init = prestera_trap_init,
+	.trap_action_set = prestera_trap_action_set,
 };
 
-struct mvsw_pr_switch *prestera_devlink_alloc(void)
+struct prestera_switch *prestera_devlink_alloc(void)
 {
 	struct devlink *dl;
 
-	dl = devlink_alloc(&prestera_dl_ops, sizeof(struct mvsw_pr_switch));
+	dl = devlink_alloc(&prestera_dl_ops, sizeof(struct prestera_switch));
 
 	return devlink_priv(dl);
 }
 
-void prestera_devlink_free(struct mvsw_pr_switch *sw)
+void prestera_devlink_free(struct prestera_switch *sw)
 {
 	struct devlink *dl = priv_to_devlink(sw);
 
 	devlink_free(dl);
 }
 
-int prestera_devlink_register(struct mvsw_pr_switch *sw)
+int prestera_devlink_register(struct prestera_switch *sw)
 {
 	struct devlink *dl = priv_to_devlink(sw);
 	int err;
 
 	err = devlink_register(dl, sw->dev->dev);
-	if (err)
+	if (err) {
 		dev_err(sw->dev->dev, "devlink_register failed: %d\n", err);
+		return err;
+	}
 
-	return err;
+	err = prestera_devlink_traps_register(sw);
+	if (err) {
+		devlink_unregister(dl);
+		dev_err(sw->dev->dev, "devlink_traps_register failed: %d\n",
+			err);
+		return err;
+	}
+
+	return 0;
 }
 
-void prestera_devlink_unregister(struct mvsw_pr_switch *sw)
+void prestera_devlink_unregister(struct prestera_switch *sw)
 {
 	struct devlink *dl = priv_to_devlink(sw);
 
+	prestera_devlink_traps_fini(sw);
 	devlink_unregister(dl);
 }
 
-int prestera_devlink_port_register(struct mvsw_pr_port *port)
+int prestera_devlink_port_register(struct prestera_port *port)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct devlink *dl = priv_to_devlink(sw);
 	struct devlink_port_attrs attrs = {};
+	struct prestera_switch *sw = port->sw;
+	struct devlink *dl;
 	int err;
 
+	dl = priv_to_devlink(sw);
+
 	attrs.flavour = DEVLINK_PORT_FLAVOUR_PHYSICAL;
 	attrs.phys.port_number = port->fp_id;
 	attrs.switch_id.id_len = sizeof(sw->id);
@@ -89,24 +387,196 @@ int prestera_devlink_port_register(struct mvsw_pr_port *port)
 	return 0;
 }
 
-void prestera_devlink_port_unregister(struct mvsw_pr_port *port)
+void prestera_devlink_port_unregister(struct prestera_port *port)
 {
 	devlink_port_unregister(&port->dl_port);
 }
 
-void prestera_devlink_port_set(struct mvsw_pr_port *port)
+void prestera_devlink_port_set(struct prestera_port *port)
 {
 	devlink_port_type_eth_set(&port->dl_port, port->net_dev);
 }
 
-void prestera_devlink_port_clear(struct mvsw_pr_port *port)
+void prestera_devlink_port_clear(struct prestera_port *port)
 {
 	devlink_port_type_clear(&port->dl_port);
 }
 
 struct devlink_port *prestera_devlink_get_port(struct net_device *dev)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	return &port->dl_port;
 }
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
+static int prestera_devlink_traps_register(struct prestera_switch *sw)
+{
+	const u32 groups_count = ARRAY_SIZE(prestera_trap_groups_arr);
+	const u32 traps_count = ARRAY_SIZE(prestera_trap_items_arr);
+	struct devlink *devlink = priv_to_devlink(sw);
+	struct prestera_trap *prestera_trap;
+	struct prestera_trap_data *trap_data;
+	int err, i;
+
+	trap_data = kzalloc(sizeof(*trap_data), GFP_KERNEL);
+	if (!trap_data)
+		return -ENOMEM;
+
+	trap_data->trap_items_arr = kcalloc(ARRAY_SIZE(prestera_trap_items_arr),
+					    sizeof(struct prestera_trap_item),
+					    GFP_KERNEL);
+	if (!trap_data->trap_items_arr) {
+		err = -ENOMEM;
+		goto err_trap_items_alloc;
+	}
+
+	trap_data->sw = sw;
+	trap_data->traps_count = ARRAY_SIZE(prestera_trap_items_arr);
+	sw->trap_data = trap_data;
+
+	err = devlink_trap_groups_register(devlink, prestera_trap_groups_arr,
+					   groups_count);
+	if (err)
+		goto err_groups_register;
+
+	for (i = 0; i < traps_count; i++) {
+		prestera_trap = &prestera_trap_items_arr[i];
+		err = devlink_traps_register(devlink, &prestera_trap->trap, 1,
+					     sw);
+		if (err)
+			goto err_trap_register;
+	}
+
+	return 0;
+
+err_trap_register:
+	for (i--; i >= 0; i--) {
+		prestera_trap = &prestera_trap_items_arr[i];
+		devlink_traps_unregister(devlink, &prestera_trap->trap, 1);
+	}
+err_groups_register:
+	kfree(trap_data->trap_items_arr);
+err_trap_items_alloc:
+	kfree(trap_data);
+	return err;
+}
+
+static struct prestera_trap_item *
+prestera_get_trap_item_by_cpu_code(struct prestera_switch *sw, u8 cpu_code)
+{
+	struct prestera_trap_data *trap_data = sw->trap_data;
+	struct prestera_trap *prestera_trap;
+	int i;
+
+	for (i = 0; i < trap_data->traps_count; i++) {
+		prestera_trap = &prestera_trap_items_arr[i];
+		if (cpu_code == prestera_trap->cpu_code)
+			return &trap_data->trap_items_arr[i];
+	}
+
+	return NULL;
+}
+
+void prestera_devlink_trap_report(struct prestera_port *port,
+				  struct sk_buff *skb, u8 cpu_code)
+{
+	struct prestera_trap_item *trap_item;
+	struct devlink *devlink;
+
+	devlink = port->dl_port.devlink;
+
+	trap_item = prestera_get_trap_item_by_cpu_code(port->sw, cpu_code);
+	if (unlikely(!trap_item))
+		return;
+
+	devlink_trap_report(devlink, skb, trap_item->trap_ctx,
+			    &port->dl_port, NULL);
+}
+
+static struct prestera_trap_item *
+prestera_devlink_trap_item_lookup(struct prestera_switch *sw, u16 trap_id)
+{
+	struct prestera_trap_data *trap_data = sw->trap_data;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(prestera_trap_items_arr); i++) {
+		if (prestera_trap_items_arr[i].trap.id == trap_id)
+			return &trap_data->trap_items_arr[i];
+	}
+
+	return NULL;
+}
+
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx)
+{
+	struct prestera_switch *sw = devlink_priv(devlink);
+	struct prestera_trap_item *trap_item;
+
+	trap_item = prestera_devlink_trap_item_lookup(sw, trap->id);
+	if (WARN_ON(!trap_item))
+		return -EINVAL;
+
+	trap_item->trap_ctx = trap_ctx;
+	trap_item->action = trap->init_action;
+
+	return 0;
+}
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack)
+{
+	/* Currently, driver does not support trap action altering */
+	return -ENOTSUPP;
+}
+
+static void prestera_devlink_traps_fini(struct prestera_switch *sw)
+{
+	struct prestera_trap_data *trap_data = sw->trap_data;
+	struct devlink *dl = priv_to_devlink(sw);
+	const struct devlink_trap *trap;
+	int i;
+
+	for (i = 0; i < ARRAY_SIZE(prestera_trap_items_arr); ++i) {
+		trap = &prestera_trap_items_arr[i].trap;
+		devlink_traps_unregister(dl, trap, 1);
+	}
+
+	devlink_trap_groups_unregister(dl, prestera_trap_groups_arr,
+				       ARRAY_SIZE(prestera_trap_groups_arr));
+
+	kfree(trap_data->trap_items_arr);
+	kfree(trap_data);
+}
+#else
+static int prestera_devlink_traps_register(struct prestera_switch *sw)
+{
+	return 0;
+}
+
+static int prestera_trap_init(struct devlink *devlink,
+			      const struct devlink_trap *trap, void *trap_ctx)
+{
+	return 0;
+}
+
+static int prestera_trap_action_set(struct devlink *devlink,
+				    const struct devlink_trap *trap,
+				    enum devlink_trap_action action,
+				    struct netlink_ext_ack *extack)
+{
+	return 0;
+}
+
+static void prestera_devlink_traps_fini(struct prestera_switch *sw)
+{
+}
+
+void prestera_devlink_trap_report(struct prestera_port *port,
+				  struct sk_buff *skb, u8 cpu_code)
+{
+}
+#endif
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_devlink.h b/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
index 4d51c42..50cd743 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_devlink.h
@@ -6,18 +6,21 @@
 
 #include "prestera.h"
 
-struct mvsw_pr_switch *prestera_devlink_alloc(void);
-void prestera_devlink_free(struct mvsw_pr_switch *sw);
+struct prestera_switch *prestera_devlink_alloc(void);
+void prestera_devlink_free(struct prestera_switch *sw);
 
-int prestera_devlink_register(struct mvsw_pr_switch *sw);
-void prestera_devlink_unregister(struct mvsw_pr_switch *sw);
+int prestera_devlink_register(struct prestera_switch *sw);
+void prestera_devlink_unregister(struct prestera_switch *sw);
 
-int prestera_devlink_port_register(struct mvsw_pr_port *port);
-void prestera_devlink_port_unregister(struct mvsw_pr_port *port);
+int prestera_devlink_port_register(struct prestera_port *port);
+void prestera_devlink_port_unregister(struct prestera_port *port);
 
-void prestera_devlink_port_set(struct mvsw_pr_port *port);
-void prestera_devlink_port_clear(struct mvsw_pr_port *port);
+void prestera_devlink_port_set(struct prestera_port *port);
+void prestera_devlink_port_clear(struct prestera_port *port);
 
 struct devlink_port *prestera_devlink_get_port(struct net_device *dev);
 
+void prestera_devlink_trap_report(struct prestera_port *port,
+				  struct sk_buff *skb, u8 cpu_code);
+
 #endif /* _PRESTERA_DEVLINK_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
index 29b3375..a289428 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
@@ -12,7 +12,7 @@
 #define PRESTERA_DRV_VER_MAJOR	2
 #define PRESTERA_DRV_VER_MINOR	0
 #define PRESTERA_DRV_VER_PATCH	0
-#define PRESTERA_DRV_VER_EXTRA
+#define PRESTERA_DRV_VER_EXTRA	-v2.9.0
 
 #define PRESTERA_DRV_VER \
 		__stringify(PRESTERA_DRV_VER_MAJOR)  "." \
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flow.c b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
new file mode 100644
index 0000000..2869bd0
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
@@ -0,0 +1,216 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+//
+// Copyright (c) 2020 Marvell International Ltd. All rights reserved.
+//
+
+#include <linux/kernel.h>
+#include <linux/list.h>
+#include <linux/netdevice.h>
+
+#include "prestera.h"
+
+static LIST_HEAD(prestera_block_cb_list);
+
+static int prestera_flow_block_mall_cb(struct prestera_flow_block *block,
+				       struct tc_cls_matchall_offload *f)
+{
+	switch (f->command) {
+	case TC_CLSMATCHALL_REPLACE:
+		return prestera_mall_replace(block, f);
+	case TC_CLSMATCHALL_DESTROY:
+		prestera_mall_destroy(block);
+		return 0;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static int prestera_flow_block_flower_cb(struct prestera_flow_block *block,
+					 struct flow_cls_offload *f)
+{
+	struct prestera_switch *sw = prestera_acl_block_sw(block);
+
+	if (f->common.chain_index != 0)
+		return -EOPNOTSUPP;
+
+	switch (f->command) {
+	case FLOW_CLS_REPLACE:
+		return mvsw_pr_flower_replace(sw, block, f);
+	case FLOW_CLS_DESTROY:
+		mvsw_pr_flower_destroy(sw, block, f);
+		return 0;
+	case FLOW_CLS_STATS:
+		return mvsw_pr_flower_stats(sw, block, f);
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static int prestera_flow_block_cb(enum tc_setup_type type,
+				  void *type_data, void *cb_priv)
+{
+	struct prestera_flow_block *block = cb_priv;
+
+	if (prestera_acl_block_disabled(block))
+		return -EOPNOTSUPP;
+
+	switch (type) {
+	case TC_SETUP_CLSFLOWER:
+		return prestera_flow_block_flower_cb(block, type_data);
+	case TC_SETUP_CLSMATCHALL:
+		return prestera_flow_block_mall_cb(block, type_data);
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static void prestera_flow_block_release(void *cb_priv)
+{
+	struct prestera_flow_block *block = cb_priv;
+
+	prestera_acl_block_destroy(block);
+}
+
+static struct prestera_flow_block *
+prestera_flow_block_get(struct prestera_switch *sw,
+			struct flow_block_offload *f,
+			bool *register_block)
+{
+	struct prestera_flow_block *block;
+	struct flow_block_cb *block_cb;
+
+	block_cb = flow_block_cb_lookup(f->block,
+					prestera_flow_block_cb, sw);
+	if (!block_cb) {
+		block = prestera_acl_block_create(sw, f->net);
+		if (!block)
+			return ERR_PTR(-ENOMEM);
+
+		block_cb = flow_block_cb_alloc(prestera_flow_block_cb,
+					       sw, block,
+					       prestera_flow_block_release);
+		if (IS_ERR(block_cb)) {
+			prestera_acl_block_destroy(block);
+			return ERR_CAST(block_cb);
+		}
+
+		block->block_cb = block_cb;
+		*register_block = true;
+	} else {
+		block = flow_block_cb_priv(block_cb);
+		*register_block = false;
+	}
+
+	flow_block_cb_incref(block_cb);
+
+	return block;
+}
+
+static void prestera_flow_block_put(struct prestera_flow_block *block)
+{
+	struct flow_block_cb *block_cb = block->block_cb;
+
+	if (flow_block_cb_decref(block_cb))
+		return;
+
+	flow_block_cb_free(block_cb);
+	prestera_acl_block_destroy(block);
+}
+
+static int prestera_setup_tc_block_bind(struct prestera_port *port,
+					struct flow_block_offload *f)
+{
+	struct prestera_switch *sw = port->sw;
+	struct prestera_flow_block *block;
+	struct flow_block_cb *block_cb;
+	bool disable_block = false;
+	bool register_block;
+	int err;
+
+	block = prestera_flow_block_get(sw, f, &register_block);
+	if (IS_ERR(block))
+		return PTR_ERR(block);
+
+	block_cb = block->block_cb;
+
+	if (!tc_can_offload(port->net_dev)) {
+		if (prestera_acl_block_rule_count(block)) {
+			err = -EOPNOTSUPP;
+			goto err_block_bind;
+		}
+
+		disable_block = true;
+	}
+
+	err = prestera_acl_block_bind(sw, block, port);
+	if (err)
+		goto err_block_bind;
+
+	if (register_block) {
+		flow_block_cb_add(block_cb, f);
+		list_add_tail(&block_cb->driver_list, &prestera_block_cb_list);
+	}
+
+	if (disable_block)
+		prestera_acl_block_disable_inc(block);
+
+	port->flow_block = block;
+	return 0;
+
+err_block_bind:
+	prestera_flow_block_put(block);
+
+	return err;
+}
+
+static void prestera_setup_tc_block_unbind(struct prestera_port *port,
+					   struct flow_block_offload *f)
+{
+	struct prestera_switch *sw = port->sw;
+	struct prestera_flow_block *block;
+	struct flow_block_cb *block_cb;
+	int err;
+
+	block_cb = flow_block_cb_lookup(f->block,
+					prestera_flow_block_cb, sw);
+	if (!block_cb)
+		return;
+
+	block = flow_block_cb_priv(block_cb);
+
+	if (!tc_can_offload(port->net_dev))
+		prestera_acl_block_disable_dec(block);
+
+	prestera_mall_destroy(block);
+
+	err = prestera_acl_block_unbind(sw, block, port);
+	if (err)
+		goto error;
+
+	if (!flow_block_cb_decref(block_cb)) {
+		flow_block_cb_remove(block_cb, f);
+		list_del(&block_cb->driver_list);
+	}
+error:
+	port->flow_block = NULL;
+}
+
+int prestera_setup_tc_block(struct prestera_port *port,
+			    struct flow_block_offload *f)
+{
+	if (f->binder_type != FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS)
+		return -EOPNOTSUPP;
+
+	f->driver_block_list = &prestera_block_cb_list;
+
+	switch (f->command) {
+	case FLOW_BLOCK_BIND:
+		return prestera_setup_tc_block_bind(port, f);
+	case FLOW_BLOCK_UNBIND:
+		prestera_setup_tc_block_unbind(port, f);
+		return 0;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flower.c b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
index 4070def..bad77f4 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_flower.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
@@ -4,57 +4,87 @@
 //
 
 #include "prestera.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
+#include "prestera_log.h"
 #include "prestera_hw.h"
 
 #define PRESTERA_DEFAULT_TC_NUM	8
 
-static int mvsw_pr_flower_parse_actions(struct mvsw_pr_switch *sw,
-					struct prestera_acl_block *block,
+static int mvsw_pr_flower_parse_actions(struct prestera_flow_block *block,
 					struct prestera_acl_rule *rule,
 					struct flow_action *flow_action,
 					struct netlink_ext_ack *extack)
 {
 	const struct flow_action_entry *act;
-	struct prestera_acl_rule_action_entry *a_entry;
-	int i;
+	struct prestera_flow_block_binding *binding;
+	struct prestera_acl_rule_action_entry a_entry;
+	int err, i;
 
 	if (!flow_action_has_entries(flow_action))
 		return 0;
 
 	flow_action_for_each(i, act, flow_action) {
-		/* allocate action entry */
-		a_entry = kmalloc(sizeof(*a_entry), GFP_KERNEL);
-		if (!a_entry)
-			return -ENOMEM;
+		memset(&a_entry, 0, sizeof(a_entry));
 
 		switch (act->id) {
 		case FLOW_ACTION_ACCEPT:
-			a_entry->id = MVSW_ACL_RULE_ACTION_ACCEPT;
-			prestera_acl_rule_action_add(rule, a_entry);
+			a_entry.info.id = MVSW_ACL_RULE_ACTION_ACCEPT;
 			break;
 		case FLOW_ACTION_DROP:
-			a_entry->id = MVSW_ACL_RULE_ACTION_DROP;
-			prestera_acl_rule_action_add(rule, a_entry);
+			a_entry.info.id = MVSW_ACL_RULE_ACTION_DROP;
 			break;
 		case FLOW_ACTION_TRAP:
-			a_entry->id = MVSW_ACL_RULE_ACTION_TRAP;
-			prestera_acl_rule_action_add(rule, a_entry);
+			a_entry.info.id = MVSW_ACL_RULE_ACTION_TRAP;
 			break;
 		case FLOW_ACTION_POLICE:
-			a_entry->id = MVSW_ACL_RULE_ACTION_POLICE;
-			a_entry->police.rate = act->police.rate_bytes_ps;
-			a_entry->police.burst =
-				div_u64(a_entry->police.rate *
-					PSCHED_NS2TICKS(act->police.burst),
-					PSCHED_TICKS_PER_SEC);
-			prestera_acl_rule_action_add(rule, a_entry);
+			a_entry.info.id = MVSW_ACL_RULE_ACTION_POLICE;
+			a_entry.info.police.rate = act->police.rate_bytes_ps;
+			a_entry.info.police.burst = act->police.burst;
+			break;
+		case FLOW_ACTION_GOTO:
+			rule_flag_set(rule, GOTO);
+			break;
+		case FLOW_ACTION_NAT:
+			if (~act->nat.mask) {
+				NL_SET_ERR_MSG_MOD(extack,
+						   "Netmask is not supported");
+				return -EOPNOTSUPP;
+			}
+			if (!act->nat.old_addr) {
+				NL_SET_ERR_MSG_MOD
+				    (extack,
+				     "All-zero IP address isn't supported");
+				return -EOPNOTSUPP;
+			}
+			a_entry.info.id = MVSW_ACL_RULE_ACTION_NAT;
+			a_entry.info.nat.old_addr = act->nat.old_addr;
+			a_entry.info.nat.new_addr = act->nat.new_addr;
+			a_entry.info.nat.flags = act->nat.flags;
+
+			/* get first interface bound to the block */
+			binding = list_first_entry
+			    (&block->binding_list,
+			     struct prestera_flow_block_binding, list);
+			a_entry.info.nat.dev = binding->port->dev_id;
+			a_entry.info.nat.port = binding->port->hw_id;
+			break;
+		case FLOW_ACTION_CT:
+			/* TODO: check ct nat commit */
+			err = prestera_ct_parse_action(act, rule, extack);
+			if (err)
+				return err;
+
+			rule_flag_set(rule, CT);
 			break;
 		default:
-			kfree(a_entry);
 			NL_SET_ERR_MSG_MOD(extack, "Unsupported action");
 			pr_err("Unsupported action\n");
 			return -EOPNOTSUPP;
 		}
+		err = prestera_acl_rule_action_add(rule, &a_entry);
+		if (err)
+			return err;
 	}
 
 	return 0;
@@ -62,11 +92,11 @@ static int mvsw_pr_flower_parse_actions(struct mvsw_pr_switch *sw,
 
 static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
 				     struct flow_cls_offload *f,
-				     struct prestera_acl_block *block)
+				     struct prestera_flow_block *block)
 {
 	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
 	struct prestera_acl_rule_match_entry *m_entry;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 	struct net_device *ingress_dev;
 	struct flow_match_meta match;
 
@@ -85,7 +115,7 @@ static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
 		return -EINVAL;
 	}
 
-	if (!mvsw_pr_netdev_check(ingress_dev)) {
+	if (!prestera_netdev_check(ingress_dev)) {
 		NL_SET_ERR_MSG_MOD(f->common.extack,
 				   "Can't match on switchdev ingress port");
 		return -EINVAL;
@@ -97,16 +127,15 @@ static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
 	if (!m_entry)
 		return -ENOMEM;
 
-	m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT;
-	m_entry->keymask.u64.key = port->hw_id | ((u64)port->dev_id << 32);
-	m_entry->keymask.u64.mask = ~(u64)0;
+	m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT;
+	m_entry->info.u64.key = port->hw_id | ((u64)port->dev_id << 32);
+	m_entry->info.u64.mask = ~(u64)0;
 	prestera_acl_rule_match_add(rule, m_entry);
 
 	return 0;
 }
 
-static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
-				struct prestera_acl_block *block,
+static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 				struct prestera_acl_rule *rule,
 				struct flow_cls_offload *f)
 {
@@ -130,8 +159,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 	      BIT(FLOW_DISSECTOR_KEY_ICMP) |
 	      BIT(FLOW_DISSECTOR_KEY_PORTS) |
 	      BIT(FLOW_DISSECTOR_KEY_PORTS_RANGE) |
+	      BIT(FLOW_DISSECTOR_KEY_CT) |
 	      BIT(FLOW_DISSECTOR_KEY_VLAN))) {
 		NL_SET_ERR_MSG_MOD(f->common.extack, "Unsupported key");
+		MVSW_LOG_INFO("Unsupported key");
 		return -EOPNOTSUPP;
 	}
 
@@ -157,6 +188,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 			return err;
 	}
 
+	err = prestera_ct_match_parse(f, f->common.extack);
+	if (err)
+		return err;
+
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_CONTROL)) {
 		struct flow_match_control match;
 
@@ -181,9 +216,9 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		if (!m_entry)
 			return -ENOMEM;
 
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE;
-		m_entry->keymask.u16.key = n_proto_key;
-		m_entry->keymask.u16.mask = n_proto_mask;
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE;
+		m_entry->info.u16.key = n_proto_key;
+		m_entry->info.u16.mask = n_proto_mask;
 		prestera_acl_rule_match_add(rule, m_entry);
 
 		/* add ip proto key,mask */
@@ -191,9 +226,9 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		if (!m_entry)
 			return -ENOMEM;
 
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO;
-		m_entry->keymask.u8.key = match.key->ip_proto;
-		m_entry->keymask.u8.mask = match.mask->ip_proto;
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO;
+		m_entry->info.u8.key = match.key->ip_proto;
+		m_entry->info.u8.mask = match.mask->ip_proto;
 		prestera_acl_rule_match_add(rule, m_entry);
 		ip_proto = match.key->ip_proto;
 	}
@@ -208,10 +243,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		if (!m_entry)
 			return -ENOMEM;
 
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC;
-		memcpy(&m_entry->keymask.mac.key,
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC;
+		memcpy(&m_entry->info.mac.key,
 		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry->keymask.mac.mask,
+		memcpy(&m_entry->info.mac.mask,
 		       &match.mask->dst, sizeof(match.mask->dst));
 		prestera_acl_rule_match_add(rule, m_entry);
 
@@ -220,10 +255,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		if (!m_entry)
 			return -ENOMEM;
 
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC;
-		memcpy(&m_entry->keymask.mac.key,
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC;
+		memcpy(&m_entry->info.mac.key,
 		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry->keymask.mac.mask,
+		memcpy(&m_entry->info.mac.mask,
 		       &match.mask->src, sizeof(match.mask->src));
 		prestera_acl_rule_match_add(rule, m_entry);
 	}
@@ -237,10 +272,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		if (!m_entry)
 			return -ENOMEM;
 
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC;
-		memcpy(&m_entry->keymask.u32.key,
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC;
+		memcpy(&m_entry->info.u32.key,
 		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry->keymask.u32.mask,
+		memcpy(&m_entry->info.u32.mask,
 		       &match.mask->src, sizeof(match.mask->src));
 		prestera_acl_rule_match_add(rule, m_entry);
 
@@ -248,10 +283,10 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		if (!m_entry)
 			return -ENOMEM;
 
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST;
-		memcpy(&m_entry->keymask.u32.key,
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST;
+		memcpy(&m_entry->info.u32.key,
 		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry->keymask.u32.mask,
+		memcpy(&m_entry->info.u32.mask,
 		       &match.mask->dst, sizeof(match.mask->dst));
 		prestera_acl_rule_match_add(rule, m_entry);
 	}
@@ -271,17 +306,17 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 		if (!m_entry)
 			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC;
-		m_entry->keymask.u16.key = ntohs(match.key->src);
-		m_entry->keymask.u16.mask = ntohs(match.mask->src);
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC;
+		m_entry->info.u16.key = ntohs(match.key->src);
+		m_entry->info.u16.mask = ntohs(match.mask->src);
 		prestera_acl_rule_match_add(rule, m_entry);
 
 		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 		if (!m_entry)
 			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST;
-		m_entry->keymask.u16.key = ntohs(match.key->dst);
-		m_entry->keymask.u16.mask = ntohs(match.mask->dst);
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST;
+		m_entry->info.u16.key = ntohs(match.key->dst);
+		m_entry->info.u16.mask = ntohs(match.mask->dst);
 		prestera_acl_rule_match_add(rule, m_entry);
 	}
 
@@ -293,22 +328,22 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 		if (!m_entry)
 			return -ENOMEM;
-		m_entry->type =
+		m_entry->info.type =
 			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC;
-		m_entry->keymask.u32.key = ntohs(match.key->tp_min.src) |
+		m_entry->info.u32.key = ntohs(match.key->tp_min.src) |
 				(u32)ntohs(match.key->tp_max.src) << 16;
-		m_entry->keymask.u32.mask = ntohs(match.mask->tp_min.src) |
+		m_entry->info.u32.mask = ntohs(match.mask->tp_min.src) |
 				(u32)ntohs(match.mask->tp_max.src) << 16;
 		prestera_acl_rule_match_add(rule, m_entry);
 
 		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 		if (!m_entry)
 			return -ENOMEM;
-		m_entry->type =
+		m_entry->info.type =
 			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST;
-		m_entry->keymask.u32.key = ntohs(match.key->tp_min.dst) |
+		m_entry->info.u32.key = ntohs(match.key->tp_min.dst) |
 				(u32)ntohs(match.key->tp_max.dst) << 16;
-		m_entry->keymask.u32.mask = ntohs(match.mask->tp_min.dst) |
+		m_entry->info.u32.mask = ntohs(match.mask->tp_min.dst) |
 				(u32)ntohs(match.mask->tp_max.dst) << 16;
 		prestera_acl_rule_match_add(rule, m_entry);
 	}
@@ -322,18 +357,19 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 			m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 			if (!m_entry)
 				return -ENOMEM;
-			m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID;
-			m_entry->keymask.u16.key = match.key->vlan_id;
-			m_entry->keymask.u16.mask = match.mask->vlan_id;
+			m_entry->info.type =
+				MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID;
+			m_entry->info.u16.key = match.key->vlan_id;
+			m_entry->info.u16.mask = match.mask->vlan_id;
 			prestera_acl_rule_match_add(rule, m_entry);
 		}
 
 		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 		if (!m_entry)
 			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID;
-		m_entry->keymask.u16.key = ntohs(match.key->vlan_tpid);
-		m_entry->keymask.u16.mask = ntohs(match.mask->vlan_tpid);
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID;
+		m_entry->info.u16.key = ntohs(match.key->vlan_tpid);
+		m_entry->info.u16.mask = ntohs(match.mask->vlan_tpid);
 		prestera_acl_rule_match_add(rule, m_entry);
 	}
 
@@ -345,37 +381,76 @@ static int mvsw_pr_flower_parse(struct mvsw_pr_switch *sw,
 		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 		if (!m_entry)
 			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE;
-		m_entry->keymask.u8.key = match.key->type;
-		m_entry->keymask.u8.mask = match.mask->type;
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE;
+		m_entry->info.u8.key = match.key->type;
+		m_entry->info.u8.mask = match.mask->type;
 		prestera_acl_rule_match_add(rule, m_entry);
 
 		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
 		if (!m_entry)
 			return -ENOMEM;
-		m_entry->type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE;
-		m_entry->keymask.u8.key = match.key->code;
-		m_entry->keymask.u8.mask = match.mask->code;
+		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE;
+		m_entry->info.u8.key = match.key->code;
+		m_entry->info.u8.mask = match.mask->code;
 		prestera_acl_rule_match_add(rule, m_entry);
 	}
 
-	return mvsw_pr_flower_parse_actions(sw, block, rule,
-					    &f->rule->action,
+	return mvsw_pr_flower_parse_actions(block, rule, &f->rule->action,
 					    f->common.extack);
 }
 
-int mvsw_pr_flower_replace(struct mvsw_pr_switch *sw,
-			   struct prestera_acl_block *block,
+static int prestera_flower_prio_check(struct prestera_flow_block *block,
+				      struct flow_cls_offload *f)
+{
+	u32 mall_prio;
+	int err;
+
+	err = prestera_mall_prio_get(block, &mall_prio);
+	if (err == -ENOENT)
+		return 0;
+	if (err)
+		return err;
+
+	if (f->common.prio <= mall_prio)
+		return -EOPNOTSUPP;
+
+	return 0;
+}
+
+int prestera_flower_prio_get(struct prestera_flow_block *block,
+			     u32 *prio)
+{
+	if (!prestera_acl_block_rule_count(block))
+		return -ENOENT;
+
+	*prio = block->flower_min_prio;
+	return 0;
+}
+
+static void prestera_flower_prio_update(struct prestera_flow_block *block,
+					u32 prio)
+{
+	if (prio < block->flower_min_prio)
+		block->flower_min_prio = prio;
+}
+
+int mvsw_pr_flower_replace(struct prestera_switch *sw,
+			   struct prestera_flow_block *block,
 			   struct flow_cls_offload *f)
 {
 	struct prestera_acl_rule *rule;
 	int err;
 
-	rule = prestera_acl_rule_create(block, f->cookie);
+	err = prestera_flower_prio_check(block, f);
+	if (err)
+		return err;
+
+	rule = prestera_acl_rule_create(block, f->cookie,
+					f->common.chain_index);
 	if (IS_ERR(rule))
 		return PTR_ERR(rule);
 
-	err = mvsw_pr_flower_parse(sw, block, rule, f);
+	err = mvsw_pr_flower_parse(block, rule, f);
 	if (err)
 		goto err_flower_parse;
 
@@ -383,6 +458,8 @@ int mvsw_pr_flower_replace(struct mvsw_pr_switch *sw,
 	if (err)
 		goto err_rule_add;
 
+	prestera_flower_prio_update(block, f->common.prio);
+
 	return 0;
 
 err_rule_add:
@@ -391,8 +468,8 @@ int mvsw_pr_flower_replace(struct mvsw_pr_switch *sw,
 	return err;
 }
 
-void mvsw_pr_flower_destroy(struct mvsw_pr_switch *sw,
-			    struct prestera_acl_block *block,
+void mvsw_pr_flower_destroy(struct prestera_switch *sw,
+			    struct prestera_flow_block *block,
 			    struct flow_cls_offload *f)
 {
 	struct prestera_acl_rule *rule;
@@ -405,8 +482,8 @@ void mvsw_pr_flower_destroy(struct mvsw_pr_switch *sw,
 	}
 }
 
-int mvsw_pr_flower_stats(struct mvsw_pr_switch *sw,
-			 struct prestera_acl_block *block,
+int mvsw_pr_flower_stats(struct prestera_switch *sw,
+			 struct prestera_flow_block *block,
 			 struct flow_cls_offload *f)
 {
 	struct prestera_acl_rule *rule;
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
index e1c9f6a..adae534 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.c
@@ -28,7 +28,7 @@
 
 #define mvsw_dev(sw)		((sw)->dev->dev)
 
-static void mvsw_pr_fw_log_evt_handler(struct mvsw_pr_switch *,
+static void mvsw_pr_fw_log_evt_handler(struct prestera_switch *,
 				       struct mvsw_pr_event *,
 				       void *);
 static ssize_t mvsw_pr_fw_log_debugfs_read(struct file *file,
@@ -40,8 +40,8 @@ static ssize_t mvsw_pr_fw_log_debugfs_write(struct file *file,
 static inline int mvsw_pr_fw_log_get_type_from_str(const char *str);
 static inline int mvsw_pr_fw_log_get_lib_from_str(const char *str);
 
-static int mvsw_pr_fw_log_event_handler_register(struct mvsw_pr_switch *sw);
-static void mvsw_pr_fw_log_event_handler_unregister(struct mvsw_pr_switch *sw);
+static int mvsw_pr_fw_log_event_handler_register(struct prestera_switch *sw);
+static void mvsw_pr_fw_log_event_handler_unregister(struct prestera_switch *sw);
 
 struct mvsw_pr_fw_log_prv_debugfs {
 	struct dentry *cfg_dir;
@@ -126,7 +126,7 @@ static const char *mvsw_pr_fw_log_prv_type_id2name[MVSW_FW_LOG_TYPE_MAX] = {
 	[MVSW_FW_LOG_TYPE_NONE]  = "none",
 };
 
-static void mvsw_pr_fw_log_evt_handler(struct mvsw_pr_switch *sw,
+static void mvsw_pr_fw_log_evt_handler(struct prestera_switch *sw,
 				       struct mvsw_pr_event *evt, void *arg)
 {
 	u32 log_len = evt->fw_log_evt.log_len;
@@ -269,7 +269,7 @@ static ssize_t mvsw_pr_fw_log_debugfs_write(struct file *file,
 					    const char __user *ubuf,
 					    size_t count, loff_t *ppos)
 {
-	struct mvsw_pr_switch *sw = file->private_data;
+	struct prestera_switch *sw = file->private_data;
 	int lib, type;
 	int i, j;
 	int err;
@@ -358,19 +358,19 @@ static inline int mvsw_pr_fw_log_get_lib_from_str(const char *str)
 	return MVSW_FW_LOG_LIB_MAX;
 }
 
-static int mvsw_pr_fw_log_event_handler_register(struct mvsw_pr_switch *sw)
+static int mvsw_pr_fw_log_event_handler_register(struct prestera_switch *sw)
 {
 	return mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_FW_LOG,
 						 mvsw_pr_fw_log_evt_handler,
 						 NULL);
 }
 
-static void mvsw_pr_fw_log_event_handler_unregister(struct mvsw_pr_switch *sw)
+static void mvsw_pr_fw_log_event_handler_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_FW_LOG);
 }
 
-int mvsw_pr_fw_log_init(struct mvsw_pr_switch *sw)
+int mvsw_pr_fw_log_init(struct prestera_switch *sw)
 {
 	fw_log_debugfs_handle.cfg_dir =
 		debugfs_create_dir(FW_LOG_DBGFS_CFG_DIR, NULL);
@@ -411,7 +411,7 @@ int mvsw_pr_fw_log_init(struct mvsw_pr_switch *sw)
 	return -1;
 }
 
-void mvsw_pr_fw_log_fini(struct mvsw_pr_switch *sw)
+void mvsw_pr_fw_log_fini(struct prestera_switch *sw)
 {
 	mvsw_pr_fw_log_event_handler_unregister(sw);
 
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
index ccd5514..9bd17b8 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_fw_log.h
@@ -9,7 +9,7 @@
 
 #include "prestera.h"
 
-int  mvsw_pr_fw_log_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_fw_log_fini(struct mvsw_pr_switch *sw);
+int  mvsw_pr_fw_log_init(struct prestera_switch *sw);
+void mvsw_pr_fw_log_fini(struct prestera_switch *sw);
 
 #endif /* _MVSW_PRESTERA_FW_LOG_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.c b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
index eb0a544..b2161d1 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
@@ -8,8 +8,8 @@
 #include <linux/netdevice.h>
 #include <linux/list.h>
 
-#include "prestera_hw.h"
 #include "prestera.h"
+#include "prestera_hw.h"
 #include "prestera_log.h"
 #include "prestera_fw_log.h"
 #include "prestera_rxtx.h"
@@ -18,13 +18,24 @@
 #define MVSW_PR_MIN_MTU 64
 #define MVSW_PR_MSG_BUFF_CHUNK_SIZE	32	/* bytes */
 
+#ifndef MVSW_FW_WD_KICK_TIMEOUT
+#define MVSW_FW_WD_KICK_TIMEOUT		1000
+#endif /* MVSW_FW_WD_KICK_TIMEOUT */
+
+#ifndef MVSW_FW_KEEPALIVE_WD_MAX_KICKS
+#define MVSW_FW_KEEPALIVE_WD_MAX_KICKS			15
+#endif /* MVSW_FW_KEEPALIVE_WD_MAX_KICKS */
+
 enum mvsw_msg_type {
 	MVSW_MSG_TYPE_SWITCH_INIT = 0x1,
 	MVSW_MSG_TYPE_SWITCH_ATTR_SET = 0x2,
 
+	MVSW_MSG_TYPE_KEEPALIVE_INIT = 0x3,
+
 	MVSW_MSG_TYPE_PORT_ATTR_SET = 0x100,
 	MVSW_MSG_TYPE_PORT_ATTR_GET = 0x101,
 	MVSW_MSG_TYPE_PORT_INFO_GET = 0x110,
+	MVSW_MSG_TYPE_PORT_RATE_LIMIT_MODE_SET = 0x111,
 
 	MVSW_MSG_TYPE_VLAN_CREATE = 0x200,
 	MVSW_MSG_TYPE_VLAN_DELETE = 0x201,
@@ -61,6 +72,7 @@ enum mvsw_msg_type {
 	MVSW_MSG_TYPE_ROUTER_LPM_DELETE = 0x611,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_SET = 0x622,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_GET = 0x644,
+	MVSW_MSG_TYPE_ROUTER_NH_GRP_BLK_GET = 0x645,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_ADD = 0x623,
 	MVSW_MSG_TYPE_ROUTER_NH_GRP_DELETE = 0x624,
 	MVSW_MSG_TYPE_ROUTER_VR_CREATE = 0x630,
@@ -78,6 +90,15 @@ enum mvsw_msg_type {
 
 	MVSW_MSG_TYPE_STP_PORT_SET = 0x1000,
 
+	MVSW_MSG_TYPE_SPAN_GET = 0X1100,
+	MVSW_MSG_TYPE_SPAN_BIND = 0X1101,
+	MVSW_MSG_TYPE_SPAN_UNBIND = 0X1102,
+	MVSW_MSG_TYPE_SPAN_RELEASE = 0X1103,
+
+	MVSW_MSG_TYPE_NAT_PORT_NEIGH_UPDATE = 0X1200,
+
+	MVSW_MSG_TYPE_CPU_CODE_COUNTERS_GET = 0x2000,
+
 	MVSW_MSG_TYPE_ACK = 0x10000,
 	MVSW_MSG_TYPE_MAX
 };
@@ -220,6 +241,7 @@ struct mvsw_msg_switch_init_ret {
 	u8  switch_id;
 	u8  lag_max;
 	u8  lag_member_max;
+	u32 size_tbl_router_nexthop;
 } __packed __aligned(4);
 
 struct mvsw_msg_port_autoneg_param {
@@ -294,6 +316,14 @@ struct mvsw_msg_port_info_ret {
 	u16 fp_id;
 } __packed __aligned(4);
 
+struct mvsw_msg_port_storm_control_cfg_set_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 port;
+	u32 dev;
+	u32 storm_type;
+	u32 kbyte_per_sec_rate;
+} __packed __aligned(4);
+
 struct mvsw_msg_vlan_cmd {
 	struct mvsw_msg_cmd cmd;
 	u32 port;
@@ -325,10 +355,91 @@ struct mvsw_msg_log_lvl_set_cmd {
 	u32 type;
 } __packed __aligned(4);
 
+struct mvsw_msg_iface {
+	u8 type;
+	u16 vid;
+	u16 vr_id;
+	union {
+		struct {
+			u32 dev;
+			u32 port;
+		} __packed;
+		u16 lag_id;
+	};
+} __packed;
+
+struct mvsw_msg_nh {
+	struct mvsw_msg_iface oif;
+	u8 is_active;
+	u32 hw_id;
+	u8 mac[ETH_ALEN];
+} __packed;
+
+struct mvsw_msg_acl_action {
+	u32 id;
+	union {
+		struct {
+			u64 rate;
+			u64 burst;
+		} __packed police;
+		struct {
+			u8 l4_src_valid:1, l4_dst_valid:1,
+			   sip_valid:1, dip_valid:1;
+			__be16 l4_src;
+			__be16 l4_dst;
+			__be32 sip;
+			__be32 dip;
+			struct mvsw_msg_nh nh;
+		} __packed mangle;
+		struct {
+			__be32 old_addr;
+			__be32 new_addr;
+			u32 port;
+			u32 dev;
+			u32 flags;
+		} __packed nat;
+		struct {
+			u32 chain;
+		} __packed jump;
+	};
+} __packed __aligned(4);
+
+struct mvsw_msg_acl_match {
+	u32 type;
+	union {
+		struct {
+			u8 key;
+			u8 mask;
+		} __packed u8;
+		struct {
+			u16 key;
+			u16 mask;
+		} __packed u16;
+		struct {
+			u32 key;
+			u32 mask;
+		} __packed u32;
+		struct {
+			u64 key;
+			u64 mask;
+		} __packed u64;
+		struct {
+			u8 key[ETH_ALEN];
+			u8 mask[ETH_ALEN];
+		} __packed mac;
+	} keymask;
+} __packed __aligned(4);
+
 struct mvsw_msg_acl_rule_cmd {
 	struct mvsw_msg_cmd cmd;
 	u32 id;
+	u32 priority;
 	u16 ruleset_id;
+	u8 chain_id;
+	u8 hw_tc;
+	u8 n_actions;
+	u8 n_matches;
+	u32 chain;
 } __packed __aligned(4);
 
 struct mvsw_msg_acl_rule_ret {
@@ -359,6 +470,25 @@ struct mvsw_msg_acl_ruleset_ret {
 	u16 id;
 } __packed __aligned(4);
 
+struct mvsw_msg_nat_port_cmd {
+	struct mvsw_msg_cmd cmd;
+	u8 neigh_mac[ETH_ALEN];
+	u32 port;
+	u32 dev;
+} __packed __aligned(4);
+
+struct mvsw_msg_span_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 port;
+	u32 dev;
+	u8 id;
+} __packed __aligned(4);
+
+struct mvsw_msg_span_ret {
+	struct mvsw_msg_ret ret;
+	u8 id;
+} __packed __aligned(4);
+
 struct mvsw_msg_event {
 	u16 type;
 	u16 id;
@@ -424,19 +554,6 @@ struct mvsw_msg_stp_cmd {
 	u8  state;
 } __packed __aligned(4);
 
-struct mvsw_msg_iface {
-	u8 type;
-	u16 vid;
-	u16 vr_id;
-	union {
-		struct {
-			u32 dev;
-			u32 port;
-		};
-		u16 lag_id;
-	};
-} __packed __aligned(4);
-
 struct mvsw_msg_rif_cmd {
 	struct mvsw_msg_cmd cmd;
 	struct mvsw_msg_iface iif;
@@ -458,13 +575,6 @@ struct mvsw_msg_lpm_cmd {
 	u16 vr_id;
 } __packed __aligned(4);
 
-struct mvsw_msg_nh {
-	struct mvsw_msg_iface oif;
-	u8 is_active;
-	u32 hw_id;
-	u8 mac[ETH_ALEN];
-} __packed __aligned(4);
-
 struct mvsw_msg_nh_cmd {
 	struct mvsw_msg_cmd cmd;
 	u32 size;
@@ -477,6 +587,16 @@ struct mvsw_msg_nh_ret {
 	struct mvsw_msg_nh nh[MVSW_PR_NHGR_SIZE_MAX];
 } __packed __aligned(4);
 
+struct mvsw_msg_nh_chunk_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 offset;
+} __packed __aligned(4);
+
+struct mvsw_msg_nh_chunk_ret {
+	struct mvsw_msg_ret ret;
+	u8 hw_state[MVSW_MSG_CHUNK_SIZE];
+} __packed __aligned(4);
+
 struct mvsw_msg_nh_grp_cmd {
 	struct mvsw_msg_cmd cmd;
 	u32 grp_id;
@@ -521,6 +641,27 @@ struct mvsw_msg_lag_cmd {
 	u16 vr_id;
 } __packed __aligned(4);
 
+struct mvsw_msg_keepalive_init_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 pulse_timeout_ms;
+} __packed __aligned(4);
+
+struct mvsw_msg_cpu_code_counter_cmd {
+	struct mvsw_msg_cmd cmd;
+	u8 counter_type;
+	u8 code;
+} __packed __aligned(4);
+
+struct mvsw_msg_cpu_code_counter_ret {
+	struct mvsw_msg_ret ret;
+	u64 packet_count;
+} __packed __aligned(4);
+
+static int mvsw_pr_cmd_qid_by_req_type(enum mvsw_msg_type type)
+{
+	return 0;
+}
+
 #define fw_check_resp(_response)	\
 ({								\
 	int __er = 0;						\
@@ -541,6 +682,7 @@ _response, _wait)						\
 	typeof(_response) __resp = (_response);			\
 	__req->cmd.type = (_type);				\
 	__e = __sw->dev->send_req(__sw->dev,			\
+		mvsw_pr_cmd_qid_by_req_type(_type),		\
 		(u8 *)__req, _req_size,				\
 		(u8 *)__resp, sizeof(*__resp),			\
 		_wait);						\
@@ -567,12 +709,34 @@ _response, _wait)						\
 struct mvsw_fw_event_handler {
 	struct list_head list;
 	enum mvsw_pr_event_type type;
-	void (*func)(struct mvsw_pr_switch *sw,
+	void (*func)(struct prestera_switch *sw,
 		     struct mvsw_pr_event *evt,
 		     void *arg);
 	void *arg;
 };
 
+static void mvsw_pr_fw_keepalive_wd_work_fn(struct work_struct *work)
+{
+	struct delayed_work *dl_work =
+		container_of(work, struct delayed_work, work);
+	struct prestera_device *dev =
+		container_of(dl_work, struct prestera_device,
+			     keepalive_wdog_work);
+
+	atomic_t *ctr = &dev->keepalive_wdog_counter;
+
+	if (atomic_add_unless(ctr, 1, MVSW_FW_KEEPALIVE_WD_MAX_KICKS)) {
+		queue_delayed_work(system_long_wq,
+				   &dev->keepalive_wdog_work,
+				   msecs_to_jiffies(MVSW_FW_WD_KICK_TIMEOUT));
+		return;
+	}
+
+	pr_err("fw_keepalive_wdog: Fw is stuck and became non-operational\n");
+
+	dev->running = false;
+}
+
 static int fw_parse_port_evt(u8 *msg, struct mvsw_pr_event *evt)
 {
 	struct mvsw_msg_event_port *hw_evt = (struct mvsw_msg_event_port *)msg;
@@ -634,7 +798,7 @@ static struct mvsw_fw_evt_parser fw_event_parsers[MVSW_EVENT_TYPE_MAX] = {
 };
 
 static struct mvsw_fw_event_handler *
-__find_event_handler(const struct mvsw_pr_switch *sw,
+__find_event_handler(const struct prestera_switch *sw,
 		     enum mvsw_pr_event_type type)
 {
 	struct mvsw_fw_event_handler *eh;
@@ -647,7 +811,7 @@ __find_event_handler(const struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static int mvsw_find_event_handler(const struct mvsw_pr_switch *sw,
+static int mvsw_find_event_handler(const struct prestera_switch *sw,
 				   enum mvsw_pr_event_type type,
 				   struct mvsw_fw_event_handler *eh)
 {
@@ -668,11 +832,14 @@ static int mvsw_find_event_handler(const struct mvsw_pr_switch *sw,
 static int fw_event_recv(struct prestera_device *dev, u8 *buf, size_t size)
 {
 	struct mvsw_msg_event *msg = (struct mvsw_msg_event *)buf;
-	struct mvsw_pr_switch *sw = dev->priv;
+	struct prestera_switch *sw = dev->priv;
 	struct mvsw_fw_event_handler eh;
 	struct mvsw_pr_event evt;
 	int err;
 
+	if (dev->running)
+		atomic_set(&dev->keepalive_wdog_counter, 0);
+
 	if (msg->type >= MVSW_EVENT_TYPE_MAX)
 		return -EINVAL;
 
@@ -692,7 +859,7 @@ static int fw_event_recv(struct prestera_device *dev, u8 *buf, size_t size)
 
 static void fw_pkt_recv(struct prestera_device *dev)
 {
-	struct mvsw_pr_switch *sw = dev->priv;
+	struct prestera_switch *sw = dev->priv;
 	struct mvsw_fw_event_handler eh;
 	struct mvsw_pr_event ev;
 	int err;
@@ -706,112 +873,7 @@ static void fw_pkt_recv(struct prestera_device *dev)
 	eh.func(sw, &ev, eh.arg);
 }
 
-static struct mvsw_msg_buff *mvsw_msg_buff_create(u16 head_size)
-{
-	struct mvsw_msg_buff *msg_buff;
-
-	msg_buff = kzalloc(sizeof(*msg_buff), GFP_KERNEL);
-	if (!msg_buff)
-		return NULL;
-
-	msg_buff->data = kzalloc(MVSW_PR_MSG_BUFF_CHUNK_SIZE + head_size,
-				 GFP_KERNEL);
-	if (!msg_buff->data) {
-		kfree(msg_buff);
-		return NULL;
-	}
-
-	msg_buff->total = MVSW_PR_MSG_BUFF_CHUNK_SIZE + head_size;
-	msg_buff->free = MVSW_PR_MSG_BUFF_CHUNK_SIZE;
-	msg_buff->used = head_size;
-
-	return msg_buff;
-}
-
-static void *mvsw_msg_buff_data(struct mvsw_msg_buff *msg_buff)
-{
-	return msg_buff->data;
-}
-
-static u32 mvsw_msg_buff_size(const struct mvsw_msg_buff *msg_buff)
-{
-	return msg_buff->used;
-}
-
-static int mvsw_msg_buff_resize(struct mvsw_msg_buff *msg_buff)
-{
-	void *data;
-
-	data = krealloc(msg_buff->data,
-			msg_buff->total + MVSW_PR_MSG_BUFF_CHUNK_SIZE,
-			GFP_KERNEL);
-	if (!data)
-		return -ENOMEM;
-
-	msg_buff->total += MVSW_PR_MSG_BUFF_CHUNK_SIZE;
-	msg_buff->free += MVSW_PR_MSG_BUFF_CHUNK_SIZE;
-	msg_buff->data = data;
-
-	return 0;
-}
-
-static int mvsw_msg_buff_put(struct mvsw_msg_buff *msg_buff,
-			     void *data, u16 size)
-{
-	void *data_ptr;
-	int err;
-
-	if (size > msg_buff->free) {
-		err = mvsw_msg_buff_resize(msg_buff);
-		if (err)
-			return err;
-	}
-	/* point to unused data */
-	data_ptr = msg_buff->data + msg_buff->used;
-
-	/* set the data */
-	memcpy(data_ptr, data, size);
-	msg_buff->used += size;
-	msg_buff->free -= size;
-
-	return 0;
-}
-
-static int mvsw_msg_buff_terminate(struct mvsw_msg_buff *msg_buff)
-{
-	u16 padding_size;
-	void *data_ptr;
-	int err;
-
-	/* the data should be aligned to 4 byte, so calculate
-	 * the padding leaving at least one byte for termination
-	 */
-	padding_size = ALIGN(msg_buff->used + sizeof(u8),
-			     sizeof(u32)) - msg_buff->used;
-	if (msg_buff->free < padding_size) {
-		err = mvsw_msg_buff_resize(msg_buff);
-		if (err)
-			return err;
-	}
-	/* point to unused data */
-	data_ptr = msg_buff->data + msg_buff->used;
-
-	/* terminate buffer by zero byte */
-	memset(data_ptr, 0, padding_size);
-	msg_buff->used += padding_size;
-	msg_buff->free -= padding_size;
-	data_ptr += padding_size;
-
-	return 0;
-}
-
-static void mvsw_msg_buff_destroy(struct mvsw_msg_buff *msg_buff)
-{
-	kfree(msg_buff->data);
-	kfree(msg_buff);
-}
-
-int mvsw_pr_hw_port_info_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_info_get(const struct prestera_port *port,
 			     u16 *fp_id, u32 *hw_id, u32 *dev_id)
 {
 	struct mvsw_msg_port_info_ret resp;
@@ -832,8 +894,11 @@ int mvsw_pr_hw_port_info_get(const struct mvsw_pr_port *port,
 	return 0;
 }
 
-int mvsw_pr_hw_switch_init(struct mvsw_pr_switch *sw)
+int mvsw_pr_hw_switch_init(struct prestera_switch *sw)
 {
+	struct mvsw_msg_keepalive_init_cmd keepalive_init_req = {
+		.pulse_timeout_ms = MVSW_FW_WD_KICK_TIMEOUT
+	};
 	struct mvsw_msg_switch_init_ret resp;
 	struct mvsw_msg_common_request req;
 	int err = 0;
@@ -851,13 +916,32 @@ int mvsw_pr_hw_switch_init(struct mvsw_pr_switch *sw)
 	sw->mtu_max = resp.mtu_max;
 	sw->lag_max = resp.lag_max;
 	sw->lag_member_max = resp.lag_member_max;
+	sw->size_tbl_router_nexthop = resp.size_tbl_router_nexthop;
 	sw->dev->recv_msg = fw_event_recv;
 	sw->dev->recv_pkt = fw_pkt_recv;
 
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_KEEPALIVE_INIT,
+			       &keepalive_init_req, &resp);
+	if (err)
+		return err;
+
+	INIT_DELAYED_WORK(&sw->dev->keepalive_wdog_work,
+			  mvsw_pr_fw_keepalive_wd_work_fn);
+
+	queue_delayed_work(system_long_wq,
+			   &sw->dev->keepalive_wdog_work,
+			   msecs_to_jiffies(MVSW_FW_WD_KICK_TIMEOUT));
+
 	return err;
 }
 
-int mvsw_pr_hw_switch_ageing_set(const struct mvsw_pr_switch *sw,
+void mvsw_pr_hw_keepalive_fini(const struct prestera_switch *sw)
+{
+	if (sw->dev->running)
+		cancel_delayed_work_sync(&sw->dev->keepalive_wdog_work);
+}
+
+int mvsw_pr_hw_switch_ageing_set(const struct prestera_switch *sw,
 				 u32 ageing_time)
 {
 	struct mvsw_msg_switch_attr_cmd req = {
@@ -868,7 +952,7 @@ int mvsw_pr_hw_switch_ageing_set(const struct mvsw_pr_switch *sw,
 	return fw_send_req(sw, MVSW_MSG_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_switch_mac_set(const struct mvsw_pr_switch *sw, const u8 *mac)
+int mvsw_pr_hw_switch_mac_set(const struct prestera_switch *sw, const u8 *mac)
 {
 	struct mvsw_msg_switch_attr_cmd req = {
 		.attr = MVSW_MSG_SWITCH_ATTR_MAC,
@@ -879,7 +963,7 @@ int mvsw_pr_hw_switch_mac_set(const struct mvsw_pr_switch *sw, const u8 *mac)
 	return fw_send_req(sw, MVSW_MSG_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_switch_trap_policer_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_switch_trap_policer_set(const struct prestera_switch *sw,
 				       u8 profile)
 {
 	struct mvsw_msg_switch_attr_cmd req = {
@@ -890,7 +974,7 @@ int mvsw_pr_hw_switch_trap_policer_set(const struct mvsw_pr_switch *sw,
 	return fw_send_req(sw, MVSW_MSG_TYPE_SWITCH_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_state_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_state_set(const struct prestera_port *port,
 			      bool admin_state)
 {
 	struct mvsw_msg_port_attr_cmd req = {
@@ -903,7 +987,7 @@ int mvsw_pr_hw_port_state_set(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_state_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_state_get(const struct prestera_port *port,
 			      bool *admin_state, bool *oper_state)
 {
 	struct mvsw_msg_port_attr_ret resp;
@@ -934,7 +1018,7 @@ int mvsw_pr_hw_port_state_get(const struct mvsw_pr_port *port,
 	return 0;
 }
 
-int mvsw_pr_hw_port_mtu_set(const struct mvsw_pr_port *port, u32 mtu)
+int mvsw_pr_hw_port_mtu_set(const struct prestera_port *port, u32 mtu)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_MTU,
@@ -946,7 +1030,7 @@ int mvsw_pr_hw_port_mtu_set(const struct mvsw_pr_port *port, u32 mtu)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_mtu_get(const struct mvsw_pr_port *port, u32 *mtu)
+int mvsw_pr_hw_port_mtu_get(const struct prestera_port *port, u32 *mtu)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -966,7 +1050,7 @@ int mvsw_pr_hw_port_mtu_get(const struct mvsw_pr_port *port, u32 *mtu)
 	return err;
 }
 
-int mvsw_pr_hw_port_mac_set(const struct mvsw_pr_port *port, char *mac)
+int mvsw_pr_hw_port_mac_set(const struct prestera_port *port, char *mac)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_MAC,
@@ -978,7 +1062,7 @@ int mvsw_pr_hw_port_mac_set(const struct mvsw_pr_port *port, char *mac)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_mac_get(const struct mvsw_pr_port *port, char *mac)
+int mvsw_pr_hw_port_mac_get(const struct prestera_port *port, char *mac)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -998,7 +1082,7 @@ int mvsw_pr_hw_port_mac_get(const struct mvsw_pr_port *port, char *mac)
 	return err;
 }
 
-int mvsw_pr_hw_port_accept_frame_type_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_accept_frame_type_set(const struct prestera_port *port,
 					  enum mvsw_pr_accept_frame_type type)
 {
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1011,7 +1095,7 @@ int mvsw_pr_hw_port_accept_frame_type_set(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_learning_set(const struct mvsw_pr_port *port, bool enable)
+int mvsw_pr_hw_port_learning_set(const struct prestera_port *port, bool enable)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_LEARNING,
@@ -1023,9 +1107,9 @@ int mvsw_pr_hw_port_learning_set(const struct mvsw_pr_port *port, bool enable)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_event_handler_register(struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_event_handler_register(struct prestera_switch *sw,
 				      enum mvsw_pr_event_type type,
-				      void (*cb)(struct mvsw_pr_switch *sw,
+				      void (*cb)(struct prestera_switch *sw,
 						 struct mvsw_pr_event *evt,
 						 void *arg),
 				      void *arg)
@@ -1050,7 +1134,7 @@ int mvsw_pr_hw_event_handler_register(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-void mvsw_pr_hw_event_handler_unregister(struct mvsw_pr_switch *sw,
+void mvsw_pr_hw_event_handler_unregister(struct prestera_switch *sw,
 					 enum mvsw_pr_event_type type)
 {
 	struct mvsw_fw_event_handler *eh;
@@ -1064,7 +1148,7 @@ void mvsw_pr_hw_event_handler_unregister(struct mvsw_pr_switch *sw,
 	kfree(eh);
 }
 
-int mvsw_pr_hw_vlan_create(const struct mvsw_pr_switch *sw, u16 vid)
+int mvsw_pr_hw_vlan_create(const struct prestera_switch *sw, u16 vid)
 {
 	struct mvsw_msg_vlan_cmd req = {
 		.vid = vid,
@@ -1073,7 +1157,7 @@ int mvsw_pr_hw_vlan_create(const struct mvsw_pr_switch *sw, u16 vid)
 	return fw_send_req(sw, MVSW_MSG_TYPE_VLAN_CREATE, &req);
 }
 
-int mvsw_pr_hw_vlan_delete(const struct mvsw_pr_switch *sw, u16 vid)
+int mvsw_pr_hw_vlan_delete(const struct prestera_switch *sw, u16 vid)
 {
 	struct mvsw_msg_vlan_cmd req = {
 		.vid = vid,
@@ -1082,7 +1166,7 @@ int mvsw_pr_hw_vlan_delete(const struct mvsw_pr_switch *sw, u16 vid)
 	return fw_send_req(sw, MVSW_MSG_TYPE_VLAN_DELETE, &req);
 }
 
-int mvsw_pr_hw_vlan_port_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_vlan_port_set(const struct prestera_port *port,
 			     u16 vid, bool is_member, bool untagged)
 {
 	struct mvsw_msg_vlan_cmd req = {
@@ -1096,7 +1180,7 @@ int mvsw_pr_hw_vlan_port_set(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_VLAN_PORT_SET, &req);
 }
 
-int mvsw_pr_hw_vlan_port_vid_set(const struct mvsw_pr_port *port, u16 vid)
+int mvsw_pr_hw_vlan_port_vid_set(const struct prestera_port *port, u16 vid)
 {
 	struct mvsw_msg_vlan_cmd req = {
 		.port = port->hw_id,
@@ -1107,7 +1191,7 @@ int mvsw_pr_hw_vlan_port_vid_set(const struct mvsw_pr_port *port, u16 vid)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_VLAN_PVID_SET, &req);
 }
 
-int mvsw_pr_hw_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
+int mvsw_pr_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state)
 {
 	struct mvsw_msg_stp_cmd req = {
 		.port = port->hw_id,
@@ -1119,7 +1203,7 @@ int mvsw_pr_hw_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_STP_PORT_SET, &req);
 }
 
-int mvsw_pr_hw_port_speed_get(const struct mvsw_pr_port *port, u32 *speed)
+int mvsw_pr_hw_port_speed_get(const struct prestera_port *port, u32 *speed)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1139,7 +1223,7 @@ int mvsw_pr_hw_port_speed_get(const struct mvsw_pr_port *port, u32 *speed)
 	return err;
 }
 
-int mvsw_pr_hw_port_uc_flood_set(const struct mvsw_pr_port *port, bool flood)
+int mvsw_pr_hw_port_uc_flood_set(const struct prestera_port *port, bool flood)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_FLOOD,
@@ -1156,7 +1240,7 @@ int mvsw_pr_hw_port_uc_flood_set(const struct mvsw_pr_port *port, bool flood)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_mc_flood_set(const struct mvsw_pr_port *port, bool flood)
+int mvsw_pr_hw_port_mc_flood_set(const struct prestera_port *port, bool flood)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_FLOOD,
@@ -1173,7 +1257,7 @@ int mvsw_pr_hw_port_mc_flood_set(const struct mvsw_pr_port *port, bool flood)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_fdb_add(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_fdb_add(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid, bool dynamic)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1191,7 +1275,7 @@ int mvsw_pr_hw_fdb_add(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_ADD, &req);
 }
 
-int mvsw_pr_hw_lag_fdb_add(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_add(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid, bool dynamic)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1206,7 +1290,7 @@ int mvsw_pr_hw_lag_fdb_add(const struct mvsw_pr_switch *sw, u16 lag_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_ADD, &req);
 }
 
-int mvsw_pr_hw_fdb_del(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_fdb_del(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1223,7 +1307,7 @@ int mvsw_pr_hw_fdb_del(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_DELETE, &req);
 }
 
-int mvsw_pr_hw_lag_fdb_del(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_del(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1237,7 +1321,7 @@ int mvsw_pr_hw_lag_fdb_del(const struct mvsw_pr_switch *sw, u16 lag_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_DELETE, &req);
 }
 
-int mvsw_pr_hw_port_cap_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_cap_get(const struct prestera_port *port,
 			    struct mvsw_pr_port_caps *caps)
 {
 	struct mvsw_msg_port_attr_ret resp;
@@ -1261,7 +1345,7 @@ int mvsw_pr_hw_port_cap_get(const struct mvsw_pr_port *port,
 	return err;
 }
 
-int mvsw_pr_hw_port_remote_cap_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_remote_cap_get(const struct prestera_port *port,
 				   u64 *link_mode_bitmap)
 {
 	struct mvsw_msg_port_attr_ret resp;
@@ -1310,7 +1394,7 @@ static u8 mvsw_mdix_from_eth(u8 mode)
 	return MVSW_PORT_TP_NA;
 }
 
-int mvsw_pr_hw_port_mdix_get(const struct mvsw_pr_port *port, u8 *status,
+int mvsw_pr_hw_port_mdix_get(const struct prestera_port *port, u8 *status,
 			     u8 *admin_mode)
 {
 	struct mvsw_msg_port_attr_ret resp;
@@ -1332,7 +1416,7 @@ int mvsw_pr_hw_port_mdix_get(const struct mvsw_pr_port *port, u8 *status,
 	return 0;
 }
 
-int mvsw_pr_hw_port_mdix_set(const struct mvsw_pr_port *port, u8 mode)
+int mvsw_pr_hw_port_mdix_set(const struct prestera_port *port, u8 mode)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_MDIX,
@@ -1345,7 +1429,7 @@ int mvsw_pr_hw_port_mdix_set(const struct mvsw_pr_port *port, u8 mode)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_type_get(const struct mvsw_pr_port *port, u8 *type)
+int mvsw_pr_hw_port_type_get(const struct prestera_port *port, u8 *type)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1365,7 +1449,7 @@ int mvsw_pr_hw_port_type_get(const struct mvsw_pr_port *port, u8 *type)
 	return err;
 }
 
-int mvsw_pr_hw_port_fec_get(const struct mvsw_pr_port *port, u8 *fec)
+int mvsw_pr_hw_port_fec_get(const struct prestera_port *port, u8 *fec)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1385,7 +1469,7 @@ int mvsw_pr_hw_port_fec_get(const struct mvsw_pr_port *port, u8 *fec)
 	return err;
 }
 
-int mvsw_pr_hw_port_fec_set(const struct mvsw_pr_port *port, u8 fec)
+int mvsw_pr_hw_port_fec_set(const struct prestera_port *port, u8 fec)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_FEC,
@@ -1397,7 +1481,7 @@ int mvsw_pr_hw_port_fec_set(const struct mvsw_pr_port *port, u8 fec)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_fw_log_level_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_fw_log_level_set(const struct prestera_switch *sw,
 				u32 lib, u32 type)
 {
 	struct mvsw_msg_log_lvl_set_cmd req = {
@@ -1413,7 +1497,7 @@ int mvsw_pr_hw_fw_log_level_set(const struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-int mvsw_pr_hw_port_autoneg_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_autoneg_set(const struct prestera_port *port,
 				bool autoneg, u64 link_modes, u8 fec)
 {
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1429,7 +1513,7 @@ int mvsw_pr_hw_port_autoneg_set(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_duplex_get(const struct mvsw_pr_port *port, u8 *duplex)
+int mvsw_pr_hw_port_duplex_get(const struct prestera_port *port, u8 *duplex)
 {
 	struct mvsw_msg_port_attr_ret resp;
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1449,7 +1533,7 @@ int mvsw_pr_hw_port_duplex_get(const struct mvsw_pr_port *port, u8 *duplex)
 	return err;
 }
 
-int mvsw_pr_hw_port_stats_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_stats_get(const struct prestera_port *port,
 			      struct mvsw_pr_port_stats *stats)
 {
 	struct mvsw_msg_port_stats_ret resp;
@@ -1505,7 +1589,7 @@ int mvsw_pr_hw_port_stats_get(const struct mvsw_pr_port *port,
 	return 0;
 }
 
-int mvsw_pr_hw_bridge_create(const struct mvsw_pr_switch *sw, u16 *bridge_id)
+int mvsw_pr_hw_bridge_create(const struct prestera_switch *sw, u16 *bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req;
 	struct mvsw_msg_bridge_ret resp;
@@ -1519,7 +1603,7 @@ int mvsw_pr_hw_bridge_create(const struct mvsw_pr_switch *sw, u16 *bridge_id)
 	return err;
 }
 
-int mvsw_pr_hw_bridge_delete(const struct mvsw_pr_switch *sw, u16 bridge_id)
+int mvsw_pr_hw_bridge_delete(const struct prestera_switch *sw, u16 bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req = {
 		.bridge = bridge_id
@@ -1528,7 +1612,7 @@ int mvsw_pr_hw_bridge_delete(const struct mvsw_pr_switch *sw, u16 bridge_id)
 	return fw_send_req(sw, MVSW_MSG_TYPE_BRIDGE_DELETE, &req);
 }
 
-int mvsw_pr_hw_bridge_port_add(const struct mvsw_pr_port *port, u16 bridge_id)
+int mvsw_pr_hw_bridge_port_add(const struct prestera_port *port, u16 bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req = {
 		.bridge = bridge_id,
@@ -1539,7 +1623,7 @@ int mvsw_pr_hw_bridge_port_add(const struct mvsw_pr_port *port, u16 bridge_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_BRIDGE_PORT_ADD, &req);
 }
 
-int mvsw_pr_hw_bridge_port_delete(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_bridge_port_delete(const struct prestera_port *port,
 				  u16 bridge_id)
 {
 	struct mvsw_msg_bridge_cmd req = {
@@ -1551,7 +1635,7 @@ int mvsw_pr_hw_bridge_port_delete(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_BRIDGE_PORT_DELETE, &req);
 }
 
-int mvsw_pr_hw_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid)
 {
 	struct mvsw_msg_macvlan_cmd req = {
@@ -1564,7 +1648,7 @@ int mvsw_pr_hw_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_MACVLAN_ADD, &req);
 }
 
-int mvsw_pr_hw_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid)
 {
 	struct mvsw_msg_macvlan_cmd req = {
@@ -1577,7 +1661,7 @@ int mvsw_pr_hw_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_MACVLAN_DEL, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_port(const struct mvsw_pr_port *port, u32 mode)
+int mvsw_pr_hw_fdb_flush_port(const struct prestera_port *port, u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
 		.dest_type = MVSW_HW_FDB_ENTRY_TYPE_REG_PORT,
@@ -1591,7 +1675,7 @@ int mvsw_pr_hw_fdb_flush_port(const struct mvsw_pr_port *port, u32 mode)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_lag(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_fdb_flush_lag(const struct prestera_switch *sw, u16 lag_id,
 			     u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1603,7 +1687,7 @@ int mvsw_pr_hw_fdb_flush_lag(const struct mvsw_pr_switch *sw, u16 lag_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_vlan(const struct mvsw_pr_switch *sw, u16 vid,
+int mvsw_pr_hw_fdb_flush_vlan(const struct prestera_switch *sw, u16 vid,
 			      u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1614,7 +1698,7 @@ int mvsw_pr_hw_fdb_flush_vlan(const struct mvsw_pr_switch *sw, u16 vid,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_FLUSH_VLAN, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_port_vlan(const struct mvsw_pr_port *port, u16 vid,
+int mvsw_pr_hw_fdb_flush_port_vlan(const struct prestera_port *port, u16 vid,
 				   u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1630,7 +1714,7 @@ int mvsw_pr_hw_fdb_flush_port_vlan(const struct mvsw_pr_port *port, u16 vid,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT_VLAN, &req);
 }
 
-int mvsw_pr_hw_fdb_flush_lag_vlan(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_fdb_flush_lag_vlan(const struct prestera_switch *sw,
 				  u16 lag_id, u16 vid, u32 mode)
 {
 	struct mvsw_msg_fdb_cmd req = {
@@ -1643,7 +1727,7 @@ int mvsw_pr_hw_fdb_flush_lag_vlan(const struct mvsw_pr_switch *sw,
 	return fw_send_req(sw, MVSW_MSG_TYPE_FDB_FLUSH_PORT_VLAN, &req);
 }
 
-int mvsw_pr_hw_port_link_mode_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_link_mode_get(const struct prestera_port *port,
 				  u32 *mode)
 {
 	struct mvsw_msg_port_attr_ret resp;
@@ -1664,7 +1748,7 @@ int mvsw_pr_hw_port_link_mode_get(const struct mvsw_pr_port *port,
 	return err;
 }
 
-int mvsw_pr_hw_port_link_mode_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_link_mode_set(const struct prestera_port *port,
 				  u32 mode)
 {
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1677,6 +1761,21 @@ int mvsw_pr_hw_port_link_mode_set(const struct mvsw_pr_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
+int mvsw_pr_hw_port_storm_control_cfg_set(const struct prestera_port *port,
+					  u32 storm_type,
+					  u32 kbyte_per_sec_rate)
+{
+	struct mvsw_msg_port_storm_control_cfg_set_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
+		.storm_type = storm_type,
+		.kbyte_per_sec_rate = kbyte_per_sec_rate
+	};
+
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_RATE_LIMIT_MODE_SET,
+			   &req);
+}
+
 static int mvsw_pr_iface_to_msg(struct mvsw_pr_iface *iface,
 				struct mvsw_msg_iface *msg_if)
 {
@@ -1699,7 +1798,7 @@ static int mvsw_pr_iface_to_msg(struct mvsw_pr_iface *iface,
 	return 0;
 }
 
-int mvsw_pr_hw_rif_create(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_rif_create(const struct prestera_switch *sw,
 			  struct mvsw_pr_iface *iif, u8 *mac, u16 *rif_id)
 {
 	struct mvsw_msg_rif_cmd req;
@@ -1721,7 +1820,7 @@ int mvsw_pr_hw_rif_create(const struct mvsw_pr_switch *sw,
 	return err;
 }
 
-int mvsw_pr_hw_rif_delete(const struct mvsw_pr_switch *sw, u16 rif_id,
+int mvsw_pr_hw_rif_delete(const struct prestera_switch *sw, u16 rif_id,
 			  struct mvsw_pr_iface *iif)
 {
 	struct mvsw_msg_rif_cmd req = {
@@ -1736,7 +1835,7 @@ int mvsw_pr_hw_rif_delete(const struct mvsw_pr_switch *sw, u16 rif_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_RIF_DELETE, &req);
 }
 
-int mvsw_pr_hw_rif_set(const struct mvsw_pr_switch *sw, u16 *rif_id,
+int mvsw_pr_hw_rif_set(const struct prestera_switch *sw, u16 *rif_id,
 		       struct mvsw_pr_iface *iif, u8 *mac)
 {
 	struct mvsw_msg_rif_ret resp;
@@ -1759,7 +1858,7 @@ int mvsw_pr_hw_rif_set(const struct mvsw_pr_switch *sw, u16 *rif_id,
 	return err;
 }
 
-int mvsw_pr_hw_vr_create(const struct mvsw_pr_switch *sw, u16 *vr_id)
+int mvsw_pr_hw_vr_create(const struct prestera_switch *sw, u16 *vr_id)
 {
 	int err;
 	struct mvsw_msg_vr_ret resp;
@@ -1773,7 +1872,7 @@ int mvsw_pr_hw_vr_create(const struct mvsw_pr_switch *sw, u16 *vr_id)
 	return err;
 }
 
-int mvsw_pr_hw_vr_delete(const struct mvsw_pr_switch *sw, u16 vr_id)
+int mvsw_pr_hw_vr_delete(const struct prestera_switch *sw, u16 vr_id)
 {
 	struct mvsw_msg_vr_cmd req = {
 		.vr_id = vr_id,
@@ -1782,7 +1881,7 @@ int mvsw_pr_hw_vr_delete(const struct mvsw_pr_switch *sw, u16 vr_id)
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_VR_DELETE, &req);
 }
 
-int mvsw_pr_hw_vr_abort(const struct mvsw_pr_switch *sw, u16 vr_id)
+int mvsw_pr_hw_vr_abort(const struct prestera_switch *sw, u16 vr_id)
 {
 	struct mvsw_msg_vr_cmd req = {
 		.vr_id = vr_id,
@@ -1791,7 +1890,7 @@ int mvsw_pr_hw_vr_abort(const struct mvsw_pr_switch *sw, u16 vr_id)
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_VR_ABORT, &req);
 }
 
-int mvsw_pr_hw_lpm_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_lpm_add(const struct prestera_switch *sw, u16 vr_id,
 		       __be32 dst, u32 dst_len, u32 grp_id)
 {
 	struct mvsw_msg_lpm_cmd req = {
@@ -1804,7 +1903,7 @@ int mvsw_pr_hw_lpm_add(const struct mvsw_pr_switch *sw, u16 vr_id,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_LPM_ADD, &req);
 }
 
-int mvsw_pr_hw_lpm_del(const struct mvsw_pr_switch *sw, u16 vr_id, __be32 dst,
+int mvsw_pr_hw_lpm_del(const struct prestera_switch *sw, u16 vr_id, __be32 dst,
 		       u32 dst_len)
 {
 	struct mvsw_msg_lpm_cmd req = {
@@ -1816,7 +1915,7 @@ int mvsw_pr_hw_lpm_del(const struct mvsw_pr_switch *sw, u16 vr_id, __be32 dst,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_LPM_DELETE, &req);
 }
 
-int mvsw_pr_hw_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
+int mvsw_pr_hw_nh_entries_set(const struct prestera_switch *sw, int count,
 			      struct mvsw_pr_neigh_info *nhs, u32 grp_id)
 {
 	struct mvsw_msg_nh_cmd req = { .size = count, .grp_id = grp_id };
@@ -1835,7 +1934,7 @@ int mvsw_pr_hw_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
 
 /* TODO: more than one nh */
 /* For now "count = 1" supported only */
-int mvsw_pr_hw_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
+int mvsw_pr_hw_nh_entries_get(const struct prestera_switch *sw, int count,
 			      struct mvsw_pr_neigh_info *nhs, u32 grp_id)
 {
 	struct mvsw_msg_nh_cmd req = { .size = count, .grp_id = grp_id };
@@ -1853,7 +1952,37 @@ int mvsw_pr_hw_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
 	return err;
 }
 
-int mvsw_pr_hw_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nhgrp_blk_get(const struct prestera_switch *sw,
+			     u8 *hw_state, u32 buf_size /* Buffer in bytes */)
+{
+	struct mvsw_msg_nh_chunk_cmd req;
+	static struct mvsw_msg_nh_chunk_ret resp;
+	int err;
+	u32 buf_offset;
+
+	memset(&hw_state[0], 0, buf_size);
+	buf_offset = 0;
+	while (1) {
+		if (buf_offset >= buf_size)
+			break;
+
+		memset(&req, 0, sizeof(req));
+		req.offset = buf_offset * 8; /* 8 bits in u8 */
+		err = fw_send_req_resp(sw, MVSW_MSG_TYPE_ROUTER_NH_GRP_BLK_GET,
+				       &req, &resp);
+		if (err)
+			return err;
+
+		memcpy(&hw_state[buf_offset], &resp.hw_state[0],
+		       buf_offset + MVSW_MSG_CHUNK_SIZE > buf_size ?
+			buf_size - buf_offset : MVSW_MSG_CHUNK_SIZE);
+		buf_offset += MVSW_MSG_CHUNK_SIZE;
+	}
+
+	return err;
+}
+
+int mvsw_pr_hw_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
 			       u32 *grp_id)
 {
 	struct mvsw_msg_nh_grp_cmd req = { .size = nh_count };
@@ -1869,7 +1998,7 @@ int mvsw_pr_hw_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return err;
 }
 
-int mvsw_pr_hw_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
 			       u32 grp_id)
 {
 	struct mvsw_msg_nh_grp_cmd req = {
@@ -1880,14 +2009,14 @@ int mvsw_pr_hw_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_NH_GRP_DELETE, &req);
 }
 
-int mvsw_pr_hw_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy)
+int mvsw_pr_hw_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy)
 {
 	struct mvsw_msg_mp_cmd req = { .hash_policy = hash_policy};
 
 	return fw_send_req(sw, MVSW_MSG_TYPE_ROUTER_MP_HASH_SET, &req);
 }
 
-int mvsw_pr_hw_rxtx_init(const struct mvsw_pr_switch *sw, bool use_sdma,
+int mvsw_pr_hw_rxtx_init(const struct prestera_switch *sw, bool use_sdma,
 			 u32 *map_addr)
 {
 	struct mvsw_msg_rxtx_ret resp;
@@ -1906,7 +2035,7 @@ int mvsw_pr_hw_rxtx_init(const struct mvsw_pr_switch *sw, bool use_sdma,
 	return 0;
 }
 
-int mvsw_pr_hw_port_autoneg_restart(struct mvsw_pr_port *port)
+int mvsw_pr_hw_port_autoneg_restart(struct prestera_port *port)
 {
 	struct mvsw_msg_port_attr_cmd req = {
 		.attr = MVSW_MSG_PORT_ATTR_AUTONEG_RESTART,
@@ -1917,7 +2046,7 @@ int mvsw_pr_hw_port_autoneg_restart(struct mvsw_pr_port *port)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_remote_fc_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_remote_fc_get(const struct prestera_port *port,
 				  bool *pause, bool *asym_pause)
 {
 	struct mvsw_msg_port_attr_ret resp;
@@ -1955,7 +2084,7 @@ int mvsw_pr_hw_port_remote_fc_get(const struct mvsw_pr_port *port,
 }
 
 /* ACL API */
-int mvsw_pr_hw_acl_ruleset_create(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_acl_ruleset_create(const struct prestera_switch *sw,
 				  u16 *ruleset_id)
 {
 	int err;
@@ -1971,7 +2100,7 @@ int mvsw_pr_hw_acl_ruleset_create(const struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-int mvsw_pr_hw_acl_ruleset_del(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_acl_ruleset_del(const struct prestera_switch *sw,
 			       u16 ruleset_id)
 {
 	struct mvsw_msg_acl_ruleset_cmd req = {
@@ -1981,185 +2110,187 @@ int mvsw_pr_hw_acl_ruleset_del(const struct mvsw_pr_switch *sw,
 	return fw_send_req(sw, MVSW_MSG_TYPE_ACL_RULESET_DELETE, &req);
 }
 
-static int acl_rule_add_put_actions(struct mvsw_msg_buff *msg,
-				    struct prestera_acl_rule *rule)
+static int acl_rule_add_put_action(struct mvsw_msg_acl_action *action,
+				   struct prestera_acl_hw_action_info *info)
 {
-	struct list_head *a_list = prestera_acl_rule_action_list_get(rule);
-	u8 n_actions = prestera_acl_rule_action_len(rule);
-	struct prestera_acl_rule_action_entry *a_entry;
-	__be64 be64;
 	int err;
 
-	err = mvsw_msg_buff_put(msg, &n_actions, sizeof(n_actions));
-	if (err)
-		return err;
-
-	list_for_each_entry(a_entry, a_list, list) {
-		err = mvsw_msg_buff_put(msg, (u8 *)&a_entry->id, sizeof(u8));
-		if (err)
-			return err;
+	action->id = info->id;
 
-		switch (a_entry->id) {
-		case MVSW_ACL_RULE_ACTION_ACCEPT:
-		case MVSW_ACL_RULE_ACTION_DROP:
-		case MVSW_ACL_RULE_ACTION_TRAP:
-			/* just rule action id, no specific data */
-			break;
-		case MVSW_ACL_RULE_ACTION_POLICE:
-			be64 = cpu_to_be64(a_entry->police.rate);
-			err = mvsw_msg_buff_put(msg, &be64, sizeof(be64));
-			be64 = cpu_to_be64(a_entry->police.burst);
-			err = mvsw_msg_buff_put(msg, &be64, sizeof(be64));
+	switch (info->id) {
+	case MVSW_ACL_RULE_ACTION_ACCEPT:
+	case MVSW_ACL_RULE_ACTION_DROP:
+	case MVSW_ACL_RULE_ACTION_TRAP:
+		/* just rule action id, no specific data */
+		break;
+	case MVSW_ACL_RULE_ACTION_JUMP:
+		action->jump.chain = info->jump.chain;
+		break;
+	case MVSW_ACL_RULE_ACTION_POLICE:
+		action->police.rate = info->police.rate;
+		action->police.burst = info->police.burst;
+		break;
+	case MVSW_ACL_RULE_ACTION_MANGLE:
+		/* TODO: trap on AGENT side ? */
+		if (!info->mangle.n.connected) {
+			action->id = MVSW_ACL_RULE_ACTION_TRAP;
 			break;
-		default:
-			err = -EINVAL;
 		}
+		action->mangle.l4_src_valid =
+			info->mangle.l4_src_valid;
+		action->mangle.l4_dst_valid =
+			info->mangle.l4_dst_valid;
+		action->mangle.sip_valid =
+			info->mangle.sip_valid;
+		action->mangle.dip_valid =
+			info->mangle.dip_valid;
+		action->mangle.l4_src = info->mangle.l4_src;
+		action->mangle.l4_dst = info->mangle.l4_dst;
+		action->mangle.sip = info->mangle.sip.u.ipv4;
+		if (WARN_ON(info->mangle.dip.v != MVSW_PR_IPV4) ||
+		    WARN_ON(info->mangle.sip.v != MVSW_PR_IPV4))
+			return -ENOTSUPP;
+		action->mangle.dip = info->mangle.dip.u.ipv4;
+		err = mvsw_pr_iface_to_msg(&info->mangle.n.iface,
+					   &action->mangle.nh.oif);
 		if (err)
-			return err;
+			return -EINVAL;
+		memcpy(&action->mangle.nh.mac[0], &info->mangle.n.ha[0],
+		       ETH_ALEN);
+		break;
+	case MVSW_ACL_RULE_ACTION_NAT:
+		action->nat.old_addr = info->nat.old_addr;
+		action->nat.new_addr = info->nat.new_addr;
+		action->nat.flags = info->nat.flags;
+		action->nat.port = info->nat.port;
+		action->nat.dev = info->nat.dev;
+		break;
+	default:
+		return -EINVAL;
 	}
 
 	return 0;
 }
 
-static int acl_rule_add_put_matches(struct mvsw_msg_buff *msg,
-				    struct prestera_acl_rule *rule)
+static int acl_rule_add_put_match(struct mvsw_msg_acl_match *match,
+				  struct prestera_acl_hw_match_info *info)
 {
-	struct list_head *m_list = prestera_acl_rule_match_list_get(rule);
-	struct prestera_acl_rule_match_entry *m_entry;
-	int err;
+	match->type = info->type;
 
-	list_for_each_entry(m_entry, m_list, list) {
-		err = mvsw_msg_buff_put(msg, (u8 *)&m_entry->type, sizeof(u8));
-		if (err)
-			return err;
-
-		switch (m_entry->type) {
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u16.key,
-				 sizeof(m_entry->keymask.u16.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u16.mask,
-				 sizeof(m_entry->keymask.u16.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u8.key,
-				 sizeof(m_entry->keymask.u8.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u8.mask,
-				 sizeof(m_entry->keymask.u8.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.mac.key,
-				 sizeof(m_entry->keymask.mac.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.mac.mask,
-				 sizeof(m_entry->keymask.mac.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC:
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u32.key,
-				 sizeof(m_entry->keymask.u32.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u32.mask,
-				 sizeof(m_entry->keymask.u32.mask));
-			break;
-		case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT:
-			err = mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u64.key,
-				 sizeof(m_entry->keymask.u64.key));
-			err |= mvsw_msg_buff_put
-				(msg, &m_entry->keymask.u64.mask,
-				 sizeof(m_entry->keymask.u64.mask));
-			break;
-		default:
-			err = -EINVAL;
-		}
-		if (err)
-			return err;
+	switch (info->type) {
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID:
+		match->keymask.u16.key = info->u16.key;
+		match->keymask.u16.mask = info->u16.mask;
+		break;
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO:
+		match->keymask.u8.key = info->u8.key;
+		match->keymask.u8.mask = info->u8.mask;
+		break;
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC:
+		memcpy(match->keymask.mac.key,
+		       info->mac.key,
+		       sizeof(match->keymask.mac.key));
+		memcpy(match->keymask.mac.mask,
+		       info->mac.mask,
+		       sizeof(match->keymask.mac.mask));
+		break;
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC:
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST:
+		match->keymask.u32.key = info->u32.key;
+		match->keymask.u32.mask = info->u32.mask;
+		break;
+	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT:
+		match->keymask.u64.key = info->u64.key;
+		match->keymask.u64.mask = info->u64.mask;
+		break;
+	default:
+		return -EINVAL;
 	}
 
 	return 0;
 }
 
-int mvsw_pr_hw_acl_rule_add(const struct mvsw_pr_switch *sw,
-			    struct prestera_acl_rule *rule,
+int mvsw_pr_hw_acl_rule_add(const struct prestera_switch *sw,
+			    u16 ruleset, u8 chain, u32 prio, u8 tc,
+			    u8 n_matches,
+			    struct prestera_acl_hw_match_info *matches,
+			    u8 n_actions,
+			    struct prestera_acl_hw_action_info *actions,
 			    u32 *rule_id)
 {
-	int err;
+	struct mvsw_msg_acl_action *actions_msg;
+	struct mvsw_msg_acl_match *matches_msg;
 	struct mvsw_msg_acl_rule_ret resp;
-	u8 hw_tc = prestera_acl_rule_hw_tc_get(rule);
-	u32 priority = prestera_acl_rule_priority_get(rule);
-	u16 ruleset_id = prestera_acl_rule_ruleset_id_get(rule);
 	struct mvsw_msg_acl_rule_cmd *req;
-	struct mvsw_msg_buff *msg;
-
-	msg = mvsw_msg_buff_create(sizeof(*req));
-	if (!msg)
-		return -ENOMEM;
+	void *buff;
+	u32 size;
+	int err;
+	u8 i;
 
-	/* put priority first */
-	err = mvsw_msg_buff_put(msg, &priority, sizeof(priority));
-	if (err)
-		goto free_msg;
+	size = sizeof(*req) + sizeof(*actions_msg) * n_actions +
+		sizeof(*matches_msg) * n_matches;
 
-	/* put hw_tc into the message */
-	err = mvsw_msg_buff_put(msg, &hw_tc, sizeof(hw_tc));
-	if (err)
-		goto free_msg;
+	buff = kzalloc(size, GFP_KERNEL);
+	if (!buff)
+		return -ENOMEM;
 
-	/* put acl actions into the message */
-	err = acl_rule_add_put_actions(msg, rule);
-	if (err)
-		goto free_msg;
+	req = buff;
+	actions_msg = buff + sizeof(*req);
+	matches_msg = buff + sizeof(*req) + sizeof(*actions_msg) * n_actions;
+	req->n_matches = n_matches;
+	req->n_actions = n_actions;
 
 	/* put acl matches into the message */
-	err = acl_rule_add_put_matches(msg, rule);
-	if (err)
-		goto free_msg;
-
-	/* terminate message */
-	err = mvsw_msg_buff_terminate(msg);
-	if (err)
-		goto free_msg;
+	for (i = 0; i < n_matches; i++) {
+		err = acl_rule_add_put_match(&matches_msg[i], &matches[i]);
+		if (err)
+			goto free_buff;
+	}
 
-	req = (struct mvsw_msg_acl_rule_cmd *)mvsw_msg_buff_data(msg);
+	/* put acl actions into the message */
+	for (i = 0; i < n_actions; i++) {
+		err = acl_rule_add_put_action(&actions_msg[i], &actions[i]);
+		if (err)
+			goto free_buff;
+	}
 
-	req->ruleset_id = ruleset_id;
+	req->ruleset_id = ruleset;
+	req->chain = chain;
+	req->priority = prio;
+	req->hw_tc = tc;
 
 	err = fw_send_nreq_resp(sw, MVSW_MSG_TYPE_ACL_RULE_ADD, req,
-				mvsw_msg_buff_size(msg), &resp);
+				size, &resp);
 	if (err)
-		goto free_msg;
+		goto free_buff;
 
 	*rule_id = resp.id;
-free_msg:
-	mvsw_msg_buff_destroy(msg);
+free_buff:
+	kfree(buff);
 	return err;
 }
 
-int mvsw_pr_hw_acl_rule_del(const struct mvsw_pr_switch *sw, u32 rule_id)
+int mvsw_pr_hw_acl_rule_del(const struct prestera_switch *sw,
+			    u32 chain, u32 rule_id)
 {
 	struct mvsw_msg_acl_rule_cmd req = {
+		.chain = chain,
 		.id = rule_id
 	};
 
 	return fw_send_req(sw, MVSW_MSG_TYPE_ACL_RULE_DELETE, &req);
 }
 
-int mvsw_pr_hw_acl_rule_stats_get(const struct mvsw_pr_switch *sw, u32 rule_id,
+int mvsw_pr_hw_acl_rule_stats_get(const struct prestera_switch *sw, u32 rule_id,
 				  u64 *packets, u64 *bytes)
 {
 	int err;
@@ -2178,7 +2309,7 @@ int mvsw_pr_hw_acl_rule_stats_get(const struct mvsw_pr_switch *sw, u32 rule_id,
 	return 0;
 }
 
-int mvsw_pr_hw_acl_port_bind(const struct mvsw_pr_port *port, u16 ruleset_id)
+int mvsw_pr_hw_acl_port_bind(const struct prestera_port *port, u16 ruleset_id)
 {
 	struct mvsw_msg_acl_ruleset_bind_cmd req = {
 		.port = port->hw_id,
@@ -2189,7 +2320,7 @@ int mvsw_pr_hw_acl_port_bind(const struct mvsw_pr_port *port, u16 ruleset_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_ACL_PORT_BIND, &req);
 }
 
-int mvsw_pr_hw_acl_port_unbind(const struct mvsw_pr_port *port, u16 ruleset_id)
+int mvsw_pr_hw_acl_port_unbind(const struct prestera_port *port, u16 ruleset_id)
 {
 	struct mvsw_msg_acl_ruleset_bind_cmd req = {
 		.port = port->hw_id,
@@ -2200,7 +2331,67 @@ int mvsw_pr_hw_acl_port_unbind(const struct mvsw_pr_port *port, u16 ruleset_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_ACL_PORT_UNBIND, &req);
 }
 
-int mvsw_pr_hw_lag_member_add(struct mvsw_pr_port *port, u16 lag_id)
+int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
+				      unsigned char *mac)
+{
+	struct mvsw_msg_nat_port_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
+	};
+	memcpy(req.neigh_mac, mac, sizeof(req.neigh_mac));
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_NAT_PORT_NEIGH_UPDATE,
+			   &req);
+}
+
+int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id)
+{
+	int err;
+	struct mvsw_msg_span_ret resp;
+	struct mvsw_msg_span_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
+	};
+
+	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_SPAN_GET, &req, &resp);
+	if (err)
+		return err;
+
+	*span_id = resp.id;
+
+	return 0;
+}
+
+int prestera_hw_span_bind(const struct prestera_port *port, u8 span_id)
+{
+	struct mvsw_msg_span_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
+		.id = span_id,
+	};
+
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_SPAN_BIND, &req);
+}
+
+int prestera_hw_span_unbind(const struct prestera_port *port)
+{
+	struct mvsw_msg_span_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
+	};
+
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_SPAN_UNBIND, &req);
+}
+
+int prestera_hw_span_release(const struct prestera_switch *sw, u8 span_id)
+{
+	struct mvsw_msg_span_cmd req = {
+		.id = span_id
+	};
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_SPAN_RELEASE, &req);
+}
+
+int mvsw_pr_hw_lag_member_add(struct prestera_port *port, u16 lag_id)
 {
 	struct mvsw_msg_lag_cmd req = {
 		.port = port->hw_id,
@@ -2211,7 +2402,7 @@ int mvsw_pr_hw_lag_member_add(struct mvsw_pr_port *port, u16 lag_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_LAG_ADD, &req);
 }
 
-int mvsw_pr_hw_lag_member_del(struct mvsw_pr_port *port, u16 lag_id)
+int mvsw_pr_hw_lag_member_del(struct prestera_port *port, u16 lag_id)
 {
 	struct mvsw_msg_lag_cmd req = {
 		.port = port->hw_id,
@@ -2222,7 +2413,7 @@ int mvsw_pr_hw_lag_member_del(struct mvsw_pr_port *port, u16 lag_id)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_LAG_DELETE, &req);
 }
 
-int mvsw_pr_hw_lag_member_enable(struct mvsw_pr_port *port, u16 lag_id,
+int mvsw_pr_hw_lag_member_enable(struct prestera_port *port, u16 lag_id,
 				 bool enable)
 {
 	u32 cmd;
@@ -2236,7 +2427,7 @@ int mvsw_pr_hw_lag_member_enable(struct mvsw_pr_port *port, u16 lag_id,
 	return fw_send_req(port->sw, cmd, &req);
 }
 
-int mvsw_pr_hw_lag_member_rif_leave(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_lag_member_rif_leave(const struct prestera_port *port,
 				    u16 lag_id, u16 vr_id)
 {
 	struct mvsw_msg_lag_cmd req = {
@@ -2248,3 +2439,25 @@ int mvsw_pr_hw_lag_member_rif_leave(const struct mvsw_pr_port *port,
 
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_LAG_ROUTER_LEAVE, &req);
 }
+
+int
+prestera_hw_cpu_code_counters_get(const struct prestera_switch *sw, u8 code,
+				  enum prestera_hw_cpu_code_cnt_t counter_type,
+				  u64 *packet_count)
+{
+	struct mvsw_msg_cpu_code_counter_cmd req = {
+		.counter_type = counter_type,
+		.code = code,
+	};
+	struct mvsw_msg_cpu_code_counter_ret resp;
+	int err;
+
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_CPU_CODE_COUNTERS_GET,
+			       &req, &resp);
+	if (err)
+		return err;
+
+	*packet_count = resp.packet_count;
+
+	return 0;
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.h b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
index ad6c4da..f844f8d 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
@@ -150,8 +150,19 @@ enum {
 	MVSW_FW_LOG_TYPE_MAX
 };
 
-struct mvsw_pr_switch;
-struct mvsw_pr_port;
+enum {
+	MVSW_PORT_STORM_CTL_TYPE_BC = 0,
+	MVSW_PORT_STORM_CTL_TYPE_UC_UNK = 1,
+	MVSW_PORT_STORM_CTL_TYPE_MC = 2
+};
+
+enum prestera_hw_cpu_code_cnt_t {
+	PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP = 0,
+	PRESTERA_HW_CPU_CODE_CNT_TYPE_TRAP = 1,
+};
+
+struct prestera_switch;
+struct prestera_port;
 struct mvsw_pr_port_stats;
 struct mvsw_pr_port_caps;
 struct prestera_acl_rule;
@@ -162,163 +173,194 @@ enum mvsw_pr_event_type;
 struct mvsw_pr_event;
 
 /* Switch API */
-int mvsw_pr_hw_switch_init(struct mvsw_pr_switch *sw);
-int mvsw_pr_hw_switch_ageing_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_switch_init(struct prestera_switch *sw);
+int mvsw_pr_hw_switch_ageing_set(const struct prestera_switch *sw,
 				 u32 ageing_time);
-int mvsw_pr_hw_switch_mac_set(const struct mvsw_pr_switch *sw, const u8 *mac);
-int mvsw_pr_hw_switch_trap_policer_set(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_switch_mac_set(const struct prestera_switch *sw, const u8 *mac);
+int mvsw_pr_hw_switch_trap_policer_set(const struct prestera_switch *sw,
 				       u8 profile);
 
 /* Port API */
-int mvsw_pr_hw_port_info_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_info_get(const struct prestera_port *port,
 			     u16 *fp_id, u32 *hw_id, u32 *dev_id);
-int mvsw_pr_hw_port_state_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_state_set(const struct prestera_port *port,
 			      bool admin_state);
-int mvsw_pr_hw_port_state_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_state_get(const struct prestera_port *port,
 			      bool *admin_state, bool *oper_state);
-int mvsw_pr_hw_port_mtu_set(const struct mvsw_pr_port *port, u32 mtu);
-int mvsw_pr_hw_port_mtu_get(const struct mvsw_pr_port *port, u32 *mtu);
-int mvsw_pr_hw_port_mac_set(const struct mvsw_pr_port *port, char *mac);
-int mvsw_pr_hw_port_mac_get(const struct mvsw_pr_port *port, char *mac);
-int mvsw_pr_hw_port_accept_frame_type_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_mtu_set(const struct prestera_port *port, u32 mtu);
+int mvsw_pr_hw_port_mtu_get(const struct prestera_port *port, u32 *mtu);
+int mvsw_pr_hw_port_mac_set(const struct prestera_port *port, char *mac);
+int mvsw_pr_hw_port_mac_get(const struct prestera_port *port, char *mac);
+int mvsw_pr_hw_port_accept_frame_type_set(const struct prestera_port *port,
 					  enum mvsw_pr_accept_frame_type type);
-int mvsw_pr_hw_port_learning_set(const struct mvsw_pr_port *port, bool enable);
-int mvsw_pr_hw_port_speed_get(const struct mvsw_pr_port *port, u32 *speed);
-int mvsw_pr_hw_port_uc_flood_set(const struct mvsw_pr_port *port, bool flood);
-int mvsw_pr_hw_port_mc_flood_set(const struct mvsw_pr_port *port, bool flood);
-int mvsw_pr_hw_port_cap_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_learning_set(const struct prestera_port *port, bool enable);
+int mvsw_pr_hw_port_speed_get(const struct prestera_port *port, u32 *speed);
+int mvsw_pr_hw_port_uc_flood_set(const struct prestera_port *port, bool flood);
+int mvsw_pr_hw_port_mc_flood_set(const struct prestera_port *port, bool flood);
+int mvsw_pr_hw_port_cap_get(const struct prestera_port *port,
 			    struct mvsw_pr_port_caps *caps);
-int mvsw_pr_hw_port_remote_cap_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_remote_cap_get(const struct prestera_port *port,
 				   u64 *link_mode_bitmap);
-int mvsw_pr_hw_port_remote_fc_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_remote_fc_get(const struct prestera_port *port,
 				  bool *pause, bool *asym_pause);
-int mvsw_pr_hw_port_type_get(const struct mvsw_pr_port *port, u8 *type);
-int mvsw_pr_hw_port_fec_get(const struct mvsw_pr_port *port, u8 *fec);
-int mvsw_pr_hw_port_fec_set(const struct mvsw_pr_port *port, u8 fec);
-int mvsw_pr_hw_port_autoneg_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_type_get(const struct prestera_port *port, u8 *type);
+int mvsw_pr_hw_port_fec_get(const struct prestera_port *port, u8 *fec);
+int mvsw_pr_hw_port_fec_set(const struct prestera_port *port, u8 fec);
+int mvsw_pr_hw_port_autoneg_set(const struct prestera_port *port,
 				bool autoneg, u64 link_modes, u8 fec);
-int mvsw_pr_hw_port_duplex_get(const struct mvsw_pr_port *port, u8 *duplex);
-int mvsw_pr_hw_port_stats_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_duplex_get(const struct prestera_port *port, u8 *duplex);
+int mvsw_pr_hw_port_stats_get(const struct prestera_port *port,
 			      struct mvsw_pr_port_stats *stats);
-int mvsw_pr_hw_port_link_mode_get(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_link_mode_get(const struct prestera_port *port,
 				  u32 *mode);
-int mvsw_pr_hw_port_link_mode_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_port_link_mode_set(const struct prestera_port *port,
 				  u32 mode);
-int mvsw_pr_hw_port_mdix_get(const struct mvsw_pr_port *port, u8 *status,
+int mvsw_pr_hw_port_mdix_get(const struct prestera_port *port, u8 *status,
 			     u8 *admin_mode);
-int mvsw_pr_hw_port_mdix_set(const struct mvsw_pr_port *port, u8 mode);
-int mvsw_pr_hw_port_autoneg_restart(struct mvsw_pr_port *port);
+int mvsw_pr_hw_port_mdix_set(const struct prestera_port *port, u8 mode);
+int mvsw_pr_hw_port_autoneg_restart(struct prestera_port *port);
+
+int mvsw_pr_hw_port_storm_control_cfg_set(const struct prestera_port *port,
+					  u32 storm_type,
+					  u32 kbyte_per_sec_rate);
 
 /* Vlan API */
-int mvsw_pr_hw_vlan_create(const struct mvsw_pr_switch *sw, u16 vid);
-int mvsw_pr_hw_vlan_delete(const struct mvsw_pr_switch *sw, u16 vid);
-int mvsw_pr_hw_vlan_port_set(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_vlan_create(const struct prestera_switch *sw, u16 vid);
+int mvsw_pr_hw_vlan_delete(const struct prestera_switch *sw, u16 vid);
+int mvsw_pr_hw_vlan_port_set(const struct prestera_port *port,
 			     u16 vid, bool is_member, bool untagged);
-int mvsw_pr_hw_vlan_port_vid_set(const struct mvsw_pr_port *port, u16 vid);
+int mvsw_pr_hw_vlan_port_vid_set(const struct prestera_port *port, u16 vid);
 
 /* FDB API */
-int mvsw_pr_hw_fdb_add(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_fdb_add(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid, bool dynamic);
-int mvsw_pr_hw_fdb_del(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_fdb_del(const struct prestera_port *port,
 		       const unsigned char *mac, u16 vid);
-int mvsw_pr_hw_fdb_flush_port(const struct mvsw_pr_port *port, u32 mode);
-int mvsw_pr_hw_fdb_flush_vlan(const struct mvsw_pr_switch *sw, u16 vid,
+int mvsw_pr_hw_fdb_flush_port(const struct prestera_port *port, u32 mode);
+int mvsw_pr_hw_fdb_flush_vlan(const struct prestera_switch *sw, u16 vid,
 			      u32 mode);
-int mvsw_pr_hw_fdb_flush_port_vlan(const struct mvsw_pr_port *port, u16 vid,
+int mvsw_pr_hw_fdb_flush_port_vlan(const struct prestera_port *port, u16 vid,
 				   u32 mode);
-int mvsw_pr_hw_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid);
-int mvsw_pr_hw_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
 			   const u8 *mac, u16 vid);
 
 /* Bridge API */
-int mvsw_pr_hw_bridge_create(const struct mvsw_pr_switch *sw, u16 *bridge_id);
-int mvsw_pr_hw_bridge_delete(const struct mvsw_pr_switch *sw, u16 bridge_id);
-int mvsw_pr_hw_bridge_port_add(const struct mvsw_pr_port *port, u16 bridge_id);
-int mvsw_pr_hw_bridge_port_delete(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_bridge_create(const struct prestera_switch *sw, u16 *bridge_id);
+int mvsw_pr_hw_bridge_delete(const struct prestera_switch *sw, u16 bridge_id);
+int mvsw_pr_hw_bridge_port_add(const struct prestera_port *port, u16 bridge_id);
+int mvsw_pr_hw_bridge_port_delete(const struct prestera_port *port,
 				  u16 bridge_id);
 
 /* STP API */
-int mvsw_pr_hw_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state);
+int mvsw_pr_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state);
 
 /* ACL API */
-int mvsw_pr_hw_acl_ruleset_create(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_acl_ruleset_create(const struct prestera_switch *sw,
 				  u16 *ruleset_id);
-int mvsw_pr_hw_acl_ruleset_del(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_acl_ruleset_del(const struct prestera_switch *sw,
 			       u16 ruleset_id);
-int mvsw_pr_hw_acl_rule_add(const struct mvsw_pr_switch *sw,
-			    struct prestera_acl_rule *rule,
+int mvsw_pr_hw_acl_rule_add(const struct prestera_switch *sw,
+			    u16 ruleset, u8 chain, u32 prio, u8 tc,
+			    u8 n_matches,
+			    struct prestera_acl_hw_match_info *matches,
+			    u8 n_actions,
+			    struct prestera_acl_hw_action_info *actions,
 			    u32 *rule_id);
-int mvsw_pr_hw_acl_rule_del(const struct mvsw_pr_switch *sw, u32 rule_id);
-int mvsw_pr_hw_acl_rule_stats_get(const struct mvsw_pr_switch *sw, u32 rule_id,
+int mvsw_pr_hw_acl_rule_del(const struct prestera_switch *sw,
+			    u32 chain, u32 rule_id);
+int mvsw_pr_hw_acl_rule_stats_get(const struct prestera_switch *sw, u32 rule_id,
 				  u64 *packets, u64 *bytes);
-int mvsw_pr_hw_acl_port_bind(const struct mvsw_pr_port *port, u16 ruleset_id);
-int mvsw_pr_hw_acl_port_unbind(const struct mvsw_pr_port *port, u16 ruleset_id);
+int mvsw_pr_hw_acl_port_bind(const struct prestera_port *port, u16 ruleset_id);
+int mvsw_pr_hw_acl_port_unbind(const struct prestera_port *port,
+			       u16 ruleset_id);
+
+/* NAT API */
+int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
+				      unsigned char *mac);
+
+/* SPAN API */
+int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id);
+int prestera_hw_span_bind(const struct prestera_port *port, u8 span_id);
+int prestera_hw_span_unbind(const struct prestera_port *port);
+int prestera_hw_span_release(const struct prestera_switch *sw, u8 span_id);
 
 /* Router API */
-int mvsw_pr_hw_rif_create(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_rif_create(const struct prestera_switch *sw,
 			  struct mvsw_pr_iface *iif, u8 *mac, u16 *rif_id);
-int mvsw_pr_hw_rif_delete(const struct mvsw_pr_switch *sw, u16 rif_id,
+int mvsw_pr_hw_rif_delete(const struct prestera_switch *sw, u16 rif_id,
 			  struct mvsw_pr_iface *iif);
-int mvsw_pr_hw_rif_set(const struct mvsw_pr_switch *sw, u16 *rif_id,
+int mvsw_pr_hw_rif_set(const struct prestera_switch *sw, u16 *rif_id,
 		       struct mvsw_pr_iface *iif, u8 *mac);
 
 /* Virtual Router API */
-int mvsw_pr_hw_vr_create(const struct mvsw_pr_switch *sw, u16 *vr_id);
-int mvsw_pr_hw_vr_delete(const struct mvsw_pr_switch *sw, u16 vr_id);
-int mvsw_pr_hw_vr_abort(const struct mvsw_pr_switch *sw, u16 vr_id);
+int mvsw_pr_hw_vr_create(const struct prestera_switch *sw, u16 *vr_id);
+int mvsw_pr_hw_vr_delete(const struct prestera_switch *sw, u16 vr_id);
+int mvsw_pr_hw_vr_abort(const struct prestera_switch *sw, u16 vr_id);
 
 /* LPM API */
-int mvsw_pr_hw_lpm_add(const struct mvsw_pr_switch *sw, u16 vr_id,
+int mvsw_pr_hw_lpm_add(const struct prestera_switch *sw, u16 vr_id,
 		       __be32 dst, u32 dst_len, u32 grp_id);
-int mvsw_pr_hw_lpm_del(const struct mvsw_pr_switch *sw, u16 vr_id, __be32 dst,
+int mvsw_pr_hw_lpm_del(const struct prestera_switch *sw, u16 vr_id, __be32 dst,
 		       u32 dst_len);
 
 /* NH API */
-int mvsw_pr_hw_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
+int mvsw_pr_hw_nh_entries_set(const struct prestera_switch *sw, int count,
 			      struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_hw_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
+int mvsw_pr_hw_nh_entries_get(const struct prestera_switch *sw, int count,
 			      struct mvsw_pr_neigh_info *nhs, u32 grp_id);
-int mvsw_pr_hw_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nhgrp_blk_get(const struct prestera_switch *sw,
+			     u8 *hw_state, u32 buf_size /* Buffer in bytes */);
+int mvsw_pr_hw_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
 			       u32 *grp_id);
-int mvsw_pr_hw_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
+int mvsw_pr_hw_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
 			       u32 grp_id);
 
 /* MP API */
-int mvsw_pr_hw_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy);
+int mvsw_pr_hw_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy);
 
 /* LAG API */
-int mvsw_pr_hw_lag_member_add(struct mvsw_pr_port *port, u16 lag_id);
-int mvsw_pr_hw_lag_member_del(struct mvsw_pr_port *port, u16 lag_id);
-int mvsw_pr_hw_lag_member_enable(struct mvsw_pr_port *port, u16 lag_id,
+int mvsw_pr_hw_lag_member_add(struct prestera_port *port, u16 lag_id);
+int mvsw_pr_hw_lag_member_del(struct prestera_port *port, u16 lag_id);
+int mvsw_pr_hw_lag_member_enable(struct prestera_port *port, u16 lag_id,
 				 bool enable);
-int mvsw_pr_hw_lag_fdb_add(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_add(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid, bool dynamic);
-int mvsw_pr_hw_lag_fdb_del(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_lag_fdb_del(const struct prestera_switch *sw, u16 lag_id,
 			   const unsigned char *mac, u16 vid);
-int mvsw_pr_hw_fdb_flush_lag(const struct mvsw_pr_switch *sw, u16 lag_id,
+int mvsw_pr_hw_fdb_flush_lag(const struct prestera_switch *sw, u16 lag_id,
 			     u32 mode);
-int mvsw_pr_hw_fdb_flush_lag_vlan(const struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_fdb_flush_lag_vlan(const struct prestera_switch *sw,
 				  u16 lag_id, u16 vid, u32 mode);
-int mvsw_pr_hw_lag_member_rif_leave(const struct mvsw_pr_port *port,
+int mvsw_pr_hw_lag_member_rif_leave(const struct prestera_port *port,
 				    u16 lag_id, u16 vr_id);
 
 /* Event handlers */
-int mvsw_pr_hw_event_handler_register(struct mvsw_pr_switch *sw,
+int mvsw_pr_hw_event_handler_register(struct prestera_switch *sw,
 				      enum mvsw_pr_event_type type,
-				      void (*cb)(struct mvsw_pr_switch *sw,
+				      void (*cb)(struct prestera_switch *sw,
 						 struct mvsw_pr_event *evt,
 						 void *arg),
 				      void *arg);
 
-void mvsw_pr_hw_event_handler_unregister(struct mvsw_pr_switch *sw,
+void mvsw_pr_hw_event_handler_unregister(struct prestera_switch *sw,
 					 enum mvsw_pr_event_type type);
 
 /* FW Log API */
-int mvsw_pr_hw_fw_log_level_set(const struct mvsw_pr_switch *sw, u32 lib,
+int mvsw_pr_hw_fw_log_level_set(const struct prestera_switch *sw, u32 lib,
 				u32 type);
 
-int mvsw_pr_hw_rxtx_init(const struct mvsw_pr_switch *sw, bool use_sdma,
+int mvsw_pr_hw_rxtx_init(const struct prestera_switch *sw, bool use_sdma,
 			 u32 *map_addr);
 
+/* FW Keepalive/ Watchdog API */
+void mvsw_pr_hw_keepalive_fini(const struct prestera_switch *sw);
+
+/* HW trap/drop counters API */
+int
+prestera_hw_cpu_code_counters_get(const struct prestera_switch *sw, u8 code,
+				  enum prestera_hw_cpu_code_cnt_t counter_type,
+				  u64 *packet_count);
+
 #endif /* _MVSW_PRESTERA_HW_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_main.c b/drivers/net/ethernet/marvell/prestera/prestera_main.c
index 05c9dc8..ebb7742 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_main.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_main.c
@@ -27,11 +27,12 @@
 #include "prestera_dsa.h"
 #include "prestera_rxtx.h"
 #include "prestera_drv_ver.h"
+#include "prestera_storm_control.h"
 
 static u8 trap_policer_profile = 1;
 
-#define MVSW_PR_MTU_DEFAULT 1536
-#define MVSW_PR_MAC_ADDR_OFFSET 4
+#define PRESTERA_MTU_DEFAULT 1536
+#define PRESTERA_MAC_ADDR_OFFSET 4
 
 #define PORT_STATS_CACHE_TIMEOUT_MS	(msecs_to_jiffies(1000))
 #define PORT_STATS_CNT	(sizeof(struct mvsw_pr_port_stats) / sizeof(u64))
@@ -42,16 +43,15 @@ static u8 trap_policer_profile = 1;
 
 static struct list_head switches_registered;
 
-static const char mvsw_driver_kind[] = "prestera_sw";
-static const char mvsw_driver_name[] = "mvsw_switchdev";
-static const char mvsw_driver_version[] = PRESTERA_DRV_VER;
+static const char prestera_driver_kind[] = "prestera";
+static const char prestera_driver_name[] = "mvsw_switchdev";
 
-#define mvsw_dev(sw)		((sw)->dev->dev)
-#define mvsw_dev_name(sw)	dev_name((sw)->dev->dev)
+#define prestera_dev(sw)	((sw)->dev->dev)
+#define prestera_dev_name(sw)	dev_name((sw)->dev->dev)
 
-static struct workqueue_struct *mvsw_pr_wq;
+static struct workqueue_struct *prestera_wq;
 
-struct mvsw_pr_link_mode {
+struct prestera_link_mode {
 	enum ethtool_link_mode_bit_indices eth_mode;
 	u32 speed;
 	u64 pr_mask;
@@ -59,8 +59,20 @@ struct mvsw_pr_link_mode {
 	u8 port_type;
 };
 
-static const struct mvsw_pr_link_mode
-mvsw_pr_link_modes[MVSW_LINK_MODE_MAX] = {
+struct prestera_span_entry {
+	struct list_head list;
+	struct prestera_port *port;
+	refcount_t ref_count;
+	u8 id;
+};
+
+struct prestera_span {
+	struct prestera_switch *sw;
+	struct list_head entries;
+};
+
+static const struct prestera_link_mode
+prestera_link_modes[MVSW_LINK_MODE_MAX] = {
 	[MVSW_LINK_MODE_10baseT_Half_BIT] = {
 		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Half_BIT,
 		.speed = 10,
@@ -237,13 +249,13 @@ mvsw_pr_link_modes[MVSW_LINK_MODE_MAX] = {
 	}
 };
 
-struct mvsw_pr_fec {
+struct prestera_fec {
 	u32 eth_fec;
 	enum ethtool_link_mode_bit_indices eth_mode;
 	u8 pr_fec;
 };
 
-static const struct mvsw_pr_fec mvsw_pr_fec_caps[MVSW_PORT_FEC_MAX] = {
+static const struct prestera_fec prestera_fec_caps[MVSW_PORT_FEC_MAX] = {
 	[MVSW_PORT_FEC_OFF_BIT] = {
 		.eth_fec = ETHTOOL_FEC_OFF,
 		.eth_mode = ETHTOOL_LINK_MODE_FEC_NONE_BIT,
@@ -261,13 +273,13 @@ static const struct mvsw_pr_fec mvsw_pr_fec_caps[MVSW_PORT_FEC_MAX] = {
 	}
 };
 
-struct mvsw_pr_port_type {
+struct prestera_port_type {
 	enum ethtool_link_mode_bit_indices eth_mode;
 	u8 eth_type;
 };
 
-static const struct mvsw_pr_port_type
-mvsw_pr_port_types[MVSW_PORT_TYPE_MAX] = {
+static const struct prestera_port_type
+prestera_port_types[MVSW_PORT_TYPE_MAX] = {
 	[MVSW_PORT_TYPE_NONE] = {
 		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
 		.eth_type = PORT_NONE,
@@ -302,7 +314,7 @@ mvsw_pr_port_types[MVSW_PORT_TYPE_MAX] = {
 	}
 };
 
-static const char mvsw_pr_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
+static const char prestera_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
 	PORT_STATS_FIELD(good_octets_received),
 	PORT_STATS_FIELD(bad_octets_received),
 	PORT_STATS_FIELD(mac_trans_error),
@@ -335,12 +347,19 @@ static const char mvsw_pr_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
 	PORT_STATS_FIELD(good_octets_sent),
 };
 
-static LIST_HEAD(mvsw_pr_block_cb_list);
+struct prestera_port *dev_to_prestera_port(struct device *dev)
+{
+	struct net_device *net_dev;
 
-static struct mvsw_pr_port *__find_pr_port(const struct mvsw_pr_switch *sw,
-					   u32 port_id)
+	net_dev = container_of(dev, struct net_device, dev);
+
+	return netdev_priv(net_dev);
+}
+
+static struct prestera_port *__find_pr_port(const struct prestera_switch *sw,
+					    u32 port_id)
 {
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
 	list_for_each_entry(port, &sw->port_list, list) {
 		if (port->id == port_id)
@@ -350,9 +369,9 @@ static struct mvsw_pr_port *__find_pr_port(const struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static int mvsw_pr_port_state_set(struct net_device *dev, bool is_up)
+static int prestera_port_state_set(struct net_device *dev, bool is_up)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	int err;
 
 	if (!is_up)
@@ -366,213 +385,55 @@ static int mvsw_pr_port_state_set(struct net_device *dev, bool is_up)
 	return err;
 }
 
-static int mvsw_pr_port_open(struct net_device *dev)
+static int prestera_port_open(struct net_device *dev)
 {
 #ifdef CONFIG_PHYLINK
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
 		phylink_start(port->phy_link);
 #endif
-	return mvsw_pr_port_state_set(dev, true);
+	return prestera_port_state_set(dev, true);
 }
 
-static int mvsw_pr_port_close(struct net_device *dev)
+static int prestera_port_close(struct net_device *dev)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
-	mvsw_pr_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_DYNAMIC);
+	prestera_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_DYNAMIC);
 
 #ifdef CONFIG_PHYLINK
 	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
 		phylink_stop(port->phy_link);
 #endif
-	return mvsw_pr_port_state_set(dev, false);
-}
-
-static netdev_tx_t mvsw_pr_port_xmit(struct sk_buff *skb,
-				     struct net_device *dev)
-{
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	struct mvsw_pr_rxtx_info rxtx_info = {
-		.port_id = port->id
-	};
-
-	return mvsw_pr_rxtx_xmit(skb, &rxtx_info);
-}
-
-/* TC flower */
-static int
-mvsw_pr_setup_tc_cls_flower(struct prestera_acl_block *acl_block,
-			    struct flow_cls_offload *f)
-{
-	struct mvsw_pr_switch *sw = prestera_acl_block_sw(acl_block);
-
-	if (f->common.chain_index != 0)
-		return -EOPNOTSUPP;
-
-	switch (f->command) {
-	case FLOW_CLS_REPLACE:
-		return mvsw_pr_flower_replace(sw, acl_block, f);
-	case FLOW_CLS_DESTROY:
-		mvsw_pr_flower_destroy(sw, acl_block, f);
-		return 0;
-	case FLOW_CLS_STATS:
-		return mvsw_pr_flower_stats(sw, acl_block, f);
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static int mvsw_pr_setup_tc_block_cb_flower(enum tc_setup_type type,
-					    void *type_data, void *cb_priv)
-{
-	struct prestera_acl_block *acl_block = cb_priv;
-
-	switch (type) {
-	case TC_SETUP_CLSFLOWER:
-		if (prestera_acl_block_disabled(acl_block))
-			return -EOPNOTSUPP;
-		return mvsw_pr_setup_tc_cls_flower(acl_block, type_data);
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static void mvsw_pr_tc_block_flower_release(void *cb_priv)
-{
-	struct prestera_acl_block *acl_block = cb_priv;
-
-	prestera_acl_block_destroy(acl_block);
-}
-
-static int
-mvsw_pr_setup_tc_block_flower_bind(struct mvsw_pr_port *port,
-				   struct flow_block_offload *f)
-{
-	struct mvsw_pr_switch *sw = port->sw;
-	struct prestera_acl_block *acl_block;
-	struct flow_block_cb *block_cb;
-	bool register_block = false;
-	bool disable_block = false;
-	int err;
-
-	block_cb = flow_block_cb_lookup(f->block,
-					mvsw_pr_setup_tc_block_cb_flower, sw);
-	if (!block_cb) {
-		acl_block = prestera_acl_block_create(sw, f->net);
-		if (!acl_block)
-			return -ENOMEM;
-		block_cb = flow_block_cb_alloc(mvsw_pr_setup_tc_block_cb_flower,
-					       sw, acl_block,
-					       mvsw_pr_tc_block_flower_release);
-		if (IS_ERR(block_cb)) {
-			prestera_acl_block_destroy(acl_block);
-			err = PTR_ERR(block_cb);
-			goto err_cb_register;
-		}
-		register_block = true;
-	} else {
-		acl_block = flow_block_cb_priv(block_cb);
-	}
-	flow_block_cb_incref(block_cb);
-
-	if (!tc_can_offload(port->net_dev)) {
-		if (prestera_acl_block_rule_count(acl_block)) {
-			err = -EOPNOTSUPP;
-			goto err_block_bind;
-		}
-
-		disable_block = true;
-	}
-
-	err = prestera_acl_block_bind(sw, acl_block, port);
-	if (err)
-		goto err_block_bind;
-
-	if (register_block) {
-		flow_block_cb_add(block_cb, f);
-		list_add_tail(&block_cb->driver_list, &mvsw_pr_block_cb_list);
-	}
-
-	if (disable_block)
-		prestera_acl_block_disable_inc(acl_block);
-
-	port->acl_block = acl_block;
-	return 0;
-
-err_block_bind:
-	if (!flow_block_cb_decref(block_cb))
-		flow_block_cb_free(block_cb);
-err_cb_register:
-	return err;
+	return prestera_port_state_set(dev, false);
 }
 
-static void
-mvsw_pr_setup_tc_block_flower_unbind(struct mvsw_pr_port *port,
-				     struct flow_block_offload *f)
+static netdev_tx_t prestera_port_xmit(struct sk_buff *skb,
+				      struct net_device *dev)
 {
-	struct mvsw_pr_switch *sw = port->sw;
-	struct prestera_acl_block *acl_block;
-	struct flow_block_cb *block_cb;
-	int err;
-
-	block_cb = flow_block_cb_lookup(f->block,
-					mvsw_pr_setup_tc_block_cb_flower, sw);
-	if (!block_cb)
-		return;
-
-	acl_block = flow_block_cb_priv(block_cb);
-
-	if (!tc_can_offload(port->net_dev))
-		prestera_acl_block_disable_dec(acl_block);
-
-	err = prestera_acl_block_unbind(sw, acl_block, port);
-	if (!err && !flow_block_cb_decref(block_cb)) {
-		flow_block_cb_remove(block_cb, f);
-		list_del(&block_cb->driver_list);
-	}
-	port->acl_block = NULL;
-}
-
-static int mvsw_sp_setup_tc_block(struct mvsw_pr_port *port,
-				  struct flow_block_offload *f)
-{
-	if (f->binder_type != FLOW_BLOCK_BINDER_TYPE_CLSACT_INGRESS)
-		return -EOPNOTSUPP;
-
-	f->driver_block_list = &mvsw_pr_block_cb_list;
-
-	switch (f->command) {
-	case FLOW_BLOCK_BIND:
-		return mvsw_pr_setup_tc_block_flower_bind(port, f);
-	case FLOW_BLOCK_UNBIND:
-		mvsw_pr_setup_tc_block_flower_unbind(port, f);
-		return 0;
-	default:
-		return -EOPNOTSUPP;
-	}
+	return prestera_rxtx_xmit(skb, netdev_priv(dev));
 }
 
-static int mvsw_pr_setup_tc(struct net_device *dev, enum tc_setup_type type,
-			    void *type_data)
+static int prestera_setup_tc(struct net_device *dev, enum tc_setup_type type,
+			     void *type_data)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	switch (type) {
 	case TC_SETUP_BLOCK:
-		return mvsw_sp_setup_tc_block(port, type_data);
+		return prestera_setup_tc_block(port, type_data);
 	default:
 		return -EOPNOTSUPP;
 	}
 }
 
-static void mvsw_pr_set_rx_mode(struct net_device *dev)
+static void prestera_set_rx_mode(struct net_device *dev)
 {
 	/* TO DO: add implementation */
 }
 
-static int mvsw_is_valid_mac_addr(struct mvsw_pr_port *port, u8 *addr)
+static int prestera_valid_mac_addr(struct prestera_port *port, u8 *addr)
 {
 	int err;
 
@@ -586,13 +447,13 @@ static int mvsw_is_valid_mac_addr(struct mvsw_pr_port *port, u8 *addr)
 	return 0;
 }
 
-static int mvsw_pr_port_set_mac_address(struct net_device *dev, void *p)
+static int prestera_port_set_mac_address(struct net_device *dev, void *p)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	struct sockaddr *addr = p;
 	int err;
 
-	err = mvsw_is_valid_mac_addr(port, addr->sa_data);
+	err = prestera_valid_mac_addr(port, addr->sa_data);
 	if (err)
 		return err;
 
@@ -603,9 +464,9 @@ static int mvsw_pr_port_set_mac_address(struct net_device *dev, void *p)
 	return err;
 }
 
-static int mvsw_pr_port_change_mtu(struct net_device *dev, int mtu)
+static int prestera_port_change_mtu(struct net_device *dev, int mtu)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	int err;
 
 	if (port->sw->mtu_min <= mtu && mtu <= port->sw->mtu_max)
@@ -619,10 +480,10 @@ static int mvsw_pr_port_change_mtu(struct net_device *dev, int mtu)
 	return err;
 }
 
-static void mvsw_pr_port_get_stats64(struct net_device *dev,
-				     struct rtnl_link_stats64 *stats)
+static void prestera_port_get_stats64(struct net_device *dev,
+				      struct rtnl_link_stats64 *stats)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	struct mvsw_pr_port_stats *port_stats = &port->cached_hw_stats.stats;
 
 	stats->rx_packets =	port_stats->broadcast_frames_received +
@@ -649,62 +510,62 @@ static void mvsw_pr_port_get_stats64(struct net_device *dev,
 	stats->rx_crc_errors = port_stats->bad_crc;
 }
 
-static void mvsw_pr_port_get_hw_stats(struct mvsw_pr_port *port)
+static void prestera_port_get_hw_stats(struct prestera_port *port)
 {
 	mvsw_pr_hw_port_stats_get(port, &port->cached_hw_stats.stats);
 }
 
 static void update_stats_cache(struct work_struct *work)
 {
-	struct mvsw_pr_port *port =
-		container_of(work, struct mvsw_pr_port,
+	struct prestera_port *port =
+		container_of(work, struct prestera_port,
 			     cached_hw_stats.caching_dw.work);
 
 	rtnl_lock();
-	mvsw_pr_port_get_hw_stats(port);
+	prestera_port_get_hw_stats(port);
 	rtnl_unlock();
 
-	queue_delayed_work(mvsw_pr_wq, &port->cached_hw_stats.caching_dw,
+	queue_delayed_work(prestera_wq, &port->cached_hw_stats.caching_dw,
 			   PORT_STATS_CACHE_TIMEOUT_MS);
 }
 
-static bool mvsw_pr_port_has_offload_stats(const struct net_device *dev,
-					   int attr_id)
+static bool prestera_port_has_offload_stats(const struct net_device *dev,
+					    int attr_id)
 {
 	/* TO DO: add implementation */
 	return false;
 }
 
-static int mvsw_pr_port_get_offload_stats(int attr_id,
-					  const struct net_device *dev,
-					  void *sp)
+static int prestera_port_get_offload_stats(int attr_id,
+					   const struct net_device *dev,
+					   void *sp)
 {
 	/* TO DO: add implementation */
 	return 0;
 }
 
-static int mvsw_pr_feature_hw_tc(struct net_device *dev, bool enable)
+static int prestera_feature_hw_tc(struct net_device *dev, bool enable)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	if (!enable) {
-		if (prestera_acl_block_rule_count(port->acl_block)) {
+		if (prestera_acl_block_rule_count(port->flow_block)) {
 			netdev_err(dev, "Active offloaded tc filters, can't turn hw_tc_offload off\n");
 			return -EINVAL;
 		}
-		prestera_acl_block_disable_inc(port->acl_block);
+		prestera_acl_block_disable_inc(port->flow_block);
 	} else {
-		prestera_acl_block_disable_dec(port->acl_block);
+		prestera_acl_block_disable_dec(port->flow_block);
 	}
 	return 0;
 }
 
 static int
-mvsw_pr_handle_feature(struct net_device *dev,
-		       netdev_features_t wanted_features,
-		       netdev_features_t feature,
-		       int (*feature_handler)(struct net_device *dev,
-					      bool enable))
+prestera_handle_feature(struct net_device *dev,
+			netdev_features_t wanted_features,
+			netdev_features_t feature,
+			int (*feature_handler)(struct net_device *dev,
+					       bool enable))
 {
 	netdev_features_t changes = wanted_features ^ dev->features;
 	bool enable = !!(wanted_features & feature);
@@ -728,14 +589,14 @@ mvsw_pr_handle_feature(struct net_device *dev,
 	return 0;
 }
 
-static int mvsw_pr_set_features(struct net_device *dev,
-				netdev_features_t features)
+static int prestera_set_features(struct net_device *dev,
+				 netdev_features_t features)
 {
 	netdev_features_t oper_features = dev->features;
 	int err = 0;
 
-	err |= mvsw_pr_handle_feature(dev, features, NETIF_F_HW_TC,
-				       mvsw_pr_feature_hw_tc);
+	err |= prestera_handle_feature(dev, features, NETIF_F_HW_TC,
+				       prestera_feature_hw_tc);
 
 	if (err) {
 		dev->features = oper_features;
@@ -745,14 +606,15 @@ static int mvsw_pr_set_features(struct net_device *dev,
 	return 0;
 }
 
-static void mvsw_pr_port_get_drvinfo(struct net_device *dev,
-				     struct ethtool_drvinfo *drvinfo)
+static void prestera_port_get_drvinfo(struct net_device *dev,
+				      struct ethtool_drvinfo *drvinfo)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_switch *sw = port->sw;
 
-	strlcpy(drvinfo->driver, mvsw_driver_kind, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->bus_info, mvsw_dev_name(sw), sizeof(drvinfo->bus_info));
+	strlcpy(drvinfo->driver, prestera_driver_kind, sizeof(drvinfo->driver));
+	strlcpy(drvinfo->bus_info, prestera_dev_name(sw),
+		sizeof(drvinfo->bus_info));
 	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),
 		 "%d.%d.%d",
 		 sw->dev->fw_rev.maj,
@@ -760,42 +622,42 @@ static void mvsw_pr_port_get_drvinfo(struct net_device *dev,
 		 sw->dev->fw_rev.sub);
 }
 
-static const struct net_device_ops mvsw_pr_netdev_ops = {
-	.ndo_open = mvsw_pr_port_open,
-	.ndo_stop = mvsw_pr_port_close,
-	.ndo_start_xmit = mvsw_pr_port_xmit,
-	.ndo_setup_tc = mvsw_pr_setup_tc,
-	.ndo_change_mtu = mvsw_pr_port_change_mtu,
-	.ndo_set_rx_mode = mvsw_pr_set_rx_mode,
-	.ndo_get_stats64 = mvsw_pr_port_get_stats64,
-	.ndo_set_features = mvsw_pr_set_features,
-	.ndo_set_mac_address = mvsw_pr_port_set_mac_address,
-	.ndo_has_offload_stats = mvsw_pr_port_has_offload_stats,
-	.ndo_get_offload_stats = mvsw_pr_port_get_offload_stats,
+static const struct net_device_ops prestera_netdev_ops = {
+	.ndo_open = prestera_port_open,
+	.ndo_stop = prestera_port_close,
+	.ndo_start_xmit = prestera_port_xmit,
+	.ndo_setup_tc = prestera_setup_tc,
+	.ndo_change_mtu = prestera_port_change_mtu,
+	.ndo_set_rx_mode = prestera_set_rx_mode,
+	.ndo_get_stats64 = prestera_port_get_stats64,
+	.ndo_set_features = prestera_set_features,
+	.ndo_set_mac_address = prestera_port_set_mac_address,
+	.ndo_has_offload_stats = prestera_port_has_offload_stats,
+	.ndo_get_offload_stats = prestera_port_get_offload_stats,
 	.ndo_get_devlink_port = prestera_devlink_get_port,
 };
 
-bool mvsw_pr_netdev_check(const struct net_device *dev)
+bool prestera_netdev_check(const struct net_device *dev)
 {
-	return dev->netdev_ops == &mvsw_pr_netdev_ops;
+	return dev->netdev_ops == &prestera_netdev_ops;
 }
 
-static int mvsw_pr_lower_dev_walk(struct net_device *lower_dev,
-	struct netdev_nested_priv  *priv)
+static int prestera_lower_dev_walk(struct net_device *dev,
+				   struct netdev_nested_priv *priv)
 {
-	struct mvsw_pr_port **pport = (struct mvsw_pr_port **)priv->data;
+	struct prestera_port **pport = (struct prestera_port **)priv->data;
 
-	if (mvsw_pr_netdev_check(lower_dev)) {
-		*pport = netdev_priv(lower_dev);
+	if (prestera_netdev_check(dev)) {
+		*pport = netdev_priv(dev);
 		return 1;
 	}
 
 	return 0;
 }
 
-struct mvsw_pr_port *mvsw_pr_port_dev_lower_find(struct net_device *dev)
+struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev)
 {
-	struct mvsw_pr_port *port = NULL;
+	struct prestera_port *port = NULL;
 	struct netdev_nested_priv priv = {
 		.data = (void *)&port,
 	};
@@ -803,53 +665,52 @@ struct mvsw_pr_port *mvsw_pr_port_dev_lower_find(struct net_device *dev)
 	if (!dev)
 		return NULL;
 
-	if (mvsw_pr_netdev_check(dev))
+	if (prestera_netdev_check(dev))
 		return netdev_priv(dev);
 
-	port = NULL;
-	netdev_walk_all_lower_dev(dev, mvsw_pr_lower_dev_walk, &priv);
+	netdev_walk_all_lower_dev(dev, prestera_lower_dev_walk, &priv);
 
 	return port;
 }
 
-struct mvsw_pr_switch *mvsw_pr_switch_get(struct net_device *dev)
+struct prestera_switch *prestera_switch_get(struct net_device *dev)
 {
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
-	port = mvsw_pr_port_dev_lower_find(dev);
+	port = prestera_port_dev_lower_find(dev);
 	return port ? port->sw : NULL;
 }
 
-static void mvsw_modes_to_eth(unsigned long *eth_modes, u64 link_modes, u8 fec,
-			      u8 type)
+static void prestera_modes_to_eth(unsigned long *eth_modes, u64 link_modes,
+				  u8 fec, u8 type)
 {
 	u32 mode;
 
 	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((mvsw_pr_link_modes[mode].pr_mask & link_modes) == 0)
+		if ((prestera_link_modes[mode].pr_mask & link_modes) == 0)
 			continue;
 		if (type != MVSW_PORT_TYPE_NONE &&
-		    mvsw_pr_link_modes[mode].port_type != type)
+		    prestera_link_modes[mode].port_type != type)
 			continue;
-		__set_bit(mvsw_pr_link_modes[mode].eth_mode, eth_modes);
+		__set_bit(prestera_link_modes[mode].eth_mode, eth_modes);
 	}
 
 	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((mvsw_pr_fec_caps[mode].pr_fec & fec) == 0)
+		if ((prestera_fec_caps[mode].pr_fec & fec) == 0)
 			continue;
-		__set_bit(mvsw_pr_fec_caps[mode].eth_mode, eth_modes);
+		__set_bit(prestera_fec_caps[mode].eth_mode, eth_modes);
 	}
 }
 
-static void mvsw_pr_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
-				     struct mvsw_pr_port *port)
+static void prestera_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
+				      struct prestera_port *port)
 {
 	ecmd->base.autoneg = port->autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
 
-	mvsw_modes_to_eth(ecmd->link_modes.supported,
-			  port->caps.supp_link_modes,
-			  port->caps.supp_fec,
-			  port->caps.type);
+	prestera_modes_to_eth(ecmd->link_modes.supported,
+			      port->caps.supp_link_modes,
+			      port->caps.supp_fec,
+			      port->caps.type);
 
 	if (port->caps.type != MVSW_PORT_TYPE_TP)
 		return;
@@ -860,10 +721,10 @@ static void mvsw_pr_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
 		return;
 
 	if (port->autoneg) {
-		mvsw_modes_to_eth(ecmd->link_modes.advertising,
-				  port->adver_link_modes,
-				  port->adver_fec,
-				  port->caps.type);
+		prestera_modes_to_eth(ecmd->link_modes.advertising,
+				      port->adver_link_modes,
+				      port->adver_fec,
+				      port->caps.type);
 		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
 						     Autoneg);
 	} else if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
@@ -871,10 +732,10 @@ static void mvsw_pr_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
 						     Autoneg);
 }
 
-static int mvsw_modes_from_eth(struct mvsw_pr_port *port,
-			       const unsigned long *advertising,
-			       const unsigned long *supported,
-			       u64 *link_modes, u8 *fec)
+static int prestera_modes_from_eth(struct prestera_port *port,
+				   const unsigned long *advertising,
+				   const unsigned long *supported,
+				   u64 *link_modes, u8 *fec)
 {
 	struct ethtool_link_ksettings curr = {};
 	u32 mode;
@@ -882,7 +743,7 @@ static int mvsw_modes_from_eth(struct mvsw_pr_port *port,
 	ethtool_link_ksettings_zero_link_mode(&curr, supported);
 	ethtool_link_ksettings_zero_link_mode(&curr, advertising);
 
-	mvsw_pr_port_autoneg_get(&curr, port);
+	prestera_port_autoneg_get(&curr, port);
 
 	if (linkmode_equal(advertising, curr.link_modes.advertising)) {
 		*link_modes = port->adver_link_modes;
@@ -898,17 +759,17 @@ static int mvsw_modes_from_eth(struct mvsw_pr_port *port,
 	*link_modes  = 0;
 	*fec = 0;
 	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if (!test_bit(mvsw_pr_link_modes[mode].eth_mode, advertising))
+		if (!test_bit(prestera_link_modes[mode].eth_mode, advertising))
 			continue;
-		if (mvsw_pr_link_modes[mode].port_type != port->caps.type)
+		if (prestera_link_modes[mode].port_type != port->caps.type)
 			continue;
-		*link_modes |= mvsw_pr_link_modes[mode].pr_mask;
+		*link_modes |= prestera_link_modes[mode].pr_mask;
 	}
 
 	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if (!test_bit(mvsw_pr_fec_caps[mode].eth_mode, advertising))
+		if (!test_bit(prestera_fec_caps[mode].eth_mode, advertising))
 			continue;
-		*fec |= mvsw_pr_fec_caps[mode].pr_fec;
+		*fec |= prestera_fec_caps[mode].pr_fec;
 	}
 
 	if (*link_modes == 0 && *fec == 0) {
@@ -924,24 +785,24 @@ static int mvsw_modes_from_eth(struct mvsw_pr_port *port,
 	return 0;
 }
 
-static void mvsw_pr_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
-					struct mvsw_pr_port *port)
+static void prestera_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
+					 struct prestera_port *port)
 {
 	u32 mode;
 	u8 ptype;
 
 	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((mvsw_pr_link_modes[mode].pr_mask &
+		if ((prestera_link_modes[mode].pr_mask &
 		    port->caps.supp_link_modes) == 0)
 			continue;
-		ptype = mvsw_pr_link_modes[mode].port_type;
-		__set_bit(mvsw_pr_port_types[ptype].eth_mode,
+		ptype = prestera_link_modes[mode].port_type;
+		__set_bit(prestera_port_types[ptype].eth_mode,
 			  ecmd->link_modes.supported);
 	}
 }
 
-static void mvsw_pr_port_speed_get(struct ethtool_link_ksettings *ecmd,
-				   struct mvsw_pr_port *port)
+static void prestera_port_speed_get(struct ethtool_link_ksettings *ecmd,
+				    struct prestera_port *port)
 {
 	u32 speed;
 	int err;
@@ -950,21 +811,21 @@ static void mvsw_pr_port_speed_get(struct ethtool_link_ksettings *ecmd,
 	ecmd->base.speed = !err ? speed : SPEED_UNKNOWN;
 }
 
-static int mvsw_pr_port_link_mode_set(struct mvsw_pr_port *port,
-				      u32 speed, u8 duplex, u8 type)
+static int prestera_port_link_mode_set(struct prestera_port *port,
+				       u32 speed, u8 duplex, u8 type)
 {
 	u32 new_mode = MVSW_LINK_MODE_MAX;
 	u32 mode;
 
 	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if (speed != mvsw_pr_link_modes[mode].speed)
+		if (speed != prestera_link_modes[mode].speed)
 			continue;
-		if (duplex != mvsw_pr_link_modes[mode].duplex)
+		if (duplex != prestera_link_modes[mode].duplex)
 			continue;
-		if (!(mvsw_pr_link_modes[mode].pr_mask &
+		if (!(prestera_link_modes[mode].pr_mask &
 		    port->caps.supp_link_modes))
 			continue;
-		if (type != mvsw_pr_link_modes[mode].port_type)
+		if (type != prestera_link_modes[mode].port_type)
 			continue;
 
 		new_mode = mode;
@@ -979,8 +840,8 @@ static int mvsw_pr_port_link_mode_set(struct mvsw_pr_port *port,
 	return mvsw_pr_hw_port_link_mode_set(port, new_mode);
 }
 
-static int mvsw_pr_port_speed_duplex_set(const struct ethtool_link_ksettings
-					 *ecmd, struct mvsw_pr_port *port)
+static int prestera_port_speed_duplex_set(const struct ethtool_link_ksettings
+					  *ecmd, struct prestera_port *port)
 {
 	int err;
 	u8 duplex;
@@ -995,33 +856,34 @@ static int mvsw_pr_port_speed_duplex_set(const struct ethtool_link_ksettings
 		duplex = ecmd->base.duplex == DUPLEX_FULL ?
 			 MVSW_PORT_DUPLEX_FULL : MVSW_PORT_DUPLEX_HALF;
 	else
-		duplex = mvsw_pr_link_modes[curr_mode].duplex;
+		duplex = prestera_link_modes[curr_mode].duplex;
 
 	if (ecmd->base.speed != SPEED_UNKNOWN)
 		speed = ecmd->base.speed;
 	else
-		speed = mvsw_pr_link_modes[curr_mode].speed;
+		speed = prestera_link_modes[curr_mode].speed;
 
-	return mvsw_pr_port_link_mode_set(port, speed, duplex, port->caps.type);
+	return prestera_port_link_mode_set(port, speed, duplex,
+					   port->caps.type);
 }
 
-static u8 mvsw_pr_port_type_get(struct mvsw_pr_port *port)
+static u8 prestera_port_type_get(struct prestera_port *port)
 {
 	if (port->caps.type < MVSW_PORT_TYPE_MAX)
-		return mvsw_pr_port_types[port->caps.type].eth_type;
+		return prestera_port_types[port->caps.type].eth_type;
 	return PORT_OTHER;
 }
 
-static int mvsw_pr_port_type_set(const struct ethtool_link_ksettings *ecmd,
-				 struct mvsw_pr_port *port)
+static int prestera_port_type_set(const struct ethtool_link_ksettings *ecmd,
+				  struct prestera_port *port)
 {
 	int err;
 	u32 type, mode;
 	u32 new_mode = MVSW_LINK_MODE_MAX;
 
 	for (type = 0; type < MVSW_PORT_TYPE_MAX; type++) {
-		if (mvsw_pr_port_types[type].eth_type == ecmd->base.port &&
-		    test_bit(mvsw_pr_port_types[type].eth_mode,
+		if (prestera_port_types[type].eth_type == ecmd->base.port &&
+		    test_bit(prestera_port_types[type].eth_mode,
 			     ecmd->link_modes.supported)) {
 			break;
 		}
@@ -1039,9 +901,9 @@ static int mvsw_pr_port_type_set(const struct ethtool_link_ksettings *ecmd,
 	}
 
 	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((mvsw_pr_link_modes[mode].pr_mask &
+		if ((prestera_link_modes[mode].pr_mask &
 		    port->caps.supp_link_modes) &&
-		    type == mvsw_pr_link_modes[mode].port_type) {
+		    type == prestera_link_modes[mode].port_type) {
 			new_mode = mode;
 		}
 	}
@@ -1059,16 +921,16 @@ static int mvsw_pr_port_type_set(const struct ethtool_link_ksettings *ecmd,
 	return err;
 }
 
-static void mvsw_pr_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
-					struct mvsw_pr_port *port)
+static void prestera_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
+					 struct prestera_port *port)
 {
 	u64 bitmap;
 	bool pause;
 	bool asym_pause;
 
 	if (!mvsw_pr_hw_port_remote_cap_get(port, &bitmap)) {
-		mvsw_modes_to_eth(ecmd->link_modes.lp_advertising,
-				  bitmap, 0, MVSW_PORT_TYPE_NONE);
+		prestera_modes_to_eth(ecmd->link_modes.lp_advertising,
+				      bitmap, 0, MVSW_PORT_TYPE_NONE);
 
 		if (!bitmap_empty(ecmd->link_modes.lp_advertising,
 				  __ETHTOOL_LINK_MODE_MASK_NBITS)) {
@@ -1090,8 +952,8 @@ static void mvsw_pr_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
 						     Asym_Pause);
 }
 
-static void mvsw_pr_port_duplex_get(struct ethtool_link_ksettings *ecmd,
-				    struct mvsw_pr_port *port)
+static void prestera_port_duplex_get(struct ethtool_link_ksettings *ecmd,
+				     struct prestera_port *port)
 {
 	u8 duplex;
 
@@ -1103,8 +965,8 @@ static void mvsw_pr_port_duplex_get(struct ethtool_link_ksettings *ecmd,
 	}
 }
 
-static int mvsw_pr_port_autoneg_set(struct mvsw_pr_port *port, bool enable,
-				    u64 link_modes, u8 fec)
+static int prestera_port_autoneg_set(struct prestera_port *port, bool enable,
+				     u64 link_modes, u8 fec)
 {
 	if (port->caps.type != MVSW_PORT_TYPE_TP)
 		return enable ? -EINVAL : 0;
@@ -1122,9 +984,9 @@ static int mvsw_pr_port_autoneg_set(struct mvsw_pr_port *port, bool enable,
 	return 0;
 }
 
-static int mvsw_pr_port_nway_reset(struct net_device *dev)
+static int prestera_port_nway_reset(struct net_device *dev)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	if (netif_running(dev) &&
 	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
@@ -1134,8 +996,8 @@ static int mvsw_pr_port_nway_reset(struct net_device *dev)
 	return -EINVAL;
 }
 
-static int mvsw_pr_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
-				 struct mvsw_pr_port *port)
+static int prestera_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
+				  struct prestera_port *port)
 {
 	if (ecmd->base.eth_tp_mdix_ctrl != ETH_TP_MDI_INVALID &&
 	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
@@ -1145,10 +1007,10 @@ static int mvsw_pr_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
 	return 0;
 }
 
-static int mvsw_pr_port_get_link_ksettings(struct net_device *dev,
-					   struct ethtool_link_ksettings *ecmd)
+static int prestera_port_get_link_ksettings(struct net_device *dev,
+					    struct ethtool_link_ksettings *ecmd)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	/* Dirty hook: Deinit ecmd.
 	 * It caused by suspicious phylink_ethtool_ksettings_get()
@@ -1160,29 +1022,28 @@ static int mvsw_pr_port_get_link_ksettings(struct net_device *dev,
 	ethtool_link_ksettings_zero_link_mode(ecmd, lp_advertising);
 	ecmd->base.speed = SPEED_UNKNOWN;
 	ecmd->base.duplex = DUPLEX_UNKNOWN;
-	ecmd->base.autoneg = AUTONEG_DISABLE;
 #ifdef CONFIG_PHYLINK
 	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
 		return phylink_ethtool_ksettings_get(port->phy_link, ecmd);
 #endif /* CONFIG_PHYLINK */
 
-	mvsw_pr_port_supp_types_get(ecmd, port);
+	prestera_port_supp_types_get(ecmd, port);
 
-	mvsw_pr_port_autoneg_get(ecmd, port);
+	prestera_port_autoneg_get(ecmd, port);
 
 	if (port->autoneg && netif_carrier_ok(dev) &&
 	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
-		mvsw_pr_port_remote_cap_get(ecmd, port);
+		prestera_port_remote_cap_get(ecmd, port);
 
 	if (netif_carrier_ok(dev)) {
-		mvsw_pr_port_speed_get(ecmd, port);
-		mvsw_pr_port_duplex_get(ecmd, port);
+		prestera_port_speed_get(ecmd, port);
+		prestera_port_duplex_get(ecmd, port);
 	} else {
 		ecmd->base.speed = SPEED_UNKNOWN;
 		ecmd->base.duplex = DUPLEX_UNKNOWN;
 	}
 
-	ecmd->base.port = mvsw_pr_port_type_get(port);
+	ecmd->base.port = prestera_port_type_get(port);
 
 	if (port->caps.type == MVSW_PORT_TYPE_TP &&
 	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
@@ -1192,11 +1053,11 @@ static int mvsw_pr_port_get_link_ksettings(struct net_device *dev,
 	return 0;
 }
 
-static int mvsw_pr_port_set_link_ksettings(struct net_device *dev,
-					   const struct ethtool_link_ksettings
-					   *ecmd)
+static int prestera_port_set_link_ksettings(struct net_device *dev,
+					    const struct ethtool_link_ksettings
+					    *ecmd)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	u64 adver_modes = 0;
 	u8 adver_fec = 0;
 	int err;
@@ -1206,20 +1067,20 @@ static int mvsw_pr_port_set_link_ksettings(struct net_device *dev,
 		return phylink_ethtool_ksettings_set(port->phy_link, ecmd);
 #endif /* CONFIG_PHYLINK */
 
-	err = mvsw_pr_port_type_set(ecmd, port);
+	err = prestera_port_type_set(ecmd, port);
 	if (err)
 		return err;
 
 	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER) {
-		err = mvsw_pr_port_mdix_set(ecmd, port);
+		err = prestera_port_mdix_set(ecmd, port);
 		if (err)
 			return err;
 	}
 
 	if (ecmd->base.autoneg == AUTONEG_ENABLE) {
-		if (mvsw_modes_from_eth(port, ecmd->link_modes.advertising,
-					ecmd->link_modes.supported,
-					&adver_modes, &adver_fec))
+		if (prestera_modes_from_eth(port, ecmd->link_modes.advertising,
+					    ecmd->link_modes.supported,
+					    &adver_modes, &adver_fec))
 			return -EINVAL;
 		if (!port->autoneg && !adver_modes)
 			adver_modes = port->caps.supp_link_modes;
@@ -1228,14 +1089,14 @@ static int mvsw_pr_port_set_link_ksettings(struct net_device *dev,
 		adver_fec = port->adver_fec;
 	}
 
-	err = mvsw_pr_port_autoneg_set(port,
-				       ecmd->base.autoneg == AUTONEG_ENABLE,
-				       adver_modes, adver_fec);
+	err = prestera_port_autoneg_set(port,
+					ecmd->base.autoneg == AUTONEG_ENABLE,
+					adver_modes, adver_fec);
 	if (err)
 		return err;
 
 	if (ecmd->base.autoneg == AUTONEG_DISABLE) {
-		err = mvsw_pr_port_speed_duplex_set(ecmd, port);
+		err = prestera_port_speed_duplex_set(ecmd, port);
 		if (err)
 			return err;
 	}
@@ -1243,10 +1104,10 @@ static int mvsw_pr_port_set_link_ksettings(struct net_device *dev,
 	return 0;
 }
 
-static int mvsw_pr_port_get_fecparam(struct net_device *dev,
-				     struct ethtool_fecparam *fecparam)
+static int prestera_port_get_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	u32 mode;
 	u8 active;
 	int err;
@@ -1257,23 +1118,23 @@ static int mvsw_pr_port_get_fecparam(struct net_device *dev,
 
 	fecparam->fec = 0;
 	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((mvsw_pr_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
+		if ((prestera_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
 			continue;
-		fecparam->fec |= mvsw_pr_fec_caps[mode].eth_fec;
+		fecparam->fec |= prestera_fec_caps[mode].eth_fec;
 	}
 
 	if (active < MVSW_PORT_FEC_MAX)
-		fecparam->active_fec = mvsw_pr_fec_caps[active].eth_fec;
+		fecparam->active_fec = prestera_fec_caps[active].eth_fec;
 	else
 		fecparam->active_fec = ETHTOOL_FEC_AUTO;
 
 	return 0;
 }
 
-static int mvsw_pr_port_set_fecparam(struct net_device *dev,
-				     struct ethtool_fecparam *fecparam)
+static int prestera_port_set_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	u8 fec, active;
 	u32 mode;
 	int err;
@@ -1289,8 +1150,8 @@ static int mvsw_pr_port_set_fecparam(struct net_device *dev,
 
 	fec = MVSW_PORT_FEC_MAX;
 	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((mvsw_pr_fec_caps[mode].eth_fec & fecparam->fec) &&
-		    (mvsw_pr_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
+		if ((prestera_fec_caps[mode].eth_fec & fecparam->fec) &&
+		    (prestera_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
 			fec = mode;
 			break;
 		}
@@ -1307,26 +1168,26 @@ static int mvsw_pr_port_set_fecparam(struct net_device *dev,
 	return mvsw_pr_hw_port_fec_set(port, fec);
 }
 
-static void mvsw_pr_port_get_ethtool_stats(struct net_device *dev,
-					   struct ethtool_stats *stats,
-					   u64 *data)
+static void prestera_port_get_ethtool_stats(struct net_device *dev,
+					    struct ethtool_stats *stats,
+					    u64 *data)
 {
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	struct mvsw_pr_port_stats *port_stats = &port->cached_hw_stats.stats;
 
 	memcpy((u8 *)data, port_stats, sizeof(*port_stats));
 }
 
-static void mvsw_pr_port_get_strings(struct net_device *dev,
-				     u32 stringset, u8 *data)
+static void prestera_port_get_strings(struct net_device *dev,
+				      u32 stringset, u8 *data)
 {
 	if (stringset != ETH_SS_STATS)
 		return;
 
-	memcpy(data, *mvsw_pr_port_cnt_name, sizeof(mvsw_pr_port_cnt_name));
+	memcpy(data, *prestera_port_cnt_name, sizeof(prestera_port_cnt_name));
 }
 
-static int mvsw_pr_port_get_sset_count(struct net_device *dev, int sset)
+static int prestera_port_get_sset_count(struct net_device *dev, int sset)
 {
 	switch (sset) {
 	case ETH_SS_STATS:
@@ -1336,35 +1197,35 @@ static int mvsw_pr_port_get_sset_count(struct net_device *dev, int sset)
 	}
 }
 
-static const struct ethtool_ops mvsw_pr_ethtool_ops = {
-	.get_drvinfo = mvsw_pr_port_get_drvinfo,
-	.get_link_ksettings = mvsw_pr_port_get_link_ksettings,
-	.set_link_ksettings = mvsw_pr_port_set_link_ksettings,
-	.get_fecparam = mvsw_pr_port_get_fecparam,
-	.set_fecparam = mvsw_pr_port_set_fecparam,
-	.get_sset_count = mvsw_pr_port_get_sset_count,
-	.get_strings = mvsw_pr_port_get_strings,
-	.get_ethtool_stats = mvsw_pr_port_get_ethtool_stats,
+static const struct ethtool_ops prestera_ethtool_ops = {
+	.get_drvinfo = prestera_port_get_drvinfo,
+	.get_link_ksettings = prestera_port_get_link_ksettings,
+	.set_link_ksettings = prestera_port_set_link_ksettings,
+	.get_fecparam = prestera_port_get_fecparam,
+	.set_fecparam = prestera_port_set_fecparam,
+	.get_sset_count = prestera_port_get_sset_count,
+	.get_strings = prestera_port_get_strings,
+	.get_ethtool_stats = prestera_port_get_ethtool_stats,
 	.get_link = ethtool_op_get_link,
-	.nway_reset = mvsw_pr_port_nway_reset
+	.nway_reset = prestera_port_nway_reset
 };
 
-int mvsw_pr_port_learning_set(struct mvsw_pr_port *port, bool learn)
+int prestera_port_learning_set(struct prestera_port *port, bool learn)
 {
 	return mvsw_pr_hw_port_learning_set(port, learn);
 }
 
-int mvsw_pr_port_uc_flood_set(struct mvsw_pr_port *port, bool flood)
+int prestera_port_uc_flood_set(struct prestera_port *port, bool flood)
 {
 	return mvsw_pr_hw_port_uc_flood_set(port, flood);
 }
 
-int mvsw_pr_port_mc_flood_set(struct mvsw_pr_port *port, bool flood)
+int prestera_port_mc_flood_set(struct prestera_port *port, bool flood)
 {
 	return mvsw_pr_hw_port_mc_flood_set(port, flood);
 }
 
-int mvsw_pr_port_pvid_set(struct mvsw_pr_port *port, u16 vid)
+int prestera_port_pvid_set(struct prestera_port *port, u16 vid)
 {
 	int err;
 
@@ -1391,7 +1252,7 @@ int mvsw_pr_port_pvid_set(struct mvsw_pr_port *port, u16 vid)
 	return err;
 }
 
-int mvsw_pr_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
+int prestera_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state)
 {
 	u8 hw_state = state;
 
@@ -1421,7 +1282,7 @@ int mvsw_pr_port_vid_stp_set(struct mvsw_pr_port *port, u16 vid, u8 state)
 }
 
 struct mvsw_pr_port_vlan*
-mvsw_pr_port_vlan_find_by_vid(const struct mvsw_pr_port *port, u16 vid)
+prestera_port_vlan_find_by_vid(const struct prestera_port *port, u16 vid)
 {
 	struct mvsw_pr_port_vlan *port_vlan;
 
@@ -1434,16 +1295,16 @@ mvsw_pr_port_vlan_find_by_vid(const struct mvsw_pr_port *port, u16 vid)
 }
 
 struct mvsw_pr_port_vlan*
-mvsw_pr_port_vlan_create(struct mvsw_pr_port *port, u16 vid, bool untagged)
+prestera_port_vlan_create(struct prestera_port *port, u16 vid, bool untagged)
 {
 	struct mvsw_pr_port_vlan *port_vlan;
 	int err;
 
-	port_vlan = mvsw_pr_port_vlan_find_by_vid(port, vid);
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (port_vlan)
 		return ERR_PTR(-EEXIST);
 
-	err = mvsw_pr_port_vlan_set(port, vid, true, untagged);
+	err = prestera_port_vlan_set(port, vid, true, untagged);
 	if (err)
 		return ERR_PTR(err);
 
@@ -1461,38 +1322,38 @@ mvsw_pr_port_vlan_create(struct mvsw_pr_port *port, u16 vid, bool untagged)
 	return port_vlan;
 
 err_port_vlan_alloc:
-	mvsw_pr_port_vlan_set(port, vid, false, false);
+	prestera_port_vlan_set(port, vid, false, false);
 	return ERR_PTR(err);
 }
 
 static void
-mvsw_pr_port_vlan_cleanup(struct mvsw_pr_port_vlan *port_vlan)
+prestera_port_vlan_cleanup(struct mvsw_pr_port_vlan *port_vlan)
 {
 	if (port_vlan->bridge_port)
 		mvsw_pr_port_vlan_bridge_leave(port_vlan);
 }
 
-void mvsw_pr_port_vlan_destroy(struct mvsw_pr_port_vlan *port_vlan)
+void prestera_port_vlan_destroy(struct mvsw_pr_port_vlan *port_vlan)
 {
-	struct mvsw_pr_port *port = port_vlan->mvsw_pr_port;
+	struct prestera_port *port = port_vlan->mvsw_pr_port;
 	u16 vid = port_vlan->vid;
 
-	mvsw_pr_port_vlan_cleanup(port_vlan);
+	prestera_port_vlan_cleanup(port_vlan);
 	list_del(&port_vlan->list);
 	kfree(port_vlan);
 	mvsw_pr_hw_vlan_port_set(port, vid, false, false);
 }
 
-int mvsw_pr_port_vlan_set(struct mvsw_pr_port *port, u16 vid,
-			  bool is_member, bool untagged)
+int prestera_port_vlan_set(struct prestera_port *port, u16 vid,
+			   bool is_member, bool untagged)
 {
 	return mvsw_pr_hw_vlan_port_set(port, vid, is_member, untagged);
 }
 
 #ifdef CONFIG_PHYLINK
-static void mvsw_pr_link_validate(struct phylink_config *config,
-	unsigned long *supported,
-	struct phylink_link_state *state)
+static void prestera_link_validate(struct phylink_config *config,
+				   unsigned long *supported,
+				   struct phylink_link_state *state)
 {
 	__ETHTOOL_DECLARE_LINK_MODE_MASK(mask) = {0,};
 
@@ -1556,16 +1417,15 @@ static void mvsw_pr_link_validate(struct phylink_config *config,
 
 empty_set:
 	bitmap_zero(supported, __ETHTOOL_LINK_MODE_MASK_NBITS);
-
 }
 
-static void mvsw_pr_mac_pcs_get_state(struct phylink_config *config,
-				      struct phylink_link_state *state)
+static void prestera_mac_pcs_get_state(struct phylink_config *config,
+				       struct phylink_link_state *state)
 {
 	struct net_device *ndev = to_net_dev(config->dev);
-	struct mvsw_pr_port *port = netdev_priv(ndev);
+	struct prestera_port *port = netdev_priv(ndev);
 
-	state->link = !!(port->hw_oper_state);
+	state->link = port->hw_oper_state;
 	state->pause = 0;
 
 	if (port->hw_oper_state) {
@@ -1582,12 +1442,12 @@ static void mvsw_pr_mac_pcs_get_state(struct phylink_config *config,
 	}
 }
 
-static void mvsw_pr_mac_config(struct phylink_config *config,
-			       unsigned int an_mode,
-			       const struct phylink_link_state *state)
+static void prestera_mac_config(struct phylink_config *config,
+				unsigned int an_mode,
+				const struct phylink_link_state *state)
 {
 	struct net_device *ndev = to_net_dev(config->dev);
-	struct mvsw_pr_port *port = netdev_priv(ndev);
+	struct prestera_port *port = netdev_priv(ndev);
 	u32 mode;
 
 	/* See sfp_select_interface... fIt */
@@ -1623,12 +1483,12 @@ static void mvsw_pr_mac_config(struct phylink_config *config,
 	 */
 
 	if (phylink_autoneg_inband(an_mode))
-		mvsw_pr_port_autoneg_set(port, false, 0, 0);
+		prestera_port_autoneg_set(port, false, 0, 0);
 	else
-		mvsw_pr_port_autoneg_set(port, false, 0, 0);
+		prestera_port_autoneg_set(port, false, 0, 0);
 }
 
-static void mvsw_pr_mac_an_restart(struct phylink_config *config)
+static void prestera_mac_an_restart(struct phylink_config *config)
 {
 	/* No need to restart autoneg as it is always with the same parameters,
 	 * because e.g. as for 1000baseX FC isn't supported. And for 1000baseT
@@ -1636,31 +1496,31 @@ static void mvsw_pr_mac_an_restart(struct phylink_config *config)
 	 */
 }
 
-static void mvsw_pr_mac_link_down(struct phylink_config *config,
-				  unsigned int mode, phy_interface_t interface)
+static void prestera_mac_link_down(struct phylink_config *config,
+				   unsigned int mode, phy_interface_t interface)
 {
 }
 
-static void mvsw_pr_mac_link_up(struct phylink_config *config,
-				struct phy_device *phy,
-				unsigned int mode, phy_interface_t interface,
-				int speed, int duplex,
-				bool tx_pause, bool rx_pause)
+static void prestera_mac_link_up(struct phylink_config *config,
+				 struct phy_device *phy,
+				 unsigned int mode, phy_interface_t interface,
+				 int speed, int duplex,
+				 bool tx_pause, bool rx_pause)
 {
 }
 
-static const struct phylink_mac_ops mvsw_pr_mac_ops = {
-	.validate = mvsw_pr_link_validate,
-	.mac_pcs_get_state = mvsw_pr_mac_pcs_get_state,
-	.mac_config = mvsw_pr_mac_config,
-	.mac_an_restart = mvsw_pr_mac_an_restart,
-	.mac_link_down = mvsw_pr_mac_link_down,
-	.mac_link_up = mvsw_pr_mac_link_up,
+static const struct phylink_mac_ops prestera_mac_ops = {
+	.validate = prestera_link_validate,
+	.mac_pcs_get_state = prestera_mac_pcs_get_state,
+	.mac_config = prestera_mac_config,
+	.mac_an_restart = prestera_mac_an_restart,
+	.mac_link_down = prestera_mac_link_down,
+	.mac_link_up = prestera_mac_link_up,
 };
 
-static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
+static int prestera_port_sfp_bind(struct prestera_port *port)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct device_node *ports, *node;
 	struct fwnode_handle *fwnode;
 	struct phylink *phy_link;
@@ -1695,7 +1555,7 @@ static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
 
 		phy_link = phylink_create(&port->phy_config, fwnode,
 					  PHY_INTERFACE_MODE_INTERNAL,
-					  &mvsw_pr_mac_ops);
+					  &prestera_mac_ops);
 		if (IS_ERR(phy_link)) {
 			netdev_err(port->net_dev, "failed to create phylink\n");
 			return PTR_ERR(phy_link);
@@ -1708,16 +1568,16 @@ static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
 	return 0;
 }
 #else
-static int mvsw_pr_port_sfp_bind(struct mvsw_pr_port *port)
+static int prestera_port_sfp_bind(struct prestera_port *port)
 {
 	return 0;
 }
 #endif
 
-static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
+static int prestera_port_create(struct prestera_switch *sw, u32 id)
 {
 	struct net_device *net_dev;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 	char *mac;
 	int err;
 
@@ -1737,7 +1597,7 @@ static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
 	err = mvsw_pr_hw_port_info_get(port, &port->fp_id,
 				       &port->hw_id, &port->dev_id);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to get port(%u) info\n", id);
+		dev_err(prestera_dev(sw), "Failed to get port(%u) info\n", id);
 		goto err_free_netdev;
 	}
 
@@ -1747,21 +1607,19 @@ static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
 
 	net_dev->needed_headroom = MVSW_PR_DSA_HLEN + 4;
 
-	net_dev->netdev_ops = &mvsw_pr_netdev_ops;
-	net_dev->ethtool_ops = &mvsw_pr_ethtool_ops;
 	net_dev->features |= NETIF_F_NETNS_LOCAL | NETIF_F_HW_TC;
 	net_dev->hw_features |= NETIF_F_HW_TC;
-	net_dev->ethtool_ops = &mvsw_pr_ethtool_ops;
-	net_dev->netdev_ops = &mvsw_pr_netdev_ops;
+	net_dev->ethtool_ops = &prestera_ethtool_ops;
+	net_dev->netdev_ops = &prestera_netdev_ops;
 	SET_NETDEV_DEV(net_dev, sw->dev->dev);
 
-	net_dev->mtu = min_t(unsigned int, sw->mtu_max, MVSW_PR_MTU_DEFAULT);
+	net_dev->mtu = min_t(unsigned int, sw->mtu_max, PRESTERA_MTU_DEFAULT);
 	net_dev->min_mtu = sw->mtu_min;
 	net_dev->max_mtu = sw->mtu_max;
 
 	err = mvsw_pr_hw_port_mtu_set(port, net_dev->mtu);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set port(%u) mtu\n", id);
+		dev_err(prestera_dev(sw), "Failed to set port(%u) mtu\n", id);
 		goto err_port_init;
 	}
 
@@ -1771,17 +1629,18 @@ static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
 
 	mac = net_dev->dev_addr;
 	memcpy(mac, sw->base_mac, net_dev->addr_len);
-	mac[net_dev->addr_len - 1] += port->fp_id + MVSW_PR_MAC_ADDR_OFFSET;
+	mac[net_dev->addr_len - 1] += port->fp_id + PRESTERA_MAC_ADDR_OFFSET;
 
 	err = mvsw_pr_hw_port_mac_set(port, mac);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set port(%u) mac addr\n", id);
+		dev_err(prestera_dev(sw),
+			"Failed to set port(%u) mac addr\n", id);
 		goto err_port_init;
 	}
 
 	err = mvsw_pr_hw_port_cap_get(port, &port->caps);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to get port(%u) caps\n", id);
+		dev_err(prestera_dev(sw), "Failed to get port(%u) caps\n", id);
 		goto err_port_init;
 	}
 
@@ -1795,12 +1654,12 @@ static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
 	port->adver_link_modes = 0;
 	port->adver_fec = 0;
 	port->autoneg = false;
-	mvsw_pr_port_autoneg_set(port, true, port->caps.supp_link_modes,
-				 BIT(MVSW_PORT_FEC_OFF_BIT));
+	prestera_port_autoneg_set(port, true, port->caps.supp_link_modes,
+				  BIT(MVSW_PORT_FEC_OFF_BIT));
 
 	err = mvsw_pr_hw_port_state_set(port, false);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set port(%u) down\n", id);
+		dev_err(prestera_dev(sw), "Failed to set port(%u) down\n", id);
 		goto err_port_init;
 	}
 
@@ -1812,15 +1671,15 @@ static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
 		goto err_port_init;
 
 	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP) {
-		err = mvsw_pr_port_sfp_bind(port);
+		err = prestera_port_sfp_bind(port);
 		if (err)
 			goto err_sfp_bind;
 	}
 
 	list_add(&port->list, &sw->port_list);
 
-	mvsw_pr_port_uc_flood_set(port, false);
-	mvsw_pr_port_mc_flood_set(port, false);
+	prestera_port_uc_flood_set(port, false);
+	prestera_port_mc_flood_set(port, false);
 
 	prestera_devlink_port_set(port);
 
@@ -1836,8 +1695,8 @@ static int mvsw_pr_port_create(struct mvsw_pr_switch *sw, u32 id)
 	return err;
 }
 
-static void mvsw_pr_port_vlan_flush(struct mvsw_pr_port *port,
-				    bool flush_default)
+static void prestera_port_vlan_flush(struct prestera_port *port,
+				     bool flush_default)
 {
 	struct mvsw_pr_port_vlan *port_vlan, *tmp;
 
@@ -1845,36 +1704,36 @@ static void mvsw_pr_port_vlan_flush(struct mvsw_pr_port *port,
 		if (!flush_default && port_vlan->vid == MVSW_PR_DEFAULT_VID)
 			continue;
 
-		mvsw_pr_port_vlan_destroy(port_vlan);
+		prestera_port_vlan_destroy(port_vlan);
 	}
 }
 
-int mvsw_pr_8021d_bridge_create(struct mvsw_pr_switch *sw, u16 *bridge_id)
+int prestera_8021d_bridge_create(struct prestera_switch *sw, u16 *bridge_id)
 {
 	return mvsw_pr_hw_bridge_create(sw, bridge_id);
 }
 
-int mvsw_pr_8021d_bridge_delete(struct mvsw_pr_switch *sw, u16 bridge_id)
+int prestera_8021d_bridge_delete(struct prestera_switch *sw, u16 bridge_id)
 {
 	return mvsw_pr_hw_bridge_delete(sw, bridge_id);
 }
 
-int mvsw_pr_8021d_bridge_port_add(struct mvsw_pr_port *port, u16 bridge_id)
+int prestera_8021d_bridge_port_add(struct prestera_port *port, u16 bridge_id)
 {
 	return mvsw_pr_hw_bridge_port_add(port, bridge_id);
 }
 
-int mvsw_pr_8021d_bridge_port_delete(struct mvsw_pr_port *port, u16 bridge_id)
+int prestera_8021d_bridge_port_delete(struct prestera_port *port, u16 bridge_id)
 {
 	return mvsw_pr_hw_bridge_port_delete(port, bridge_id);
 }
 
-int mvsw_pr_switch_ageing_set(struct mvsw_pr_switch *sw, u32 ageing_time)
+int prestera_switch_ageing_set(struct prestera_switch *sw, u32 ageing_time)
 {
 	return mvsw_pr_hw_switch_ageing_set(sw, ageing_time / 1000);
 }
 
-int mvsw_pr_dev_if_type(const struct net_device *dev)
+int prestera_dev_if_type(const struct net_device *dev)
 {
 	struct macvlan_dev *vlan;
 
@@ -1886,14 +1745,14 @@ int mvsw_pr_dev_if_type(const struct net_device *dev)
 		return MVSW_IF_LAG_E;
 	else if (netif_is_macvlan(dev)) {
 		vlan = netdev_priv(dev);
-		return mvsw_pr_dev_if_type(vlan->lowerdev);
+		return prestera_dev_if_type(vlan->lowerdev);
 	}
 	else
 		return MVSW_IF_PORT_E;
 }
 
-int mvsw_pr_lpm_add(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len, u32 grp_id)
+int prestera_lpm_add(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct mvsw_pr_ip_addr *addr, u32 prefix_len, u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1906,8 +1765,8 @@ int mvsw_pr_lpm_add(struct mvsw_pr_switch *sw, u16 hw_vr_id,
 				  prefix_len, grp_id);
 }
 
-int mvsw_pr_lpm_del(struct mvsw_pr_switch *sw, u16 hw_vr_id,
-		    struct mvsw_pr_ip_addr *addr, u32 prefix_len)
+int prestera_lpm_del(struct prestera_switch *sw, u16 hw_vr_id,
+		     struct mvsw_pr_ip_addr *addr, u32 prefix_len)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1920,8 +1779,8 @@ int mvsw_pr_lpm_del(struct mvsw_pr_switch *sw, u16 hw_vr_id,
 				  prefix_len);
 }
 
-int mvsw_pr_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id)
+int prestera_nh_entries_set(const struct prestera_switch *sw, int count,
+			    struct mvsw_pr_neigh_info *nhs, u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1932,8 +1791,8 @@ int mvsw_pr_nh_entries_set(const struct mvsw_pr_switch *sw, int count,
 	return mvsw_pr_hw_nh_entries_set(sw, count, nhs, grp_id);
 }
 
-int mvsw_pr_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
-			   struct mvsw_pr_neigh_info *nhs, u32 grp_id)
+int prestera_nh_entries_get(const struct prestera_switch *sw, int count,
+			    struct mvsw_pr_neigh_info *nhs, u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1944,8 +1803,20 @@ int mvsw_pr_nh_entries_get(const struct mvsw_pr_switch *sw, int count,
 	return mvsw_pr_hw_nh_entries_get(sw, count, nhs, grp_id);
 }
 
-int mvsw_pr_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 *grp_id)
+int prestera_nhgrp_blk_get(const struct prestera_switch *sw, u8 *hw_state,
+			   u32 buf_size)
+{
+	/* Dont waste time on hw requests,
+	 * if router (and probably vr) aborted
+	 */
+	if (sw->router->aborted)
+		return -ENOENT;
+
+	return mvsw_pr_hw_nhgrp_blk_get(sw, hw_state, buf_size);
+}
+
+int prestera_nh_group_create(const struct prestera_switch *sw, u16 nh_count,
+			     u32 *grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1956,8 +1827,8 @@ int mvsw_pr_nh_group_create(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return mvsw_pr_hw_nh_group_create(sw, nh_count, grp_id);
 }
 
-int mvsw_pr_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
-			    u32 grp_id)
+int prestera_nh_group_delete(const struct prestera_switch *sw, u16 nh_count,
+			     u32 grp_id)
 {
 	/* Dont waste time on hw requests,
 	 * if router (and probably vr) aborted
@@ -1968,72 +1839,72 @@ int mvsw_pr_nh_group_delete(const struct mvsw_pr_switch *sw, u16 nh_count,
 	return mvsw_pr_hw_nh_group_delete(sw, nh_count, grp_id);
 }
 
-int mvsw_pr_mp4_hash_set(const struct mvsw_pr_switch *sw, u8 hash_policy)
+int prestera_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy)
 {
 	return mvsw_pr_hw_mp4_hash_set(sw, hash_policy);
 }
 
-int mvsw_pr_fdb_flush_vlan(struct mvsw_pr_switch *sw, u16 vid,
-			   enum mvsw_pr_fdb_flush_mode mode)
+int prestera_fdb_flush_vlan(struct prestera_switch *sw, u16 vid,
+			    enum mvsw_pr_fdb_flush_mode mode)
 {
 	return mvsw_pr_hw_fdb_flush_vlan(sw, vid, mode);
 }
 
-int mvsw_pr_fdb_flush_port_vlan(struct mvsw_pr_port *port, u16 vid,
-				enum mvsw_pr_fdb_flush_mode mode)
+int prestera_fdb_flush_port_vlan(struct prestera_port *port, u16 vid,
+				 enum mvsw_pr_fdb_flush_mode mode)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_fdb_flush_lag_vlan(port->sw, port->lag_id,
 						     vid, mode);
 	else
 		return mvsw_pr_hw_fdb_flush_port_vlan(port, vid, mode);
 }
 
-int mvsw_pr_fdb_flush_port(struct mvsw_pr_port *port,
-			   enum mvsw_pr_fdb_flush_mode mode)
+int prestera_fdb_flush_port(struct prestera_port *port,
+			    enum mvsw_pr_fdb_flush_mode mode)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_fdb_flush_lag(port->sw, port->lag_id, mode);
 	else
 		return mvsw_pr_hw_fdb_flush_port(port, mode);
 }
 
-int mvsw_pr_macvlan_add(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid)
+int prestera_macvlan_add(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid)
 {
 	return mvsw_pr_hw_macvlan_add(sw, vr_id, mac,  vid);
 }
 
-int mvsw_pr_macvlan_del(const struct mvsw_pr_switch *sw, u16 vr_id,
-			const u8 *mac, u16 vid)
+int prestera_macvlan_del(const struct prestera_switch *sw, u16 vr_id,
+			 const u8 *mac, u16 vid)
 {
 	return mvsw_pr_hw_macvlan_del(sw, vr_id, mac,  vid);
 }
 
 static struct prestera_lag *
-prestera_lag_get(struct mvsw_pr_switch *sw, u8 id)
+prestera_lag_get(struct prestera_switch *sw, u8 id)
 {
 	return id < sw->lag_max ? &sw->lags[id] : NULL;
 }
 
-static void mvsw_pr_port_lag_create(struct mvsw_pr_switch *sw, u16 lag_id,
-				    struct net_device *lag_dev)
+static void prestera_port_lag_create(struct prestera_switch *sw, u16 lag_id,
+				     struct net_device *lag_dev)
 {
 	INIT_LIST_HEAD(&sw->lags[lag_id].members);
 	sw->lags[lag_id].dev = lag_dev;
 }
 
-static void mvsw_pr_port_lag_destroy(struct mvsw_pr_switch *sw, u16 lag_id)
+static void prestera_port_lag_destroy(struct prestera_switch *sw, u16 lag_id)
 {
 	WARN_ON(!list_empty(&sw->lags[lag_id].members));
 	sw->lags[lag_id].dev = NULL;
 	sw->lags[lag_id].member_count = 0;
 }
 
-int prestera_lag_member_add(struct mvsw_pr_port *port,
+int prestera_lag_member_add(struct prestera_port *port,
 			    struct net_device *lag_dev, u16 lag_id)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct prestera_lag_member *member;
 	struct prestera_lag *lag;
 
@@ -2042,7 +1913,7 @@ int prestera_lag_member_add(struct mvsw_pr_port *port,
 	if (lag->member_count >= sw->lag_member_max)
 		return -ENOSPC;
 	else if (!lag->member_count)
-		mvsw_pr_port_lag_create(sw, lag_id, lag_dev);
+		prestera_port_lag_create(sw, lag_id, lag_dev);
 
 	member = kzalloc(sizeof(*member), GFP_KERNEL);
 	if (!member)
@@ -2051,7 +1922,7 @@ int prestera_lag_member_add(struct mvsw_pr_port *port,
 	if (mvsw_pr_hw_lag_member_add(port, lag_id)) {
 		kfree(member);
 		if (!lag->member_count)
-			mvsw_pr_port_lag_destroy(sw, lag_id);
+			prestera_port_lag_destroy(sw, lag_id);
 		return -EBUSY;
 	}
 
@@ -2062,9 +1933,9 @@ int prestera_lag_member_add(struct mvsw_pr_port *port,
 	return 0;
 }
 
-int prestera_lag_member_del(struct mvsw_pr_port *port)
+int prestera_lag_member_del(struct prestera_port *port)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct prestera_lag_member *member;
 	struct list_head *pos, *n;
 	u16 lag_id = port->lag_id;
@@ -2093,23 +1964,23 @@ int prestera_lag_member_del(struct mvsw_pr_port *port)
 
 	if (!lag->member_count) {
 		prestera_lag_router_leave(sw, lag->dev);
-		mvsw_pr_port_lag_destroy(sw, lag_id);
+		prestera_port_lag_destroy(sw, lag_id);
 	}
 
 	return 0;
 }
 
-int prestera_lag_member_enable(struct mvsw_pr_port *port, bool enable)
+int prestera_lag_member_enable(struct prestera_port *port, bool enable)
 {
 	return mvsw_pr_hw_lag_member_enable(port, port->lag_id, enable);
 }
 
-bool mvsw_pr_port_is_lag_member(const struct mvsw_pr_port *port)
+bool prestera_port_is_lag_member(const struct prestera_port *port)
 {
 	return port->lag_id < port->sw->lag_max;
 }
 
-int prestera_lag_id_find(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
+int prestera_lag_id_find(struct prestera_switch *sw, struct net_device *lag_dev,
 			 u16 *lag_id)
 {
 	struct prestera_lag *lag;
@@ -2133,19 +2004,19 @@ int prestera_lag_id_find(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
 	return 0;
 }
 
-void prestera_lag_member_rif_leave(const struct mvsw_pr_port *port,
+void prestera_lag_member_rif_leave(const struct prestera_port *port,
 				   u16 lag_id, u16 vr_id)
 {
 	mvsw_pr_hw_lag_member_rif_leave(port, lag_id, vr_id);
 }
 
-static int prestera_lag_init(struct mvsw_pr_switch *sw)
+static int prestera_lag_init(struct prestera_switch *sw)
 {
 	sw->lags = kcalloc(sw->lag_max, sizeof(*sw->lags), GFP_KERNEL);
 	return sw->lags ? 0 : -ENOMEM;
 }
 
-static void prestera_lag_fini(struct mvsw_pr_switch *sw)
+static void prestera_lag_fini(struct prestera_switch *sw)
 {
 	u8 idx;
 
@@ -2155,11 +2026,133 @@ static void prestera_lag_fini(struct mvsw_pr_switch *sw)
 	kfree(sw->lags);
 }
 
-static int mvsw_pr_clear_ports(struct mvsw_pr_switch *sw)
+static int prestera_span_init(struct prestera_switch *sw)
+{
+	struct prestera_span *span;
+
+	span = kzalloc(sizeof(*span), GFP_KERNEL);
+	if (!span)
+		return -ENOMEM;
+
+	INIT_LIST_HEAD(&span->entries);
+
+	sw->span = span;
+	span->sw = sw;
+
+	return 0;
+}
+
+static void prestera_span_fini(struct prestera_switch *sw)
+{
+	struct prestera_span *span = sw->span;
+
+	WARN_ON(!list_empty(&span->entries));
+	kfree(span);
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_create(struct prestera_port *port, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+
+	entry = kzalloc(sizeof(*entry), GFP_KERNEL);
+	if (!entry)
+		return ERR_PTR(-ENOMEM);
+
+	refcount_set(&entry->ref_count, 1);
+	entry->port = port;
+	entry->id = span_id;
+	list_add_tail(&entry->list, &port->sw->span->entries);
+
+	return entry;
+}
+
+static void prestera_span_entry_del(struct prestera_span_entry *entry)
+{
+	list_del(&entry->list);
+	kfree(entry);
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_find_by_id(struct prestera_span *span, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+
+	list_for_each_entry(entry, &span->entries, list) {
+		if (entry->id == span_id)
+			return entry;
+	}
+
+	return NULL;
+}
+
+static struct prestera_span_entry *
+prestera_span_entry_find_by_port(struct prestera_span *span,
+				 struct prestera_port *port)
+{
+	struct prestera_span_entry *entry;
+
+	list_for_each_entry(entry, &span->entries, list) {
+		if (entry->port == port)
+			return entry;
+	}
+
+	return NULL;
+}
+
+int prestera_span_get(struct prestera_port *port, u8 *span_id)
+{
+	u8 new_span_id;
+	struct prestera_switch *sw = port->sw;
+	struct prestera_span_entry *entry;
+	int err;
+
+	entry = prestera_span_entry_find_by_port(sw->span, port);
+	if (entry) {
+		refcount_inc(&entry->ref_count);
+		*span_id = entry->id;
+		return 0;
+	}
+
+	err = prestera_hw_span_get(port, &new_span_id);
+	if (err)
+		return err;
+
+	entry = prestera_span_entry_create(port, new_span_id);
+	if (IS_ERR(entry)) {
+		prestera_hw_span_release(sw, new_span_id);
+		return PTR_ERR(entry);
+	}
+
+	*span_id = new_span_id;
+	return 0;
+}
+
+int prestera_span_put(const struct prestera_switch *sw, u8 span_id)
+{
+	struct prestera_span_entry *entry;
+	int err;
+
+	entry = prestera_span_entry_find_by_id(sw->span, span_id);
+	if (!entry)
+		return false;
+
+	if (!refcount_dec_and_test(&entry->ref_count))
+		return 0;
+
+	err = prestera_hw_span_release(sw, span_id);
+	if (err)
+		return err;
+
+	prestera_span_entry_del(entry);
+	return 0;
+}
+
+static int prestera_clear_ports(struct prestera_switch *sw)
 {
 	struct net_device *net_dev;
 	struct list_head *pos, *n;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
 	list_for_each_safe(pos, n, &sw->port_list) {
 		port = list_entry(pos, typeof(*port), list);
@@ -2172,7 +2165,7 @@ static int mvsw_pr_clear_ports(struct mvsw_pr_switch *sw)
 		if (port->phy_link)
 			phylink_destroy(port->phy_link);
 #endif
-		mvsw_pr_port_vlan_flush(port, true);
+		prestera_port_vlan_flush(port, true);
 		WARN_ON_ONCE(!list_empty(&port->vlans_list));
 		mvsw_pr_port_router_leave(port);
 		prestera_devlink_port_unregister(port);
@@ -2182,10 +2175,10 @@ static int mvsw_pr_clear_ports(struct mvsw_pr_switch *sw)
 	return (!list_empty(&sw->port_list));
 }
 
-static void mvsw_pr_port_handle_event(struct mvsw_pr_switch *sw,
-				      struct mvsw_pr_event *evt, void *arg)
+static void prestera_port_handle_event(struct prestera_switch *sw,
+				       struct mvsw_pr_event *evt, void *arg)
 {
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 	struct delayed_work *caching_dw;
 
 	port = __find_pr_port(sw, evt->port_evt.port_id);
@@ -2212,7 +2205,7 @@ static void mvsw_pr_port_handle_event(struct mvsw_pr_switch *sw,
 #endif
 
 			if (!delayed_work_pending(caching_dw))
-				queue_delayed_work(mvsw_pr_wq, caching_dw, 0);
+				queue_delayed_work(prestera_wq, caching_dw, 0);
 		} else {
 			port->hw_duplex = 0;
 			port->hw_speed = 0;
@@ -2233,18 +2226,18 @@ static void mvsw_pr_port_handle_event(struct mvsw_pr_switch *sw,
 	}
 }
 
-static bool prestera_lag_exists(const struct mvsw_pr_switch *sw, u16 lag_id)
+static bool prestera_lag_exists(const struct prestera_switch *sw, u16 lag_id)
 {
 	return lag_id < sw->lag_max &&
 	       sw->lags[lag_id].member_count != 0;
 }
 
-static void mvsw_pr_fdb_handle_event(struct mvsw_pr_switch *sw,
-				     struct mvsw_pr_event *evt, void *arg)
+static void prestera_fdb_handle_event(struct prestera_switch *sw,
+				      struct mvsw_pr_event *evt, void *arg)
 {
 	struct switchdev_notifier_fdb_info info;
 	struct net_device *dev = NULL;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 	u16 lag_id;
 
 	switch (evt->fdb_evt.type) {
@@ -2283,84 +2276,79 @@ static void mvsw_pr_fdb_handle_event(struct mvsw_pr_switch *sw,
 	rtnl_unlock();
 }
 
-int mvsw_pr_fdb_add(struct mvsw_pr_port *port, const unsigned char *mac,
-		    u16 vid, bool dynamic)
+int prestera_fdb_add(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid, bool dynamic)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_lag_fdb_add(port->sw, port->lag_id,
 					      mac, vid, dynamic);
 	else
 		return mvsw_pr_hw_fdb_add(port, mac, vid, dynamic);
 }
 
-int mvsw_pr_fdb_del(struct mvsw_pr_port *port, const unsigned char *mac,
-		    u16 vid)
+int prestera_fdb_del(struct prestera_port *port, const unsigned char *mac,
+		     u16 vid)
 {
-	if (mvsw_pr_port_is_lag_member(port))
+	if (prestera_port_is_lag_member(port))
 		return mvsw_pr_hw_lag_fdb_del(port->sw, port->lag_id,
 					      mac, vid);
 	else
 		return mvsw_pr_hw_fdb_del(port, mac, vid);
 }
 
-static void mvsw_pr_fdb_event_handler_unregister(struct mvsw_pr_switch *sw)
+static void prestera_fdb_event_handler_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_FDB);
 }
 
-static void mvsw_pr_port_event_handler_unregister(struct mvsw_pr_switch *sw)
+static void prestera_port_event_handler_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_PORT);
 }
 
-static void mvsw_pr_event_handlers_unregister(struct mvsw_pr_switch *sw)
+static void prestera_event_handlers_unregister(struct prestera_switch *sw)
 {
-	mvsw_pr_fdb_event_handler_unregister(sw);
-	mvsw_pr_port_event_handler_unregister(sw);
+	prestera_fdb_event_handler_unregister(sw);
+	prestera_port_event_handler_unregister(sw);
 }
 
-static int mvsw_pr_fdb_event_handler_register(struct mvsw_pr_switch *sw)
+static int prestera_fdb_event_handler_register(struct prestera_switch *sw)
 {
 	return mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_FDB,
-						 mvsw_pr_fdb_handle_event,
+						 prestera_fdb_handle_event,
 						 NULL);
 }
 
-static int mvsw_pr_port_event_handler_register(struct mvsw_pr_switch *sw)
+static int prestera_port_event_handler_register(struct prestera_switch *sw)
 {
 	return mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_PORT,
-						 mvsw_pr_port_handle_event,
+						 prestera_port_handle_event,
 						 NULL);
 }
 
-static int mvsw_pr_event_handlers_register(struct mvsw_pr_switch *sw)
+static int prestera_event_handlers_register(struct prestera_switch *sw)
 {
 	int err;
 
-	err = mvsw_pr_port_event_handler_register(sw);
+	err = prestera_port_event_handler_register(sw);
 	if (err)
 		return err;
 
-	err = mvsw_pr_fdb_event_handler_register(sw);
+	err = prestera_fdb_event_handler_register(sw);
 	if (err)
 		goto err_fdb_handler_register;
 
 	return 0;
 
 err_fdb_handler_register:
-	mvsw_pr_port_event_handler_unregister(sw);
+	prestera_port_event_handler_unregister(sw);
 	return err;
 }
 
-int mvsw_pr_schedule_dw(struct delayed_work *dwork, unsigned long delay)
+struct prestera_port *prestera_port_find(u32 dev_hw_id, u32 port_hw_id)
 {
-	return queue_delayed_work(mvsw_pr_wq, dwork, delay);
-}
-
-const struct mvsw_pr_port *mvsw_pr_port_find(u32 dev_hw_id, u32 port_hw_id)
-{
-	struct mvsw_pr_port *port = NULL;
-	struct mvsw_pr_switch *sw;
+	struct prestera_port *port = NULL;
+	struct prestera_switch *sw;
 
 	list_for_each_entry(sw, &switches_registered, list) {
 		list_for_each_entry(port, &sw->port_list, list) {
@@ -2372,7 +2360,7 @@ const struct mvsw_pr_port *mvsw_pr_port_find(u32 dev_hw_id, u32 port_hw_id)
 	return NULL;
 }
 
-static int mvsw_pr_sw_init_base_mac(struct mvsw_pr_switch *sw)
+static int prestera_sw_init_base_mac(struct prestera_switch *sw)
 {
 	struct device_node *mac_dev_np;
 	u32 lsb;
@@ -2393,7 +2381,7 @@ static int mvsw_pr_sw_init_base_mac(struct mvsw_pr_switch *sw)
 		eth_random_addr(sw->base_mac);
 
 	lsb = sw->base_mac[ETH_ALEN - 1];
-	if (lsb + sw->port_count + MVSW_PR_MAC_ADDR_OFFSET > 0xFF)
+	if (lsb + sw->port_count + PRESTERA_MAC_ADDR_OFFSET > 0xFF)
 		sw->base_mac[ETH_ALEN - 1] = 0;
 
 	err = mvsw_pr_hw_switch_mac_set(sw, sw->base_mac);
@@ -2403,7 +2391,7 @@ static int mvsw_pr_sw_init_base_mac(struct mvsw_pr_switch *sw)
 	return 0;
 }
 
-static int mvsw_pr_init(struct mvsw_pr_switch *sw)
+static int prestera_init(struct prestera_switch *sw)
 {
 	u32 port;
 	int err;
@@ -2412,21 +2400,22 @@ static int mvsw_pr_init(struct mvsw_pr_switch *sw)
 
 	err = mvsw_pr_hw_switch_init(sw);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to init Switch device\n");
+		dev_err(prestera_dev(sw), "Failed to init Switch device\n");
 		return err;
 	}
 
 	err = mvsw_pr_hw_switch_trap_policer_set(sw, trap_policer_profile);
 	if (err) {
-		dev_err(mvsw_dev(sw), "Failed to set trap policer profile\n");
+		dev_err(prestera_dev(sw),
+			"Failed to set trap policer profile\n");
 		return err;
 	}
 
-	err = mvsw_pr_sw_init_base_mac(sw);
+	err = prestera_sw_init_base_mac(sw);
 	if (err)
 		return err;
 
-	dev_info(mvsw_dev(sw), "Initialized Switch device\n");
+	dev_info(prestera_dev(sw), "Initialized Switch device\n");
 
 	err = prestera_lag_init(sw);
 	if (err)
@@ -2443,20 +2432,20 @@ static int mvsw_pr_init(struct mvsw_pr_switch *sw)
 	INIT_LIST_HEAD(&sw->port_list);
 
 	for (port = 0; port < sw->port_count; port++) {
-		err = mvsw_pr_port_create(sw, port);
+		err = prestera_port_create(sw, port);
 		if (err)
 			goto err_ports_init;
 	}
 
-	err = mvsw_pr_rxtx_switch_init(sw);
+	err = prestera_rxtx_switch_init(sw);
 	if (err)
 		goto err_rxtx_init;
 
-	err = mvsw_pr_event_handlers_register(sw);
+	err = prestera_event_handlers_register(sw);
 	if (err)
 		goto err_event_handlers;
 
-	err = mvsw_pr_debugfs_init(sw);
+	err = prestera_debugfs_init(sw);
 	if (err)
 		goto err_debugfs_init;
 
@@ -2464,31 +2453,45 @@ static int mvsw_pr_init(struct mvsw_pr_switch *sw)
 	if (err)
 		goto err_acl_init;
 
+	err = prestera_span_init(sw);
+	if (err)
+		goto err_span_init;
+
+	err = prestera_storm_control_init(sw);
+	if (err)
+		goto err_storm_control_init;
+
 	return 0;
 
+err_storm_control_init:
+err_span_init:
 err_acl_init:
 err_debugfs_init:
-	mvsw_pr_event_handlers_unregister(sw);
+	prestera_event_handlers_unregister(sw);
 err_event_handlers:
-	mvsw_pr_rxtx_switch_fini(sw);
+	prestera_rxtx_switch_fini(sw);
 err_rxtx_init:
 err_ports_init:
-	mvsw_pr_clear_ports(sw);
+	prestera_clear_ports(sw);
 err_devl_reg:
 	prestera_switchdev_unregister(sw);
 	return err;
 }
 
-static void mvsw_pr_fini(struct mvsw_pr_switch *sw)
+static void prestera_fini(struct prestera_switch *sw)
 {
-	mvsw_pr_debugfs_fini(sw);
+	prestera_debugfs_fini(sw);
+	mvsw_pr_hw_keepalive_fini(sw);
 
-	mvsw_pr_event_handlers_unregister(sw);
+	prestera_event_handlers_unregister(sw);
 
-	mvsw_pr_clear_ports(sw);
-	mvsw_pr_rxtx_switch_fini(sw);
+	prestera_storm_control_fini(sw);
+
+	prestera_clear_ports(sw);
+	prestera_rxtx_switch_fini(sw);
 	prestera_devlink_unregister(sw);
 	prestera_switchdev_unregister(sw);
+	prestera_span_fini(sw);
 	prestera_acl_fini(sw);
 	prestera_lag_fini(sw);
 	of_node_put(sw->np);
@@ -2496,7 +2499,7 @@ static void mvsw_pr_fini(struct mvsw_pr_switch *sw)
 
 int prestera_device_register(struct prestera_device *dev)
 {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	int err;
 
 	sw = prestera_devlink_alloc();
@@ -2506,7 +2509,7 @@ int prestera_device_register(struct prestera_device *dev)
 	dev->priv = sw;
 	sw->dev = dev;
 
-	err = mvsw_pr_init(sw);
+	err = prestera_init(sw);
 	if (err) {
 		prestera_devlink_free(sw);
 		return err;
@@ -2520,45 +2523,35 @@ EXPORT_SYMBOL(prestera_device_register);
 
 void prestera_device_unregister(struct prestera_device *dev)
 {
-	struct mvsw_pr_switch *sw = dev->priv;
+	struct prestera_switch *sw = dev->priv;
 
 	list_del(&sw->list);
-	mvsw_pr_fini(sw);
+	prestera_fini(sw);
 	prestera_devlink_free(sw);
 }
 EXPORT_SYMBOL(prestera_device_unregister);
 
-static int __init mvsw_pr_module_init(void)
+static int __init prestera_module_init(void)
 {
-	int err;
-
 	INIT_LIST_HEAD(&switches_registered);
 
-	mvsw_pr_wq = alloc_workqueue(mvsw_driver_name, 0, 0);
-	if (!mvsw_pr_wq)
+	prestera_wq = alloc_workqueue(prestera_driver_name, 0, 0);
+	if (!prestera_wq)
 		return -ENOMEM;
 
-	err = mvsw_pr_rxtx_init();
-	if (err) {
-		pr_err("failed to initialize prestera rxtx\n");
-		destroy_workqueue(mvsw_pr_wq);
-		return err;
-	}
-
 	pr_info("Loading Marvell Prestera Switch Driver\n");
 	return 0;
 }
 
-static void __exit mvsw_pr_module_exit(void)
+static void __exit prestera_module_exit(void)
 {
-	destroy_workqueue(mvsw_pr_wq);
-	mvsw_pr_rxtx_fini();
+	destroy_workqueue(prestera_wq);
 
 	pr_info("Unloading Marvell Prestera Switch Driver\n");
 }
 
-module_init(mvsw_pr_module_init);
-module_exit(mvsw_pr_module_exit);
+module_init(prestera_module_init);
+module_exit(prestera_module_exit);
 
 MODULE_AUTHOR("Marvell Semi.");
 MODULE_LICENSE("GPL");
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_matchall.c b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
new file mode 100644
index 0000000..54ce5d4
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
@@ -0,0 +1,153 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+//
+// Copyright (c) 2020 Marvell International Ltd. All rights reserved.
+//
+
+#include <linux/kernel.h>
+#include <linux/list.h>
+
+#include "prestera.h"
+#include "prestera_hw.h"
+
+static int prestera_mall_rule_add(struct prestera_flow_block_binding *binding,
+				  struct prestera_port *to_port)
+{
+	int err;
+	u8 span_id;
+	struct prestera_switch *sw = binding->port->sw;
+
+	if (binding->span_id != PRESTERA_SPAN_INVALID_ID)
+		/* port already in mirroring */
+		return -EEXIST;
+
+	err = prestera_span_get(to_port, &span_id);
+	if (err)
+		return err;
+
+	err = prestera_hw_span_bind(binding->port, span_id);
+	if (err) {
+		prestera_span_put(sw, span_id);
+		return err;
+	}
+
+	binding->span_id = span_id;
+	return 0;
+}
+
+static int prestera_mall_rule_del(struct prestera_flow_block_binding *binding)
+{
+	int err;
+
+	err = prestera_hw_span_unbind(binding->port);
+	if (err)
+		return err;
+
+	err = prestera_span_put(binding->port->sw, binding->span_id);
+	if (err)
+		return err;
+
+	binding->span_id = PRESTERA_SPAN_INVALID_ID;
+	return 0;
+}
+
+static int prestera_mall_prio_check(struct prestera_flow_block *block,
+				    struct tc_cls_matchall_offload *f)
+{
+	u32 flower_prio;
+	int err;
+
+	err = prestera_flower_prio_get(block, &flower_prio);
+	if (err == -ENOENT)
+		return 0;
+	if (err)
+		return err;
+
+	if (f->common.prio >= flower_prio)
+		return -EOPNOTSUPP;
+
+	return 0;
+}
+
+int prestera_mall_prio_get(struct prestera_flow_block *block,
+			   u32 *prio)
+{
+	if (block->mall_prio == UINT_MAX)
+		return -ENOENT;
+
+	*prio = block->mall_prio;
+	return 0;
+}
+
+static void prestera_mall_prio_update(struct prestera_flow_block *block,
+				      struct tc_cls_matchall_offload *f)
+{
+	if (f->common.prio > block->mall_prio || block->mall_prio == UINT_MAX)
+		block->mall_prio = f->common.prio;
+}
+
+int prestera_mall_replace(struct prestera_flow_block *block,
+			  struct tc_cls_matchall_offload *f)
+{
+	struct prestera_flow_block_binding *binding;
+	__be16 protocol = f->common.protocol;
+	struct flow_action_entry *act;
+	struct prestera_port *port;
+	int err;
+
+	if (!flow_offload_has_one_action(&f->rule->action)) {
+		NL_SET_ERR_MSG(f->common.extack,
+			       "Only singular actions are supported");
+		return -EOPNOTSUPP;
+	}
+
+	if (f->common.chain_index) {
+		NL_SET_ERR_MSG(f->common.extack, "Only chain 0 is supported");
+		return -EOPNOTSUPP;
+	}
+
+	act = &f->rule->action.entries[0];
+
+	if (act->id != FLOW_ACTION_MIRRED)
+		return -EOPNOTSUPP;
+
+	if (protocol != htons(ETH_P_ALL))
+		return -EOPNOTSUPP;
+
+	err = prestera_mall_prio_check(block, f);
+	if (err)
+		return err;
+
+	if (!prestera_netdev_check(act->dev)) {
+		NL_SET_ERR_MSG(f->common.extack,
+			       "Only switchdev port is supported");
+		return -EINVAL;
+	}
+
+	port = netdev_priv(act->dev);
+	list_for_each_entry(binding, &block->binding_list, list) {
+		err = prestera_mall_rule_add(binding, port);
+		if (err)
+			goto rollback;
+	}
+
+	prestera_mall_prio_update(block, f);
+
+	return 0;
+
+rollback:
+	list_for_each_entry_continue_reverse(binding,
+					     &block->binding_list, list)
+		prestera_mall_rule_del(binding);
+	return err;
+}
+
+void prestera_mall_destroy(struct prestera_flow_block *block)
+{
+	struct prestera_flow_block_binding *binding;
+
+	list_for_each_entry(binding, &block->binding_list, list)
+		prestera_mall_rule_del(binding);
+
+	block->mall_prio = UINT_MAX;
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_pci.c b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
index 28ef761..79321cd 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_pci.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
@@ -13,13 +13,13 @@
 
 #include "prestera.h"
 
-#define MVSW_FW_FILENAME	"marvell/mvsw_prestera_fw.img"
+#define PRESTERA_FW_FILENAME	"marvell/mvsw_prestera_fw.img"
 
-#define MVSW_SUPP_FW_MAJ_VER 2
-#define MVSW_SUPP_FW_MIN_VER 8
-#define MVSW_SUPP_FW_PATCH_VER 0
+#define PRESTERA_SUPP_FW_MAJ_VER	2
+#define PRESTERA_SUPP_FW_MIN_VER	9
+#define PRESTERA_SUPP_FW_PATCH_VER	0
 
-#define mvsw_wait_timeout(cond, waitms) \
+#define prestera_wait(cond, waitms) \
 ({ \
 	unsigned long __wait_end = jiffies + msecs_to_jiffies(waitms); \
 	bool __wait_ret = false; \
@@ -33,9 +33,9 @@
 	__wait_ret; \
 })
 
-#define MVSW_FW_HDR_MAGIC 0x351D9D06
-#define MVSW_FW_DL_TIMEOUT 50000
-#define MVSW_FW_BLK_SZ 1024
+#define PRESTERA_FW_HDR_MAGIC	0x351D9D06
+#define PRESTERA_FW_DL_TIMEOUT	50000
+#define PRESTERA_FW_BLK_SZ	1024
 
 #define FW_VER_MAJ_MUL 1000000
 #define FW_VER_MIN_MUL 1000
@@ -48,13 +48,13 @@
 #define FW_VER_PATCH(v) \
 	(v - (FW_VER_MAJ(v) * FW_VER_MAJ_MUL) - (FW_VER_MIN(v) * FW_VER_MIN_MUL))
 
-struct mvsw_pr_fw_header {
+struct prestera_fw_header {
 	__be32 magic_number;
 	__be32 version_value;
 	u8 reserved[8];
 } __packed;
 
-struct mvsw_pr_ldr_regs {
+struct prestera_ldr_regs {
 	u32 ldr_ready;
 	u32 pad1;
 
@@ -71,55 +71,55 @@ struct mvsw_pr_ldr_regs {
 	u32 ldr_status;
 } __packed __aligned(4);
 
-#define MVSW_LDR_REG_OFFSET(f)	offsetof(struct mvsw_pr_ldr_regs, f)
+#define PRESTERA_LDR_REG_OFFSET(f)	offsetof(struct prestera_ldr_regs, f)
 
-#define MVSW_LDR_READY_MAGIC	0xf00dfeed
+#define PRESTERA_LDR_READY_MAGIC	0xf00dfeed
 
-#define MVSW_LDR_STATUS_IMG_DL		BIT(0)
-#define MVSW_LDR_STATUS_START_FW	BIT(1)
-#define MVSW_LDR_STATUS_INVALID_IMG	BIT(2)
-#define MVSW_LDR_STATUS_NOMEM		BIT(3)
+#define PRESTERA_LDR_STATUS_IMG_DL	BIT(0)
+#define PRESTERA_LDR_STATUS_START_FW	BIT(1)
+#define PRESTERA_LDR_STATUS_INVALID_IMG	BIT(2)
+#define PRESTERA_LDR_STATUS_NOMEM	BIT(3)
 
-#define mvsw_ldr_write(fw, reg, val) \
+#define prestera_ldr_write(fw, reg, val) \
 	writel(val, (fw)->ldr_regs + (reg))
-#define mvsw_ldr_read(fw, reg)	\
+#define prestera_ldr_read(fw, reg)	\
 	readl((fw)->ldr_regs + (reg))
 
 /* fw loader registers */
-#define MVSW_LDR_READY_REG	MVSW_LDR_REG_OFFSET(ldr_ready)
-#define MVSW_LDR_IMG_SIZE_REG	MVSW_LDR_REG_OFFSET(ldr_img_size)
-#define MVSW_LDR_CTL_REG	MVSW_LDR_REG_OFFSET(ldr_ctl_flags)
-#define MVSW_LDR_BUF_SIZE_REG	MVSW_LDR_REG_OFFSET(ldr_buf_size)
-#define MVSW_LDR_BUF_OFFS_REG	MVSW_LDR_REG_OFFSET(ldr_buf_offs)
-#define MVSW_LDR_BUF_RD_REG	MVSW_LDR_REG_OFFSET(ldr_buf_rd)
-#define MVSW_LDR_BUF_WR_REG	MVSW_LDR_REG_OFFSET(ldr_buf_wr)
-#define MVSW_LDR_STATUS_REG	MVSW_LDR_REG_OFFSET(ldr_status)
-
-#define MVSW_LDR_CTL_DL_START	BIT(0)
-
-#define MVSW_LDR_WR_IDX_MOVE(fw, n) \
+#define PRESTERA_LDR_READY_REG		PRESTERA_LDR_REG_OFFSET(ldr_ready)
+#define PRESTERA_LDR_IMG_SIZE_REG	PRESTERA_LDR_REG_OFFSET(ldr_img_size)
+#define PRESTERA_LDR_CTL_REG		PRESTERA_LDR_REG_OFFSET(ldr_ctl_flags)
+#define PRESTERA_LDR_BUF_SIZE_REG	PRESTERA_LDR_REG_OFFSET(ldr_buf_size)
+#define PRESTERA_LDR_BUF_OFFS_REG	PRESTERA_LDR_REG_OFFSET(ldr_buf_offs)
+#define PRESTERA_LDR_BUF_RD_REG		PRESTERA_LDR_REG_OFFSET(ldr_buf_rd)
+#define PRESTERA_LDR_BUF_WR_REG		PRESTERA_LDR_REG_OFFSET(ldr_buf_wr)
+#define PRESTERA_LDR_STATUS_REG		PRESTERA_LDR_REG_OFFSET(ldr_status)
+
+#define PRESTERA_LDR_CTL_DL_START	BIT(0)
+
+#define PRESTERA_LDR_WR_IDX_MOVE(fw, n) \
 do { \
 	typeof(fw) __fw = (fw); \
 	(__fw)->ldr_wr_idx = ((__fw)->ldr_wr_idx + (n)) & \
 				((__fw)->ldr_buf_len - 1); \
 } while (0)
 
-#define MVSW_LDR_WR_IDX_COMMIT(fw) \
+#define PRESTERA_LDR_WR_IDX_COMMIT(fw) \
 ({ \
 	typeof(fw) __fw = (fw); \
-	mvsw_ldr_write((__fw), MVSW_LDR_BUF_WR_REG, \
-		       (__fw)->ldr_wr_idx); \
+	prestera_ldr_write((__fw), PRESTERA_LDR_BUF_WR_REG, \
+			   (__fw)->ldr_wr_idx); \
 })
 
-#define MVSW_LDR_WR_PTR(fw) \
+#define PRESTERA_LDR_WR_PTR(fw) \
 ({ \
 	typeof(fw) __fw = (fw); \
 	((__fw)->ldr_ring_buf + (__fw)->ldr_wr_idx); \
 })
 
-#define MVSW_EVT_QNUM_MAX	4
+#define PRESTERA_EVT_QNUM_MAX	4
 
-struct mvsw_pr_fw_evtq_regs {
+struct prestera_fw_evtq_regs {
 	u32 rd_idx;
 	u32 pad1;
 	u32 wr_idx;
@@ -128,74 +128,96 @@ struct mvsw_pr_fw_evtq_regs {
 	u32 len;
 };
 
-struct mvsw_pr_fw_regs {
-	u32 fw_ready;
-	u32 pad;
-	u32 cmd_offs;
-	u32 cmd_len;
-	u32 evt_offs;
-	u32 evt_qnum;
+#define PRESTERA_CMD_QNUM_MAX	4
 
+struct prestera_fw_cmdq_regs {
 	u32 cmd_req_ctl;
 	u32 cmd_req_len;
 	u32 cmd_rcv_ctl;
 	u32 cmd_rcv_len;
+	u32 offs;
+	u32 len;
+};
+
+struct prestera_fw_regs {
+	u32 fw_ready;
+	u32 cmd_offs;
+	u32 cmd_len;
+	u32 cmd_qnum;
+	u32 evt_offs;
+	u32 evt_qnum;
 
 	u32 fw_status;
 	u32 rx_status;
 
-	struct mvsw_pr_fw_evtq_regs evtq_list[MVSW_EVT_QNUM_MAX];
+	struct prestera_fw_cmdq_regs cmdq_list[PRESTERA_CMD_QNUM_MAX];
+	struct prestera_fw_evtq_regs evtq_list[PRESTERA_EVT_QNUM_MAX];
 };
 
-#define MVSW_FW_REG_OFFSET(f)	offsetof(struct mvsw_pr_fw_regs, f)
+#define PRESTERA_FW_REG_OFFSET(f)	offsetof(struct prestera_fw_regs, f)
 
-#define MVSW_FW_READY_MAGIC	0xcafebabe
+#define PRESTERA_FW_READY_MAGIC	0xcafebabe
 
 /* fw registers */
-#define MVSW_FW_READY_REG		MVSW_FW_REG_OFFSET(fw_ready)
+#define PRESTERA_FW_READY_REG		PRESTERA_FW_REG_OFFSET(fw_ready)
+
+#define PRESTERA_CMDQ_REG_OFFSET(q, f)			\
+	(PRESTERA_FW_REG_OFFSET(cmdq_list) +		\
+	 (q) * sizeof(struct prestera_fw_cmdq_regs) +	\
+	 offsetof(struct prestera_fw_cmdq_regs, f))
 
-#define MVSW_CMD_BUF_OFFS_REG		MVSW_FW_REG_OFFSET(cmd_offs)
-#define MVSW_CMD_BUF_LEN_REG		MVSW_FW_REG_OFFSET(cmd_len)
-#define MVSW_EVT_BUF_OFFS_REG		MVSW_FW_REG_OFFSET(evt_offs)
-#define MVSW_EVT_QNUM_REG		MVSW_FW_REG_OFFSET(evt_qnum)
+#define PRESTERA_CMD_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(cmd_offs)
+#define PRESTERA_CMD_BUF_LEN_REG	PRESTERA_FW_REG_OFFSET(cmd_len)
+#define PRESTERA_CMD_QNUM_REG		PRESTERA_FW_REG_OFFSET(cmd_qnum)
+#define PRESTERA_EVT_BUF_OFFS_REG	PRESTERA_FW_REG_OFFSET(evt_offs)
+#define PRESTERA_EVT_QNUM_REG		PRESTERA_FW_REG_OFFSET(evt_qnum)
 
-#define MVSW_CMD_REQ_CTL_REG		MVSW_FW_REG_OFFSET(cmd_req_ctl)
-#define MVSW_CMD_REQ_LEN_REG		MVSW_FW_REG_OFFSET(cmd_req_len)
+#define PRESTERA_CMDQ_REQ_CTL_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_req_ctl)
+#define PRESTERA_CMDQ_REQ_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_req_len)
+#define PRESTERA_CMDQ_RCV_CTL_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_rcv_ctl)
+#define PRESTERA_CMDQ_RCV_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, cmd_rcv_len)
+#define PRESTERA_CMDQ_OFFS_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, offs)
+#define PRESTERA_CMDQ_LEN_REG(q)	PRESTERA_CMDQ_REG_OFFSET(q, len)
 
-#define MVSW_CMD_RCV_CTL_REG		MVSW_FW_REG_OFFSET(cmd_rcv_ctl)
-#define MVSW_CMD_RCV_LEN_REG		MVSW_FW_REG_OFFSET(cmd_rcv_len)
-#define MVSW_FW_STATUS_REG		MVSW_FW_REG_OFFSET(fw_status)
-#define MVSW_RX_STATUS_REG		MVSW_FW_REG_OFFSET(rx_status)
+#define PRESTERA_FW_STATUS_REG		PRESTERA_FW_REG_OFFSET(fw_status)
+#define PRESTERA_RX_STATUS_REG		PRESTERA_FW_REG_OFFSET(rx_status)
 
-/* MVSW_CMD_REQ_CTL_REG flags */
-#define MVSW_CMD_F_REQ_SENT		BIT(0)
-#define MVSW_CMD_F_REPL_RCVD		BIT(1)
+/* PRESTERA_CMDQ_REQ_CTL_REG flags */
+#define PRESTERA_CMD_F_REQ_SENT		BIT(0)
+#define PRESTERA_CMD_F_REPL_RCVD	BIT(1)
 
-/* MVSW_CMD_RCV_CTL_REG flags */
-#define MVSW_CMD_F_REPL_SENT		BIT(0)
+/* PRESTERA_CMDQ_RCV_CTL_REG flags */
+#define PRESTERA_CMD_F_REPL_SENT	BIT(0)
 
-/* MVSW_FW_STATUS_REG flags */
-#define MVSW_STATUS_F_EVT_OFF		BIT(0)
+/* PRESTERA_FW_STATUS_REG flags */
+#define PRESTERA_STATUS_F_EVT_OFF	BIT(0)
 
-#define MVSW_EVTQ_REG_OFFSET(q, f)			\
-	(MVSW_FW_REG_OFFSET(evtq_list) +		\
-	 (q) * sizeof(struct mvsw_pr_fw_evtq_regs) +	\
-	 offsetof(struct mvsw_pr_fw_evtq_regs, f))
+#define PRESTERA_EVTQ_REG_OFFSET(q, f)			\
+	(PRESTERA_FW_REG_OFFSET(evtq_list) +		\
+	 (q) * sizeof(struct prestera_fw_evtq_regs) +	\
+	 offsetof(struct prestera_fw_evtq_regs, f))
 
-#define MVSW_EVTQ_RD_IDX_REG(q)		MVSW_EVTQ_REG_OFFSET(q, rd_idx)
-#define MVSW_EVTQ_WR_IDX_REG(q)		MVSW_EVTQ_REG_OFFSET(q, wr_idx)
-#define MVSW_EVTQ_OFFS_REG(q)		MVSW_EVTQ_REG_OFFSET(q, offs)
-#define MVSW_EVTQ_LEN_REG(q)		MVSW_EVTQ_REG_OFFSET(q, len)
+#define PRESTERA_EVTQ_RD_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, rd_idx)
+#define PRESTERA_EVTQ_WR_IDX_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, wr_idx)
+#define PRESTERA_EVTQ_OFFS_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, offs)
+#define PRESTERA_EVTQ_LEN_REG(q)	PRESTERA_EVTQ_REG_OFFSET(q, len)
 
-#define mvsw_fw_write(fw, reg, val)	writel(val, (fw)->hw_regs + (reg))
-#define mvsw_fw_read(fw, reg)		readl((fw)->hw_regs + (reg))
+#define prestera_fw_write(fw, reg, val)	writel(val, (fw)->hw_regs + (reg))
+#define prestera_fw_read(fw, reg)	readl((fw)->hw_regs + (reg))
 
-struct mvsw_pr_fw_evtq {
+struct prestera_fw_evtq {
 	u8 __iomem *addr;
 	size_t len;
 };
 
-struct mvsw_pr_fw {
+struct prestera_fw_cmdq {
+	/* serialize access to dev->send_req */
+	struct mutex cmd_mtx;
+	u8 __iomem *addr;
+	size_t len;
+};
+
+struct prestera_fw {
 	struct workqueue_struct *wq;
 	struct prestera_device dev;
 	struct pci_dev *pci_dev;
@@ -207,28 +229,27 @@ struct mvsw_pr_fw {
 	u8 __iomem *ldr_ring_buf;
 	u32 ldr_buf_len;
 	u32 ldr_wr_idx;
-	bool active;
 
-	/* serialize access to dev->send_req */
-	struct mutex cmd_mtx;
 	size_t cmd_mbox_len;
 	u8 __iomem *cmd_mbox;
-	struct mvsw_pr_fw_evtq evt_queue[MVSW_EVT_QNUM_MAX];
+	struct prestera_fw_cmdq cmd_queue[PRESTERA_CMD_QNUM_MAX];
+	u8 cmd_qnum;
+	struct prestera_fw_evtq evt_queue[PRESTERA_EVT_QNUM_MAX];
 	u8 evt_qnum;
 	struct work_struct evt_work;
 	u8 __iomem *evt_buf;
 	u8 *evt_msg;
 };
 
-#define mvsw_fw_dev(fw)	((fw)->dev.dev)
+#define prestera_fw_dev(fw)	((fw)->dev.dev)
 
 #define PRESTERA_DEVICE(id) PCI_VDEVICE(MARVELL, (id))
 
-static struct mvsw_pr_pci_match {
+static struct prestera_pci_match {
 	struct pci_driver driver;
 	const struct pci_device_id id;
 	bool registered;
-} mvsw_pci_devices[] = {
+} prestera_devices[] = {
 	{
 		.driver = { .name = "AC3x B2B 98DX3255", },
 		.id = { PRESTERA_DEVICE(0xC804), 0 },
@@ -244,137 +265,156 @@ static struct mvsw_pr_pci_match {
 	{{ }, }
 };
 
-static int mvsw_pr_fw_load(struct mvsw_pr_fw *fw);
+static int prestera_fw_load(struct prestera_fw *fw);
+
+static void prestera_fw_cmdq_lock(struct prestera_fw *fw, u8 qid)
+{
+	mutex_lock(&fw->cmd_queue[qid].cmd_mtx);
+}
+
+static void prestera_fw_cmdq_unlock(struct prestera_fw *fw, u8 qid)
+{
+	mutex_unlock(&fw->cmd_queue[qid].cmd_mtx);
+}
 
-static u32 mvsw_pr_fw_evtq_len(struct mvsw_pr_fw *fw, u8 qid)
+static u32 prestera_fw_cmdq_len(struct prestera_fw *fw, u8 qid)
+{
+	return fw->cmd_queue[qid].len;
+}
+
+static u8 __iomem *prestera_fw_cmdq_buf(struct prestera_fw *fw, u8 qid)
+{
+	return fw->cmd_queue[qid].addr;
+}
+
+static u32 prestera_fw_evtq_len(struct prestera_fw *fw, u8 qid)
 {
 	return fw->evt_queue[qid].len;
 }
 
-static u32 mvsw_pr_fw_evtq_avail(struct mvsw_pr_fw *fw, u8 qid)
+static u32 prestera_fw_evtq_avail(struct prestera_fw *fw, u8 qid)
 {
-	u32 wr_idx = mvsw_fw_read(fw, MVSW_EVTQ_WR_IDX_REG(qid));
-	u32 rd_idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
+	u32 wr_idx = prestera_fw_read(fw, PRESTERA_EVTQ_WR_IDX_REG(qid));
+	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
 
-	return CIRC_CNT(wr_idx, rd_idx, mvsw_pr_fw_evtq_len(fw, qid));
+	return CIRC_CNT(wr_idx, rd_idx, prestera_fw_evtq_len(fw, qid));
 }
 
-static void mvsw_pr_fw_evtq_rd_set(struct mvsw_pr_fw *fw,
-				   u8 qid, u32 idx)
+static void prestera_fw_evtq_rd_set(struct prestera_fw *fw, u8 qid, u32 idx)
 {
-	u32 rd_idx = idx & (mvsw_pr_fw_evtq_len(fw, qid) - 1);
+	u32 rd_idx = idx & (prestera_fw_evtq_len(fw, qid) - 1);
 
-	mvsw_fw_write(fw, MVSW_EVTQ_RD_IDX_REG(qid), rd_idx);
+	prestera_fw_write(fw, PRESTERA_EVTQ_RD_IDX_REG(qid), rd_idx);
 }
 
-static u8 __iomem *mvsw_pr_fw_evtq_buf(struct mvsw_pr_fw *fw,
-				       u8 qid)
+static u8 __iomem *prestera_fw_evtq_buf(struct prestera_fw *fw, u8 qid)
 {
 	return fw->evt_queue[qid].addr;
 }
 
-static u32 mvsw_pr_fw_evtq_read32(struct mvsw_pr_fw *fw, u8 qid)
+static u32 prestera_fw_evtq_read32(struct prestera_fw *fw, u8 qid)
 {
-	u32 rd_idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
+	u32 rd_idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
 	u32 val;
 
-	val = readl(mvsw_pr_fw_evtq_buf(fw, qid) + rd_idx);
-	mvsw_pr_fw_evtq_rd_set(fw, qid, rd_idx + 4);
+	val = readl(prestera_fw_evtq_buf(fw, qid) + rd_idx);
+	prestera_fw_evtq_rd_set(fw, qid, rd_idx + 4);
 	return val;
 }
 
-static ssize_t mvsw_pr_fw_evtq_read_buf(struct mvsw_pr_fw *fw,
-					u8 qid, u8 *buf, size_t len)
+static ssize_t prestera_fw_evtq_read_buf(struct prestera_fw *fw, u8 qid,
+					 u8 *buf, size_t len)
 {
-	u32 idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
-	u8 __iomem *evtq_addr = mvsw_pr_fw_evtq_buf(fw, qid);
+	u32 idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
+	u8 __iomem *evtq_addr = prestera_fw_evtq_buf(fw, qid);
 	u32 *buf32 = (u32 *)buf;
 	int i;
 
 	for (i = 0; i < len / 4; buf32++, i++) {
 		*buf32 = readl_relaxed(evtq_addr + idx);
-		idx = (idx + 4) & (mvsw_pr_fw_evtq_len(fw, qid) - 1);
+		idx = (idx + 4) & (prestera_fw_evtq_len(fw, qid) - 1);
 	}
 
-	mvsw_pr_fw_evtq_rd_set(fw, qid, idx);
+	prestera_fw_evtq_rd_set(fw, qid, idx);
 
 	return i;
 }
 
-static u8 mvsw_pr_fw_evtq_pick(struct mvsw_pr_fw *fw)
+static u8 prestera_fw_evtq_pick(struct prestera_fw *fw)
 {
 	int qid;
 
 	for (qid = 0; qid < fw->evt_qnum; qid++) {
-		if (mvsw_pr_fw_evtq_avail(fw, qid) >= 4)
+		if (prestera_fw_evtq_avail(fw, qid) >= 4)
 			return qid;
 	}
 
-	return MVSW_EVT_QNUM_MAX;
+	return PRESTERA_EVT_QNUM_MAX;
 }
 
-static void mvsw_pr_fw_status_set(struct mvsw_pr_fw *fw, unsigned int val)
+static void prestera_fw_status_set(struct prestera_fw *fw, unsigned int val)
 {
-	u32 status = mvsw_fw_read(fw, MVSW_FW_STATUS_REG);
+	u32 status = prestera_fw_read(fw, PRESTERA_FW_STATUS_REG);
 
 	status |= val;
 
-	mvsw_fw_write(fw, MVSW_FW_STATUS_REG, status);
+	prestera_fw_write(fw, PRESTERA_FW_STATUS_REG, status);
 }
 
-static void mvsw_pr_fw_status_clear(struct mvsw_pr_fw *fw, u32 val)
+static void prestera_fw_status_clear(struct prestera_fw *fw, u32 val)
 {
-	u32 status = mvsw_fw_read(fw, MVSW_FW_STATUS_REG);
+	u32 status = prestera_fw_read(fw, PRESTERA_FW_STATUS_REG);
 
 	status &= ~val;
 
-	mvsw_fw_write(fw, MVSW_FW_STATUS_REG, status);
+	prestera_fw_write(fw, PRESTERA_FW_STATUS_REG, status);
 }
 
-static void mvsw_pr_fw_evt_work_fn(struct work_struct *work)
+static void prestera_fw_evt_work_fn(struct work_struct *work)
 {
-	struct mvsw_pr_fw *fw;
+	struct prestera_fw *fw;
 	u8 *msg;
 	u8 qid;
 
-	fw = container_of(work, struct mvsw_pr_fw, evt_work);
+	fw = container_of(work, struct prestera_fw, evt_work);
 	msg = fw->evt_msg;
 
-	mvsw_pr_fw_status_set(fw, MVSW_STATUS_F_EVT_OFF);
+	prestera_fw_status_set(fw, PRESTERA_STATUS_F_EVT_OFF);
 
-	while ((qid = mvsw_pr_fw_evtq_pick(fw)) < MVSW_EVT_QNUM_MAX) {
+	while ((qid = prestera_fw_evtq_pick(fw)) < PRESTERA_EVT_QNUM_MAX) {
 		u32 idx;
 		u32 len;
 
-		len = mvsw_pr_fw_evtq_read32(fw, qid);
-		idx = mvsw_fw_read(fw, MVSW_EVTQ_RD_IDX_REG(qid));
+		len = prestera_fw_evtq_read32(fw, qid);
+		idx = prestera_fw_read(fw, PRESTERA_EVTQ_RD_IDX_REG(qid));
 
-		WARN_ON(mvsw_pr_fw_evtq_avail(fw, qid) < len);
+		WARN_ON(prestera_fw_evtq_avail(fw, qid) < len);
 
-		if (WARN_ON(len > MVSW_MSG_MAX_SIZE)) {
-			mvsw_pr_fw_evtq_rd_set(fw, qid, idx + len);
+		if (WARN_ON(len > PRESTERA_MSG_MAX_SIZE)) {
+			prestera_fw_evtq_rd_set(fw, qid, idx + len);
 			continue;
 		}
 
-		mvsw_pr_fw_evtq_read_buf(fw, qid, msg, len);
+		prestera_fw_evtq_read_buf(fw, qid, msg, len);
 
 		if (fw->dev.recv_msg)
 			fw->dev.recv_msg(&fw->dev, msg, len);
 	}
 
-	mvsw_pr_fw_status_clear(fw, MVSW_STATUS_F_EVT_OFF);
+	prestera_fw_status_clear(fw, PRESTERA_STATUS_F_EVT_OFF);
 }
 
-static int mvsw_pr_fw_wait_reg32(struct mvsw_pr_fw *fw,
-				 u32 reg, u32 val, unsigned int wait)
+static int prestera_fw_wait_reg32(struct prestera_fw *fw, u32 reg, u32 val,
+				  unsigned int wait)
 {
-	if (mvsw_wait_timeout(mvsw_fw_read(fw, reg) == val, wait))
-		return 0;
+	if (prestera_wait(prestera_fw_read(fw, reg) == val || !fw->dev.running,
+			  wait))
+		return fw->dev.running ? 0 : -ENODEV;
 
 	return -EBUSY;
 }
 
-static void mvsw_pci_copy_to(u8 __iomem *dst, u8 *src, size_t len)
+static void prestera_pci_copy_to(u8 __iomem *dst, u8 *src, size_t len)
 {
 	u32 __iomem *dst32 = (u32 __iomem *)dst;
 	u32 *src32 = (u32 *)src;
@@ -384,7 +424,7 @@ static void mvsw_pci_copy_to(u8 __iomem *dst, u8 *src, size_t len)
 		writel_relaxed(*src32, dst32);
 }
 
-static void mvsw_pci_copy_from(u8 *dst, u8 __iomem *src, size_t len)
+static void prestera_pci_copy_from(u8 *dst, u8 __iomem *src, size_t len)
 {
 	u32 *dst32 = (u32 *)dst;
 	u32 __iomem *src32 = (u32 __iomem *)src;
@@ -394,10 +434,10 @@ static void mvsw_pci_copy_from(u8 *dst, u8 __iomem *src, size_t len)
 		*dst32 = readl_relaxed(src32);
 }
 
-static int mvsw_pr_fw_cmd_send(struct mvsw_pr_fw *fw,
-			       u8 *in_msg, size_t in_size,
-			       u8 *out_msg, size_t out_size,
-			       unsigned int wait)
+static int prestera_fw_cmd_send(struct prestera_fw *fw, int qid,
+				u8 *in_msg, size_t in_size,
+				u8 *out_msg, size_t out_size,
+				unsigned int wait)
 {
 	u32 ret_size = 0;
 	int err = 0;
@@ -405,116 +445,131 @@ static int mvsw_pr_fw_cmd_send(struct mvsw_pr_fw *fw,
 	if (!wait)
 		wait = 30000;
 
-	if (ALIGN(in_size, 4) > fw->cmd_mbox_len)
+	if (ALIGN(in_size, 4) > prestera_fw_cmdq_len(fw, qid))
 		return -EMSGSIZE;
 
 	/* wait for finish previous reply from FW */
-	err = mvsw_pr_fw_wait_reg32(fw, MVSW_CMD_RCV_CTL_REG, 0, 1000);
+	err = prestera_fw_wait_reg32(fw, PRESTERA_CMDQ_RCV_CTL_REG(qid),
+				     0, 1000);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "finish reply from FW is timed out\n");
+		dev_err(prestera_fw_dev(fw),
+			"finish reply from FW is timed out\n");
 		return err;
 	}
 
-	mvsw_fw_write(fw, MVSW_CMD_REQ_LEN_REG, in_size);
-	mvsw_pci_copy_to(fw->cmd_mbox, in_msg, in_size);
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_LEN_REG(qid), in_size);
+	prestera_pci_copy_to(prestera_fw_cmdq_buf(fw, qid), in_msg, in_size);
 
-	mvsw_fw_write(fw, MVSW_CMD_REQ_CTL_REG, MVSW_CMD_F_REQ_SENT);
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_CTL_REG(qid),
+			  PRESTERA_CMD_F_REQ_SENT);
 
 	/* wait for reply from FW */
-	err = mvsw_pr_fw_wait_reg32(fw, MVSW_CMD_RCV_CTL_REG, MVSW_CMD_F_REPL_SENT,
-				    wait);
+	err = prestera_fw_wait_reg32(fw, PRESTERA_CMDQ_RCV_CTL_REG(qid),
+				     PRESTERA_CMD_F_REPL_SENT, wait);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "reply from FW is timed out\n");
-		fw->active = false;
+		dev_err(prestera_fw_dev(fw),
+			"reply from FW is timed out\n");
 		goto cmd_exit;
 	}
 
-	ret_size = mvsw_fw_read(fw, MVSW_CMD_RCV_LEN_REG);
+	ret_size = prestera_fw_read(fw, PRESTERA_CMDQ_RCV_LEN_REG(qid));
 	if (ret_size > out_size) {
-		dev_err(mvsw_fw_dev(fw), "ret_size (%u) > out_len(%zu)\n",
+		dev_err(prestera_fw_dev(fw), "ret_size (%u) > out_len(%zu)\n",
 			ret_size, out_size);
 		err = -EMSGSIZE;
 		goto cmd_exit;
 	}
 
-	mvsw_pci_copy_from(out_msg, fw->cmd_mbox + in_size, ret_size);
+	prestera_pci_copy_from(out_msg, prestera_fw_cmdq_buf(fw, qid) + in_size,
+			       ret_size);
 
 cmd_exit:
-	mvsw_fw_write(fw, MVSW_CMD_REQ_CTL_REG, MVSW_CMD_F_REPL_RCVD);
+	prestera_fw_write(fw, PRESTERA_CMDQ_REQ_CTL_REG(qid),
+			  PRESTERA_CMD_F_REPL_RCVD);
 	return err;
 }
 
-static int mvsw_pr_fw_send_req(struct prestera_device *dev,
-			       u8 *in_msg, size_t in_size, u8 *out_msg,
-			       size_t out_size, unsigned int wait)
+static int prestera_fw_send_req(struct prestera_device *dev, int qid,
+				u8 *in_msg, size_t in_size, u8 *out_msg,
+				size_t out_size, unsigned int wait)
 {
-	struct mvsw_pr_fw *fw;
+	struct prestera_fw *fw;
 	ssize_t ret;
 
-	fw = container_of(dev, struct mvsw_pr_fw, dev);
+	fw = container_of(dev, struct prestera_fw, dev);
 
-	if (!fw->active)
-		return -1;
+	if (!fw->dev.running)
+		return -ENODEV;
 
-	mutex_lock(&fw->cmd_mtx);
-	ret = mvsw_pr_fw_cmd_send(fw, in_msg, in_size, out_msg, out_size, wait);
-	mutex_unlock(&fw->cmd_mtx);
+	prestera_fw_cmdq_lock(fw, qid);
+	ret = prestera_fw_cmd_send(fw, qid, in_msg, in_size, out_msg, out_size,
+				   wait);
+	prestera_fw_cmdq_unlock(fw, qid);
 
 	return ret;
 }
 
-static int mvsw_pr_fw_init(struct mvsw_pr_fw *fw)
+static int prestera_fw_init(struct prestera_fw *fw)
 {
 	u8 __iomem *base;
 	int err;
 	u8 qid;
 
-	err = mvsw_pr_fw_load(fw);
+	err = prestera_fw_load(fw);
 	if (err)
 		return err;
 
-	err = mvsw_pr_fw_wait_reg32(fw, MVSW_FW_READY_REG,
-				    MVSW_FW_READY_MAGIC, 20000);
+	err = prestera_fw_wait_reg32(fw, PRESTERA_FW_READY_REG,
+				     PRESTERA_FW_READY_MAGIC, 20000);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "FW is failed to start\n");
+		dev_err(prestera_fw_dev(fw), "FW is failed to start\n");
 		return err;
 	}
 
 	base = fw->mem_addr;
 
-	fw->cmd_mbox = base + mvsw_fw_read(fw, MVSW_CMD_BUF_OFFS_REG);
-	fw->cmd_mbox_len = mvsw_fw_read(fw, MVSW_CMD_BUF_LEN_REG);
-	mutex_init(&fw->cmd_mtx);
+	fw->cmd_mbox = base + prestera_fw_read(fw, PRESTERA_CMD_BUF_OFFS_REG);
+	fw->cmd_mbox_len = prestera_fw_read(fw, PRESTERA_CMD_BUF_LEN_REG);
+	fw->cmd_qnum = prestera_fw_read(fw, PRESTERA_CMD_QNUM_REG);
+
+	for (qid = 0; qid < fw->cmd_qnum; qid++) {
+		u32 offs = prestera_fw_read(fw, PRESTERA_CMDQ_OFFS_REG(qid));
+		struct prestera_fw_cmdq *cmdq = &fw->cmd_queue[qid];
+
+		cmdq->len = prestera_fw_read(fw, PRESTERA_CMDQ_LEN_REG(qid));
+		cmdq->addr = fw->cmd_mbox + offs;
+		mutex_init(&cmdq->cmd_mtx);
+	}
 
-	fw->evt_buf = base + mvsw_fw_read(fw, MVSW_EVT_BUF_OFFS_REG);
-	fw->evt_qnum = mvsw_fw_read(fw, MVSW_EVT_QNUM_REG);
-	fw->evt_msg = kmalloc(MVSW_MSG_MAX_SIZE, GFP_KERNEL);
+	fw->evt_buf = base + prestera_fw_read(fw, PRESTERA_EVT_BUF_OFFS_REG);
+	fw->evt_qnum = prestera_fw_read(fw, PRESTERA_EVT_QNUM_REG);
+	fw->evt_msg = kmalloc(PRESTERA_MSG_MAX_SIZE, GFP_KERNEL);
 	if (!fw->evt_msg)
 		return -ENOMEM;
 
 	for (qid = 0; qid < fw->evt_qnum; qid++) {
-		u32 offs = mvsw_fw_read(fw, MVSW_EVTQ_OFFS_REG(qid));
-		struct mvsw_pr_fw_evtq *evtq = &fw->evt_queue[qid];
+		u32 offs = prestera_fw_read(fw, PRESTERA_EVTQ_OFFS_REG(qid));
+		struct prestera_fw_evtq *evtq = &fw->evt_queue[qid];
 
-		evtq->len = mvsw_fw_read(fw, MVSW_EVTQ_LEN_REG(qid));
+		evtq->len = prestera_fw_read(fw, PRESTERA_EVTQ_LEN_REG(qid));
 		evtq->addr = fw->evt_buf + offs;
 	}
 
 	return 0;
 }
 
-static void mvsw_pr_fw_uninit(struct mvsw_pr_fw *fw)
+static void prestera_fw_uninit(struct prestera_fw *fw)
 {
 	kfree(fw->evt_msg);
 }
 
-static irqreturn_t mvsw_pci_irq_handler(int irq, void *dev_id)
+static irqreturn_t prestera_irq_handler(int irq, void *dev_id)
 {
-	struct mvsw_pr_fw *fw = dev_id;
+	struct prestera_fw *fw = dev_id;
 
-	if (mvsw_fw_read(fw, MVSW_RX_STATUS_REG)) {
+	if (prestera_fw_read(fw, PRESTERA_RX_STATUS_REG)) {
 		if (fw->dev.recv_pkt) {
-			mvsw_fw_write(fw, MVSW_RX_STATUS_REG, 0);
+			prestera_fw_write(fw, PRESTERA_RX_STATUS_REG, 0);
 			fw->dev.recv_pkt(&fw->dev);
 		}
 	}
@@ -524,64 +579,66 @@ static irqreturn_t mvsw_pci_irq_handler(int irq, void *dev_id)
 	return IRQ_HANDLED;
 }
 
-static int mvsw_pr_ldr_wait_reg32(struct mvsw_pr_fw *fw,
-				  u32 reg, u32 val, unsigned int wait)
+static int prestera_ldr_wait_reg32(struct prestera_fw *fw, u32 reg, u32 val,
+				   unsigned int wait)
 {
-	if (mvsw_wait_timeout(mvsw_ldr_read(fw, reg) == val, wait))
+	if (prestera_wait(prestera_ldr_read(fw, reg) == val, wait))
 		return 0;
 
 	return -EBUSY;
 }
 
-static u32 mvsw_pr_ldr_buf_avail(struct mvsw_pr_fw *fw)
+static u32 prestera_ldr_buf_avail(struct prestera_fw *fw)
 {
-	u32 rd_idx = mvsw_ldr_read(fw, MVSW_LDR_BUF_RD_REG);
+	u32 rd_idx = prestera_ldr_read(fw, PRESTERA_LDR_BUF_RD_REG);
 
 	return CIRC_SPACE(fw->ldr_wr_idx, rd_idx, fw->ldr_buf_len);
 }
 
-static int mvsw_pr_ldr_send_buf(struct mvsw_pr_fw *fw, const u8 *buf,
-				size_t len)
+static int prestera_ldr_send_buf(struct prestera_fw *fw, const u8 *buf,
+				 size_t len)
 {
 	int i;
 
-	if (!mvsw_wait_timeout(mvsw_pr_ldr_buf_avail(fw) >= len, 100)) {
-		dev_err(mvsw_fw_dev(fw), "failed wait for sending firmware\n");
+	if (!prestera_wait(prestera_ldr_buf_avail(fw) >= len, 100)) {
+		dev_err(prestera_fw_dev(fw),
+			"failed wait for sending firmware\n");
 		return -EBUSY;
 	}
 
 	for (i = 0; i < len; i += 4) {
-		writel_relaxed(*(u32 *)(buf + i), MVSW_LDR_WR_PTR(fw));
-		MVSW_LDR_WR_IDX_MOVE(fw, 4);
+		writel_relaxed(*(u32 *)(buf + i), PRESTERA_LDR_WR_PTR(fw));
+		PRESTERA_LDR_WR_IDX_MOVE(fw, 4);
 	}
 
-	MVSW_LDR_WR_IDX_COMMIT(fw);
+	PRESTERA_LDR_WR_IDX_COMMIT(fw);
 	return 0;
 }
 
-static int mvsw_pr_ldr_send(struct mvsw_pr_fw *fw,
-			    const char *img, u32 fw_size)
+static int prestera_ldr_send(struct prestera_fw *fw, const char *img,
+			     u32 fw_size)
 {
 	unsigned long mask;
 	u32 status;
 	u32 pos;
 	int err;
 
-	if (mvsw_pr_ldr_wait_reg32(fw, MVSW_LDR_STATUS_REG,
-				   MVSW_LDR_STATUS_IMG_DL, 1000)) {
-		dev_err(mvsw_fw_dev(fw), "Loader is not ready to load image\n");
+	if (prestera_ldr_wait_reg32(fw, PRESTERA_LDR_STATUS_REG,
+				    PRESTERA_LDR_STATUS_IMG_DL, 1000)) {
+		dev_err(prestera_fw_dev(fw),
+			"Loader is not ready to load image\n");
 		return -EBUSY;
 	}
 
-	for (pos = 0; pos < fw_size; pos += MVSW_FW_BLK_SZ) {
-		if (pos + MVSW_FW_BLK_SZ > fw_size)
+	for (pos = 0; pos < fw_size; pos += PRESTERA_FW_BLK_SZ) {
+		if (pos + PRESTERA_FW_BLK_SZ > fw_size)
 			break;
 
-		err = mvsw_pr_ldr_send_buf(fw, img + pos, MVSW_FW_BLK_SZ);
+		err = prestera_ldr_send_buf(fw, img + pos, PRESTERA_FW_BLK_SZ);
 		if (err) {
-			if (mvsw_fw_read(fw, MVSW_LDR_STATUS_REG) ==
-					 MVSW_LDR_STATUS_NOMEM) {
-				dev_err(mvsw_fw_dev(fw),
+			if (prestera_fw_read(fw, PRESTERA_LDR_STATUS_REG) ==
+					     PRESTERA_LDR_STATUS_NOMEM) {
+				dev_err(prestera_fw_dev(fw),
 					"Fw image is too big or invalid\n");
 				return -EINVAL;
 			}
@@ -590,29 +647,31 @@ static int mvsw_pr_ldr_send(struct mvsw_pr_fw *fw,
 	}
 
 	if (pos < fw_size) {
-		err = mvsw_pr_ldr_send_buf(fw, img + pos, fw_size - pos);
+		err = prestera_ldr_send_buf(fw, img + pos, fw_size - pos);
 		if (err)
 			return err;
 	}
 
 	/* Waiting for status IMG_DOWNLOADING to change to something else */
-	mask = ~(MVSW_LDR_STATUS_IMG_DL);
+	mask = ~(PRESTERA_LDR_STATUS_IMG_DL);
 
-	if (!mvsw_wait_timeout(mvsw_ldr_read(fw, MVSW_LDR_STATUS_REG) & mask,
-			       MVSW_FW_DL_TIMEOUT)) {
-		dev_err(mvsw_fw_dev(fw), "Timeout to load FW img [state=%d]",
-			mvsw_ldr_read(fw, MVSW_LDR_STATUS_REG));
+	if (!prestera_wait(prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG) &
+			   mask, PRESTERA_FW_DL_TIMEOUT)) {
+		dev_err(prestera_fw_dev(fw),
+			"Timeout to load FW img [state=%d]",
+			prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG));
 		return -ETIMEDOUT;
 	}
 
-	status = mvsw_ldr_read(fw, MVSW_LDR_STATUS_REG);
-	if (status != MVSW_LDR_STATUS_START_FW) {
+	status = prestera_ldr_read(fw, PRESTERA_LDR_STATUS_REG);
+	if (status != PRESTERA_LDR_STATUS_START_FW) {
 		switch (status) {
-		case MVSW_LDR_STATUS_INVALID_IMG:
-			dev_err(mvsw_fw_dev(fw), "FW img has bad crc\n");
+		case PRESTERA_LDR_STATUS_INVALID_IMG:
+			dev_err(prestera_fw_dev(fw), "FW img has bad crc\n");
 			return -EINVAL;
-		case MVSW_LDR_STATUS_NOMEM:
-			dev_err(mvsw_fw_dev(fw), "Loader has no enough mem\n");
+		case PRESTERA_LDR_STATUS_NOMEM:
+			dev_err(prestera_fw_dev(fw),
+				"Loader has no enough mem\n");
 			return -ENOMEM;
 		default:
 			break;
@@ -622,13 +681,14 @@ static int mvsw_pr_ldr_send(struct mvsw_pr_fw *fw,
 	return 0;
 }
 
-static bool mvsw_pr_ldr_is_ready(struct mvsw_pr_fw *fw)
+static bool prestera_ldr_is_ready(struct prestera_fw *fw)
 {
-	return mvsw_ldr_read(fw, MVSW_LDR_READY_REG) == MVSW_LDR_READY_MAGIC;
+	return prestera_ldr_read(fw, PRESTERA_LDR_READY_REG) ==
+				 PRESTERA_LDR_READY_MAGIC;
 }
 
-static void mvsw_pr_fw_rev_parse(const struct mvsw_pr_fw_header *hdr,
-				 struct prestera_fw_rev *rev)
+static void prestera_fw_rev_parse(const struct prestera_fw_header *hdr,
+				  struct prestera_fw_rev *rev)
 {
 	u32 version = be32_to_cpu(hdr->version_value);
 
@@ -637,41 +697,41 @@ static void mvsw_pr_fw_rev_parse(const struct mvsw_pr_fw_header *hdr,
 	rev->sub = FW_VER_PATCH(version);
 }
 
-static int mvsw_pr_fw_rev_check(struct mvsw_pr_fw *fw)
+static int prestera_fw_rev_check(struct prestera_fw *fw)
 {
 	struct prestera_fw_rev *rev = &fw->dev.fw_rev;
 
-	if (rev->maj == MVSW_SUPP_FW_MAJ_VER &&
-	    rev->min == MVSW_SUPP_FW_MIN_VER) {
+	if (rev->maj == PRESTERA_SUPP_FW_MAJ_VER &&
+	    rev->min == PRESTERA_SUPP_FW_MIN_VER) {
 		return 0;
 	}
 
 	return -EINVAL;
 }
 
-static int mvsw_pr_fw_hdr_parse(struct mvsw_pr_fw *fw,
-				const struct firmware *img)
+static int prestera_fw_hdr_parse(struct prestera_fw *fw,
+				 const struct firmware *img)
 {
-	struct mvsw_pr_fw_header *hdr = (struct mvsw_pr_fw_header *)img->data;
+	struct prestera_fw_header *hdr = (struct prestera_fw_header *)img->data;
 	struct prestera_fw_rev *rev = &fw->dev.fw_rev;
 	u32 magic;
 
 	magic = be32_to_cpu(hdr->magic_number);
-	if (magic != MVSW_FW_HDR_MAGIC) {
-		dev_err(mvsw_fw_dev(fw), "FW img type is invalid");
+	if (magic != PRESTERA_FW_HDR_MAGIC) {
+		dev_err(prestera_fw_dev(fw), "FW img type is invalid");
 		return -EINVAL;
 	}
 
-	mvsw_pr_fw_rev_parse(hdr, rev);
+	prestera_fw_rev_parse(hdr, rev);
 
-	dev_info(mvsw_fw_dev(fw), "FW version '%u.%u.%u'\n",
+	dev_info(prestera_fw_dev(fw), "FW version '%u.%u.%u'\n",
 		 rev->maj, rev->min, rev->sub);
-	dev_info(mvsw_fw_dev(fw), "Driver version '%u.%u.%u'\n",
-		 MVSW_SUPP_FW_MAJ_VER, MVSW_SUPP_FW_MIN_VER,
-		 MVSW_SUPP_FW_PATCH_VER);
+	dev_info(prestera_fw_dev(fw), "Driver version '%u.%u.%u'\n",
+		 PRESTERA_SUPP_FW_MAJ_VER, PRESTERA_SUPP_FW_MIN_VER,
+		 PRESTERA_SUPP_FW_PATCH_VER);
 
-	if (mvsw_pr_fw_rev_check(fw)) {
-		dev_err(mvsw_fw_dev(fw),
+	if (prestera_fw_rev_check(fw)) {
+		dev_err(prestera_fw_dev(fw),
 			"Driver is incomatible with FW: version mismatch");
 		return -EINVAL;
 	}
@@ -679,63 +739,65 @@ static int mvsw_pr_fw_hdr_parse(struct mvsw_pr_fw *fw,
 	return 0;
 }
 
-static int mvsw_pr_fw_load(struct mvsw_pr_fw *fw)
+static int prestera_fw_load(struct prestera_fw *fw)
 {
-	size_t hlen = sizeof(struct mvsw_pr_fw_header);
+	size_t hlen = sizeof(struct prestera_fw_header);
 	const struct firmware *f;
 	bool has_ldr;
 	int err;
 
-	has_ldr = mvsw_wait_timeout(mvsw_pr_ldr_is_ready(fw), 1000);
+	has_ldr = prestera_wait(prestera_ldr_is_ready(fw), 1000);
 	if (!has_ldr) {
-		dev_err(mvsw_fw_dev(fw), "waiting for FW loader is timed out");
+		dev_err(prestera_fw_dev(fw),
+			"waiting for FW loader is timed out");
 		return -ETIMEDOUT;
 	}
 
 	fw->ldr_ring_buf = fw->ldr_regs +
-		mvsw_ldr_read(fw, MVSW_LDR_BUF_OFFS_REG);
+		prestera_ldr_read(fw, PRESTERA_LDR_BUF_OFFS_REG);
 
-	fw->ldr_buf_len =
-		mvsw_ldr_read(fw, MVSW_LDR_BUF_SIZE_REG);
+	fw->ldr_buf_len = prestera_ldr_read(fw, PRESTERA_LDR_BUF_SIZE_REG);
 
 	fw->ldr_wr_idx = 0;
 
-	err = request_firmware_direct(&f, MVSW_FW_FILENAME, &fw->pci_dev->dev);
+	err = request_firmware_direct(&f, PRESTERA_FW_FILENAME,
+				      &fw->pci_dev->dev);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "failed to request firmware file\n");
+		dev_err(prestera_fw_dev(fw),
+			"failed to request firmware file\n");
 		return err;
 	}
 
 	if (!IS_ALIGNED(f->size, 4)) {
-		dev_err(mvsw_fw_dev(fw), "FW image file is not aligned");
+		dev_err(prestera_fw_dev(fw), "FW image file is not aligned");
 		release_firmware(f);
 		return -EINVAL;
 	}
 
-	err = mvsw_pr_fw_hdr_parse(fw, f);
+	err = prestera_fw_hdr_parse(fw, f);
 	if (err) {
-		dev_err(mvsw_fw_dev(fw), "FW image is invalid\n");
+		dev_err(prestera_fw_dev(fw), "FW image is invalid\n");
 		release_firmware(f);
 		return err;
 	}
 
-	mvsw_ldr_write(fw, MVSW_LDR_IMG_SIZE_REG, f->size - hlen);
-	mvsw_ldr_write(fw, MVSW_LDR_CTL_REG, MVSW_LDR_CTL_DL_START);
+	prestera_ldr_write(fw, PRESTERA_LDR_IMG_SIZE_REG, f->size - hlen);
+	prestera_ldr_write(fw, PRESTERA_LDR_CTL_REG, PRESTERA_LDR_CTL_DL_START);
 
-	dev_info(mvsw_fw_dev(fw), "Loading prestera FW image ...");
+	dev_info(prestera_fw_dev(fw), "Loading prestera FW image ...");
 
-	err = mvsw_pr_ldr_send(fw, f->data + hlen, f->size - hlen);
+	err = prestera_ldr_send(fw, f->data + hlen, f->size - hlen);
 
 	release_firmware(f);
 	return err;
 }
 
-static int mvsw_pr_pci_probe(struct pci_dev *pdev,
-			     const struct pci_device_id *id)
+static int prestera_pci_probe(struct pci_dev *pdev,
+			      const struct pci_device_id *id)
 {
 	const char *driver_name = pdev->driver->name;
 	u8 __iomem *mem_addr, *pp_addr;
-	struct mvsw_pr_fw *fw;
+	struct prestera_fw *fw;
 	int err;
 
 	err = pci_enable_device(pdev);
@@ -780,18 +842,18 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 
 	fw->pci_dev = pdev;
 	fw->dev.dev = &pdev->dev;
-	fw->dev.send_req = mvsw_pr_fw_send_req;
+	fw->dev.send_req = prestera_fw_send_req;
 	fw->dev.pp_regs = pp_addr;
+	fw->dev.running = true;
 	fw->mem_addr = mem_addr;
 	fw->ldr_regs = mem_addr;
 	fw->hw_regs = mem_addr;
-	fw->active = true;
 
-	fw->wq = alloc_workqueue("mvsw_fw_wq", WQ_HIGHPRI, 1);
+	fw->wq = alloc_workqueue("prestera_fw_wq", WQ_HIGHPRI, 1);
 	if (!fw->wq)
 		goto err_wq_alloc;
 
-	INIT_WORK(&fw->evt_work, mvsw_pr_fw_evt_work_fn);
+	INIT_WORK(&fw->evt_work, prestera_fw_evt_work_fn);
 
 	err = pci_alloc_irq_vectors(pdev, 1, 1, PCI_IRQ_MSI);
 	if (err < 0) {
@@ -799,7 +861,7 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 		goto err_irq_alloc;
 	}
 
-	err = request_irq(pci_irq_vector(pdev, 0), mvsw_pci_irq_handler,
+	err = request_irq(pci_irq_vector(pdev, 0), prestera_irq_handler,
 			  0, driver_name, fw);
 	if (err) {
 		dev_err(&pdev->dev, "fail to request IRQ\n");
@@ -808,21 +870,21 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 
 	pci_set_drvdata(pdev, fw);
 
-	err = mvsw_pr_fw_init(fw);
+	err = prestera_fw_init(fw);
 	if (err)
-		goto err_mvsw_fw_init;
+		goto err_fw_init;
 
-	dev_info(mvsw_fw_dev(fw), "Prestera Switch FW is ready\n");
+	dev_info(prestera_fw_dev(fw), "Prestera Switch FW is ready\n");
 
 	err = prestera_device_register(&fw->dev);
 	if (err)
-		goto err_mvsw_dev_register;
+		goto err_prestera_dev_register;
 
 	return 0;
 
-err_mvsw_dev_register:
-	mvsw_pr_fw_uninit(fw);
-err_mvsw_fw_init:
+err_prestera_dev_register:
+	prestera_fw_uninit(fw);
+err_fw_init:
 	free_irq(pci_irq_vector(pdev, 0), fw);
 err_request_irq:
 	pci_free_irq_vectors(pdev);
@@ -843,16 +905,16 @@ static int mvsw_pr_pci_probe(struct pci_dev *pdev,
 	return err;
 }
 
-static void mvsw_pr_pci_remove(struct pci_dev *pdev)
+static void prestera_pci_remove(struct pci_dev *pdev)
 {
-	struct mvsw_pr_fw *fw = pci_get_drvdata(pdev);
+	struct prestera_fw *fw = pci_get_drvdata(pdev);
 
 	free_irq(pci_irq_vector(pdev, 0), fw);
 	pci_free_irq_vectors(pdev);
 	prestera_device_unregister(&fw->dev);
 	flush_workqueue(fw->wq);
 	destroy_workqueue(fw->wq);
-	mvsw_pr_fw_uninit(fw);
+	prestera_fw_uninit(fw);
 	iounmap(fw->dev.pp_regs);
 	iounmap(fw->mem_addr);
 	pci_release_regions(pdev);
@@ -860,14 +922,14 @@ static void mvsw_pr_pci_remove(struct pci_dev *pdev)
 	kfree(fw);
 }
 
-static int __init mvsw_pr_pci_init(void)
+static int __init prestera_pci_init(void)
 {
-	struct mvsw_pr_pci_match *match;
+	struct prestera_pci_match *match;
 	int err = 0;
 
-	for (match = mvsw_pci_devices; match->driver.name; match++) {
-		match->driver.probe = mvsw_pr_pci_probe;
-		match->driver.remove = mvsw_pr_pci_remove;
+	for (match = prestera_devices; match->driver.name; match++) {
+		match->driver.probe = prestera_pci_probe;
+		match->driver.remove = prestera_pci_remove;
 		match->driver.id_table = &match->id;
 
 		err = pci_register_driver(&match->driver);
@@ -881,7 +943,7 @@ static int __init mvsw_pr_pci_init(void)
 	}
 
 	if (err) {
-		for (match = mvsw_pci_devices; match->driver.name; match++) {
+		for (match = prestera_devices; match->driver.name; match++) {
 			if (!match->registered)
 				break;
 
@@ -895,11 +957,11 @@ static int __init mvsw_pr_pci_init(void)
 	return 0;
 }
 
-static void __exit mvsw_pr_pci_exit(void)
+static void __exit prestera_pci_exit(void)
 {
-	struct mvsw_pr_pci_match *match;
+	struct prestera_pci_match *match;
 
-	for (match = mvsw_pci_devices; match->driver.name; match++) {
+	for (match = prestera_devices; match->driver.name; match++) {
 		if (!match->registered)
 			break;
 
@@ -909,8 +971,8 @@ static void __exit mvsw_pr_pci_exit(void)
 	pr_info("prestera_pci: Unregistered Marvell Prestera PCI driver\n");
 }
 
-module_init(mvsw_pr_pci_init);
-module_exit(mvsw_pr_pci_exit);
+module_init(prestera_pci_init);
+module_exit(prestera_pci_exit);
 
 MODULE_AUTHOR("Marvell Semi.");
 MODULE_LICENSE("GPL");
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_router.c b/drivers/net/ethernet/marvell/prestera/prestera_router.c
index 141ac01..7145b10 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_router.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_router.c
@@ -11,7 +11,6 @@
 #include <linux/inetdevice.h>
 #include <linux/netdevice.h>
 #include <linux/if_bridge.h>
-#include <linux/rhashtable.h>
 #include <net/netevent.h>
 #include <net/neighbour.h>
 #include <net/addrconf.h>
@@ -19,6 +18,7 @@
 #include <net/switchdev.h>
 #include <net/arp.h>
 #include <net/nexthop.h>
+#include <linux/rhashtable.h>
 
 #include "prestera.h"
 #include "prestera_hw.h"
@@ -41,7 +41,7 @@ struct mvsw_pr_rif {
 	bool is_active;
 	u16 rif_id;
 	struct mvsw_pr_vr *vr;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	unsigned int ref_cnt;
 };
 
@@ -63,10 +63,6 @@ struct mvsw_pr_vr {
 	unsigned int ref_cnt;
 };
 
-struct mvsw_pr_nexthop_group_key {
-	struct mvsw_pr_nh_neigh_key neigh[MVSW_PR_NHGR_SIZE_MAX];
-};
-
 struct mvsw_pr_nexthop_group {
 	struct mvsw_pr_nexthop_group_key key;
 	/* Store intermediate object here.
@@ -82,7 +78,6 @@ struct mvsw_pr_nexthop_group {
 		struct mvsw_pr_nh_neigh *neigh;
 	} nh_neigh_head[MVSW_PR_NHGR_SIZE_MAX];
 	u32 grp_id; /* hw */
-	unsigned long hw_last_connected; /* jiffies */
 	struct rhash_head ht_node; /* node of mvsw_pr_vr */
 	unsigned int ref_cnt;
 };
@@ -95,23 +90,40 @@ enum mvsw_pr_mp_hash_policy {
 
 struct mvsw_pr_kern_neigh_cache {
 	struct mvsw_pr_nh_neigh_key key;
-	bool offloaded;
 	struct rhash_head ht_node;
 	struct list_head kern_fib_cache_list;
-	bool lpm_added; /* Indicate if neigh is reachable by connected route */
-	bool in_kernel; /* Valid in kernel */
+	/* Lock cache if neigh is present in kernel */
+	bool in_kernel;
+	/* Hold prepared nh_neigh info if is in_kernel */
+	struct mvsw_pr_neigh_info nh_neigh_info;
+	/* Indicate if neighbour is reachable by direct route */
+	bool reachable;
 };
 
-/* Used to track offloaded fib entries */
+struct mvsw_pr_kern_fib_cache_key {
+	struct mvsw_pr_ip_addr addr;
+	u32 prefix_len;
+	u32 kern_tb_id; /* tb_id from kernel (not fixed) */
+};
+
+/* Subscribing on neighbours in kernel */
 struct mvsw_pr_kern_fib_cache {
-	struct mvsw_pr_fib_key key;
-	struct fib_info *fi;
+	struct mvsw_pr_kern_fib_cache_key key;
+	struct {
+		struct mvsw_pr_fib_key fib_key;
+		enum mvsw_pr_fib_type fib_type;
+		struct mvsw_pr_nexthop_group_key nh_grp_key;
+	} lpm_info; /* hold prepared lpm info */
+	/* Indicate if route is not overlapped by another table */
+	bool reachable;
+	bool allow_oflag;
 	struct rhash_head ht_node; /* node of mvsw_pr_router */
 	struct mvsw_pr_kern_neigh_cache_head {
 		struct mvsw_pr_kern_fib_cache *this;
 		struct list_head head;
 		struct mvsw_pr_kern_neigh_cache *n_cache;
 	} kern_neigh_cache_head[MVSW_PR_NHGR_SIZE_MAX];
+	struct fib_info *fi;
 };
 
 static const struct rhashtable_params __mvsw_pr_kern_neigh_cache_ht_params = {
@@ -124,7 +136,7 @@ static const struct rhashtable_params __mvsw_pr_kern_neigh_cache_ht_params = {
 static const struct rhashtable_params __mvsw_pr_kern_fib_cache_ht_params = {
 	.key_offset  = offsetof(struct mvsw_pr_kern_fib_cache, key),
 	.head_offset = offsetof(struct mvsw_pr_kern_fib_cache, ht_node),
-	.key_len     = sizeof(struct mvsw_pr_fib_key),
+	.key_len     = sizeof(struct mvsw_pr_kern_fib_cache_key),
 	.automatic_shrinking = true,
 };
 
@@ -199,54 +211,56 @@ static const unsigned char mvsw_pr_mac_mask[ETH_ALEN] = {
 	0xff, 0xff, 0xff, 0xff, 0xfc, 0x00
 };
 
-static struct mvsw_pr_vr *mvsw_pr_vr_get(struct mvsw_pr_switch *sw, u32 tb_id,
+static struct mvsw_pr_vr *mvsw_pr_vr_get(struct prestera_switch *sw, u32 tb_id,
 					 struct netlink_ext_ack *extack);
 static u32 mvsw_pr_fix_tb_id(u32 tb_id);
-static void mvsw_pr_vr_put(struct mvsw_pr_switch *sw, struct mvsw_pr_vr *vr);
-static void mvsw_pr_vr_util_hw_abort(struct mvsw_pr_switch *sw);
-static struct mvsw_pr_rif *mvsw_pr_rif_create(struct mvsw_pr_switch *sw,
+static void mvsw_pr_vr_put(struct prestera_switch *sw, struct mvsw_pr_vr *vr);
+static void mvsw_pr_vr_util_hw_abort(struct prestera_switch *sw);
+static struct mvsw_pr_rif *mvsw_pr_rif_create(struct prestera_switch *sw,
 					      const struct mvsw_pr_rif_params
 					      *params,
 					      struct netlink_ext_ack *extack);
-static int mvsw_pr_rif_vr_update(struct mvsw_pr_switch *sw,
+static int mvsw_pr_rif_vr_update(struct prestera_switch *sw,
 				 struct mvsw_pr_rif *rif,
 				 struct netlink_ext_ack *extack);
 static void mvsw_pr_rif_destroy(struct mvsw_pr_rif *rif);
 static void mvsw_pr_rif_put(struct mvsw_pr_rif *rif);
 static int mvsw_pr_rif_update(struct mvsw_pr_rif *rif, char *mac);
-static struct mvsw_pr_rif *mvsw_pr_rif_find(const struct mvsw_pr_switch *sw,
+static struct mvsw_pr_rif *mvsw_pr_rif_find(const struct prestera_switch *sw,
 					    const struct net_device *dev);
 static u16 mvsw_pr_rif_vr_id(struct mvsw_pr_rif *rif);
 static bool
-mvsw_pr_nh_neigh_util_hw_state(struct mvsw_pr_switch *sw,
+mvsw_pr_nh_neigh_util_hw_state(struct prestera_switch *sw,
 			       struct mvsw_pr_nh_neigh *nh_neigh);
 static bool
-mvsw_pr_nexthop_group_util_hw_state(struct mvsw_pr_switch *sw,
+mvsw_pr_nexthop_group_util_hw_state(struct prestera_switch *sw,
 				    struct mvsw_pr_nexthop_group *nh_grp);
-static struct mvsw_pr_nh_neigh *
-mvsw_pr_nh_neigh_find(struct mvsw_pr_switch *sw,
-		      struct mvsw_pr_nh_neigh_key *key);
-static int mvsw_pr_nh_neigh_set(struct mvsw_pr_switch *sw,
+static int mvsw_pr_nh_neigh_set(struct prestera_switch *sw,
 				struct mvsw_pr_nh_neigh *neigh);
-static int mvsw_pr_nexthop_group_set(struct mvsw_pr_switch *sw,
+static int mvsw_pr_nexthop_group_set(struct prestera_switch *sw,
 				     struct mvsw_pr_nexthop_group *nh_grp);
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_find(struct mvsw_pr_switch *sw, struct mvsw_pr_fib_key *key);
-static void mvsw_pr_fib_node_destroy(struct mvsw_pr_switch *sw,
+mvsw_pr_fib_node_find(struct prestera_switch *sw, struct mvsw_pr_fib_key *key);
+static void mvsw_pr_fib_node_destroy(struct prestera_switch *sw,
 				     struct mvsw_pr_fib_node *fib_node);
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
-			      struct mvsw_pr_fib_key *key,
-			      struct mvsw_pr_nexthop_group_key *nh_grp_key);
+mvsw_pr_fib_node_create(struct prestera_switch *sw,
+			struct mvsw_pr_fib_key *key,
+			enum mvsw_pr_fib_type fib_type,
+			struct mvsw_pr_nexthop_group_key *nh_grp_key);
 static bool mvsw_pr_fi_is_direct(struct fib_info *fi);
+static bool mvsw_pr_fi_is_hw_direct(struct prestera_switch *sw,
+				    struct fib_info *fi);
 static bool mvsw_pr_fi_is_nh(struct fib_info *fi);
+static bool mvsw_pr_nh_neigh_key_is_valid(struct mvsw_pr_nh_neigh_key *key);
 static bool
 mvsw_pr_fib_node_util_is_neighbour(struct mvsw_pr_fib_node *fib_node);
-static void
-mvsw_pr_kern_fib_cache_offload_set(struct mvsw_pr_switch *sw,
-				   struct mvsw_pr_kern_fib_cache *fib_cache);
+static int
+mvsw_pr_util_fi2nh_gr_key(struct prestera_switch *sw, struct fib_info *fi,
+			  size_t limit,
+			  struct mvsw_pr_nexthop_group_key *grp_key);
 
-static u16 mvsw_pr_nh_dev_to_vid(struct mvsw_pr_switch *sw,
+static u16 mvsw_pr_nh_dev_to_vid(struct prestera_switch *sw,
 				 struct net_device *dev)
 {
 	struct macvlan_dev *vlan;
@@ -268,7 +282,7 @@ static u16 mvsw_pr_nh_dev_to_vid(struct mvsw_pr_switch *sw,
 }
 
 static struct net_device*
-mvsw_pr_nh_dev_egress(struct mvsw_pr_switch *sw, struct net_device *dev,
+mvsw_pr_nh_dev_egress(struct prestera_switch *sw, struct net_device *dev,
 		      u8 *ha)
 {
 	struct net_device *bridge_dev, *egress_dev = dev;
@@ -302,9 +316,9 @@ static int
 mvsw_pr_rif_iface_init(struct mvsw_pr_rif *rif)
 {
 	struct net_device *dev = rif->dev;
-	struct mvsw_pr_switch *sw = rif->sw;
-	struct mvsw_pr_port *port;
-	int if_type = mvsw_pr_dev_if_type(dev);
+	struct prestera_switch *sw = rif->sw;
+	struct prestera_port *port;
+	int if_type = prestera_dev_if_type(dev);
 
 	switch (if_type) {
 	case MVSW_IF_PORT_E:
@@ -330,16 +344,16 @@ mvsw_pr_rif_iface_init(struct mvsw_pr_rif *rif)
 }
 
 static int
-__mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
+__mvsw_pr_neigh_iface_init(struct prestera_switch *sw,
 			   struct mvsw_pr_iface *iface,
 			   struct neighbour *n,
 			   struct net_device *dev)
 {
 	bool is_nud_perm = n->nud_state & NUD_PERMANENT;
 	struct net_device *egress_dev;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
-	iface->type = mvsw_pr_dev_if_type(dev);
+	iface->type = prestera_dev_if_type(dev);
 
 	switch (iface->type) {
 	case MVSW_IF_PORT_E:
@@ -350,13 +364,13 @@ __mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
 		 * of the ports which is needed by the hardware, therefore
 		 * use any valid lower
 		 */
-			port = mvsw_pr_port_dev_lower_find(dev);
+			port = prestera_port_dev_lower_find(dev);
 			egress_dev = port->net_dev;
 		}
 		if (!egress_dev)
 			return -ENOENT;
 
-		if (!mvsw_pr_netdev_check(egress_dev))
+		if (!prestera_netdev_check(egress_dev))
 			return __mvsw_pr_neigh_iface_init(sw, iface, n,
 							  egress_dev);
 
@@ -376,9 +390,9 @@ __mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
 }
 
 static int
-mvsw_pr_neigh_iface_init(struct mvsw_pr_switch *sw,
-			struct mvsw_pr_iface *iface,
-			struct neighbour *n)
+mvsw_pr_neigh_iface_init(struct prestera_switch *sw,
+			 struct mvsw_pr_iface *iface,
+			 struct neighbour *n)
 {
 	/* TODO vr_id is obsolete in iface ? */
 	iface->vlan_id = mvsw_pr_nh_dev_to_vid(sw, n->dev);
@@ -394,21 +408,6 @@ static void mvsw_pr_util_kern_set_neigh_offload(struct neighbour *n,
 		n->flags &= ~NTF_OFFLOADED;
 }
 
-static void
-__mvsw_pr_util_kern_unset_allneigh_offload_cb(struct neighbour *n,
-					      void *cookie)
-{
-	mvsw_pr_util_kern_set_neigh_offload(n, false);
-}
-
-static void mvsw_pr_util_kern_unset_allneigh_offload(void)
-{
-	/* Walk through every neighbour in kernel */
-	neigh_for_each(&arp_tbl,
-		       __mvsw_pr_util_kern_unset_allneigh_offload_cb,
-		       NULL);
-}
-
 static void
 mvsw_pr_util_kern_set_nh_offload(struct fib_nh *fib_nh, bool offloaded)
 {
@@ -443,22 +442,168 @@ static int mvsw_pr_util_kern_get_route(struct fib_result *res,
 	return 0;
 }
 
+int prestera_util_kern_dip2nh_grp_key(struct prestera_switch *sw,
+				      u32 tb_id, struct mvsw_pr_ip_addr *addr,
+				      struct mvsw_pr_nexthop_group_key *res)
+{
+	int err;
+	struct fib_result fib_res;
+	struct fib_nh *fib_nh;
+
+	err = mvsw_pr_util_kern_get_route(&fib_res, tb_id, addr);
+	if (err)
+		return 0;
+
+	if (mvsw_pr_fi_is_direct(fib_res.fi)) {
+		fib_nh = fib_info_nh(fib_res.fi, 0);
+		memset(res, 0, sizeof(*res));
+		res->neigh[0].addr = *addr;
+		res->neigh[0].rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+		if (!res->neigh[0].rif || !res->neigh[0].rif->is_active)
+			return 0;
+
+		return 1;
+	}
+
+	return mvsw_pr_util_fi2nh_gr_key(sw, fib_res.fi,
+					 MVSW_PR_NHGR_SIZE_MAX, res);
+}
+
+/* Check if neigh route is reachable */
+static bool
+mvsw_pr_util_kern_n_is_reachable(u32 tb_id,
+				 struct mvsw_pr_ip_addr *addr,
+				 struct net_device *dev)
+{
+	bool reachable;
+	struct fib_nh *fib_nh;
+	struct fib_result res;
+
+	reachable = false;
+
+	if (!mvsw_pr_util_kern_get_route(&res, tb_id, addr))
+		if (res.type == RTN_UNICAST &&
+		    mvsw_pr_fi_is_direct(res.fi)) {
+			fib_nh = fib_info_nh(res.fi, 0);
+			if (dev == fib_nh->fib_nh_dev)
+				reachable = true;
+		}
+
+	return reachable;
+}
+
+static bool
+mvsw_pr_util_fi_is_point2dev(struct fib_info *fi,
+			     const struct net_device *dev)
+{
+	int nhs, i;
+	struct fib_nh *fib_nh;
+
+	nhs = fib_info_num_path(fi);
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fi, i);
+		if (fib_nh->fib_nh_dev == dev)
+			return true;
+	}
+
+	return false;
+}
+
 static int
-mvsw_pr_util_fib_nh2nh_neigh_key(struct mvsw_pr_switch *sw,
+mvsw_pr_util_fib_nh2nh_neigh_key(struct prestera_switch *sw,
 				 struct fib_nh *fib_nh,
 				 struct mvsw_pr_nh_neigh_key *nh_key)
 {
 	memset(nh_key, 0, sizeof(*nh_key));
 	nh_key->addr.u.ipv4 = fib_nh->fib_nh_gw4;
 	nh_key->rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
-	if (!nh_key->rif)
+	if (!nh_key->rif || !nh_key->rif->is_active)
+		return -ENOENT;
+
+	return 0;
+}
+
+static int
+mvsw_pr_util_fi2nh_gr_key(struct prestera_switch *sw, struct fib_info *fi,
+			  size_t limit,
+			  struct mvsw_pr_nexthop_group_key *grp_key)
+{
+	int i, nhs, err;
+	struct fib_nh *fib_nh;
+
+	if (!mvsw_pr_fi_is_nh(fi))
+		return 0;
+
+	nhs = fib_info_num_path(fi);
+	if (nhs > limit)
+		return 0;
+
+	memset(grp_key, 0, sizeof(*grp_key));
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fi, i);
+		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw,
+						       fib_nh,
+						       &grp_key->neigh[i]);
+		if (err)
+			return 0;
+	}
+
+	return nhs;
+}
+
+static void
+mvsw_pr_util_fen_info2fib_cache_key(struct fib_entry_notifier_info *fen_info,
+				    struct mvsw_pr_kern_fib_cache_key *key)
+{
+	memset(key, 0, sizeof(*key));
+	key->addr.u.ipv4 = cpu_to_be32(fen_info->dst);
+	key->prefix_len = fen_info->dst_len;
+	key->kern_tb_id = fen_info->tb_id;
+}
+
+static void
+mvsw_pr_util_fib_cache_key2fib_key(struct mvsw_pr_kern_fib_cache_key *ckey,
+				   struct mvsw_pr_fib_key *fkey)
+{
+	memset(fkey, 0, sizeof(*fkey));
+	fkey->addr = ckey->addr;
+	fkey->prefix_len = ckey->prefix_len;
+	fkey->tb_id = mvsw_pr_fix_tb_id(ckey->kern_tb_id);
+}
+
+static bool
+mvsw_pr_util_is_fib_nh_equal2nh_neigh_key(struct prestera_switch *sw,
+					  struct fib_nh *fib_nh,
+					  struct mvsw_pr_nh_neigh_key *nk)
+{
+	int err;
+	struct mvsw_pr_nh_neigh_key tk;
+
+	err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_nh, &tk);
+	if (err)
+		return false;
+
+	if (memcmp(&tk, nk, sizeof(tk)))
+		return false;
+
+	return true;
+}
+
+static int mvsw_pr_util_neigh2nh_neigh_key(struct prestera_switch *sw,
+					   struct neighbour *n,
+					   struct mvsw_pr_nh_neigh_key *key)
+{
+	memset(key, 0, sizeof(*key));
+	key->addr.u.ipv4 = *(__be32 *)n->primary_key;
+	key->rif = mvsw_pr_rif_find(sw, n->dev);
+	if (!key->rif)
 		return -ENOENT;
 
 	return 0;
 }
 
 static struct mvsw_pr_kern_neigh_cache *
-mvsw_pr_kern_neigh_cache_find(struct mvsw_pr_switch *sw,
+mvsw_pr_kern_neigh_cache_find(struct prestera_switch *sw,
 			      struct mvsw_pr_nh_neigh_key *key)
 {
 	struct mvsw_pr_kern_neigh_cache *n_cache;
@@ -470,7 +615,7 @@ mvsw_pr_kern_neigh_cache_find(struct mvsw_pr_switch *sw,
 }
 
 static void
-__mvsw_pr_kern_neigh_cache_destroy(struct mvsw_pr_switch *sw,
+__mvsw_pr_kern_neigh_cache_destroy(struct prestera_switch *sw,
 				   struct mvsw_pr_kern_neigh_cache *n_cache)
 {
 	n_cache->key.rif->ref_cnt--;
@@ -482,7 +627,7 @@ __mvsw_pr_kern_neigh_cache_destroy(struct mvsw_pr_switch *sw,
 }
 
 static struct mvsw_pr_kern_neigh_cache *
-__mvsw_pr_kern_neigh_cache_create(struct mvsw_pr_switch *sw,
+__mvsw_pr_kern_neigh_cache_create(struct prestera_switch *sw,
 				  struct mvsw_pr_nh_neigh_key *key)
 {
 	struct mvsw_pr_kern_neigh_cache *n_cache;
@@ -513,7 +658,7 @@ __mvsw_pr_kern_neigh_cache_create(struct mvsw_pr_switch *sw,
 }
 
 static struct mvsw_pr_kern_neigh_cache *
-mvsw_pr_kern_neigh_cache_get(struct mvsw_pr_switch *sw,
+mvsw_pr_kern_neigh_cache_get(struct prestera_switch *sw,
 			     struct mvsw_pr_nh_neigh_key *key)
 {
 	struct mvsw_pr_kern_neigh_cache *n_cache;
@@ -525,61 +670,22 @@ mvsw_pr_kern_neigh_cache_get(struct mvsw_pr_switch *sw,
 	return n_cache;
 }
 
-static void
-mvsw_pr_kern_neigh_cache_put(struct mvsw_pr_switch *sw,
+static struct mvsw_pr_kern_neigh_cache *
+mvsw_pr_kern_neigh_cache_put(struct prestera_switch *sw,
 			     struct mvsw_pr_kern_neigh_cache *n_cache)
 {
-	if (!n_cache->in_kernel && !n_cache->lpm_added &&
-	    list_empty(&n_cache->kern_fib_cache_list))
+	if (!n_cache->in_kernel &&
+	    list_empty(&n_cache->kern_fib_cache_list)) {
 		__mvsw_pr_kern_neigh_cache_destroy(sw, n_cache);
-}
-
-static void
-mvsw_pr_kern_neigh_cache_offload_set(struct mvsw_pr_switch *sw,
-				     struct mvsw_pr_kern_neigh_cache *n_cache)
-{
-	struct mvsw_pr_kern_neigh_cache_head *n_head;
-
-	list_for_each_entry(n_head, &n_cache->kern_fib_cache_list, head) {
-		mvsw_pr_kern_fib_cache_offload_set(sw, n_head->this);
-	}
-}
-
-static void
-mvsw_pr_kern_neigh_cache_lpm_set(struct mvsw_pr_switch *sw,
-				 struct mvsw_pr_kern_neigh_cache *n_cache)
-{
-	struct mvsw_pr_fib_key fib_key;
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_nexthop_group_key nh_grp_key;
-
-	memset(&fib_key, 0, sizeof(fib_key));
-	fib_key.addr = n_cache->key.addr;
-	fib_key.prefix_len = 32;
-	fib_key.tb_id = n_cache->key.rif->vr->tb_id;
-	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
-	if (!n_cache->lpm_added && fib_node) {
-		if (mvsw_pr_fib_node_util_is_neighbour(fib_node))
-			mvsw_pr_fib_node_destroy(sw, fib_node);
-		return;
+		return NULL;
 	}
 
-	if (n_cache->lpm_added && !fib_node) {
-		memset(&nh_grp_key, 0, sizeof(nh_grp_key));
-		nh_grp_key.neigh[0] = n_cache->key;
-		fib_node = mvsw_pr_fib_node_uc_nh_create(sw, &fib_key,
-							 &nh_grp_key);
-		if (!fib_node)
-			MVSW_LOG_ERROR("%s failed ip=%pI4n",
-				       "mvsw_pr_fib_node_uc_nh_create",
-				       &fib_key.addr.u.ipv4);
-		return;
-	}
+	return n_cache;
 }
 
 static struct mvsw_pr_kern_fib_cache *
-mvsw_pr_kern_fib_cache_find(struct mvsw_pr_switch *sw,
-			    struct mvsw_pr_fib_key *key)
+mvsw_pr_kern_fib_cache_find(struct prestera_switch *sw,
+			    struct mvsw_pr_kern_fib_cache_key *key)
 {
 	struct mvsw_pr_kern_fib_cache *fib_cache;
 
@@ -590,116 +696,40 @@ mvsw_pr_kern_fib_cache_find(struct mvsw_pr_switch *sw,
 }
 
 static void
-__mvsw_pr_kern_fib_cache_destruct(struct mvsw_pr_switch *sw,
-				  struct mvsw_pr_kern_fib_cache *fib_cache)
+mvsw_pr_kern_fib_cache_destroy(struct prestera_switch *sw,
+			       struct mvsw_pr_kern_fib_cache *fib_cache)
 {
 	int i;
 	struct mvsw_pr_kern_neigh_cache *n_cache;
-	struct fib_nh *fib_nh;
-
-	if (mvsw_pr_fi_is_direct(fib_cache->fi)) {
-		fib_nh = fib_info_nh(fib_cache->fi, 0);
-		mvsw_pr_util_kern_set_nh_offload(fib_nh, true);
-		goto out;
-	}
 
 	for (i = 0; i < MVSW_PR_NHGR_SIZE_MAX; i++) {
 		n_cache = fib_cache->kern_neigh_cache_head[i].n_cache;
 		if (n_cache) {
 			list_del(&fib_cache->kern_neigh_cache_head[i].head);
 			mvsw_pr_kern_neigh_cache_put(sw, n_cache);
-			fib_nh = fib_info_nh(fib_cache->fi, i);
-			mvsw_pr_util_kern_set_nh_offload(fib_nh, false);
 		}
 	}
 
-out:
 	fib_info_put(fib_cache->fi);
-}
-
-static void
-mvsw_pr_kern_fib_cache_offload_set(struct mvsw_pr_switch *sw,
-				   struct mvsw_pr_kern_fib_cache *fib_cache)
-{
-	int i;
-	struct mvsw_pr_kern_neigh_cache *n_cache;
-	struct fib_nh *fib_nh;
-	bool offloaded;
-
-	if (mvsw_pr_fi_is_direct(fib_cache->fi)) {
-		fib_nh = fib_info_nh(fib_cache->fi, 0);
-		if (mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev))
-			mvsw_pr_util_kern_set_nh_offload(fib_nh, true);
-		goto out;
-	}
-
-	for (i = 0; i < MVSW_PR_NHGR_SIZE_MAX; i++) {
-		n_cache = fib_cache->kern_neigh_cache_head[i].n_cache;
-		if (!n_cache)
-			continue;
-
-		offloaded = n_cache->offloaded;
-		fib_nh = fib_info_nh(fib_cache->fi, i);
-		mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
-	}
-
-out:
-	return;
-}
-
-static void
-mvsw_pr_kern_fib_cache_destroy(struct mvsw_pr_switch *sw,
-			       struct mvsw_pr_kern_fib_cache *fib_cache)
-{
-	__mvsw_pr_kern_fib_cache_destruct(sw, fib_cache);
 	rhashtable_remove_fast(&sw->router->kern_fib_cache_ht,
 			       &fib_cache->ht_node,
 			       __mvsw_pr_kern_fib_cache_ht_params);
 	kfree(fib_cache);
 }
 
-static void
-mvsw_pr_kern_fib_cache_destroy_ht(struct mvsw_pr_switch *sw)
-{
-	struct mvsw_pr_kern_fib_cache *fib_cache, *tfib_cache;
-	struct rhashtable_iter iter;
-
-	tfib_cache = NULL;
-	rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
-	rhashtable_walk_start(&iter);
-	while (1) {
-		fib_cache = rhashtable_walk_next(&iter);
-		if (tfib_cache) {
-			rhashtable_remove_fast(&sw->router->kern_fib_cache_ht,
-					       &tfib_cache->ht_node,
-					    __mvsw_pr_kern_fib_cache_ht_params);
-			kfree(tfib_cache);
-			tfib_cache = NULL;
-		}
-
-		if (!fib_cache)
-			break;
-
-		if (IS_ERR(fib_cache))
-			continue;
-
-		__mvsw_pr_kern_fib_cache_destruct(sw, fib_cache);
-		tfib_cache = fib_cache;
-	}
-	rhashtable_walk_stop(&iter);
-	rhashtable_walk_exit(&iter);
-}
-
+/* Pass also grp_key, because we may implement logic to     *
+ * differ fib_nh's and created nh_neighs.                   *
+ * Operations on fi (offload, etc) must be wrapped in utils *
+ */
 static struct mvsw_pr_kern_fib_cache *
-mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
-			      struct mvsw_pr_fib_key *key,
-			      struct fib_info *fi)
+__mvsw_pr_kern_fib_cache_create(struct prestera_switch *sw,
+				struct mvsw_pr_kern_fib_cache_key *key,
+				struct mvsw_pr_nexthop_group_key *grp_key,
+				struct fib_info *fi)
 {
 	struct mvsw_pr_kern_fib_cache *fib_cache;
 	struct mvsw_pr_kern_neigh_cache *n_cache;
-	struct mvsw_pr_nh_neigh_key nh_key;
-	struct fib_nh *fib_nh;
-	int err, i, nhs;
+	int err, i;
 
 	fib_cache = kzalloc(sizeof(*fib_cache), GFP_KERNEL);
 	if (!fib_cache)
@@ -715,17 +745,14 @@ mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
 	if (err)
 		goto err_ht_insert;
 
-	if (!mvsw_pr_fi_is_nh(fi))
+	if (!grp_key)
 		goto out;
 
-	nhs = fib_info_num_path(fi);
-	for (i = 0; i < nhs; i++) {
-		fib_nh = fib_info_nh(fi, i);
-		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_nh, &nh_key);
-		if (err)
-			continue;
+	for (i = 0; i < MVSW_PR_NHGR_SIZE_MAX; i++) {
+		if (!mvsw_pr_nh_neigh_key_is_valid(&grp_key->neigh[i]))
+			break;
 
-		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &nh_key);
+		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &grp_key->neigh[i]);
 		if (!n_cache)
 			continue;
 
@@ -736,8 +763,6 @@ mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
 	}
 
 out:
-	mvsw_pr_kern_fib_cache_offload_set(sw, fib_cache);
-
 	return fib_cache;
 
 err_ht_insert:
@@ -747,207 +772,375 @@ mvsw_pr_kern_fib_cache_create(struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static int mvsw_pr_util_neigh2nh_neigh_key(struct mvsw_pr_switch *sw,
-					   struct neighbour *n,
-					   struct mvsw_pr_nh_neigh_key *key)
+static struct mvsw_pr_kern_fib_cache *
+mvsw_pr_kern_fib_cache_create(struct prestera_switch *sw,
+			      struct mvsw_pr_kern_fib_cache_key *fc_key,
+			      struct fib_info *fi)
 {
-	memset(key, 0, sizeof(*key));
-	key->addr.u.ipv4 = *(__be32 *)n->primary_key;
-	key->rif = mvsw_pr_rif_find(sw, n->dev);
-	if (!key->rif)
-		return -ENOENT;
+	struct mvsw_pr_kern_fib_cache *fc;
+	struct mvsw_pr_nexthop_group_key grp_key;
+	int nh_cnt;
 
-	return 0;
-}
+	switch (fi->fib_type) {
+	case RTN_UNICAST:
+		nh_cnt = mvsw_pr_util_fi2nh_gr_key(sw, fi,
+						   MVSW_PR_NHGR_SIZE_MAX,
+						   &grp_key);
+		fc = __mvsw_pr_kern_fib_cache_create(sw, fc_key,
+						     nh_cnt ? &grp_key : NULL,
+						     fi);
+		if (!fc)
+			return NULL;
+
+		fc->lpm_info.fib_type = nh_cnt ?
+					MVSW_PR_FIB_TYPE_UC_NH :
+					MVSW_PR_FIB_TYPE_TRAP;
+		fc->lpm_info.nh_grp_key = grp_key;
+		fc->allow_oflag = !!(nh_cnt || mvsw_pr_fi_is_hw_direct(sw, fi));
+		break;
+	/* Unsupported. Leave it for kernel: */
+	case RTN_BROADCAST:
+	case RTN_MULTICAST:
+	/* Routes we must trap by design: */
+	case RTN_LOCAL:
+	case RTN_UNREACHABLE:
+	case RTN_PROHIBIT:
+		fc = __mvsw_pr_kern_fib_cache_create(sw, fc_key, NULL, fi);
+		if (!fc)
+			return NULL;
 
-static void __mvsw_pr_neigh2nh_neigh_update(struct mvsw_pr_switch *sw,
-					    struct neighbour *n)
-{
-	struct mvsw_pr_nh_neigh_key nh_neigh_key;
-	struct mvsw_pr_nh_neigh *nh_neigh;
-	struct mvsw_pr_neigh_info new_info;
-	struct mvsw_pr_kern_neigh_cache *n_cache;
-	bool offloaded;
-	int err;
+		fc->lpm_info.fib_type = MVSW_PR_FIB_TYPE_TRAP;
+		break;
+	case RTN_BLACKHOLE:
+		fc = __mvsw_pr_kern_fib_cache_create(sw, fc_key, NULL, fi);
+		if (!fc)
+			return NULL;
 
-	err = mvsw_pr_util_neigh2nh_neigh_key(sw, n, &nh_neigh_key);
-	if (err)
-		return;
+		fc->lpm_info.fib_type = MVSW_PR_FIB_TYPE_DROP;
+		break;
+	default:
+		MVSW_LOG_ERROR("Unsupported fib_type");
+		return NULL;
+	}
 
-	nh_neigh = mvsw_pr_nh_neigh_find(sw, &nh_neigh_key);
-	if (!nh_neigh)
-		return;
+	mvsw_pr_util_fib_cache_key2fib_key(fc_key,
+					   &fc->lpm_info.fib_key);
 
-	memset(&new_info, 0, sizeof(new_info));
-	read_lock_bh(&n->lock);
-	if (n->nud_state & NUD_VALID && !n->dead) {
-		memcpy(&new_info.ha[0], &n->ha[0], ETH_ALEN);
-		err = mvsw_pr_neigh_iface_init(sw, &new_info.iface, n);
-		if (err) {
-			MVSW_LOG_ERROR("Cannot initialize iface for %pI4n %pM",
+	return fc;
+}
+
+static void
+__mvsw_pr_k_arb_fib_offload_set(struct prestera_switch *sw,
+				struct mvsw_pr_kern_fib_cache *fibc,
+				struct mvsw_pr_kern_neigh_cache *nc,
+				bool offloaded)
+{
+	int i, nhs;
+	struct fib_nh *fib_nh;
+
+	nhs = fib_info_num_path(fibc->fi);
+	for (i = 0; i < nhs; i++) {
+		fib_nh = fib_info_nh(fibc->fi, i);
+		if (!nc) {
+			mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
+			continue;
+		}
+
+		if (mvsw_pr_util_is_fib_nh_equal2nh_neigh_key(sw,
+							      fib_nh,
+							      &nc->key)) {
+			mvsw_pr_util_kern_set_nh_offload(fib_nh, offloaded);
+			break;
+		}
+	}
+}
+
+static void
+__mvsw_pr_k_arb_n_offload_set(struct prestera_switch *sw,
+			      struct mvsw_pr_kern_neigh_cache *nc,
+			      bool offloaded)
+{
+	struct neighbour *n;
+
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+
+	if (!n)
+		return;
+
+	mvsw_pr_util_kern_set_neigh_offload(n, offloaded);
+	neigh_release(n);
+}
+
+static void
+__mvsw_pr_k_arb_n_lpm_set(struct prestera_switch *sw,
+			  struct mvsw_pr_kern_neigh_cache *n_cache,
+			  bool enabled)
+{
+	struct mvsw_pr_fib_key fib_key;
+	struct mvsw_pr_fib_node *fib_node;
+	struct mvsw_pr_nexthop_group_key nh_grp_key;
+
+	memset(&fib_key, 0, sizeof(fib_key));
+	fib_key.addr = n_cache->key.addr;
+	fib_key.prefix_len = 32;
+	fib_key.tb_id = n_cache->key.rif->vr->tb_id;
+	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
+	if (!enabled && fib_node) {
+		if (mvsw_pr_fib_node_util_is_neighbour(fib_node))
+			mvsw_pr_fib_node_destroy(sw, fib_node);
+		return;
+	}
+
+	if (enabled && !fib_node) {
+		memset(&nh_grp_key, 0, sizeof(nh_grp_key));
+		nh_grp_key.neigh[0] = n_cache->key;
+		fib_node = mvsw_pr_fib_node_create(sw, &fib_key,
+						   MVSW_PR_FIB_TYPE_UC_NH,
+						   &nh_grp_key);
+		if (!fib_node)
+			MVSW_LOG_ERROR("%s failed ip=%pI4n",
+				       "mvsw_pr_fib_node_create",
+				       &fib_key.addr.u.ipv4);
+		return;
+	}
+}
+
+static void
+__mvsw_pr_k_arb_nc_kern_fib_fetch(struct prestera_switch *sw,
+				  struct mvsw_pr_kern_neigh_cache *nc)
+{
+	if (mvsw_pr_util_kern_n_is_reachable(nc->key.rif->vr->tb_id,
+					     &nc->key.addr,
+					     nc->key.rif->dev))
+		nc->reachable = true;
+	else
+		nc->reachable = false;
+}
+
+/* Kernel neighbour -> neigh_cache info */
+static void
+__mvsw_pr_k_arb_nc_kern_n_fetch(struct prestera_switch *sw,
+				struct mvsw_pr_kern_neigh_cache *nc)
+{
+	struct neighbour *n;
+	int err;
+
+	memset(&nc->nh_neigh_info, 0, sizeof(nc->nh_neigh_info));
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+	if (!n)
+		goto out;
+
+	read_lock_bh(&n->lock);
+	if (n->nud_state & NUD_VALID && !n->dead) {
+		err = mvsw_pr_neigh_iface_init(sw, &nc->nh_neigh_info.iface, n);
+		if (err) {
+			MVSW_LOG_ERROR("Cannot initialize iface for %pI4n %pM",
 				       n->primary_key, &n->ha[0]);
-			new_info.connected = false;
-		} else {
-			new_info.connected = true;
+			goto n_read_out;
 		}
-	} else {
-		new_info.connected = false;
+
+		memcpy(&nc->nh_neigh_info.ha[0], &n->ha[0], ETH_ALEN);
+		nc->nh_neigh_info.connected = true;
 	}
+n_read_out:
 	read_unlock_bh(&n->lock);
+out:
+	nc->in_kernel = nc->nh_neigh_info.connected;
+	if (n)
+		neigh_release(n);
+}
+
+/* neigh_cache info -> lpm update */
+static void
+__mvsw_pr_k_arb_nc_apply(struct prestera_switch *sw,
+			 struct mvsw_pr_kern_neigh_cache *nc)
+{
+	struct mvsw_pr_nh_neigh *nh_neigh;
+	struct mvsw_pr_kern_neigh_cache_head *nhead;
+	struct prestera_acl_nat_port *nat_port;
+	struct prestera_port *port;
+	u32 port_hw_id, port_dev_id;
+	int err;
+
+	__mvsw_pr_k_arb_n_lpm_set(sw, nc,
+				  nc->reachable && nc->in_kernel);
+	__mvsw_pr_k_arb_n_offload_set(sw, nc,
+				      nc->reachable && nc->in_kernel);
+
+	/* update NAT port on neighbour change */
+	port_hw_id = nc->key.rif->iface.dev_port.port_num;
+	port_dev_id = nc->key.rif->iface.dev_port.hw_dev_num;
+	nat_port = prestera_acl_nat_port_get(sw->acl, port_hw_id,
+					     port_dev_id);
+	if (!nat_port)
+		goto skip_nat_port_update;
+
+	port = prestera_acl_nat_port_to_port(nat_port);
+	prestera_acl_nat_port_put(nat_port);
+
+	err = prestera_hw_nat_port_neigh_update(port,
+						nc->nh_neigh_info.ha);
+	if (err)
+		/* do not fail others, just print an error */
+		MVSW_LOG_ERROR("Update NAT neigh fail [%pI4n, %pM]",
+			       &nc->key.addr.u.ipv4,
+			       nc->nh_neigh_info.ha);
+
+skip_nat_port_update:
+	nh_neigh = mvsw_pr_nh_neigh_find(sw, &nc->key);
+	if (!nh_neigh)
+		goto out;
 
-	offloaded = new_info.connected;
 	/* Do hw update only if something changed to prevent nh flap */
-	if (memcmp(&new_info, &nh_neigh->info, sizeof(new_info))) {
-		memcpy(&nh_neigh->info, &new_info, sizeof(new_info));
+	if (memcmp(&nc->nh_neigh_info, &nh_neigh->info,
+		   sizeof(nh_neigh->info))) {
+		memcpy(&nh_neigh->info, &nc->nh_neigh_info,
+		       sizeof(nh_neigh->info));
 		err = mvsw_pr_nh_neigh_set(sw, nh_neigh);
 		if (err) {
-			offloaded = false;
 			MVSW_LOG_ERROR("%s failed with err=%d ip=%pI4n mac=%pM",
 				       "mvsw_pr_nh_neigh_set", err,
 				       &nh_neigh->key.addr.u.ipv4,
 				       &nh_neigh->info.ha[0]);
+			goto out;
 		}
 	}
 
-	mvsw_pr_util_kern_set_neigh_offload(n, offloaded);
-	n_cache = mvsw_pr_kern_neigh_cache_find(sw, &nh_neigh_key);
-	if (!n_cache) {
-		MVSW_LOG_ERROR("Cannot get neigh cache for %pI4n %pM",
-			       n->primary_key, &n->ha[0]);
-	} else {
-		n_cache->offloaded = offloaded;
-		mvsw_pr_kern_neigh_cache_offload_set(sw, n_cache);
+out:
+	list_for_each_entry(nhead, &nc->kern_fib_cache_list, head) {
+		__mvsw_pr_k_arb_fib_offload_set(sw, nhead->this, nc,
+						nc->in_kernel &&
+						nhead->this->reachable &&
+						nhead->this->allow_oflag);
 	}
 }
 
-static void __mvsw_pr_neigh2nh_neigh_update_all(struct mvsw_pr_switch *sw)
+static void __mvsw_pr_k_arb_hw_state_upd(struct prestera_switch *sw,
+					 struct mvsw_pr_kern_neigh_cache *nc)
 {
+	bool hw_active;
 	struct mvsw_pr_nh_neigh *nh_neigh;
-	struct rhashtable_iter iter;
 	struct neighbour *n;
-	struct mvsw_pr_nh_neigh_key *nkey;
-
-	rhashtable_walk_enter(&sw->router->nh_neigh_ht, &iter);
-	rhashtable_walk_start(&iter);
-	while ((nh_neigh = rhashtable_walk_next(&iter))) {
-		if (IS_ERR(nh_neigh))
-			continue;
 
-		nkey = &nh_neigh->key;
-		n = neigh_lookup(&arp_tbl, &nkey->addr.u.ipv4, nkey->rif->dev);
-		if (n) {
-			__mvsw_pr_neigh2nh_neigh_update(sw, n);
-			neigh_release(n);
-		}
+	nh_neigh = mvsw_pr_nh_neigh_find(sw, &nc->key);
+	if (!nh_neigh) {
+		MVSW_LOG_ERROR("Cannot find nh_neigh for cached %pI4n",
+			       &nc->key.addr.u.ipv4);
+		return;
 	}
-	rhashtable_walk_stop(&iter);
-	rhashtable_walk_exit(&iter);
-}
-
-/* I dont think that optimiztaion of this
- * function withone neighbour will make sense...
- * Just select direction nh_neigh -> kernel or vice versa
- */
-static void
-__mvsw_pr_neigh_hwstate_update_all(struct mvsw_pr_switch *sw)
-{
-	struct mvsw_pr_nh_neigh *nh_neigh;
-	struct rhashtable_iter iter;
-	struct neighbour *n;
-	struct mvsw_pr_nh_neigh_key *nkey;
-	bool n_resolved, hw_active;
 
-	rhashtable_walk_enter(&sw->router->nh_neigh_ht, &iter);
-	rhashtable_walk_start(&iter);
-	while ((nh_neigh = rhashtable_walk_next(&iter))) {
-		if (IS_ERR(nh_neigh))
-			continue;
-
-		hw_active = mvsw_pr_nh_neigh_util_hw_state(sw, nh_neigh);
-		nkey = &nh_neigh->key;
-		n = neigh_lookup(&arp_tbl, &nkey->addr.u.ipv4, nkey->rif->dev);
-		if (n) {
-			read_lock_bh(&n->lock);
-			if (n->dead || !(n->nud_state & NUD_VALID))
-				n_resolved = false;
-			else
-				n_resolved = true;
-			read_unlock_bh(&n->lock);
-		} else {
-			n_resolved = false;
-		}
+	hw_active = mvsw_pr_nh_neigh_util_hw_state(sw, nh_neigh);
 
 #ifdef MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH
-		if (!hw_active && n_resolved)
-			goto next_nh_neigh;
+	if (!hw_active && nc->in_kernel)
+		goto out;
 #else /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
-		if (!hw_active)
-			goto next_nh_neigh;
+	if (!hw_active)
+		goto out;
 #endif /* MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH */
 
-		if (!n) {
-			MVSW_LOG_INFO("Push active neighbour %pI4n to kernel",
-				      &nkey->addr.u.ipv4);
-			n = neigh_create(&arp_tbl, &nkey->addr.u.ipv4,
-					 nkey->rif->dev);
-			if (IS_ERR(n)) {
-				n = NULL;
-				MVSW_LOG_ERROR("Cannot create neighbour %pI4n",
-					       &nkey->addr.u.ipv4);
-
-				goto next_nh_neigh;
-			}
+	n = neigh_lookup(&arp_tbl, &nc->key.addr.u.ipv4, nc->key.rif->dev);
+	if (!n) {
+		n = neigh_create(&arp_tbl, &nc->key.addr.u.ipv4,
+				 nc->key.rif->dev);
+		if (IS_ERR(n)) {
+			n = NULL;
+			MVSW_LOG_ERROR("Cannot create neighbour %pI4n",
+				       &nc->key.addr.u.ipv4);
 		}
+	}
 
+	if (n) {
 		neigh_event_send(n, NULL);
+		neigh_release(n);
+	}
+
+out:
+	return;
+}
 
-next_nh_neigh:
-		if (n)
-			neigh_release(n);
+static int __mvsw_pr_k_arb_f_lpm_set(struct prestera_switch *sw,
+				     struct mvsw_pr_kern_fib_cache *fc,
+				     bool enabled)
+{
+	struct mvsw_pr_fib_node *fib_node;
+
+	fib_node = mvsw_pr_fib_node_find(sw, &fc->lpm_info.fib_key);
+	if (fib_node)
+		mvsw_pr_fib_node_destroy(sw, fib_node);
+
+	if (!enabled)
+		return 0;
+
+	fib_node = mvsw_pr_fib_node_create(sw, &fc->lpm_info.fib_key,
+					   fc->lpm_info.fib_type,
+					   &fc->lpm_info.nh_grp_key);
+
+	if (!fib_node) {
+		MVSW_LOG_ERROR("fib_node=NULL %pI4n/%d kern_tb_id = %d",
+			       &fc->key.addr.u.ipv4, fc->key.prefix_len,
+			       fc->key.kern_tb_id);
+		return -ENOENT;
 	}
-	rhashtable_walk_stop(&iter);
-	rhashtable_walk_exit(&iter);
+
+	return 0;
 }
 
-static void
-__mvsw_pr_sync_neigh_cache_kernel(struct mvsw_pr_switch *sw,
-				  struct mvsw_pr_kern_neigh_cache *n_cache)
+static int __mvsw_pr_k_arb_fc_apply(struct prestera_switch *sw,
+				    struct mvsw_pr_kern_fib_cache *fc)
 {
-	struct neighbour *n;
-	struct fib_result res;
-	struct fib_nh *fib_nh;
-	struct mvsw_pr_nh_neigh_key *key;
+	int err;
 
-	key = &n_cache->key;
+	/* 1. Update lpm */
+	err = __mvsw_pr_k_arb_f_lpm_set(sw, fc, fc->reachable);
+	if (err)
+		return err;
 
-	n_cache->in_kernel = false;
-	n_cache->lpm_added = false;
-	n = neigh_lookup(&arp_tbl, &key->addr.u.ipv4, key->rif->dev);
-	if (n) {
-		read_lock_bh(&n->lock);
-		if (!n->dead && (n->nud_state & NUD_VALID))
-			n_cache->in_kernel = true;
-		read_unlock_bh(&n->lock);
-	}
-
-	if (n_cache->in_kernel) {
-		if (!mvsw_pr_util_kern_get_route(&res, key->rif->vr->tb_id,
-						 &key->addr))
-			if (res.type == RTN_UNICAST &&
-			    mvsw_pr_fi_is_direct(res.fi)) {
-				fib_nh = fib_info_nh(res.fi, 0);
-				if (n->dev == fib_nh->fib_nh_dev)
-					n_cache->lpm_added = true;
-			}
+	/* UC_NH offload flag is managed by neighbours cache */
+	if (fc->lpm_info.fib_type != MVSW_PR_FIB_TYPE_UC_NH || !fc->reachable)
+		__mvsw_pr_k_arb_fib_offload_set(sw, fc, NULL, fc->reachable &&
+						fc->allow_oflag);
+
+	return 0;
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_util_fib_overlaps(struct prestera_switch *sw,
+				  struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct mvsw_pr_kern_fib_cache *rfc;
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+
+	/* TODO: parse kernel rules */
+	rfc = NULL;
+	if (fc->key.kern_tb_id == RT_TABLE_LOCAL) {
+		memcpy(&fc_key, &fc->key, sizeof(fc_key));
+		fc_key.kern_tb_id = RT_TABLE_MAIN;
+		rfc = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
 	}
 
-	if (n)
-		neigh_release(n);
+	return rfc;
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_util_fib_overlapped(struct prestera_switch *sw,
+				    struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct mvsw_pr_kern_fib_cache *rfc;
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+
+	/* TODO: parse kernel rules */
+	rfc = NULL;
+	if (fc->key.kern_tb_id == RT_TABLE_MAIN) {
+		memcpy(&fc_key, &fc->key, sizeof(fc_key));
+		fc_key.kern_tb_id = RT_TABLE_LOCAL;
+		rfc = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	}
 
-	mvsw_pr_kern_neigh_cache_lpm_set(sw, n_cache);
+	return rfc;
 }
 
-static void __mvsw_pr_sync_neigh_cache_kernel_all(struct mvsw_pr_switch *sw)
+static void __mvsw_pr_k_arb_abort_neigh(struct prestera_switch *sw)
 {
 	struct mvsw_pr_kern_neigh_cache *n_cache, *tn_cache;
 	struct rhashtable_iter iter;
@@ -958,6 +1151,12 @@ static void __mvsw_pr_sync_neigh_cache_kernel_all(struct mvsw_pr_switch *sw)
 	while (1) {
 		n_cache = rhashtable_walk_next(&iter);
 		if (tn_cache) {
+			__mvsw_pr_k_arb_n_offload_set(sw, tn_cache,
+						      false);
+			tn_cache->in_kernel = false;
+			/* No need to destroy lpm.
+			 * It will be aborted by destroy_ht
+			 */
 			mvsw_pr_kern_neigh_cache_put(sw, tn_cache);
 			tn_cache = NULL;
 		}
@@ -968,16 +1167,53 @@ static void __mvsw_pr_sync_neigh_cache_kernel_all(struct mvsw_pr_switch *sw)
 		if (IS_ERR(n_cache))
 			continue;
 
-		__mvsw_pr_sync_neigh_cache_kernel(sw, n_cache);
 		tn_cache = n_cache;
 	}
 	rhashtable_walk_stop(&iter);
 	rhashtable_walk_exit(&iter);
 }
 
+static void __mvsw_pr_k_arb_abort_fib(struct prestera_switch *sw)
+{
+	struct mvsw_pr_kern_fib_cache *fib_cache, *tfib_cache;
+	struct rhashtable_iter iter;
+
+	tfib_cache = NULL;
+	rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		fib_cache = rhashtable_walk_next(&iter);
+		if (tfib_cache) {
+			__mvsw_pr_k_arb_fib_offload_set(sw, tfib_cache,
+							NULL, false);
+			/* No need to destroy lpm.
+			 * It will be aborted by destroy_ht
+			 */
+			mvsw_pr_kern_fib_cache_destroy(sw, tfib_cache);
+			tfib_cache = NULL;
+		}
+
+		if (!fib_cache)
+			break;
+
+		if (IS_ERR(fib_cache))
+			continue;
+
+		tfib_cache = fib_cache;
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+}
+
+static void mvsw_pr_k_arb_abort(struct prestera_switch *sw)
+{
+	__mvsw_pr_k_arb_abort_neigh(sw);
+	__mvsw_pr_k_arb_abort_fib(sw);
+}
+
 /* Propagate kernel event to hw */
-static void mvsw_pr_neigh_arbiter_n_evt(struct mvsw_pr_switch *sw,
-					struct neighbour *n)
+static void mvsw_pr_k_arb_n_evt(struct prestera_switch *sw,
+				struct neighbour *n)
 {
 	struct mvsw_pr_kern_neigh_cache *n_cache;
 	struct mvsw_pr_nh_neigh_key n_key;
@@ -987,51 +1223,247 @@ static void mvsw_pr_neigh_arbiter_n_evt(struct mvsw_pr_switch *sw,
 	if (err)
 		return;
 
-	n_cache = mvsw_pr_kern_neigh_cache_get(sw, &n_key);
-	if (!n_cache)
+	n_cache = mvsw_pr_kern_neigh_cache_find(sw, &n_key);
+	if (!n_cache) {
+		n_cache = mvsw_pr_kern_neigh_cache_get(sw, &n_key);
+		if (!n_cache)
+			return;
+		__mvsw_pr_k_arb_nc_kern_fib_fetch(sw, n_cache);
+	}
+
+	__mvsw_pr_k_arb_nc_kern_n_fetch(sw, n_cache);
+	__mvsw_pr_k_arb_nc_apply(sw, n_cache);
+
+	mvsw_pr_kern_neigh_cache_put(sw, n_cache);
+}
+
+/* Propagate hw state to kernel */
+static void mvsw_pr_k_arb_hw_evt(struct prestera_switch *sw)
+{
+	struct mvsw_pr_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		n_cache = rhashtable_walk_next(&iter);
+
+		if (!n_cache)
+			break;
+
+		if (IS_ERR(n_cache))
+			continue;
+
+		__mvsw_pr_k_arb_hw_state_upd(sw, n_cache);
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+}
+
+static void __mvsw_pr_k_arb_fib_evt2nc(struct prestera_switch *sw)
+{
+	struct mvsw_pr_kern_neigh_cache *n_cache;
+	struct rhashtable_iter iter;
+
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		n_cache = rhashtable_walk_next(&iter);
+
+		if (!n_cache)
+			break;
+
+		if (IS_ERR(n_cache))
+			continue;
+
+		__mvsw_pr_k_arb_nc_kern_fib_fetch(sw, n_cache);
+		__mvsw_pr_k_arb_nc_apply(sw, n_cache);
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
+}
+
+/* Propagate fib changes to hw neighs */
+static int
+mvsw_pr_k_arb_fib_evt(struct prestera_switch *sw,
+		      bool replace, /* replace or del */
+		      struct fib_entry_notifier_info *fen_info)
+{
+	struct mvsw_pr_kern_fib_cache_key fc_key;
+	struct mvsw_pr_kern_fib_cache *fib_cache;
+	struct mvsw_pr_kern_fib_cache *tfib_cache, *bfib_cache;
+	int err;
+
+	mvsw_pr_util_fen_info2fib_cache_key(fen_info, &fc_key);
+	fib_cache = mvsw_pr_kern_fib_cache_find(sw, &fc_key);
+	if (fib_cache) {
+		fib_cache->reachable = false;
+		err = __mvsw_pr_k_arb_fc_apply(sw, fib_cache);
+		if (err)
+			MVSW_LOG_ERROR("Applying destroyed fib_cache failed");
+
+		bfib_cache = __mvsw_pr_k_arb_util_fib_overlaps(sw, fib_cache);
+		tfib_cache = __mvsw_pr_k_arb_util_fib_overlapped(sw, fib_cache);
+		if (!tfib_cache && bfib_cache) {
+			bfib_cache->reachable = true;
+			err = __mvsw_pr_k_arb_fc_apply(sw, bfib_cache);
+			if (err) {
+				MVSW_LOG_ERROR("Applying fib_cache btm failed");
+				return -ENOENT;
+			}
+		}
+
+		mvsw_pr_kern_fib_cache_destroy(sw, fib_cache);
+	}
+
+	if (replace) {
+		fib_cache = mvsw_pr_kern_fib_cache_create(sw, &fc_key,
+							  fen_info->fi);
+		if (!fib_cache) {
+			MVSW_LOG_ERROR("fib_cache == NULL");
+			return -ENOENT;
+		}
+
+		bfib_cache = __mvsw_pr_k_arb_util_fib_overlaps(sw, fib_cache);
+		tfib_cache = __mvsw_pr_k_arb_util_fib_overlapped(sw, fib_cache);
+		if (!tfib_cache)
+			fib_cache->reachable = true;
+
+		if (bfib_cache) {
+			bfib_cache->reachable = false;
+			err = __mvsw_pr_k_arb_fc_apply(sw, bfib_cache);
+			if (err)
+				MVSW_LOG_ERROR("Applying fib_cache btm failed");
+		}
+
+		err = __mvsw_pr_k_arb_fc_apply(sw, fib_cache);
+		if (err) {
+			MVSW_LOG_ERROR("Applying fib_cache failed");
+			return -ENOENT;
+		}
+	}
+
+	/* Update all neighs to resolve overlapped and apply related */
+	__mvsw_pr_k_arb_fib_evt2nc(sw);
+
+	return 0;
+}
+
+static void mvsw_pr_k_arb_nh_evt(struct prestera_switch *sw,
+				 bool replace,
+				 struct fib_nh *fib_nh)
+{
+	struct mvsw_pr_kern_neigh_cache *nc;
+	struct mvsw_pr_nh_neigh_key nkey;
+	int err;
+
+	err = mvsw_pr_util_fib_nh2nh_neigh_key(sw, fib_nh, &nkey);
+	if (err)
+		return;
+
+	nc = mvsw_pr_kern_neigh_cache_find(sw, &nkey);
+	if (!nc)
 		return;
 
-	__mvsw_pr_sync_neigh_cache_kernel(sw, n_cache);
-	mvsw_pr_kern_neigh_cache_put(sw, n_cache);
+	/* NOTE: we also get from kernel n_evt after this one
+	 * mvsw_pr_k_arb_nh_evt is used only to speedup nh update after
+	 * linkdown on ECMP routes
+	 */
+	nc->nh_neigh_info.connected = false;
+	__mvsw_pr_k_arb_nc_apply(sw, nc);
+}
+
+static struct mvsw_pr_kern_fib_cache *
+__mvsw_pr_k_arb_fc_rebuild(struct prestera_switch *sw,
+			   struct mvsw_pr_kern_fib_cache *fc)
+{
+	struct fib_info *fi;
+	struct mvsw_pr_kern_fib_cache_key key;
+	struct mvsw_pr_kern_fib_cache *new_fc;
+	bool reachable;
+
+	memcpy(&key, &fc->key, sizeof(key));
+	fi = fc->fi;
+	fib_info_hold(fi);
+	reachable = fc->reachable;
+
+	fc->reachable = false;
+	__mvsw_pr_k_arb_fc_apply(sw, fc);
+	mvsw_pr_kern_fib_cache_destroy(sw, fc);
+
+	new_fc = mvsw_pr_kern_fib_cache_create(sw, &key, fi);
+	fib_info_put(fi);
+	if (!new_fc)
+		return NULL;
+
+	new_fc->reachable = reachable;
+	__mvsw_pr_k_arb_fc_apply(sw, new_fc);
+
+	return new_fc;
+}
+
+static void mvsw_pr_k_arb_rif_evt(struct prestera_switch *sw,
+				  struct mvsw_pr_rif *rif)
+{
+	struct mvsw_pr_kern_fib_cache *fc, *tfc, *nfc;
+	struct mvsw_pr_kern_neigh_cache *nc, *tnc;
+	struct rhashtable_iter iter;
+
+	/* Walk every fc, which related to rif and set to trap */
+	tfc = NULL;
+	rhashtable_walk_enter(&sw->router->kern_fib_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		fc = rhashtable_walk_next(&iter);
+		if (tfc && mvsw_pr_util_fi_is_point2dev(tfc->fi, rif->dev)) {
+			nfc = __mvsw_pr_k_arb_fc_rebuild(sw, tfc);
+			/* TODO: way to crash ? */
+			if (WARN_ON(!nfc))
+				MVSW_LOG_ERROR("Rebuild failed %pI4n/%d",
+					       &tfc->key.addr.u.ipv4,
+					       tfc->key.prefix_len);
+		}
+
+		if (!fc)
+			break;
+
+		tfc = NULL;
+		if (IS_ERR(fc))
+			continue;
 
-	__mvsw_pr_neigh2nh_neigh_update(sw, n);
-}
+		tfc = fc;
+	}
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
 
-/* Propagate hw state to kernel */
-static void mvsw_pr_neigh_arbiter_hw_evt(struct mvsw_pr_switch *sw)
-{
-	__mvsw_pr_neigh_hwstate_update_all(sw);
-}
+	/* Destroy every nc, which related to rif */
+	tnc = NULL;
+	rhashtable_walk_enter(&sw->router->kern_neigh_cache_ht, &iter);
+	rhashtable_walk_start(&iter);
+	while (1) {
+		nc = rhashtable_walk_next(&iter);
+		if (tnc && tnc->key.rif == rif) {
+			tnc->in_kernel = false;
+			__mvsw_pr_k_arb_nc_apply(sw, tnc);
+			WARN_ON(mvsw_pr_kern_neigh_cache_put(sw, tnc));
+		}
 
-/* Propagate fib changes to hw neighs */
-static void
-mvsw_pr_neigh_arbiter_fib_evt(struct mvsw_pr_switch *sw,
-			      bool replace, /* replace or del */
-			      struct mvsw_pr_fib_key *fib_key,
-			      struct fib_info *fi)
-{
-	struct mvsw_pr_kern_fib_cache *fib_cache;
+		if (!nc)
+			break;
 
-	fib_cache = mvsw_pr_kern_fib_cache_find(sw, fib_key);
-		if (fib_cache)
-			mvsw_pr_kern_fib_cache_destroy(sw, fib_cache);
+		tnc = NULL;
+		if (IS_ERR(nc))
+			continue;
 
-	/* TODO: add util function IS_NH / IS_DIR */
-	if (replace) {
-		fib_cache = mvsw_pr_kern_fib_cache_create(sw, fib_key, fi);
-		if (!fib_cache)
-			MVSW_LOG_ERROR("%s failed for %pI4n",
-				       "mvsw_pr_kern_fib_cache_create",
-				       &fib_key->addr.u.ipv4);
+		tnc = nc;
 	}
-
-	__mvsw_pr_sync_neigh_cache_kernel_all(sw);
-	__mvsw_pr_neigh2nh_neigh_update_all(sw);
+	rhashtable_walk_stop(&iter);
+	rhashtable_walk_exit(&iter);
 }
 
 struct mvsw_pr_netevent_work {
 	struct work_struct work;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct neighbour *n;
 };
 
@@ -1039,7 +1471,7 @@ static void mvsw_pr_router_neigh_event_work(struct work_struct *work)
 {
 	struct mvsw_pr_netevent_work *net_work =
 		container_of(work, struct mvsw_pr_netevent_work, work);
-	struct mvsw_pr_switch *sw = net_work->sw;
+	struct prestera_switch *sw = net_work->sw;
 	struct neighbour *n = net_work->n;
 
 	/* neigh - its not hw related object. It stored only in kernel. So... */
@@ -1048,7 +1480,7 @@ static void mvsw_pr_router_neigh_event_work(struct work_struct *work)
 	if (sw->router->aborted)
 		goto out;
 
-	mvsw_pr_neigh_arbiter_n_evt(sw, n);
+	mvsw_pr_k_arb_n_evt(sw, n);
 
 out:
 	neigh_release(n);
@@ -1106,7 +1538,7 @@ static void mvsw_pr_router_update_neighs_work(struct work_struct *work)
 	if (router->aborted)
 		goto out;
 
-	mvsw_pr_neigh_arbiter_hw_evt(router->sw);
+	mvsw_pr_k_arb_hw_evt(router->sw);
 
 out:
 	rtnl_unlock();
@@ -1115,7 +1547,7 @@ static void mvsw_pr_router_update_neighs_work(struct work_struct *work)
 			   msecs_to_jiffies(router->neighs_update.interval));
 }
 
-static int mvsw_pr_neigh_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_neigh_init(struct prestera_switch *sw)
 {
 	int err;
 
@@ -1132,14 +1564,14 @@ static int mvsw_pr_neigh_init(struct mvsw_pr_switch *sw)
 	return 0;
 }
 
-static void mvsw_pr_neigh_fini(struct mvsw_pr_switch *sw)
+static void mvsw_pr_neigh_fini(struct prestera_switch *sw)
 {
 	cancel_delayed_work_sync(&sw->router->neighs_update.dw);
 	rhashtable_destroy(&sw->router->nh_neigh_ht);
 }
 
 static struct mvsw_pr_rif*
-mvsw_pr_rif_find(const struct mvsw_pr_switch *sw,
+mvsw_pr_rif_find(const struct prestera_switch *sw,
 		 const struct net_device *dev)
 {
 	struct mvsw_pr_rif *rif;
@@ -1152,7 +1584,7 @@ mvsw_pr_rif_find(const struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-bool mvsw_pr_rif_exists(const struct mvsw_pr_switch *sw,
+bool mvsw_pr_rif_exists(const struct prestera_switch *sw,
 			const struct net_device *dev)
 {
 	return !!mvsw_pr_rif_find(sw, dev);
@@ -1163,8 +1595,8 @@ mvsw_pr_port_vlan_router_join(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan,
 			      struct net_device *dev,
 			      struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *mvsw_pr_port = mvsw_pr_port_vlan->mvsw_pr_port;
-	struct mvsw_pr_switch *sw = mvsw_pr_port->sw;
+	struct prestera_port *port = mvsw_pr_port_vlan->mvsw_pr_port;
+	struct prestera_switch *sw = port->sw;
 
 	struct mvsw_pr_rif_params params = {
 		.dev = dev,
@@ -1195,8 +1627,8 @@ mvsw_pr_port_vlan_router_leave(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan,
 			       struct net_device *dev)
 
 {
-	struct mvsw_pr_port *mvsw_pr_port = mvsw_pr_port_vlan->mvsw_pr_port;
-	struct mvsw_pr_switch *sw = mvsw_pr_port->sw;
+	struct prestera_port *port = mvsw_pr_port_vlan->mvsw_pr_port;
+	struct prestera_switch *sw = port->sw;
 	struct mvsw_pr_rif *rif;
 
 	rif = mvsw_pr_rif_find(sw, dev);
@@ -1210,11 +1642,11 @@ mvsw_pr_port_vlan_router_leave(struct mvsw_pr_port_vlan *mvsw_pr_port_vlan,
 }
 
 static int
-mvsw_pr_port_router_join(struct mvsw_pr_port *mvsw_pr_port,
+mvsw_pr_port_router_join(struct prestera_port *port,
 			 struct net_device *dev,
 			 struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_port->sw;
+	struct prestera_switch *sw = port->sw;
 
 	struct mvsw_pr_rif_params params = {
 		.dev = dev,
@@ -1238,7 +1670,7 @@ mvsw_pr_port_router_join(struct mvsw_pr_port *mvsw_pr_port,
 	return 0;
 }
 
-void mvsw_pr_port_router_leave(struct mvsw_pr_port *mvsw_pr_port)
+void mvsw_pr_port_router_leave(struct prestera_port *port)
 {
 	struct mvsw_pr_rif *rif;
 
@@ -1247,7 +1679,7 @@ void mvsw_pr_port_router_leave(struct mvsw_pr_port *mvsw_pr_port)
 	 * - vid learning set (true)
 	 */
 
-	rif = mvsw_pr_rif_find(mvsw_pr_port->sw, mvsw_pr_port->net_dev);
+	rif = mvsw_pr_rif_find(port->sw, port->net_dev);
 	if (rif) {
 		rif->is_active = false;
 		mvsw_pr_rif_put(rif);
@@ -1258,16 +1690,16 @@ static int mvsw_pr_rif_fdb_op(struct mvsw_pr_rif *rif, const char *mac,
 			      bool adding)
 {
 	if (adding)
-		mvsw_pr_macvlan_add(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
-				    rif->iface.vlan_id);
+		prestera_macvlan_add(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
+				     rif->iface.vlan_id);
 	else
-		mvsw_pr_macvlan_del(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
-				    rif->iface.vlan_id);
+		prestera_macvlan_del(rif->sw, mvsw_pr_rif_vr_id(rif), mac,
+				     rif->iface.vlan_id);
 
 	return 0;
 }
 
-static int mvsw_pr_rif_macvlan_add(struct mvsw_pr_switch *sw,
+static int mvsw_pr_rif_macvlan_add(struct prestera_switch *sw,
 				   const struct net_device *macvlan_dev,
 				   struct netlink_ext_ack *extack)
 {
@@ -1289,7 +1721,7 @@ static int mvsw_pr_rif_macvlan_add(struct mvsw_pr_switch *sw,
 	return err;
 }
 
-static void __mvsw_pr_rif_macvlan_del(struct mvsw_pr_switch *sw,
+static void __mvsw_pr_rif_macvlan_del(struct prestera_switch *sw,
 				      const struct net_device *macvlan_dev)
 {
 	struct macvlan_dev *vlan = netdev_priv(macvlan_dev);
@@ -1302,13 +1734,13 @@ static void __mvsw_pr_rif_macvlan_del(struct mvsw_pr_switch *sw,
 	mvsw_pr_rif_fdb_op(rif, macvlan_dev->dev_addr,  false);
 }
 
-static void mvsw_pr_rif_macvlan_del(struct mvsw_pr_switch *sw,
+static void mvsw_pr_rif_macvlan_del(struct prestera_switch *sw,
 				    const struct net_device *macvlan_dev)
 {
 	__mvsw_pr_rif_macvlan_del(sw, macvlan_dev);
 }
 
-static int mvsw_pr_inetaddr_macvlan_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_macvlan_event(struct prestera_switch *sw,
 					  struct net_device *macvlan_dev,
 					  unsigned long event,
 					  struct netlink_ext_ack *extack)
@@ -1324,7 +1756,7 @@ static int mvsw_pr_inetaddr_macvlan_event(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-static int mvsw_pr_router_port_check_rif_addr(struct mvsw_pr_switch *sw,
+static int mvsw_pr_router_port_check_rif_addr(struct prestera_switch *sw,
 					      struct net_device *dev,
 					      const unsigned char *dev_addr,
 					      struct netlink_ext_ack *extack)
@@ -1346,7 +1778,7 @@ static int mvsw_pr_inetaddr_port_event(struct net_device *port_dev,
 				       unsigned long event,
 				       struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *mvsw_pr_port = netdev_priv(port_dev);
+	struct prestera_port *port = netdev_priv(port_dev);
 
 	MVSW_LOG_ERROR("dev=%s", port_dev->name);
 
@@ -1355,16 +1787,16 @@ static int mvsw_pr_inetaddr_port_event(struct net_device *port_dev,
 		if (netif_is_bridge_port(port_dev) ||
 		    netif_is_lag_port(port_dev) || netif_is_ovs_port(port_dev))
 			return 0;
-		return mvsw_pr_port_router_join(mvsw_pr_port, port_dev, extack);
+		return mvsw_pr_port_router_join(port, port_dev, extack);
 	case NETDEV_DOWN:
-		mvsw_pr_port_router_leave(mvsw_pr_port);
+		mvsw_pr_port_router_leave(port);
 		break;
 	}
 
 	return 0;
 }
 
-static int mvsw_pr_inetaddr_bridge_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_bridge_event(struct prestera_switch *sw,
 					 struct net_device *dev,
 					 unsigned long event,
 					 struct netlink_ext_ack *extack)
@@ -1399,10 +1831,10 @@ static int mvsw_pr_inetaddr_port_vlan_event(struct net_device *l3_dev,
 					    unsigned long event, u16 vid,
 					    struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *mvsw_pr_port = netdev_priv(port_dev);
+	struct prestera_port *port = netdev_priv(port_dev);
 	struct mvsw_pr_port_vlan *mvsw_pr_port_vlan;
 
-	mvsw_pr_port_vlan = mvsw_pr_port_vlan_find_by_vid(mvsw_pr_port, vid);
+	mvsw_pr_port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (WARN_ON(!mvsw_pr_port_vlan))
 		return -EINVAL;
 
@@ -1418,7 +1850,7 @@ static int mvsw_pr_inetaddr_port_vlan_event(struct net_device *l3_dev,
 	return 0;
 }
 
-static int mvsw_pr_inetaddr_vlan_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_vlan_event(struct prestera_switch *sw,
 				       struct net_device *vlan_dev,
 				       unsigned long event,
 				       struct netlink_ext_ack *extack)
@@ -1431,7 +1863,7 @@ static int mvsw_pr_inetaddr_vlan_event(struct mvsw_pr_switch *sw,
 	if (netif_is_bridge_port(vlan_dev))
 		return 0;
 
-	if (mvsw_pr_netdev_check(real_dev))
+	if (prestera_netdev_check(real_dev))
 		return mvsw_pr_inetaddr_port_vlan_event(vlan_dev, real_dev,
 							event, vid, extack);
 	else if (netif_is_bridge_master(real_dev) && br_vlan_enabled(real_dev))
@@ -1441,7 +1873,7 @@ static int mvsw_pr_inetaddr_vlan_event(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-static int mvsw_pr_inetaddr_lag_event(struct mvsw_pr_switch *sw,
+static int mvsw_pr_inetaddr_lag_event(struct prestera_switch *sw,
 				      struct net_device *lag_dev,
 				      unsigned long event,
 				      struct netlink_ext_ack *extack)
@@ -1473,12 +1905,12 @@ static int mvsw_pr_inetaddr_lag_event(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-static int __mvsw_pr_inetaddr_event(struct mvsw_pr_switch *sw,
+static int __mvsw_pr_inetaddr_event(struct prestera_switch *sw,
 				    struct net_device *dev,
 				    unsigned long event,
 				    struct netlink_ext_ack *extack)
 {
-	if (mvsw_pr_netdev_check(dev))
+	if (prestera_netdev_check(dev))
 		return mvsw_pr_inetaddr_port_event(dev, event, extack);
 	else if (is_vlan_dev(dev))
 		return mvsw_pr_inetaddr_vlan_event(sw, dev, event, extack);
@@ -1525,7 +1957,7 @@ static int mvsw_pr_inetaddr_event(struct notifier_block *nb,
 	struct in_ifaddr *ifa = (struct in_ifaddr *)ptr;
 	struct net_device *dev = ifa->ifa_dev->dev;
 	struct mvsw_pr_router *router;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct mvsw_pr_rif *rif;
 	int err = 0;
 
@@ -1559,11 +1991,11 @@ int mvsw_pr_inetaddr_valid_event(struct notifier_block *unused,
 {
 	struct in_validator_info *ivi = (struct in_validator_info *)ptr;
 	struct net_device *dev = ivi->ivi_dev->dev;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct mvsw_pr_rif *rif;
 	int err = 0;
 
-	sw = mvsw_pr_switch_get(dev);
+	sw = prestera_switch_get(dev);
 	if (!sw)
 		goto out;
 
@@ -1608,6 +2040,23 @@ static bool mvsw_pr_fi_is_direct(struct fib_info *fi)
 	return __mvsw_pr_fi_is_direct(fi);
 }
 
+static bool mvsw_pr_fi_is_hw_direct(struct prestera_switch *sw,
+				    struct fib_info *fi)
+{
+	struct fib_nh *fib_nh;
+	struct mvsw_pr_rif *rif;
+
+	if (!mvsw_pr_fi_is_direct(fi))
+		return false;
+
+	fib_nh = fib_info_nh(fi, 0);
+	rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
+	if (!rif || !rif->is_active)
+		return false;
+
+	return true;
+}
+
 static bool mvsw_pr_fi_is_nh(struct fib_info *fi)
 {
 	if (fi->fib_type != RTN_UNICAST)
@@ -1616,7 +2065,7 @@ static bool mvsw_pr_fi_is_nh(struct fib_info *fi)
 	return !__mvsw_pr_fi_is_direct(fi);
 }
 
-static void __mvsw_pr_nh_neigh_destroy(struct mvsw_pr_switch *sw,
+static void __mvsw_pr_nh_neigh_destroy(struct prestera_switch *sw,
 				       struct mvsw_pr_nh_neigh *neigh)
 {
 	neigh->key.rif->ref_cnt--;
@@ -1628,7 +2077,7 @@ static void __mvsw_pr_nh_neigh_destroy(struct mvsw_pr_switch *sw,
 }
 
 static struct mvsw_pr_nh_neigh *
-__mvsw_pr_nh_neigh_create(struct mvsw_pr_switch *sw,
+__mvsw_pr_nh_neigh_create(struct prestera_switch *sw,
 			  struct mvsw_pr_nh_neigh_key *key)
 {
 	struct mvsw_pr_nh_neigh *neigh;
@@ -1651,13 +2100,15 @@ __mvsw_pr_nh_neigh_create(struct mvsw_pr_switch *sw,
 	return neigh;
 
 err_rhashtable_insert:
+	neigh->key.rif->ref_cnt--;
+	mvsw_pr_rif_put(neigh->key.rif);
 	kfree(neigh);
 err_kzalloc:
 	return NULL;
 }
 
-static struct mvsw_pr_nh_neigh *
-mvsw_pr_nh_neigh_find(struct mvsw_pr_switch *sw,
+struct mvsw_pr_nh_neigh *
+mvsw_pr_nh_neigh_find(struct prestera_switch *sw,
 		      struct mvsw_pr_nh_neigh_key *key)
 {
 	struct mvsw_pr_nh_neigh *nh_neigh;
@@ -1668,7 +2119,7 @@ mvsw_pr_nh_neigh_find(struct mvsw_pr_switch *sw,
 }
 
 static struct mvsw_pr_nh_neigh *
-mvsw_pr_nh_neigh_get(struct mvsw_pr_switch *sw,
+mvsw_pr_nh_neigh_get(struct prestera_switch *sw,
 		     struct mvsw_pr_nh_neigh_key *key)
 {
 	struct mvsw_pr_nh_neigh *neigh;
@@ -1680,7 +2131,7 @@ mvsw_pr_nh_neigh_get(struct mvsw_pr_switch *sw,
 	return neigh;
 }
 
-static void mvsw_pr_nh_neigh_put(struct mvsw_pr_switch *sw,
+static void mvsw_pr_nh_neigh_put(struct prestera_switch *sw,
 				 struct mvsw_pr_nh_neigh *neigh)
 {
 	if (list_empty(&neigh->nexthop_group_list))
@@ -1688,7 +2139,7 @@ static void mvsw_pr_nh_neigh_put(struct mvsw_pr_switch *sw,
 }
 
 /* Updates new mvsw_pr_neigh_info */
-static int mvsw_pr_nh_neigh_set(struct mvsw_pr_switch *sw,
+static int mvsw_pr_nh_neigh_set(struct prestera_switch *sw,
 				struct mvsw_pr_nh_neigh *neigh)
 {
 	struct mvsw_pr_nh_neigh_head *nh_head;
@@ -1705,13 +2156,13 @@ static int mvsw_pr_nh_neigh_set(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-static bool __mvsw_pr_nh_neigh_key_is_valid(struct mvsw_pr_nh_neigh_key *key)
+static bool mvsw_pr_nh_neigh_key_is_valid(struct mvsw_pr_nh_neigh_key *key)
 {
 	return memchr_inv(key, 0, sizeof(*key)) ? true : false;
 }
 
 static bool
-mvsw_pr_nh_neigh_util_hw_state(struct mvsw_pr_switch *sw,
+mvsw_pr_nh_neigh_util_hw_state(struct prestera_switch *sw,
 			       struct mvsw_pr_nh_neigh *nh_neigh)
 {
 	bool state;
@@ -1728,21 +2179,8 @@ mvsw_pr_nh_neigh_util_hw_state(struct mvsw_pr_switch *sw,
 	return state;
 }
 
-static size_t
-__mvsw_pr_nexthop_group_key_size(struct mvsw_pr_nexthop_group_key *key)
-{
-	size_t nh_cnt;
-
-	for (nh_cnt = 0; nh_cnt < MVSW_PR_NHGR_SIZE_MAX; nh_cnt++) {
-		if (!__mvsw_pr_nh_neigh_key_is_valid(&key->neigh[nh_cnt]))
-			break;
-	}
-
-	return nh_cnt;
-}
-
 static struct mvsw_pr_nexthop_group *
-__mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
+__mvsw_pr_nexthop_group_create(struct prestera_switch *sw,
 			       struct mvsw_pr_nexthop_group_key *key)
 {
 	struct mvsw_pr_nexthop_group *nh_grp;
@@ -1755,7 +2193,7 @@ __mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
 
 	memcpy(&nh_grp->key, key, sizeof(*key));
 	for (nh_cnt = 0; nh_cnt < MVSW_PR_NHGR_SIZE_MAX; nh_cnt++) {
-		if (!__mvsw_pr_nh_neigh_key_is_valid(&nh_grp->key.neigh[nh_cnt])
+		if (!mvsw_pr_nh_neigh_key_is_valid(&nh_grp->key.neigh[nh_cnt])
 		   )
 			break;
 
@@ -1769,7 +2207,7 @@ __mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
 			 &nh_neigh->nexthop_group_list);
 	}
 
-	err = mvsw_pr_nh_group_create(sw, nh_cnt, &nh_grp->grp_id);
+	err = prestera_nh_group_create(sw, nh_cnt, &nh_grp->grp_id);
 	if (err)
 		goto err_nh_group_create;
 
@@ -1787,7 +2225,7 @@ __mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
 
 err_ht_insert:
 err_nexthop_group_set:
-	mvsw_pr_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
+	prestera_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
 err_nh_group_create:
 err_nh_neigh_get:
 	for (nh_cnt--; nh_cnt >= 0; nh_cnt--) {
@@ -1801,7 +2239,7 @@ __mvsw_pr_nexthop_group_create(struct mvsw_pr_switch *sw,
 }
 
 static void
-__mvsw_pr_nexthop_group_destroy(struct mvsw_pr_switch *sw,
+__mvsw_pr_nexthop_group_destroy(struct prestera_switch *sw,
 				struct mvsw_pr_nexthop_group *nh_grp)
 {
 	struct mvsw_pr_nh_neigh *nh_neigh;
@@ -1820,12 +2258,12 @@ __mvsw_pr_nexthop_group_destroy(struct mvsw_pr_switch *sw,
 		mvsw_pr_nh_neigh_put(sw, nh_neigh);
 	}
 
-	mvsw_pr_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
+	prestera_nh_group_delete(sw, nh_cnt, nh_grp->grp_id);
 	kfree(nh_grp);
 }
 
 static struct mvsw_pr_nexthop_group *
-mvsw_pr_nexthop_group_find(struct mvsw_pr_switch *sw,
+mvsw_pr_nexthop_group_find(struct prestera_switch *sw,
 			   struct mvsw_pr_nexthop_group_key *key)
 {
 	struct mvsw_pr_nexthop_group *nh_grp;
@@ -1836,7 +2274,7 @@ mvsw_pr_nexthop_group_find(struct mvsw_pr_switch *sw,
 }
 
 static struct mvsw_pr_nexthop_group *
-mvsw_pr_nexthop_group_get(struct mvsw_pr_switch *sw,
+mvsw_pr_nexthop_group_get(struct prestera_switch *sw,
 			  struct mvsw_pr_nexthop_group_key *key)
 {
 	struct mvsw_pr_nexthop_group *nh_grp;
@@ -1848,7 +2286,7 @@ mvsw_pr_nexthop_group_get(struct mvsw_pr_switch *sw,
 	return nh_grp;
 }
 
-static void mvsw_pr_nexthop_group_put(struct mvsw_pr_switch *sw,
+static void mvsw_pr_nexthop_group_put(struct prestera_switch *sw,
 				      struct mvsw_pr_nexthop_group *nh_grp)
 {
 	if (!nh_grp->ref_cnt)
@@ -1856,7 +2294,7 @@ static void mvsw_pr_nexthop_group_put(struct mvsw_pr_switch *sw,
 }
 
 /* Updates with new nh_neigh's info */
-static int mvsw_pr_nexthop_group_set(struct mvsw_pr_switch *sw,
+static int mvsw_pr_nexthop_group_set(struct prestera_switch *sw,
 				     struct mvsw_pr_nexthop_group *nh_grp)
 {
 	struct mvsw_pr_neigh_info info[MVSW_PR_NHGR_SIZE_MAX];
@@ -1872,45 +2310,42 @@ static int mvsw_pr_nexthop_group_set(struct mvsw_pr_switch *sw,
 		memcpy(&info[nh_cnt], &neigh->info, sizeof(neigh->info));
 	}
 
-	return mvsw_pr_nh_entries_set(sw, nh_cnt, &info[0], nh_grp->grp_id);
+	return prestera_nh_entries_set(sw, nh_cnt, &info[0], nh_grp->grp_id);
 }
 
 static bool
-mvsw_pr_nexthop_group_util_hw_state(struct mvsw_pr_switch *sw,
+mvsw_pr_nexthop_group_util_hw_state(struct prestera_switch *sw,
 				    struct mvsw_pr_nexthop_group *nh_grp)
 {
-	int err, nh_cnt;
-	struct mvsw_pr_neigh_info info[MVSW_PR_NHGR_SIZE_MAX];
-	size_t grp_size;
+	int err;
+	u32 buf_size = sw->size_tbl_router_nexthop / 8 + 1;
+	u32 gid = nh_grp->grp_id;
+	u8 *cache = sw->router->nhgrp_hw_state_cache;
 
 	/* Antijitter
 	 * Prevent situation, when we read state of nh_grp twice in short time,
 	 * and state bit is still cleared on second call. So just stuck active
 	 * state for MVSW_PR_NH_ACTIVE_JIFFER_FILTER, after last occurred.
 	 */
-	if (time_before(jiffies, nh_grp->hw_last_connected +
-			msecs_to_jiffies(MVSW_PR_NH_ACTIVE_JIFFER_FILTER)))
-		return true;
+	if (!time_before(jiffies, sw->router->nhgrp_hw_cache_kick +
+			msecs_to_jiffies(MVSW_PR_NH_ACTIVE_JIFFER_FILTER))) {
+		err = prestera_nhgrp_blk_get(sw, cache, buf_size);
+		if (err) {
+			MVSW_LOG_ERROR("Failed to get hw state nh_grp's");
+			return false;
+		}
 
-	grp_size =  __mvsw_pr_nexthop_group_key_size(&nh_grp->key);
-	err = mvsw_pr_nh_entries_get(sw, grp_size, &info[0], nh_grp->grp_id);
-	if (err) {
-		MVSW_LOG_ERROR("Failed to get hw state of nh_grp %d",
-			       nh_grp->grp_id);
-		return false;
+		sw->router->nhgrp_hw_cache_kick = jiffies;
 	}
 
-	for (nh_cnt = 0; nh_cnt < grp_size; nh_cnt++)
-		if (info[nh_cnt].connected) {
-			nh_grp->hw_last_connected = jiffies;
-			return true;
-		}
+	if (cache[gid / 8] & (1 << (gid % 8)))
+		return true;
 
 	return false;
 }
 
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_find(struct mvsw_pr_switch *sw, struct mvsw_pr_fib_key *key)
+mvsw_pr_fib_node_find(struct prestera_switch *sw, struct mvsw_pr_fib_key *key)
 {
 	struct mvsw_pr_fib_node *fib_node;
 
@@ -1919,14 +2354,14 @@ mvsw_pr_fib_node_find(struct mvsw_pr_switch *sw, struct mvsw_pr_fib_key *key)
 	return IS_ERR(fib_node) ? NULL : fib_node;
 }
 
-static void __mvsw_pr_fib_node_destruct(struct mvsw_pr_switch *sw,
+static void __mvsw_pr_fib_node_destruct(struct prestera_switch *sw,
 					struct mvsw_pr_fib_node *fib_node)
 {
 	struct mvsw_pr_vr *vr;
 
 	vr = fib_node->info.vr;
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id, &fib_node->key.addr,
-			fib_node->key.prefix_len);
+	prestera_lpm_del(sw, vr->hw_vr_id, &fib_node->key.addr,
+			 fib_node->key.prefix_len);
 	switch (fib_node->info.type) {
 	case MVSW_PR_FIB_TYPE_UC_NH:
 		fib_node->info.nh_grp->ref_cnt--;
@@ -1945,7 +2380,7 @@ static void __mvsw_pr_fib_node_destruct(struct mvsw_pr_switch *sw,
 	mvsw_pr_vr_put(sw, vr);
 }
 
-static void mvsw_pr_fib_node_destroy(struct mvsw_pr_switch *sw,
+static void mvsw_pr_fib_node_destroy(struct prestera_switch *sw,
 				     struct mvsw_pr_fib_node *fib_node)
 {
 	__mvsw_pr_fib_node_destruct(sw, fib_node);
@@ -1954,7 +2389,7 @@ static void mvsw_pr_fib_node_destroy(struct mvsw_pr_switch *sw,
 	kfree(fib_node);
 }
 
-static void mvsw_pr_fib_node_destroy_ht(struct mvsw_pr_switch *sw)
+static void mvsw_pr_fib_node_destroy_ht(struct prestera_switch *sw)
 {
 	struct mvsw_pr_fib_node *node, *tnode;
 	struct rhashtable_iter iter;
@@ -1985,13 +2420,15 @@ static void mvsw_pr_fib_node_destroy_ht(struct mvsw_pr_switch *sw)
 	rhashtable_walk_exit(&iter);
 }
 
+/* nh_grp_key valid only if fib_type == MVSW_PR_FIB_TYPE_UC_NH */
 static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
-			      struct mvsw_pr_fib_key *key,
-			      struct mvsw_pr_nexthop_group_key *nh_grp_key)
+mvsw_pr_fib_node_create(struct prestera_switch *sw,
+			struct mvsw_pr_fib_key *key,
+			enum mvsw_pr_fib_type fib_type,
+			struct mvsw_pr_nexthop_group_key *nh_grp_key)
 {
 	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_nexthop_group *nh_grp;
+	u32 grp_id;
 	struct mvsw_pr_vr *vr;
 	int err;
 
@@ -2000,7 +2437,7 @@ mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
 		goto err_kzalloc;
 
 	memcpy(&fib_node->key, key, sizeof(*key));
-	fib_node->info.type = MVSW_PR_FIB_TYPE_UC_NH;
+	fib_node->info.type = fib_type;
 
 	vr = mvsw_pr_vr_get(sw, key->tb_id, NULL);
 	if (!vr)
@@ -2009,15 +2446,30 @@ mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
 	fib_node->info.vr = vr;
 	vr->ref_cnt++;
 
-	nh_grp = mvsw_pr_nexthop_group_get(sw, nh_grp_key);
-	if (!nh_grp)
+	switch (fib_type) {
+	case MVSW_PR_FIB_TYPE_TRAP:
+		grp_id = MVSW_PR_NHGR_UNUSED;
+		break;
+	case MVSW_PR_FIB_TYPE_DROP:
+		grp_id = MVSW_PR_NHGR_DROP;
+		break;
+	case MVSW_PR_FIB_TYPE_UC_NH:
+		fib_node->info.nh_grp = mvsw_pr_nexthop_group_get(sw,
+								  nh_grp_key);
+		if (!fib_node->info.nh_grp)
+			goto err_nh_grp_get;
+
+		fib_node->info.nh_grp->ref_cnt++;
+		grp_id = fib_node->info.nh_grp->grp_id;
+		break;
+	default:
+		MVSW_LOG_ERROR("Unsupported fib_type %d", fib_type);
 		goto err_nh_grp_get;
+	}
 
-	fib_node->info.nh_grp = nh_grp;
-	nh_grp->ref_cnt++;
 
-	err = mvsw_pr_lpm_add(sw, vr->hw_vr_id, &key->addr,
-			      key->prefix_len, nh_grp->grp_id);
+	err = prestera_lpm_add(sw, vr->hw_vr_id, &key->addr,
+			       key->prefix_len, grp_id);
 	if (err)
 		goto err_lpm_add;
 
@@ -2029,10 +2481,12 @@ mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
 	return fib_node;
 
 err_ht_insert:
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id, &key->addr, key->prefix_len);
+	prestera_lpm_del(sw, vr->hw_vr_id, &key->addr, key->prefix_len);
 err_lpm_add:
-	nh_grp->ref_cnt--;
-	mvsw_pr_nexthop_group_put(sw, nh_grp);
+	if (fib_type == MVSW_PR_FIB_TYPE_UC_NH) {
+		fib_node->info.nh_grp->ref_cnt--;
+		mvsw_pr_nexthop_group_put(sw, fib_node->info.nh_grp);
+	}
 err_nh_grp_get:
 	vr->ref_cnt--;
 	mvsw_pr_vr_put(sw, vr);
@@ -2040,6 +2494,7 @@ mvsw_pr_fib_node_uc_nh_create(struct mvsw_pr_switch *sw,
 	kfree(fib_node);
 err_kzalloc:
 	return NULL;
+
 }
 
 /* Decided, that uc_nh route with key==nh is obviously neighbour route */
@@ -2062,265 +2517,16 @@ mvsw_pr_fib_node_util_is_neighbour(struct mvsw_pr_fib_node *fib_node)
 	return true;
 }
 
-static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_trap_create(struct mvsw_pr_switch *sw,
-			     struct mvsw_pr_fib_key *key)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_vr *vr;
-	int err;
-
-	fib_node = kzalloc(sizeof(*fib_node), GFP_KERNEL);
-	if (!fib_node)
-		goto err_kzalloc;
-
-	vr = mvsw_pr_vr_get(sw, key->tb_id, NULL);
-	if (!vr)
-		goto err_vr_get;
-
-	fib_node->info.vr = vr;
-	vr->ref_cnt++;
-
-	memcpy(&fib_node->key, key, sizeof(*key));
-	fib_node->info.type = MVSW_PR_FIB_TYPE_TRAP;
-	err = mvsw_pr_lpm_add(sw, vr->hw_vr_id, &key->addr,
-			      key->prefix_len, MVSW_PR_NHGR_UNUSED);
-	if (err)
-		goto err_lpm_add;
-
-	err = rhashtable_insert_fast(&sw->router->fib_ht, &fib_node->ht_node,
-				     __mvsw_pr_fib_ht_params);
-	if (err)
-		goto err_ht_insert;
-
-	return fib_node;
-
-err_ht_insert:
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id, &key->addr, key->prefix_len);
-err_lpm_add:
-	vr->ref_cnt--;
-	mvsw_pr_vr_put(sw, vr);
-err_vr_get:
-	kfree(fib_node);
-err_kzalloc:
-	return NULL;
-}
-
-static struct mvsw_pr_fib_node *
-mvsw_pr_fib_node_drop_create(struct mvsw_pr_switch *sw,
-			     struct mvsw_pr_fib_key *key)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_vr *vr;
-	int err;
-
-	fib_node = kzalloc(sizeof(*fib_node), GFP_KERNEL);
-	if (!fib_node)
-		goto err_kzalloc;
-
-	vr = mvsw_pr_vr_get(sw, key->tb_id, NULL);
-	if (!vr)
-		goto err_vr_get;
-
-	fib_node->info.vr = vr;
-	vr->ref_cnt++;
-
-	memcpy(&fib_node->key, key, sizeof(*key));
-	fib_node->info.type = MVSW_PR_FIB_TYPE_DROP;
-	err = mvsw_pr_lpm_add(sw, vr->hw_vr_id,
-			      &key->addr, key->prefix_len, MVSW_PR_NHGR_DROP);
-	if (err)
-		goto err_lpm_add;
-
-	err = rhashtable_insert_fast(&sw->router->fib_ht, &fib_node->ht_node,
-				     __mvsw_pr_fib_ht_params);
-	if (err)
-		goto err_ht_insert;
-
-	return fib_node;
-
-err_ht_insert:
-	mvsw_pr_lpm_del(sw, vr->hw_vr_id,
-			&key->addr, key->prefix_len);
-err_lpm_add:
-	vr->ref_cnt--;
-	mvsw_pr_vr_put(sw, vr);
-err_vr_get:
-	kfree(fib_node);
-err_kzalloc:
-	return NULL;
-}
-
-static void mvsw_pr_fib_nh_del2nh_neigh_set(struct mvsw_pr_switch *sw,
-					    struct fib_nh *fib_nh)
-{
-	struct mvsw_pr_nh_neigh_key nh_neigh_key;
-	struct mvsw_pr_nh_neigh *nh_neigh;
-
-	memset(&nh_neigh_key, 0, sizeof(nh_neigh_key));
-	nh_neigh_key.addr.u.ipv4 = fib_nh->fib_nh_gw4;
-	nh_neigh_key.rif = mvsw_pr_rif_find(sw, fib_nh->fib_nh_dev);
-	if (!nh_neigh_key.rif)
-		return;
-
-	nh_neigh = mvsw_pr_nh_neigh_find(sw, &nh_neigh_key);
-	if (!nh_neigh)
-		return;
-
-	nh_neigh->info.connected = false;
-	mvsw_pr_nh_neigh_set(sw, nh_neigh);
-}
-
-static void __mvsw_pr_fen_info2fib_key(struct fib_entry_notifier_info *fen_info,
-				       struct mvsw_pr_fib_key *key)
-{
-	memset(key, 0, sizeof(*key));
-	key->addr.u.ipv4 = cpu_to_be32(fen_info->dst);
-	key->prefix_len = fen_info->dst_len;
-	key->tb_id = mvsw_pr_fix_tb_id(fen_info->tb_id);
-}
-
-static int
-mvsw_pr_fi2nh_gr_key(struct mvsw_pr_switch *sw, struct fib_info *fi,
-		     size_t limit, struct mvsw_pr_nexthop_group_key *grp_key)
-{
-	int i, nhs, err;
-	struct fib_nh *fib_nh;
-
-	nhs = fib_info_num_path(fi);
-	if (nhs > limit)
-		return 0;
-
-	memset(grp_key, 0, sizeof(*grp_key));
-	for (i = 0; i < nhs; i++) {
-		fib_nh = fib_info_nh(fi, i);
-		err = mvsw_pr_util_fib_nh2nh_neigh_key(sw,
-						       fib_nh,
-						       &grp_key->neigh[i]);
-		if (err)
-			return 0;
-	}
-
-	return nhs;
-}
-
-static int
-mvsw_pr_router_fib_replace(struct mvsw_pr_switch *sw,
-			   struct fib_entry_notifier_info *fen_info)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_fib_key fib_key;
-	struct mvsw_pr_nexthop_group_key nh_grp_key;
-	int nh_cnt;
-
-	__mvsw_pr_fen_info2fib_key(fen_info, &fib_key);
-
-	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
-	if (fib_node) {
-		MVSW_LOG_INFO("fib_node found. destroy.");
-		mvsw_pr_fib_node_destroy(sw, fib_node);
-	}
-
-	/* TODO: fib lookup here to check if another route with the same key
-	 * is occurred in another kernel's table
-	 */
-	switch (fen_info->fi->fib_type) {
-	case RTN_UNICAST:
-		if (mvsw_pr_fi_is_nh(fen_info->fi))
-			nh_cnt = mvsw_pr_fi2nh_gr_key(sw, fen_info->fi,
-						      MVSW_PR_NHGR_SIZE_MAX,
-						      &nh_grp_key);
-		else
-			nh_cnt = 0;
-
-		if (nh_cnt) {
-			fib_node = mvsw_pr_fib_node_uc_nh_create(sw, &fib_key,
-								 &nh_grp_key);
-		} else {
-			fib_node = mvsw_pr_fib_node_trap_create(sw, &fib_key);
-		}
-
-		if (!fib_node)
-			goto err_fib_create;
-
-		break;
-	/* Unsupported. Leave it for kernel: */
-	case RTN_BROADCAST:
-	case RTN_MULTICAST:
-	/* Routes we must trap by design: */
-	case RTN_LOCAL:
-	case RTN_UNREACHABLE:
-	case RTN_PROHIBIT:
-		fib_node = mvsw_pr_fib_node_trap_create(sw, &fib_key);
-		if (!fib_node)
-			goto err_fib_create;
-		break;
-	case RTN_BLACKHOLE:
-		fib_node = mvsw_pr_fib_node_drop_create(sw, &fib_key);
-		if (!fib_node)
-			goto err_fib_create;
-
-		break;
-	default:
-		goto err_type;
-	}
-
-	mvsw_pr_neigh_arbiter_fib_evt(sw, true, &fib_key, fen_info->fi);
-
-	return 0;
-
-err_fib_create:
-	MVSW_LOG_ERROR("fib_create failed");
-	goto err_out;
-err_type:
-	MVSW_LOG_ERROR("Invalid fen_info->fi->fib_type %d",
-		       fen_info->fi->fib_type);
-	goto err_out;
-err_out:
-	MVSW_LOG_ERROR("Error when processing %pI4h/%d", &fen_info->dst,
-		       fen_info->dst_len);
-	return -EINVAL;
-}
-
-static void mvsw_pr_router_fib_del(struct mvsw_pr_switch *sw,
-				   struct fib_entry_notifier_info *fen_info)
-{
-	struct mvsw_pr_fib_node *fib_node;
-	struct mvsw_pr_fib_key fib_key;
-
-	/* TODO: fib lookup here to check if another route with the same key
-	 * is occurred in another kernel's table
-	 */
-	__mvsw_pr_fen_info2fib_key(fen_info, &fib_key);
-
-	fib_node = mvsw_pr_fib_node_find(sw, &fib_key);
-	if (fib_node) {
-		mvsw_pr_fib_node_destroy(sw, fib_node);
-	} else {
-		MVSW_LOG_ERROR("Cant find fib_node");
-		goto err_out;
-	}
-
-	mvsw_pr_neigh_arbiter_fib_evt(sw, false, &fib_key, fen_info->fi);
-
-	return;
-
-err_out:
-	MVSW_LOG_ERROR("Error when processing %pI4h/%d", &fen_info->dst,
-		       fen_info->dst_len);
-}
-
-static void mvsw_pr_router_fib_abort(struct mvsw_pr_switch *sw)
+static void mvsw_pr_router_fib_abort(struct prestera_switch *sw)
 {
 	mvsw_pr_vr_util_hw_abort(sw);
 	mvsw_pr_fib_node_destroy_ht(sw);
-	mvsw_pr_kern_fib_cache_destroy_ht(sw);
-	mvsw_pr_util_kern_unset_allneigh_offload();
+	mvsw_pr_k_arb_abort(sw);
 }
 
 struct mvsw_pr_fib_event_work {
 	struct work_struct work;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	union {
 		struct fib_entry_notifier_info fen_info;
 		struct fib_nh_notifier_info fnh_info;
@@ -2332,7 +2538,7 @@ static void mvsw_pr_router_fib4_event_work(struct work_struct *work)
 {
 	struct mvsw_pr_fib_event_work *fib_work =
 			container_of(work, struct mvsw_pr_fib_event_work, work);
-	struct mvsw_pr_switch *sw = fib_work->sw;
+	struct prestera_switch *sw = fib_work->sw;
 	int err;
 
 	mvsw_owq_lock();
@@ -2342,19 +2548,27 @@ static void mvsw_pr_router_fib4_event_work(struct work_struct *work)
 
 	switch (fib_work->event) {
 	case FIB_EVENT_ENTRY_REPLACE:
-		err = mvsw_pr_router_fib_replace(sw,
-						 &fib_work->fen_info);
+		err = mvsw_pr_k_arb_fib_evt(sw, true, &fib_work->fen_info);
 		if (err)
 			goto abort_out;
+
 		break;
 	case FIB_EVENT_ENTRY_DEL:
-		mvsw_pr_router_fib_del(sw, &fib_work->fen_info);
+		err = mvsw_pr_k_arb_fib_evt(sw, false, &fib_work->fen_info);
+		if (err)
+			MVSW_LOG_ERROR("Cant delete %pI4n/%d",
+				       &fib_work->fen_info.dst,
+				       fib_work->fen_info.dst_len);
+
 		break;
 	}
 
 	goto out;
 
 abort_out:
+	dev_err(sw->dev->dev, "Error when processing %pI4h/%d",
+		&fib_work->fen_info.dst,
+		fib_work->fen_info.dst_len);
 	sw->router->aborted = true;
 	mvsw_pr_router_fib_abort(sw);
 	dev_err(sw->dev->dev, "Abort. HW routing offloading disabled");
@@ -2368,7 +2582,7 @@ static void mvsw_pr_router_nh_update_event_work(struct work_struct *work)
 {
 	struct mvsw_pr_fib_event_work *fib_work =
 			container_of(work, struct mvsw_pr_fib_event_work, work);
-	struct mvsw_pr_switch *sw = fib_work->sw;
+	struct prestera_switch *sw = fib_work->sw;
 	struct fib_nh *fib_nh = fib_work->fnh_info.fib_nh;
 
 	mvsw_owq_lock();
@@ -2378,7 +2592,7 @@ static void mvsw_pr_router_nh_update_event_work(struct work_struct *work)
 
 	/* For now provided only deletion */
 	if (fib_work->event == FIB_EVENT_NH_DEL)
-		mvsw_pr_fib_nh_del2nh_neigh_set(sw, fib_nh);
+		mvsw_pr_k_arb_nh_evt(sw, false, fib_nh);
 
 out:
 	fib_info_put(fib_nh->nh_parent);
@@ -2515,10 +2729,10 @@ mvsw_pr_router_port_pre_change(struct mvsw_pr_rif *rif,
 int mvsw_pr_netdevice_router_port_event(struct net_device *dev,
 					unsigned long event, void *ptr)
 {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	struct mvsw_pr_rif *rif;
 
-	sw = mvsw_pr_switch_get(dev);
+	sw = prestera_switch_get(dev);
 	if (!sw)
 		return 0;
 
@@ -2536,7 +2750,7 @@ int mvsw_pr_netdevice_router_port_event(struct net_device *dev,
 	return 0;
 }
 
-static int mvsw_pr_port_vrf_join(struct mvsw_pr_switch *sw,
+static int mvsw_pr_port_vrf_join(struct prestera_switch *sw,
 				 struct net_device *dev,
 				 struct netlink_ext_ack *extack)
 {
@@ -2554,7 +2768,7 @@ static int mvsw_pr_port_vrf_join(struct mvsw_pr_switch *sw,
 	return mvsw_pr_rif_vr_update(sw, rif, extack);
 }
 
-static void mvsw_pr_port_vrf_leave(struct mvsw_pr_switch *sw,
+static void mvsw_pr_port_vrf_leave(struct prestera_switch *sw,
 				   struct net_device *dev,
 				   struct netlink_ext_ack *extack)
 {
@@ -2580,13 +2794,15 @@ static void mvsw_pr_port_vrf_leave(struct mvsw_pr_switch *sw,
 int mvsw_pr_netdevice_vrf_event(struct net_device *dev, unsigned long event,
 				struct netdev_notifier_changeupper_info *info)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(dev);
+	struct prestera_switch *sw = prestera_switch_get(dev);
 	struct netlink_ext_ack *extack = NULL;
 	int err = 0;
 
 	if (!sw || netif_is_macvlan(dev))
 		return 0;
 
+	mvsw_owq_flush();
+
 	switch (event) {
 	case NETDEV_PRECHANGEUPPER:
 		return 0;
@@ -2625,19 +2841,20 @@ static int mvsw_pr_rif_macvlan_flush(struct mvsw_pr_rif *rif)
 	netdev_warn(rif->dev,
 		    "Router interface is deleted. Upper macvlans will not work\n");
 	return netdev_walk_all_upper_dev_rcu(rif->dev,
-					     __mvsw_pr_rif_macvlan_flush, &priv);
+					     __mvsw_pr_rif_macvlan_flush,
+					     &priv);
 }
 
 #ifdef CONFIG_IP_ROUTE_MULTIPATH
-static int mvsw_pr_mp_hash_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_mp_hash_init(struct prestera_switch *sw)
 {
 	u8 hash_policy;
 
 	hash_policy = init_net.ipv4.sysctl_fib_multipath_hash_policy;
-	return  mvsw_pr_mp4_hash_set(sw, hash_policy);
+	return  prestera_mp4_hash_set(sw, hash_policy);
 }
 #else
-static int mvsw_pr_mp_hash_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_mp_hash_init(struct prestera_switch *sw)
 {
 	return 0;
 }
@@ -2647,10 +2864,10 @@ static struct notifier_block mvsw_pr_inetaddr_valid_nb __read_mostly = {
 	.notifier_call = mvsw_pr_inetaddr_valid_event,
 };
 
-int mvsw_pr_router_init(struct mvsw_pr_switch *sw)
+int mvsw_pr_router_init(struct prestera_switch *sw)
 {
 	struct mvsw_pr_router *router;
-	int err;
+	int err, nhgrp_cache_bytes;
 
 	router = kzalloc(sizeof(*sw->router), GFP_KERNEL);
 	if (!router)
@@ -2682,6 +2899,11 @@ int mvsw_pr_router_init(struct mvsw_pr_switch *sw)
 	if (err)
 		goto err_kern_neigh_cache_ht_init;
 
+	nhgrp_cache_bytes = sw->size_tbl_router_nexthop / 8 + 1;
+	router->nhgrp_hw_state_cache = kzalloc(nhgrp_cache_bytes, GFP_KERNEL);
+	if (!router->nhgrp_hw_state_cache)
+		return -ENOMEM;
+
 	INIT_LIST_HEAD(&sw->router->rif_list);
 	INIT_LIST_HEAD(&sw->router->vr_list);
 
@@ -2749,7 +2971,7 @@ int mvsw_pr_router_init(struct mvsw_pr_switch *sw)
 	return err;
 }
 
-static void mvsw_pr_rifs_fini(struct mvsw_pr_switch *sw)
+static void mvsw_pr_rifs_fini(struct prestera_switch *sw)
 {
 	struct mvsw_pr_rif *rif, *tmp;
 
@@ -2759,7 +2981,7 @@ static void mvsw_pr_rifs_fini(struct mvsw_pr_switch *sw)
 	}
 }
 
-void mvsw_pr_router_fini(struct mvsw_pr_switch *sw)
+void mvsw_pr_router_fini(struct prestera_switch *sw)
 {
 	unregister_fib_notifier(&init_net, &sw->router->fib_nb);
 	unregister_netevent_notifier(&sw->router->netevent_nb);
@@ -2793,7 +3015,7 @@ static u32 mvsw_pr_fix_tb_id(u32 tb_id)
 	return tb_id;
 }
 
-static struct mvsw_pr_vr *__mvsw_pr_vr_find(struct mvsw_pr_switch *sw,
+static struct mvsw_pr_vr *__mvsw_pr_vr_find(struct prestera_switch *sw,
 					    u32 tb_id)
 {
 	struct mvsw_pr_vr *vr;
@@ -2806,7 +3028,7 @@ static struct mvsw_pr_vr *__mvsw_pr_vr_find(struct mvsw_pr_switch *sw,
 	return NULL;
 }
 
-static struct mvsw_pr_vr *__mvsw_pr_vr_create(struct mvsw_pr_switch *sw,
+static struct mvsw_pr_vr *__mvsw_pr_vr_create(struct prestera_switch *sw,
 					      u32 tb_id,
 					      struct netlink_ext_ack *extack)
 {
@@ -2837,7 +3059,7 @@ static struct mvsw_pr_vr *__mvsw_pr_vr_create(struct mvsw_pr_switch *sw,
 	return ERR_PTR(err);
 }
 
-static void __mvsw_pr_vr_destroy(struct mvsw_pr_switch *sw,
+static void __mvsw_pr_vr_destroy(struct prestera_switch *sw,
 				 struct mvsw_pr_vr *vr)
 {
 	mvsw_pr_hw_vr_delete(sw, vr->hw_vr_id);
@@ -2845,7 +3067,7 @@ static void __mvsw_pr_vr_destroy(struct mvsw_pr_switch *sw,
 	kfree(vr);
 }
 
-static struct mvsw_pr_vr *mvsw_pr_vr_get(struct mvsw_pr_switch *sw, u32 tb_id,
+static struct mvsw_pr_vr *mvsw_pr_vr_get(struct prestera_switch *sw, u32 tb_id,
 					 struct netlink_ext_ack *extack)
 {
 	struct mvsw_pr_vr *vr;
@@ -2859,13 +3081,13 @@ static struct mvsw_pr_vr *mvsw_pr_vr_get(struct mvsw_pr_switch *sw, u32 tb_id,
 	return vr;
 }
 
-static void mvsw_pr_vr_put(struct mvsw_pr_switch *sw, struct mvsw_pr_vr *vr)
+static void mvsw_pr_vr_put(struct prestera_switch *sw, struct mvsw_pr_vr *vr)
 {
 	if (!vr->ref_cnt)
 		__mvsw_pr_vr_destroy(sw, vr);
 }
 
-static void mvsw_pr_vr_util_hw_abort(struct mvsw_pr_switch *sw)
+static void mvsw_pr_vr_util_hw_abort(struct prestera_switch *sw)
 {
 	struct mvsw_pr_vr *vr, *vr_tmp;
 
@@ -2875,7 +3097,7 @@ static void mvsw_pr_vr_util_hw_abort(struct mvsw_pr_switch *sw)
 }
 
 static struct mvsw_pr_rif*
-mvsw_pr_rif_alloc(struct mvsw_pr_switch *sw,
+mvsw_pr_rif_alloc(struct prestera_switch *sw,
 		  struct mvsw_pr_vr *vr,
 		  const struct mvsw_pr_rif_params *params)
 {
@@ -2912,7 +3134,7 @@ static int mvsw_pr_rif_offload(struct mvsw_pr_rif *rif)
 				     &rif->rif_id);
 }
 
-static struct mvsw_pr_rif *mvsw_pr_rif_create(struct mvsw_pr_switch *sw,
+static struct mvsw_pr_rif *mvsw_pr_rif_create(struct prestera_switch *sw,
 					      const struct mvsw_pr_rif_params
 					      *params,
 					      struct netlink_ext_ack *extack)
@@ -2970,11 +3192,11 @@ static void mvsw_pr_rif_destroy(struct mvsw_pr_rif *rif)
 
 static void mvsw_pr_rif_put(struct mvsw_pr_rif *rif)
 {
-	if (!rif->ref_cnt)
+	if (!rif->ref_cnt && !rif->is_active)
 		mvsw_pr_rif_destroy(rif);
 }
 
-void mvsw_pr_rif_enable(struct mvsw_pr_switch *sw,
+void mvsw_pr_rif_enable(struct prestera_switch *sw,
 			struct net_device *dev, bool enable)
 {
 	struct mvsw_pr_rif *rif;
@@ -2994,7 +3216,7 @@ static int mvsw_pr_rif_update(struct mvsw_pr_rif *rif, char *mac)
 	return mvsw_pr_hw_rif_set(rif->sw, &rif->rif_id, &rif->iface, mac);
 }
 
-static int mvsw_pr_rif_vr_update(struct mvsw_pr_switch *sw,
+static int mvsw_pr_rif_vr_update(struct prestera_switch *sw,
 				 struct mvsw_pr_rif *rif,
 				 struct netlink_ext_ack *extack)
 {
@@ -3015,7 +3237,7 @@ static int mvsw_pr_rif_vr_update(struct mvsw_pr_switch *sw,
 	return 0;
 }
 
-void mvsw_pr_router_lag_member_leave(const struct mvsw_pr_port *port,
+void mvsw_pr_router_lag_member_leave(const struct prestera_port *port,
 				     const struct net_device *dev)
 {
 	struct mvsw_pr_rif *rif;
@@ -3029,7 +3251,7 @@ void mvsw_pr_router_lag_member_leave(const struct mvsw_pr_port *port,
 	prestera_lag_member_rif_leave(port, port->lag_id, vr_id);
 }
 
-void prestera_lag_router_leave(struct mvsw_pr_switch *sw,
+void prestera_lag_router_leave(struct prestera_switch *sw,
 			       struct net_device *lag_dev)
 {
 	struct mvsw_pr_rif *rif;
@@ -3041,29 +3263,37 @@ void prestera_lag_router_leave(struct mvsw_pr_switch *sw,
 	}
 }
 
-static int mvsw_pr_bridge_device_rif_put(struct net_device *bridge_dev,
-					struct netdev_nested_priv *priv)
+static int mvsw_pr_bridge_device_rif_put(struct net_device *dev,
+					 struct netdev_nested_priv *priv)
 {
+	struct prestera_switch *sw = priv->data;
 	struct mvsw_pr_rif *rif;
-	struct mvsw_pr_switch *sw = priv->data;
 
-	rif = mvsw_pr_rif_find(sw, bridge_dev);
+	rif = mvsw_pr_rif_find(sw, dev);
 	if (rif) {
 		rif->is_active = false;
 		mvsw_pr_rif_put(rif);
+		mvsw_pr_k_arb_rif_evt(sw, rif);
 	}
 
 	return 0;
 }
 
-void mvsw_pr_bridge_device_rifs_destroy(struct mvsw_pr_switch *sw,
+void mvsw_pr_bridge_device_rifs_destroy(struct prestera_switch *sw,
 					struct net_device *bridge_dev)
 {
 	struct netdev_nested_priv priv = {
 		.data = (void *)sw,
 	};
+
 	mvsw_pr_bridge_device_rif_put(bridge_dev, &priv);
 	netdev_walk_all_upper_dev_rcu(bridge_dev,
 				      mvsw_pr_bridge_device_rif_put,
 				      &priv);
 }
+
+struct mvsw_pr_neigh_info *
+prestera_kern_neigh_cache_to_neigh_info(struct mvsw_pr_kern_neigh_cache *nc)
+{
+	return &nc->nh_neigh_info;
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
index 50b811e..acbad5a 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
@@ -3,91 +3,259 @@
  * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
  *
  */
-#include "prestera.h"
-#include "prestera_rxtx_priv.h"
-#include "prestera_dsa.h"
 
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/dmapool.h>
 #include <linux/if_vlan.h>
 #include <net/ip.h>
 
+#include "prestera.h"
+#include "prestera_hw.h"
+#include "prestera_dsa.h"
+#include "prestera_rxtx.h"
+#include "prestera_devlink.h"
+
 #define MVSW_DSA_TAG_ARP_BROADCAST 5
 #define MVSW_DSA_TAG_IPV4_BROADCAST 19
+#define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC 16
 #define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_1 29
 #define MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_2 30
 #define MVSW_DSA_TAG_UDP_BROADCAST 33
 #define MVSW_DSA_TAG_ARP_BROADCAST_TO_ME 179
 
-struct mvsw_pr_rxtx;
+struct mvsw_sdma_desc {
+	__le32 word1;
+	__le32 word2;
+	__le32 buff;
+	__le32 next;
+} __packed __aligned(16);
+
+#define SDMA_BUFF_SIZE_MAX	1544
+
+#define SDMA_RX_DESC_PKT_LEN(desc) \
+	((le32_to_cpu((desc)->word2) >> 16) & 0x3FFF)
+
+#define SDMA_RX_DESC_OWNER(desc) \
+	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
+
+#define SDMA_RX_DESC_CPU_OWN	0
+#define SDMA_RX_DESC_DMA_OWN	1
+
+#define SDMA_RX_QUEUE_NUM	8
+
+#define SDMA_RX_DESC_PER_Q	1000
+
+#define SDMA_TX_DESC_PER_Q	1000
+#define SDMA_TX_MAX_BURST	32
+
+#define SDMA_TX_DESC_OWNER(desc) \
+	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
+
+#define SDMA_TX_DESC_CPU_OWN	0
+#define SDMA_TX_DESC_DMA_OWN	1
+
+#define SDMA_TX_DESC_IS_SENT(desc) \
+	(SDMA_TX_DESC_OWNER(desc) == SDMA_TX_DESC_CPU_OWN)
+
+#define SDMA_TX_DESC_LAST	BIT(20)
+#define SDMA_TX_DESC_FIRST	BIT(21)
+#define SDMA_TX_DESC_SINGLE	(SDMA_TX_DESC_FIRST | SDMA_TX_DESC_LAST)
+#define SDMA_TX_DESC_CALC_CRC	BIT(12)
+
+#define mvsw_reg_write(sw, reg, val) \
+	writel(val, (sw)->dev->pp_regs + (reg))
+#define mvsw_reg_read(sw, reg) \
+	readl((sw)->dev->pp_regs + (reg))
+
+#define SDMA_RX_INTR_MASK_REG		0x2814
+#define SDMA_RX_QUEUE_STATUS_REG	0x2680
+#define SDMA_RX_QUEUE_DESC_REG(n)	(0x260C + (n) * 16)
+
+#define SDMA_TX_QUEUE_DESC_REG		0x26C0
+#define SDMA_TX_QUEUE_START_REG		0x2868
+
+struct mvsw_sdma_buf {
+	struct mvsw_sdma_desc *desc;
+	dma_addr_t desc_dma;
+	struct sk_buff *skb;
+	dma_addr_t buf_dma;
+	bool is_used;
+};
+
+struct mvsw_sdma_rx_ring {
+	struct mvsw_sdma_buf *bufs;
+	int next_rx;
+	int weight;
+	int recvd;
+};
+
+struct mvsw_sdma_tx_ring {
+	struct mvsw_sdma_buf *bufs;
+	int next_tx;
+	int max_burst;
+	int burst;
+};
 
-enum mvsw_pr_rxtx_type {
-	MVSW_PR_RXTX_MVPP,
-	MVSW_PR_RXTX_ETH,
-	MVSW_PR_RXTX_SDMA,
+struct mvsw_pr_rxtx_sdma {
+	struct mvsw_sdma_rx_ring rx_ring[SDMA_RX_QUEUE_NUM];
+	struct mvsw_sdma_tx_ring tx_ring;
+	const struct prestera_switch *sw;
+	struct dma_pool *desc_pool;
+	struct work_struct tx_work;
+	struct napi_struct rx_napi;
+	int next_rxq;
+	struct net_device napi_dev;
+	/* protect SDMA with concurrrent access from multiple CPUs */
+	spinlock_t tx_lock;
+	u32 map_addr;
+	u64 dma_mask;
 };
 
-static struct mvsw_pr_rxtx *rxtx_registered;
+struct prestera_rxtx {
+	struct mvsw_pr_rxtx_sdma sdma;
+};
+
+static int prestera_rx_weight_map[SDMA_RX_QUEUE_NUM] = {
+	1, 2, 2, 2, 2, 4, 4, 8
+};
 
 static u64 *cpu_code_stats;
 
-netdev_tx_t mvsw_pr_rxtx_xmit(struct sk_buff *skb,
-			      struct mvsw_pr_rxtx_info *info)
+static int mvsw_sdma_buf_desc_alloc(struct mvsw_pr_rxtx_sdma *sdma,
+				    struct mvsw_sdma_buf *buf)
 {
-	struct mvsw_pr_dsa dsa;
-	struct mvsw_pr_dsa_from_cpu *from_cpu;
-	struct net_device *dev = skb->dev;
-	struct mvsw_pr_port *port = netdev_priv(dev);
-	size_t dsa_resize_len = MVSW_PR_DSA_HLEN;
+	struct device *dma_dev = sdma->sw->dev->dev;
+	struct mvsw_sdma_desc *desc;
+	dma_addr_t dma;
 
-	if (!rxtx_registered)
-		return NET_XMIT_DROP;
+	desc = dma_pool_alloc(sdma->desc_pool, GFP_DMA | GFP_KERNEL, &dma);
+	if (!desc)
+		return -ENOMEM;
 
-	/* common DSA tag fill-up */
-	memset(&dsa, 0, sizeof(dsa));
-	dsa.dsa_cmd = MVSW_NET_DSA_CMD_FROM_CPU_E;
+	if (dma + sizeof(struct mvsw_sdma_desc) > sdma->dma_mask) {
+		dev_err(dma_dev, "failed to alloc desc\n");
+		dma_pool_free(sdma->desc_pool, desc, dma);
+		return -ENOMEM;
+	}
 
-	from_cpu = &dsa.dsa_info.from_cpu;
-	from_cpu->egr_filter_en = false;
-	from_cpu->egr_filter_registered = false;
-	from_cpu->dst_eport = port->hw_id;
+	buf->desc_dma = dma;
+	buf->desc = desc;
 
-	from_cpu->dst_iface.dev_port.port_num = port->hw_id;
-	from_cpu->dst_iface.dev_port.hw_dev_num = port->dev_id;
-	from_cpu->dst_iface.type = MVSW_IF_PORT_E;
+	return 0;
+}
 
-	/* epmorary removing due to issue with vlan sub interface
-	 * on 1.Q bridge
-	 */
-	/* If (skb->protocol == htons(ETH_P_8021Q)) { */
-		/* 802.1q packet tag size is 4 bytes, so DSA len would
-		 * need only allocation of MVSW_PR_DSA_HLEN - size of
-		 * 802.1q tag
-		 */
-		/*dsa.common_params.vpt = skb_vlan_tag_get_prio(skb);
-		 * dsa.common_params.cfi_bit = skb_vlan_tag_get_cfi(skb);
-		 * dsa.common_params.vid = skb_vlan_tag_get_id(skb);
-		 * dsa_resize_len -= VLAN_HLEN;
-		 */
-	/* } */
+static u32 mvsw_sdma_addr_phy(struct mvsw_pr_rxtx_sdma *sdma, dma_addr_t pa)
+{
+	return sdma->map_addr + pa;
+}
 
+static void mvsw_sdma_rx_desc_set_len(struct mvsw_sdma_desc *desc, size_t val)
+{
+	u32 word = le32_to_cpu(desc->word2);
 
-	if (skb_cow_head(skb, dsa_resize_len) < 0)
-		return NET_XMIT_DROP;
+	word = (word & ~GENMASK(15, 0)) | val;
+	desc->word2 = cpu_to_le32(word);
+}
 
-	/* expects skb->data at mac header */
-	skb_push(skb, dsa_resize_len);
-	memmove(skb->data, skb->data + dsa_resize_len, 2 * ETH_ALEN);
+static void mvsw_sdma_rx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_desc *desc,
+				   dma_addr_t buf)
+{
+	mvsw_sdma_rx_desc_set_len(desc, SDMA_BUFF_SIZE_MAX);
+	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
+	/* make sure buffer is set before reset the descriptor */
+	wmb();
+	desc->word1 = cpu_to_le32(0xA0000000);
+}
 
-	if (mvsw_pr_dsa_build(&dsa, skb->data + 2 * ETH_ALEN) != 0)
-		return NET_XMIT_DROP;
+static void mvsw_sdma_rx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
+				       struct mvsw_sdma_desc *desc,
+				       dma_addr_t next)
+{
+	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
+}
+
+static int mvsw_sdma_rx_dma_alloc(struct mvsw_pr_rxtx_sdma *sdma,
+				  struct mvsw_sdma_buf *buf)
+{
+	struct device *dev = sdma->sw->dev->dev;
 
-	return rxtx_registered->ops->rxtx_xmit(rxtx_registered, skb);
+	buf->skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_DMA | GFP_ATOMIC);
+	if (!buf->skb)
+		return -ENOMEM;
+
+	buf->buf_dma = dma_map_single(dev, buf->skb->data, buf->skb->len,
+				      DMA_FROM_DEVICE);
+
+	if (dma_mapping_error(dev, buf->buf_dma))
+		goto err_dma_map;
+	if (buf->buf_dma + buf->skb->len > sdma->dma_mask)
+		goto err_dma_range;
+
+	return 0;
+
+err_dma_range:
+	dma_unmap_single(dev, buf->buf_dma, buf->skb->len, DMA_FROM_DEVICE);
+	buf->buf_dma = DMA_MAPPING_ERROR;
+err_dma_map:
+	kfree_skb(buf->skb);
+	buf->skb = NULL;
+
+	return -ENOMEM;
+}
+
+static struct sk_buff *mvsw_sdma_rx_buf_get(struct mvsw_pr_rxtx_sdma *sdma,
+					    struct mvsw_sdma_buf *buf)
+{
+	struct sk_buff *skb_orig = buf->skb;
+	dma_addr_t buf_dma = buf->buf_dma;
+	u32 len = skb_orig->len;
+	int err;
+
+	err = mvsw_sdma_rx_dma_alloc(sdma, buf);
+	if (err) {
+		struct sk_buff *skb;
+
+		buf->buf_dma = buf_dma;
+		buf->skb = skb_orig;
+
+		skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_ATOMIC);
+		if (!skb)
+			return NULL;
+
+		skb_copy_from_linear_data(buf->skb, skb_put(skb, len), len);
+		return skb;
+	}
+
+	return skb_orig;
+}
+
+static void mvsw_sdma_rx_set_next_queue(struct mvsw_pr_rxtx_sdma *sdma, int rxq)
+{
+	sdma->next_rxq = rxq % SDMA_RX_QUEUE_NUM;
 }
 
-int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb)
+static int mvsw_sdma_rx_pick_next_queue(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	const struct mvsw_pr_port *port;
+	struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[sdma->next_rxq];
+
+	if (ring->recvd >= ring->weight) {
+		mvsw_sdma_rx_set_next_queue(sdma, sdma->next_rxq + 1);
+		ring->recvd = 0;
+	}
+
+	return sdma->next_rxq;
+}
+
+static int mvsw_pr_sdma_recv_skb(struct sk_buff *skb)
+{
+	struct prestera_port *port;
 	struct mvsw_pr_dsa dsa;
 	u32 hw_port, hw_id;
+	u8 cpu_code;
 	int err;
 
 	skb_pull(skb, ETH_HLEN);
@@ -102,7 +270,7 @@ int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb)
 	/* get switch port */
 	hw_port = dsa.dsa_info.to_cpu.iface.port_num;
 	hw_id = dsa.dsa_info.to_cpu.hw_dev_num;
-	port = mvsw_pr_port_find(hw_id, hw_port);
+	port = prestera_port_find(hw_id, hw_port);
 	if (unlikely(!port)) {
 		pr_warn_ratelimited("prestera: received pkt for non-existent port(%u, %u)\n",
 				    hw_id, hw_port);
@@ -132,88 +300,605 @@ int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb)
 		__vlan_hwaccel_put_tag(skb, htons(ETH_P_8021Q), tci);
 	}
 
-	switch (dsa.dsa_info.to_cpu.cpu_code) {
+	cpu_code = dsa.dsa_info.to_cpu.cpu_code;
+
+	prestera_devlink_trap_report(port, skb, cpu_code);
+
+	switch (cpu_code) {
 	case MVSW_DSA_TAG_ARP_BROADCAST:
 	case MVSW_DSA_TAG_IPV4_BROADCAST:
+	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC:
 	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_1:
 	case MVSW_DSA_TAG_IPV4_IPV6_LINK_LOCAL_MC_2:
 	case MVSW_DSA_TAG_UDP_BROADCAST:
 	case MVSW_DSA_TAG_ARP_BROADCAST_TO_ME:
 		skb->offload_fwd_mark = 1;
 	}
-	++cpu_code_stats[dsa.dsa_info.to_cpu.cpu_code];
+	++cpu_code_stats[cpu_code];
 
 	return 0;
 }
 
-static struct mvsw_pr_rxtx_ops rxtx_driver_ops[] = {
-	[MVSW_PR_RXTX_SDMA] = {
-		.rxtx_init = mvsw_pr_rxtx_sdma_init,
-		.rxtx_fini = mvsw_pr_rxtx_sdma_fini,
-		.rxtx_switch_init = mvsw_pr_rxtx_sdma_switch_init,
-		.rxtx_switch_fini = mvsw_pr_rxtx_sdma_switch_fini,
-		.rxtx_xmit = mvsw_pr_rxtx_sdma_xmit,
-	},
-};
+static int mvsw_sdma_rx_poll(struct napi_struct *napi, int budget)
+{
+	unsigned int qmask = GENMASK(SDMA_RX_QUEUE_NUM - 1, 0);
+	struct mvsw_pr_rxtx_sdma *sdma;
+	unsigned int rxq_done_map = 0;
+	struct list_head rx_list;
+	int pkts_done = 0;
+
+	INIT_LIST_HEAD(&rx_list);
+
+	sdma = container_of(napi, struct mvsw_pr_rxtx_sdma, rx_napi);
+
+	while (pkts_done < budget && rxq_done_map != qmask) {
+		struct mvsw_sdma_rx_ring *ring;
+		struct mvsw_sdma_desc *desc;
+		struct mvsw_sdma_buf *buf;
+		struct sk_buff *skb;
+		int buf_idx;
+		int rxq;
+
+		rxq = mvsw_sdma_rx_pick_next_queue(sdma);
+		ring = &sdma->rx_ring[rxq];
+
+		buf_idx = ring->next_rx;
+		buf = &ring->bufs[buf_idx];
+		desc = buf->desc;
+
+		if (SDMA_RX_DESC_OWNER(desc) != SDMA_RX_DESC_CPU_OWN) {
+			mvsw_sdma_rx_set_next_queue(sdma, rxq + 1);
+			rxq_done_map |= BIT(rxq);
+			continue;
+		} else {
+			rxq_done_map &= ~BIT(rxq);
+		}
+
+		ring->recvd++;
+		pkts_done++;
+
+		__skb_trim(buf->skb, SDMA_RX_DESC_PKT_LEN(desc));
+
+		skb = mvsw_sdma_rx_buf_get(sdma, buf);
+		if (!skb)
+			goto rx_reset_buf;
+
+		if (unlikely(mvsw_pr_sdma_recv_skb(skb)))
+			goto rx_reset_buf;
+
+		list_add_tail(&skb->list, &rx_list);
+rx_reset_buf:
+		mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
+		ring->next_rx = (buf_idx + 1) % SDMA_RX_DESC_PER_Q;
+	}
+
+	if (pkts_done < budget && napi_complete_done(napi, pkts_done))
+		mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0xff << 2);
+
+	netif_receive_skb_list(&rx_list);
+
+	return pkts_done;
+}
 
-int mvsw_pr_rxtx_init(void)
+static void mvsw_sdma_rx_fini(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	cpu_code_stats = kzalloc(sizeof(u64) * MVSW_PR_RXTX_CPU_CODE_MAX_NUM,
-				 GFP_KERNEL);
-	if (!cpu_code_stats)
-		return -ENOMEM;
+	int q, b;
 
-	rxtx_registered = kzalloc(sizeof(*rxtx_registered), GFP_KERNEL);
-	if (!rxtx_registered) {
-		kfree(cpu_code_stats);
-		return -ENOMEM;
+	/* disable all rx queues */
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
+
+	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
+		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
+
+		if (!ring->bufs)
+			break;
+
+		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
+			struct mvsw_sdma_buf *buf = &ring->bufs[b];
+
+			if (buf->desc_dma)
+				dma_pool_free(sdma->desc_pool, buf->desc,
+					      buf->desc_dma);
+
+			if (!buf->skb)
+				continue;
+
+			if (buf->buf_dma != DMA_MAPPING_ERROR)
+				dma_unmap_single(sdma->sw->dev->dev,
+						 buf->buf_dma, buf->skb->len,
+						 DMA_FROM_DEVICE);
+			kfree_skb(buf->skb);
+		}
 	}
+}
+
+static int mvsw_sdma_rx_init(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	int q, b;
+	int err;
+
+	/* disable all rx queues */
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
+
+	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
+		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
+		struct mvsw_sdma_buf *head;
+
+		ring->bufs = kmalloc_array(SDMA_RX_DESC_PER_Q, sizeof(*head),
+					   GFP_KERNEL);
+		if (!ring->bufs)
+			return -ENOMEM;
 
-	rxtx_registered->ops = &rxtx_driver_ops[MVSW_PR_RXTX_SDMA];
+		ring->weight = prestera_rx_weight_map[q];
+		ring->recvd = 0;
+		ring->next_rx = 0;
+
+		head = &ring->bufs[0];
+
+		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
+			struct mvsw_sdma_buf *buf = &ring->bufs[b];
+
+			err = mvsw_sdma_buf_desc_alloc(sdma, buf);
+			if (err)
+				return err;
+
+			err = mvsw_sdma_rx_dma_alloc(sdma, buf);
+			if (err)
+				return err;
+
+			mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
+
+			if (b == 0)
+				continue;
+
+			mvsw_sdma_rx_desc_set_next(sdma, ring->bufs[b - 1].desc,
+						   buf->desc_dma);
+
+			if (b == SDMA_RX_DESC_PER_Q - 1)
+				mvsw_sdma_rx_desc_set_next(sdma, buf->desc,
+							   head->desc_dma);
+		}
+
+		mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_DESC_REG(q),
+			       mvsw_sdma_addr_phy(sdma, head->desc_dma));
+	}
 
-	if (rxtx_registered->ops->rxtx_init)
-		return rxtx_registered->ops->rxtx_init(rxtx_registered);
+	/* make sure all rx descs are filled before enabling all rx queues */
+	wmb();
+	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff);
 
 	return 0;
 }
 
-void mvsw_pr_rxtx_fini(void)
+static void mvsw_sdma_tx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_desc *desc)
 {
-	struct mvsw_pr_rxtx *rxtx = rxtx_registered;
+	desc->word1 = cpu_to_le32(SDMA_TX_DESC_SINGLE | SDMA_TX_DESC_CALC_CRC);
+	desc->word2 = 0;
+}
 
-	if (rxtx->ops->rxtx_fini)
-		rxtx->ops->rxtx_fini(rxtx);
+static void mvsw_sdma_tx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
+				       struct mvsw_sdma_desc *desc,
+				       dma_addr_t next)
+{
+	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
+}
 
-	kfree(rxtx_registered);
-	rxtx_registered = NULL;
-	kfree(cpu_code_stats);
+static void mvsw_sdma_tx_desc_set_buf(struct mvsw_pr_rxtx_sdma *sdma,
+				      struct mvsw_sdma_desc *desc,
+				      dma_addr_t buf, size_t len)
+{
+	u32 word = le32_to_cpu(desc->word2);
+
+	word = (word & ~GENMASK(30, 16)) | ((len + 4) << 16);
+
+	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
+	desc->word2 = cpu_to_le32(word);
 }
 
-int mvsw_pr_rxtx_switch_init(struct mvsw_pr_switch *sw)
+static void mvsw_sdma_tx_desc_xmit(struct mvsw_sdma_desc *desc)
 {
-	int err;
+	u32 word = le32_to_cpu(desc->word1);
 
-	if (!rxtx_registered) {
-		pr_info("No RxTx driver registered");
+	word |= (SDMA_TX_DESC_DMA_OWN << 31);
+
+	/* make sure everything is written before enable xmit */
+	wmb();
+	desc->word1 = cpu_to_le32(word);
+}
+
+static int mvsw_sdma_tx_buf_map(struct mvsw_pr_rxtx_sdma *sdma,
+				struct mvsw_sdma_buf *buf,
+				struct sk_buff *skb)
+{
+	struct device *dma_dev = sdma->sw->dev->dev;
+	struct sk_buff *new_skb;
+	size_t len = skb->len;
+	dma_addr_t dma;
+
+	dma = dma_map_single(dma_dev, skb->data, len, DMA_TO_DEVICE);
+	if (!dma_mapping_error(dma_dev, dma) && dma + len <= sdma->dma_mask) {
+		buf->buf_dma = dma;
+		buf->skb = skb;
 		return 0;
 	}
 
-	if (!rxtx_registered->ops->rxtx_switch_init)
-		return 0;
+	if (!dma_mapping_error(dma_dev, dma))
+		dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
 
-	err = rxtx_registered->ops->rxtx_switch_init(rxtx_registered, sw);
-	if (err)
-		return err;
+	new_skb = alloc_skb(len, GFP_ATOMIC | GFP_DMA);
+	if (!new_skb)
+		goto err_alloc_skb;
+
+	dma = dma_map_single(dma_dev, new_skb->data, len, DMA_TO_DEVICE);
+	if (dma_mapping_error(dma_dev, dma))
+		goto err_dma_map;
+	if (dma + len > sdma->dma_mask)
+		goto err_dma_range;
+
+	skb_copy_from_linear_data(skb, skb_put(new_skb, len), len);
+
+	dev_consume_skb_any(skb);
+
+	buf->skb = new_skb;
+	buf->buf_dma = dma;
+
+	return 0;
+
+err_dma_range:
+	dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
+err_dma_map:
+	dev_kfree_skb(new_skb);
+err_alloc_skb:
+	dev_kfree_skb(skb);
+
+	return -ENOMEM;
+}
+
+static void mvsw_sdma_tx_buf_unmap(struct mvsw_pr_rxtx_sdma *sdma,
+				   struct mvsw_sdma_buf *buf)
+{
+	struct device *dma_dev = sdma->sw->dev->dev;
+
+	dma_unmap_single(dma_dev, buf->buf_dma, buf->skb->len, DMA_TO_DEVICE);
+}
+
+static void mvsw_sdma_tx_recycle_work_fn(struct work_struct *work)
+{
+	struct mvsw_sdma_tx_ring *tx_ring;
+	struct mvsw_pr_rxtx_sdma *sdma;
+	struct device *dma_dev;
+	int b;
+
+	sdma = container_of(work, struct mvsw_pr_rxtx_sdma, tx_work);
+
+	dma_dev = sdma->sw->dev->dev;
+	tx_ring = &sdma->tx_ring;
+
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
+
+		if (!buf->is_used)
+			continue;
+
+		if (!SDMA_TX_DESC_IS_SENT(buf->desc))
+			continue;
+
+		mvsw_sdma_tx_buf_unmap(sdma, buf);
+		dev_consume_skb_any(buf->skb);
+		buf->skb = NULL;
+
+		/* make sure everything is cleaned up */
+		wmb();
+
+		buf->is_used = false;
+	}
+}
+
+static int mvsw_sdma_tx_init(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	struct mvsw_sdma_tx_ring *tx_ring = &sdma->tx_ring;
+	struct mvsw_sdma_buf *head;
+	int err;
+	int b;
+
+	spin_lock_init(&sdma->tx_lock);
+
+	INIT_WORK(&sdma->tx_work, mvsw_sdma_tx_recycle_work_fn);
+
+	tx_ring->bufs = kmalloc_array(SDMA_TX_DESC_PER_Q, sizeof(*head),
+				      GFP_KERNEL);
+	if (!tx_ring->bufs)
+		return -ENOMEM;
+
+	head = &tx_ring->bufs[0];
+
+	tx_ring->max_burst = SDMA_TX_MAX_BURST;
+	tx_ring->burst = tx_ring->max_burst;
+	tx_ring->next_tx = 0;
+
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
+
+		err = mvsw_sdma_buf_desc_alloc(sdma, buf);
+		if (err)
+			return err;
+
+		mvsw_sdma_tx_desc_init(sdma, buf->desc);
+
+		buf->is_used = false;
+		buf->skb = NULL;
+
+		if (b == 0)
+			continue;
+
+		mvsw_sdma_tx_desc_set_next(sdma, tx_ring->bufs[b - 1].desc,
+					   buf->desc_dma);
+
+		if (b == SDMA_TX_DESC_PER_Q - 1)
+			mvsw_sdma_tx_desc_set_next(sdma, buf->desc,
+						   head->desc_dma);
+	}
+
+	/* make sure descriptors are written */
+	wmb();
+	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_DESC_REG,
+		       mvsw_sdma_addr_phy(sdma, head->desc_dma));
 
 	return 0;
 }
 
-void mvsw_pr_rxtx_switch_fini(struct mvsw_pr_switch *sw)
+static void mvsw_sdma_tx_fini(struct mvsw_pr_rxtx_sdma *sdma)
 {
-	if (!rxtx_registered || !rxtx_registered->ops->rxtx_switch_init)
+	struct mvsw_sdma_tx_ring *ring = &sdma->tx_ring;
+	int b;
+
+	cancel_work_sync(&sdma->tx_work);
+
+	if (!ring->bufs)
+		return;
+
+	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
+		struct mvsw_sdma_buf *buf = &ring->bufs[b];
+
+		if (buf->desc)
+			dma_pool_free(sdma->desc_pool, buf->desc,
+				      buf->desc_dma);
+
+		if (!buf->skb)
+			continue;
+
+		dma_unmap_single(sdma->sw->dev->dev, buf->buf_dma,
+				 buf->skb->len, DMA_TO_DEVICE);
+
+		dev_consume_skb_any(buf->skb);
+	}
+}
+
+static void mvsw_rxtx_handle_event(struct prestera_switch *sw,
+				   struct mvsw_pr_event *evt, void *arg)
+{
+	struct mvsw_pr_rxtx_sdma *sdma = arg;
+
+	if (evt->id != MVSW_RXTX_EVENT_RCV_PKT)
 		return;
 
-	return rxtx_registered->ops->rxtx_switch_fini(rxtx_registered, sw);
+	mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0);
+	napi_schedule(&sdma->rx_napi);
+}
+
+int prestera_rxtx_switch_init(struct prestera_switch *sw)
+{
+	struct mvsw_pr_rxtx_sdma *sdma;
+	int err;
+
+	if (!cpu_code_stats) {
+		cpu_code_stats = kzalloc(sizeof(u64) *
+				     MVSW_PR_RXTX_CPU_CODE_MAX_NUM, GFP_KERNEL);
+		if (!cpu_code_stats)
+			return -ENOMEM;
+	}
+
+	sw->rxtx = kzalloc(sizeof(*sw->rxtx), GFP_KERNEL);
+	if (!sw->rxtx)
+		goto err_rxtx_alloc;
+
+	sdma = &sw->rxtx->sdma;
+
+	err = mvsw_pr_hw_rxtx_init(sw, true, &sdma->map_addr);
+	if (err) {
+		dev_err(sw->dev->dev, "failed to init rxtx by hw\n");
+		goto err_hw_rxtx_init;
+	}
+
+	sdma->dma_mask = dma_get_mask(sw->dev->dev);
+	sdma->sw = sw;
+
+	sdma->desc_pool = dma_pool_create("desc_pool", sdma->sw->dev->dev,
+					  sizeof(struct mvsw_sdma_desc), 16, 0);
+	if (!sdma->desc_pool) {
+		err = -ENOMEM;
+		goto err_dma_pool;
+	}
+
+	err = mvsw_sdma_rx_init(sdma);
+	if (err) {
+		dev_err(sw->dev->dev, "failed to init rx ring\n");
+		goto err_rx_init;
+	}
+
+	err = mvsw_sdma_tx_init(sdma);
+	if (err) {
+		dev_err(sw->dev->dev, "failed to init tx ring\n");
+		goto err_tx_init;
+	}
+
+	err = mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_RXTX,
+						mvsw_rxtx_handle_event, sdma);
+	if (err)
+		goto err_evt_register;
+
+	init_dummy_netdev(&sdma->napi_dev);
+
+	netif_napi_add(&sdma->napi_dev, &sdma->rx_napi, mvsw_sdma_rx_poll, 64);
+	napi_enable(&sdma->rx_napi);
+
+	return 0;
+
+err_evt_register:
+err_tx_init:
+	mvsw_sdma_tx_fini(sdma);
+err_rx_init:
+	mvsw_sdma_rx_fini(sdma);
+
+	dma_pool_destroy(sdma->desc_pool);
+err_dma_pool:
+err_hw_rxtx_init:
+	kfree(sw->rxtx);
+err_rxtx_alloc:
+	kfree(cpu_code_stats);
+	return err;
+}
+
+void prestera_rxtx_switch_fini(struct prestera_switch *sw)
+{
+	struct mvsw_pr_rxtx_sdma *sdma = &sw->rxtx->sdma;
+
+	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_RXTX);
+	napi_disable(&sdma->rx_napi);
+	netif_napi_del(&sdma->rx_napi);
+	mvsw_sdma_rx_fini(sdma);
+	mvsw_sdma_tx_fini(sdma);
+	dma_pool_destroy(sdma->desc_pool);
+	kfree(sw->rxtx);
+	kfree(cpu_code_stats);
+}
+
+static int mvsw_sdma_wait_tx(struct mvsw_pr_rxtx_sdma *sdma,
+			     struct mvsw_sdma_tx_ring *tx_ring)
+{
+	int tx_retry_num = 10 * tx_ring->max_burst;
+
+	while (--tx_retry_num) {
+		if (!(mvsw_reg_read(sdma->sw, SDMA_TX_QUEUE_START_REG) & 1))
+			return 0;
+
+		udelay(5);
+	}
+
+	return -EBUSY;
+}
+
+static void mvsw_sdma_start_tx(struct mvsw_pr_rxtx_sdma *sdma)
+{
+	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_START_REG, 1);
+	schedule_work(&sdma->tx_work);
+}
+
+static netdev_tx_t mvsw_pr_rxtx_sdma_xmit(struct prestera_rxtx *rxtx,
+					  struct sk_buff *skb)
+{
+	struct mvsw_pr_rxtx_sdma *sdma = &rxtx->sdma;
+	struct device *dma_dev = sdma->sw->dev->dev;
+	struct mvsw_sdma_tx_ring *tx_ring;
+	struct net_device *dev = skb->dev;
+	struct mvsw_sdma_buf *buf;
+	int err;
+
+	spin_lock(&sdma->tx_lock);
+
+	tx_ring = &sdma->tx_ring;
+
+	buf = &tx_ring->bufs[tx_ring->next_tx];
+	if (buf->is_used) {
+		schedule_work(&sdma->tx_work);
+		goto drop_skb;
+	}
+
+	if (unlikely(skb_put_padto(skb, ETH_ZLEN)))
+		goto drop_skb_nofree;
+
+	err = mvsw_sdma_tx_buf_map(sdma, buf, skb);
+	if (err)
+		goto drop_skb;
+
+	mvsw_sdma_tx_desc_set_buf(sdma, buf->desc, buf->buf_dma, skb->len);
+
+	dma_sync_single_for_device(dma_dev, buf->buf_dma, skb->len,
+				   DMA_TO_DEVICE);
+
+	if (!tx_ring->burst--) {
+		tx_ring->burst = tx_ring->max_burst;
+
+		err = mvsw_sdma_wait_tx(sdma, tx_ring);
+		if (err)
+			goto drop_skb_unmap;
+	}
+
+	tx_ring->next_tx = (tx_ring->next_tx + 1) % SDMA_TX_DESC_PER_Q;
+	mvsw_sdma_tx_desc_xmit(buf->desc);
+	buf->is_used = true;
+
+	mvsw_sdma_start_tx(sdma);
+
+	goto tx_done;
+
+drop_skb_unmap:
+	mvsw_sdma_tx_buf_unmap(sdma, buf);
+drop_skb:
+	dev_consume_skb_any(skb);
+drop_skb_nofree:
+	dev->stats.tx_dropped++;
+tx_done:
+	spin_unlock(&sdma->tx_lock);
+	return NETDEV_TX_OK;
+}
+
+netdev_tx_t prestera_rxtx_xmit(struct sk_buff *skb, struct prestera_port *port)
+{
+	struct mvsw_pr_dsa dsa;
+	struct mvsw_pr_dsa_from_cpu *from_cpu;
+	size_t dsa_resize_len = MVSW_PR_DSA_HLEN;
+
+	/* common DSA tag fill-up */
+	memset(&dsa, 0, sizeof(dsa));
+	dsa.dsa_cmd = MVSW_NET_DSA_CMD_FROM_CPU_E;
+
+	from_cpu = &dsa.dsa_info.from_cpu;
+	from_cpu->egr_filter_en = false;
+	from_cpu->egr_filter_registered = false;
+	from_cpu->dst_eport = port->hw_id;
+
+	from_cpu->dst_iface.dev_port.port_num = port->hw_id;
+	from_cpu->dst_iface.dev_port.hw_dev_num = port->dev_id;
+	from_cpu->dst_iface.type = MVSW_IF_PORT_E;
+
+	/* epmorary removing due to issue with vlan sub interface
+	 * on 1.Q bridge
+	 */
+	/* If (skb->protocol == htons(ETH_P_8021Q)) { */
+		/* 802.1q packet tag size is 4 bytes, so DSA len would
+		 * need only allocation of MVSW_PR_DSA_HLEN - size of
+		 * 802.1q tag
+		 */
+		/*dsa.common_params.vpt = skb_vlan_tag_get_prio(skb);
+		 * dsa.common_params.cfi_bit = skb_vlan_tag_get_cfi(skb);
+		 * dsa.common_params.vid = skb_vlan_tag_get_id(skb);
+		 * dsa_resize_len -= VLAN_HLEN;
+		 */
+	/* } */
+
+	if (skb_cow_head(skb, dsa_resize_len) < 0)
+		return NET_XMIT_DROP;
+
+	/* expects skb->data at mac header */
+	skb_push(skb, dsa_resize_len);
+	memmove(skb->data, skb->data + dsa_resize_len, 2 * ETH_ALEN);
+
+	if (mvsw_pr_dsa_build(&dsa, skb->data + 2 * ETH_ALEN) != 0)
+		return NET_XMIT_DROP;
+
+	return mvsw_pr_rxtx_sdma_xmit(port->sw->rxtx, skb);
 }
 
 u64 mvsw_pr_rxtx_get_cpu_code_stats(u8 cpu_code)
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
index a105225..c8dc69c 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.h
@@ -11,21 +11,12 @@
 
 #define MVSW_PR_RXTX_CPU_CODE_MAX_NUM	256
 
-struct mvsw_pr_switch;
+struct prestera_switch;
 
-struct mvsw_pr_rxtx_info {
-	u32 port_id;
-	u32 dev_id;
-};
+int prestera_rxtx_switch_init(struct prestera_switch *sw);
+void prestera_rxtx_switch_fini(struct prestera_switch *sw);
 
-int mvsw_pr_rxtx_init(void);
-void mvsw_pr_rxtx_fini(void);
-
-int mvsw_pr_rxtx_switch_init(struct mvsw_pr_switch *sw);
-void mvsw_pr_rxtx_switch_fini(struct mvsw_pr_switch *sw);
-
-netdev_tx_t mvsw_pr_rxtx_xmit(struct sk_buff *skb,
-			      struct mvsw_pr_rxtx_info *info);
+netdev_tx_t prestera_rxtx_xmit(struct sk_buff *skb, struct prestera_port *port);
 
 u64 mvsw_pr_rxtx_get_cpu_code_stats(u8 cpu_code);
 
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_priv.h b/drivers/net/ethernet/marvell/prestera/prestera_rxtx_priv.h
deleted file mode 100644
index 13527b9..0000000
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_priv.h
+++ /dev/null
@@ -1,61 +0,0 @@
-/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
- *
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
-#include <linux/kernel.h>
-#include <linux/netdevice.h>
-#include <linux/rtnetlink.h>
-#include <linux/platform_device.h>
-#include <linux/of.h>
-#include <linux/of_device.h>
-
-#include "prestera_rxtx.h"
-
-struct mvsw_pr_rxtx;
-
-struct mvsw_pr_rxtx_ops {
-	int (*rxtx_init)(struct mvsw_pr_rxtx *rxtx);
-	int (*rxtx_fini)(struct mvsw_pr_rxtx *rxtx);
-
-	int (*rxtx_switch_init)(struct mvsw_pr_rxtx *rxtx,
-				struct mvsw_pr_switch *sw);
-	void (*rxtx_switch_fini)(struct mvsw_pr_rxtx *rxtx,
-				 struct mvsw_pr_switch *sw);
-
-	netdev_tx_t (*rxtx_xmit)(struct mvsw_pr_rxtx *rxtx,
-				 struct sk_buff *skb);
-};
-
-struct mvsw_pr_rxtx {
-	struct platform_device *pdev;
-	struct device *dev;
-
-	const struct mvsw_pr_rxtx_ops *ops;
-	void *priv;
-};
-
-int mvsw_pr_rxtx_recv_skb(struct mvsw_pr_rxtx *rxtx, struct sk_buff *skb);
-
-int mvsw_pr_rxtx_eth_init(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_eth_fini(struct mvsw_pr_rxtx *rxtx);
-netdev_tx_t mvsw_pr_rxtx_eth_xmit(struct mvsw_pr_rxtx *rxtx,
-				  struct sk_buff *skb);
-
-int mvsw_pr_rxtx_mvpp_init(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_mvpp_fini(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_eth_switch_init(struct mvsw_pr_rxtx *rxtx,
-				 struct mvsw_pr_switch *sw);
-void mvsw_pr_rxtx_eth_switch_fini(struct mvsw_pr_rxtx *rxtx,
-				  struct mvsw_pr_switch *sw);
-netdev_tx_t mvsw_pr_rxtx_mvpp_xmit(struct mvsw_pr_rxtx *rxtx,
-				   struct sk_buff *skb);
-
-int mvsw_pr_rxtx_sdma_init(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_sdma_fini(struct mvsw_pr_rxtx *rxtx);
-int mvsw_pr_rxtx_sdma_switch_init(struct mvsw_pr_rxtx *rxtx,
-				  struct mvsw_pr_switch *sw);
-void mvsw_pr_rxtx_sdma_switch_fini(struct mvsw_pr_rxtx *rxtx,
-				   struct mvsw_pr_switch *sw);
-netdev_tx_t mvsw_pr_rxtx_sdma_xmit(struct mvsw_pr_rxtx *rxtx,
-				   struct sk_buff *skb);
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_sdma.c b/drivers/net/ethernet/marvell/prestera/prestera_rxtx_sdma.c
deleted file mode 100644
index 9a65f3c..0000000
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx_sdma.c
+++ /dev/null
@@ -1,769 +0,0 @@
-// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
-/*
- * Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved.
- *
- */
-
-#include <linux/platform_device.h>
-#include <linux/of.h>
-#include <linux/of_address.h>
-#include <linux/of_device.h>
-#include <linux/dmapool.h>
-
-#include "prestera.h"
-#include "prestera_hw.h"
-#include "prestera_rxtx_priv.h"
-
-struct mvsw_sdma_desc {
-	__le32 word1;
-	__le32 word2;
-	__le32 buff;
-	__le32 next;
-} __packed __aligned(16);
-
-#define SDMA_BUFF_SIZE_MAX	1544
-
-#define SDMA_RX_DESC_PKT_LEN(desc) \
-	((le32_to_cpu((desc)->word2) >> 16) & 0x3FFF)
-
-#define SDMA_RX_DESC_OWNER(desc) \
-	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
-
-#define SDMA_RX_DESC_CPU_OWN	0
-#define SDMA_RX_DESC_DMA_OWN	1
-
-#define SDMA_RX_QUEUE_NUM	8
-
-#define SDMA_RX_DESC_PER_Q	1000
-
-#define SDMA_TX_DESC_PER_Q	1000
-#define SDMA_TX_MAX_BURST	32
-
-#define SDMA_TX_DESC_OWNER(desc) \
-	((le32_to_cpu((desc)->word1) & BIT(31)) >> 31)
-
-#define SDMA_TX_DESC_CPU_OWN	0
-#define SDMA_TX_DESC_DMA_OWN	1
-
-#define SDMA_TX_DESC_IS_SENT(desc) \
-	(SDMA_TX_DESC_OWNER(desc) == SDMA_TX_DESC_CPU_OWN)
-
-#define SDMA_TX_DESC_LAST	BIT(20)
-#define SDMA_TX_DESC_FIRST	BIT(21)
-#define SDMA_TX_DESC_SINGLE	(SDMA_TX_DESC_FIRST | SDMA_TX_DESC_LAST)
-#define SDMA_TX_DESC_CALC_CRC	BIT(12)
-
-#define mvsw_reg_write(sw, reg, val) \
-	writel(val, (sw)->dev->pp_regs + (reg))
-#define mvsw_reg_read(sw, reg) \
-	readl((sw)->dev->pp_regs + (reg))
-
-#define SDMA_RX_INTR_MASK_REG		0x2814
-#define SDMA_RX_QUEUE_STATUS_REG	0x2680
-#define SDMA_RX_QUEUE_DESC_REG(n)	(0x260C + (n) * 16)
-
-#define SDMA_TX_QUEUE_DESC_REG		0x26C0
-#define SDMA_TX_QUEUE_START_REG		0x2868
-
-struct mvsw_sdma_buf {
-	struct mvsw_sdma_desc *desc;
-	dma_addr_t desc_dma;
-	struct sk_buff *skb;
-	dma_addr_t buf_dma;
-	bool is_used;
-};
-
-struct mvsw_sdma_rx_ring {
-	struct mvsw_sdma_buf *bufs;
-	int next_rx;
-	int weight;
-	int recvd;
-};
-
-struct mvsw_sdma_tx_ring {
-	struct mvsw_sdma_buf *bufs;
-	int next_tx;
-	int max_burst;
-	int burst;
-};
-
-struct mvsw_pr_rxtx_sdma {
-	struct mvsw_sdma_rx_ring rx_ring[SDMA_RX_QUEUE_NUM];
-	struct mvsw_sdma_tx_ring tx_ring;
-	const struct mvsw_pr_switch *sw;
-	struct dma_pool *desc_pool;
-	struct mvsw_pr_rxtx *rxtx;
-	struct work_struct tx_work;
-	struct napi_struct rx_napi;
-	int next_rxq;
-	struct net_device napi_dev;
-	/* protect SDMA with concurrrent access from multiple CPUs */
-	spinlock_t tx_lock;
-	u32 map_addr;
-	u64 dma_mask;
-};
-
-static int prestera_rx_weight_map[SDMA_RX_QUEUE_NUM] = {
-	1, 2, 2, 2, 2, 4, 4, 8
-};
-
-static int mvsw_sdma_buf_desc_alloc(struct mvsw_pr_rxtx_sdma *sdma,
-				    struct mvsw_sdma_buf *buf)
-{
-	struct device *dma_dev = sdma->sw->dev->dev;
-	struct mvsw_sdma_desc *desc;
-	dma_addr_t dma;
-
-	desc = dma_pool_alloc(sdma->desc_pool, GFP_DMA | GFP_KERNEL, &dma);
-	if (!desc)
-		return -ENOMEM;
-
-	if (dma + sizeof(struct mvsw_sdma_desc) > sdma->dma_mask) {
-		dev_err(dma_dev, "failed to alloc desc\n");
-		dma_pool_free(sdma->desc_pool, desc, dma);
-		return -ENOMEM;
-	}
-
-	buf->desc_dma = dma;
-	buf->desc = desc;
-
-	return 0;
-}
-
-static u32 mvsw_sdma_addr_phy(struct mvsw_pr_rxtx_sdma *sdma, dma_addr_t pa)
-{
-	return sdma->map_addr + pa;
-}
-
-static void mvsw_sdma_rx_desc_set_len(struct mvsw_sdma_desc *desc, size_t val)
-{
-	u32 word = le32_to_cpu(desc->word2);
-
-	word = (word & ~GENMASK(15, 0)) | val;
-	desc->word2 = cpu_to_le32(word);
-}
-
-static void mvsw_sdma_rx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
-				   struct mvsw_sdma_desc *desc,
-				   dma_addr_t buf)
-{
-	mvsw_sdma_rx_desc_set_len(desc, SDMA_BUFF_SIZE_MAX);
-	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
-	/* make sure buffer is set before reset the descriptor */
-	wmb();
-	desc->word1 = cpu_to_le32(0xA0000000);
-}
-
-static void mvsw_sdma_rx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
-				       struct mvsw_sdma_desc *desc,
-				       dma_addr_t next)
-{
-	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
-}
-
-static int mvsw_sdma_rx_dma_alloc(struct mvsw_pr_rxtx_sdma *sdma,
-				  struct mvsw_sdma_buf *buf)
-{
-	struct device *dev = sdma->sw->dev->dev;
-
-	buf->skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_DMA | GFP_ATOMIC);
-	if (!buf->skb)
-		return -ENOMEM;
-
-	buf->buf_dma = dma_map_single(dev, buf->skb->data, buf->skb->len,
-				      DMA_FROM_DEVICE);
-
-	if (dma_mapping_error(dev, buf->buf_dma))
-		goto err_dma_map;
-	if (buf->buf_dma + buf->skb->len > sdma->dma_mask)
-		goto err_dma_range;
-
-	return 0;
-
-err_dma_range:
-	dma_unmap_single(dev, buf->buf_dma, buf->skb->len, DMA_FROM_DEVICE);
-	buf->buf_dma = DMA_MAPPING_ERROR;
-err_dma_map:
-	kfree_skb(buf->skb);
-	buf->skb = NULL;
-
-	return -ENOMEM;
-}
-
-static struct sk_buff *mvsw_sdma_rx_buf_get(struct mvsw_pr_rxtx_sdma *sdma,
-					    struct mvsw_sdma_buf *buf)
-{
-	struct sk_buff *skb_orig = buf->skb;
-	dma_addr_t buf_dma = buf->buf_dma;
-	u32 len = skb_orig->len;
-	int err;
-
-	err = mvsw_sdma_rx_dma_alloc(sdma, buf);
-	if (err) {
-		struct sk_buff *skb;
-
-		buf->buf_dma = buf_dma;
-		buf->skb = skb_orig;
-
-		skb = alloc_skb(SDMA_BUFF_SIZE_MAX, GFP_ATOMIC);
-		if (!skb)
-			return NULL;
-
-		skb_copy_from_linear_data(buf->skb, skb_put(skb, len), len);
-		return skb;
-	}
-
-	return skb_orig;
-}
-
-static void mvsw_sdma_rx_set_next_queue(struct mvsw_pr_rxtx_sdma *sdma, int rxq)
-{
-	sdma->next_rxq = rxq % SDMA_RX_QUEUE_NUM;
-}
-
-static int mvsw_sdma_rx_pick_next_queue(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[sdma->next_rxq];
-
-	if (ring->recvd >= ring->weight) {
-		mvsw_sdma_rx_set_next_queue(sdma, sdma->next_rxq + 1);
-		ring->recvd = 0;
-	}
-
-	return sdma->next_rxq;
-}
-
-static int mvsw_sdma_rx_poll(struct napi_struct *napi, int budget)
-{
-	unsigned int qmask = GENMASK(SDMA_RX_QUEUE_NUM - 1, 0);
-	struct mvsw_pr_rxtx_sdma *sdma;
-	unsigned int rxq_done_map = 0;
-	struct list_head rx_list;
-	int pkts_done = 0;
-
-	INIT_LIST_HEAD(&rx_list);
-
-	sdma = container_of(napi, struct mvsw_pr_rxtx_sdma, rx_napi);
-
-	while (pkts_done < budget && rxq_done_map != qmask) {
-		struct mvsw_sdma_rx_ring *ring;
-		struct mvsw_sdma_desc *desc;
-		struct mvsw_sdma_buf *buf;
-		struct sk_buff *skb;
-		int buf_idx;
-		int rxq;
-
-		rxq = mvsw_sdma_rx_pick_next_queue(sdma);
-		ring = &sdma->rx_ring[rxq];
-
-		buf_idx = ring->next_rx;
-		buf = &ring->bufs[buf_idx];
-		desc = buf->desc;
-
-		if (SDMA_RX_DESC_OWNER(desc) != SDMA_RX_DESC_CPU_OWN) {
-			mvsw_sdma_rx_set_next_queue(sdma, rxq + 1);
-			rxq_done_map |= BIT(rxq);
-			continue;
-		} else {
-			rxq_done_map &= ~BIT(rxq);
-		}
-
-		ring->recvd++;
-		pkts_done++;
-
-		__skb_trim(buf->skb, SDMA_RX_DESC_PKT_LEN(desc));
-
-		skb = mvsw_sdma_rx_buf_get(sdma, buf);
-		if (!skb)
-			goto rx_reset_buf;
-
-		if (unlikely(mvsw_pr_rxtx_recv_skb(sdma->rxtx, skb)))
-			goto rx_reset_buf;
-
-		list_add_tail(&skb->list, &rx_list);
-rx_reset_buf:
-		mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
-		ring->next_rx = (buf_idx + 1) % SDMA_RX_DESC_PER_Q;
-	}
-
-	if (pkts_done < budget && napi_complete_done(napi, pkts_done))
-		mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0xff << 2);
-
-	netif_receive_skb_list(&rx_list);
-
-	return pkts_done;
-}
-
-static void mvsw_sdma_rx_fini(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	int q, b;
-
-	/* disable all rx queues */
-	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
-
-	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
-		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
-
-		if (!ring->bufs)
-			break;
-
-		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
-			struct mvsw_sdma_buf *buf = &ring->bufs[b];
-
-			if (buf->desc_dma)
-				dma_pool_free(sdma->desc_pool, buf->desc,
-					      buf->desc_dma);
-
-			if (!buf->skb)
-				continue;
-
-			if (buf->buf_dma != DMA_MAPPING_ERROR)
-				dma_unmap_single(sdma->sw->dev->dev,
-						 buf->buf_dma, buf->skb->len,
-						 DMA_FROM_DEVICE);
-			kfree_skb(buf->skb);
-		}
-	}
-}
-
-static int mvsw_sdma_rx_init(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	int q, b;
-	int err;
-
-	/* disable all rx queues */
-	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff00);
-
-	for (q = 0; q < SDMA_RX_QUEUE_NUM; q++) {
-		struct mvsw_sdma_rx_ring *ring = &sdma->rx_ring[q];
-		struct mvsw_sdma_buf *head;
-
-		ring->bufs = kmalloc_array(SDMA_RX_DESC_PER_Q, sizeof(*head),
-					   GFP_KERNEL);
-		if (!ring->bufs)
-			return -ENOMEM;
-
-		ring->weight = prestera_rx_weight_map[q];
-		ring->recvd = 0;
-		ring->next_rx = 0;
-
-		head = &ring->bufs[0];
-
-		for (b = 0; b < SDMA_RX_DESC_PER_Q; b++) {
-			struct mvsw_sdma_buf *buf = &ring->bufs[b];
-
-			err = mvsw_sdma_buf_desc_alloc(sdma, buf);
-			if (err)
-				return err;
-
-			err = mvsw_sdma_rx_dma_alloc(sdma, buf);
-			if (err)
-				return err;
-
-			mvsw_sdma_rx_desc_init(sdma, buf->desc, buf->buf_dma);
-
-			if (b == 0)
-				continue;
-
-			mvsw_sdma_rx_desc_set_next(sdma, ring->bufs[b - 1].desc,
-						   buf->desc_dma);
-
-			if (b == SDMA_RX_DESC_PER_Q - 1)
-				mvsw_sdma_rx_desc_set_next(sdma, buf->desc,
-							   head->desc_dma);
-		}
-
-		mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_DESC_REG(q),
-			       mvsw_sdma_addr_phy(sdma, head->desc_dma));
-	}
-
-	/* make sure all rx descs are filled before enabling all rx queues */
-	wmb();
-	mvsw_reg_write(sdma->sw, SDMA_RX_QUEUE_STATUS_REG, 0xff);
-
-	return 0;
-}
-
-static void mvsw_sdma_tx_desc_init(struct mvsw_pr_rxtx_sdma *sdma,
-				   struct mvsw_sdma_desc *desc)
-{
-	desc->word1 = cpu_to_le32(SDMA_TX_DESC_SINGLE | SDMA_TX_DESC_CALC_CRC);
-	desc->word2 = 0;
-}
-
-static void mvsw_sdma_tx_desc_set_next(struct mvsw_pr_rxtx_sdma *sdma,
-				       struct mvsw_sdma_desc *desc,
-				       dma_addr_t next)
-{
-	desc->next = cpu_to_le32(mvsw_sdma_addr_phy(sdma, next));
-}
-
-static void mvsw_sdma_tx_desc_set_buf(struct mvsw_pr_rxtx_sdma *sdma,
-				      struct mvsw_sdma_desc *desc,
-				      dma_addr_t buf, size_t len)
-{
-	u32 word = le32_to_cpu(desc->word2);
-
-	word = (word & ~GENMASK(30, 16)) | ((len + 4) << 16);
-
-	desc->buff = cpu_to_le32(mvsw_sdma_addr_phy(sdma, buf));
-	desc->word2 = cpu_to_le32(word);
-}
-
-static void mvsw_sdma_tx_desc_xmit(struct mvsw_sdma_desc *desc)
-{
-	u32 word = le32_to_cpu(desc->word1);
-
-	word |= (SDMA_TX_DESC_DMA_OWN << 31);
-
-	/* make sure everything is written before enable xmit */
-	wmb();
-	desc->word1 = cpu_to_le32(word);
-}
-
-static int mvsw_sdma_tx_buf_map(struct mvsw_pr_rxtx_sdma *sdma,
-				struct mvsw_sdma_buf *buf,
-				struct sk_buff *skb)
-{
-	struct device *dma_dev = sdma->sw->dev->dev;
-	struct sk_buff *new_skb;
-	size_t len = skb->len;
-	dma_addr_t dma;
-
-	dma = dma_map_single(dma_dev, skb->data, len, DMA_TO_DEVICE);
-	if (!dma_mapping_error(dma_dev, dma) && dma + len <= sdma->dma_mask) {
-		buf->buf_dma = dma;
-		buf->skb = skb;
-		return 0;
-	}
-
-	if (!dma_mapping_error(dma_dev, dma))
-		dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
-
-	new_skb = alloc_skb(len, GFP_ATOMIC | GFP_DMA);
-	if (!new_skb)
-		goto err_alloc_skb;
-
-	dma = dma_map_single(dma_dev, new_skb->data, len, DMA_TO_DEVICE);
-	if (dma_mapping_error(dma_dev, dma))
-		goto err_dma_map;
-	if (dma + len > sdma->dma_mask)
-		goto err_dma_range;
-
-	skb_copy_from_linear_data(skb, skb_put(new_skb, len), len);
-
-	dev_consume_skb_any(skb);
-
-	buf->skb = new_skb;
-	buf->buf_dma = dma;
-
-	return 0;
-
-err_dma_range:
-	dma_unmap_single(dma_dev, dma, len, DMA_TO_DEVICE);
-err_dma_map:
-	dev_kfree_skb(new_skb);
-err_alloc_skb:
-	dev_kfree_skb(skb);
-
-	return -ENOMEM;
-}
-
-static void mvsw_sdma_tx_buf_unmap(struct mvsw_pr_rxtx_sdma *sdma,
-				   struct mvsw_sdma_buf *buf)
-{
-	struct device *dma_dev = sdma->sw->dev->dev;
-
-	dma_unmap_single(dma_dev, buf->buf_dma, buf->skb->len, DMA_TO_DEVICE);
-}
-
-static void mvsw_sdma_tx_recycle_work_fn(struct work_struct *work)
-{
-	struct mvsw_sdma_tx_ring *tx_ring;
-	struct mvsw_pr_rxtx_sdma *sdma;
-	struct device *dma_dev;
-	int b;
-
-	sdma = container_of(work, struct mvsw_pr_rxtx_sdma, tx_work);
-
-	dma_dev = sdma->sw->dev->dev;
-	tx_ring = &sdma->tx_ring;
-
-	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
-		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
-
-		if (!buf->is_used)
-			continue;
-
-		if (!SDMA_TX_DESC_IS_SENT(buf->desc))
-			continue;
-
-		mvsw_sdma_tx_buf_unmap(sdma, buf);
-		dev_consume_skb_any(buf->skb);
-		buf->skb = NULL;
-
-		/* make sure everything is cleaned up */
-		wmb();
-
-		buf->is_used = false;
-	}
-}
-
-static int mvsw_sdma_tx_init(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	struct mvsw_sdma_tx_ring *tx_ring = &sdma->tx_ring;
-	struct mvsw_sdma_buf *head;
-	int err;
-	int b;
-
-	spin_lock_init(&sdma->tx_lock);
-
-	INIT_WORK(&sdma->tx_work, mvsw_sdma_tx_recycle_work_fn);
-
-	tx_ring->bufs = kmalloc_array(SDMA_TX_DESC_PER_Q, sizeof(*head),
-				      GFP_KERNEL);
-	if (!tx_ring->bufs)
-		return -ENOMEM;
-
-	head = &tx_ring->bufs[0];
-
-	tx_ring->max_burst = SDMA_TX_MAX_BURST;
-	tx_ring->burst = tx_ring->max_burst;
-	tx_ring->next_tx = 0;
-
-	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
-		struct mvsw_sdma_buf *buf = &tx_ring->bufs[b];
-
-		err = mvsw_sdma_buf_desc_alloc(sdma, buf);
-		if (err)
-			return err;
-
-		mvsw_sdma_tx_desc_init(sdma, buf->desc);
-
-		buf->is_used = false;
-		buf->skb = NULL;
-
-		if (b == 0)
-			continue;
-
-		mvsw_sdma_tx_desc_set_next(sdma, tx_ring->bufs[b - 1].desc,
-					   buf->desc_dma);
-
-		if (b == SDMA_TX_DESC_PER_Q - 1)
-			mvsw_sdma_tx_desc_set_next(sdma, buf->desc,
-						   head->desc_dma);
-	}
-
-	/* make sure descriptors are written */
-	wmb();
-	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_DESC_REG,
-		       mvsw_sdma_addr_phy(sdma, head->desc_dma));
-
-	return 0;
-}
-
-static void mvsw_sdma_tx_fini(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	struct mvsw_sdma_tx_ring *ring = &sdma->tx_ring;
-	int b;
-
-	cancel_work_sync(&sdma->tx_work);
-
-	if (!ring->bufs)
-		return;
-
-	for (b = 0; b < SDMA_TX_DESC_PER_Q; b++) {
-		struct mvsw_sdma_buf *buf = &ring->bufs[b];
-
-		if (buf->desc)
-			dma_pool_free(sdma->desc_pool, buf->desc,
-				      buf->desc_dma);
-
-		if (!buf->skb)
-			continue;
-
-		dma_unmap_single(sdma->sw->dev->dev, buf->buf_dma,
-				 buf->skb->len, DMA_TO_DEVICE);
-
-		dev_consume_skb_any(buf->skb);
-	}
-}
-
-int mvsw_pr_rxtx_sdma_init(struct mvsw_pr_rxtx *rxtx)
-{
-	struct mvsw_pr_rxtx_sdma *sdma;
-
-	sdma = kzalloc(sizeof(*sdma), GFP_KERNEL);
-	if (!sdma)
-		return -ENOMEM;
-
-	rxtx->priv = sdma;
-	sdma->rxtx = rxtx;
-
-	return 0;
-}
-
-int mvsw_pr_rxtx_sdma_fini(struct mvsw_pr_rxtx *rxtx)
-{
-	kfree(rxtx->priv);
-	return 0;
-}
-
-static void mvsw_rxtx_handle_event(struct mvsw_pr_switch *sw,
-				   struct mvsw_pr_event *evt, void *arg)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = arg;
-
-	if (evt->id != MVSW_RXTX_EVENT_RCV_PKT)
-		return;
-
-	mvsw_reg_write(sdma->sw, SDMA_RX_INTR_MASK_REG, 0);
-	napi_schedule(&sdma->rx_napi);
-}
-
-int mvsw_pr_rxtx_sdma_switch_init(struct mvsw_pr_rxtx *rxtx,
-				  struct mvsw_pr_switch *sw)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = rxtx->priv;
-	int err;
-
-	err = mvsw_pr_hw_rxtx_init(sw, true, &sdma->map_addr);
-	if (err) {
-		dev_err(sw->dev->dev, "failed to init rxtx by hw\n");
-		return err;
-	}
-
-	sdma->dma_mask = dma_get_mask(sw->dev->dev);
-	sdma->sw = sw;
-
-	sdma->desc_pool = dma_pool_create("desc_pool", sdma->sw->dev->dev,
-					  sizeof(struct mvsw_sdma_desc), 16, 0);
-	if (!sdma->desc_pool)
-		return -ENOMEM;
-
-	err = mvsw_sdma_rx_init(sdma);
-	if (err) {
-		dev_err(sw->dev->dev, "failed to init rx ring\n");
-		goto err_rx_init;
-	}
-
-	err = mvsw_sdma_tx_init(sdma);
-	if (err) {
-		dev_err(sw->dev->dev, "failed to init tx ring\n");
-		goto err_tx_init;
-	}
-
-	err = mvsw_pr_hw_event_handler_register(sw, MVSW_EVENT_TYPE_RXTX,
-						mvsw_rxtx_handle_event, sdma);
-	if (err)
-		goto err_evt_register;
-
-	init_dummy_netdev(&sdma->napi_dev);
-
-	netif_napi_add(&sdma->napi_dev, &sdma->rx_napi, mvsw_sdma_rx_poll, 64);
-	napi_enable(&sdma->rx_napi);
-
-	return 0;
-
-err_evt_register:
-err_tx_init:
-	mvsw_sdma_tx_fini(sdma);
-err_rx_init:
-	mvsw_sdma_rx_fini(sdma);
-
-	dma_pool_destroy(sdma->desc_pool);
-	return err;
-}
-
-void mvsw_pr_rxtx_sdma_switch_fini(struct mvsw_pr_rxtx *rxtx,
-				   struct mvsw_pr_switch *sw)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = rxtx->priv;
-
-	mvsw_pr_hw_event_handler_unregister(sw, MVSW_EVENT_TYPE_RXTX);
-	napi_disable(&sdma->rx_napi);
-	netif_napi_del(&sdma->rx_napi);
-	mvsw_sdma_rx_fini(sdma);
-	mvsw_sdma_tx_fini(sdma);
-	dma_pool_destroy(sdma->desc_pool);
-}
-
-static int mvsw_sdma_wait_tx(struct mvsw_pr_rxtx_sdma *sdma,
-			     struct mvsw_sdma_tx_ring *tx_ring)
-{
-	int tx_retry_num = 10 * tx_ring->max_burst;
-
-	while (--tx_retry_num) {
-		if (!(mvsw_reg_read(sdma->sw, SDMA_TX_QUEUE_START_REG) & 1))
-			return 0;
-
-		udelay(5);
-	}
-
-	return -EBUSY;
-}
-
-static void mvsw_sdma_start_tx(struct mvsw_pr_rxtx_sdma *sdma)
-{
-	mvsw_reg_write(sdma->sw, SDMA_TX_QUEUE_START_REG, 1);
-	schedule_work(&sdma->tx_work);
-}
-
-netdev_tx_t mvsw_pr_rxtx_sdma_xmit(struct mvsw_pr_rxtx *rxtx,
-				   struct sk_buff *skb)
-{
-	struct mvsw_pr_rxtx_sdma *sdma = rxtx->priv;
-	struct device *dma_dev = sdma->sw->dev->dev;
-	struct mvsw_sdma_tx_ring *tx_ring;
-	struct net_device *dev = skb->dev;
-	struct mvsw_sdma_buf *buf;
-	int err;
-
-	spin_lock(&sdma->tx_lock);
-
-	tx_ring = &sdma->tx_ring;
-
-	buf = &tx_ring->bufs[tx_ring->next_tx];
-	if (buf->is_used) {
-		schedule_work(&sdma->tx_work);
-		goto drop_skb;
-	}
-
-	if (unlikely(skb_put_padto(skb, ETH_ZLEN)))
-		goto drop_skb_nofree;
-
-	err = mvsw_sdma_tx_buf_map(sdma, buf, skb);
-	if (err)
-		goto drop_skb;
-
-	mvsw_sdma_tx_desc_set_buf(sdma, buf->desc, buf->buf_dma, skb->len);
-
-	dma_sync_single_for_device(dma_dev, buf->buf_dma, skb->len,
-				   DMA_TO_DEVICE);
-
-	if (!tx_ring->burst--) {
-		tx_ring->burst = tx_ring->max_burst;
-
-		err = mvsw_sdma_wait_tx(sdma, tx_ring);
-		if (err)
-			goto drop_skb_unmap;
-	}
-
-	tx_ring->next_tx = (tx_ring->next_tx + 1) % SDMA_TX_DESC_PER_Q;
-	mvsw_sdma_tx_desc_xmit(buf->desc);
-	buf->is_used = true;
-
-	mvsw_sdma_start_tx(sdma);
-
-	goto tx_done;
-
-drop_skb_unmap:
-	mvsw_sdma_tx_buf_unmap(sdma, buf);
-drop_skb:
-	dev_consume_skb_any(skb);
-drop_skb_nofree:
-	dev->stats.tx_dropped++;
-tx_done:
-	spin_unlock(&sdma->tx_lock);
-	return NETDEV_TX_OK;
-}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c
new file mode 100644
index 0000000..81a12df
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.c
@@ -0,0 +1,191 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/*
+ * Copyright (c) 2020 Marvell International Ltd. All rights reserved.
+ *
+ */
+#include "prestera_storm_control.h"
+#include "prestera_hw.h"
+
+#define SYSFS_ATTR_MODE		0644
+
+static ssize_t storm_control_attr_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size);
+static ssize_t storm_control_attr_show(struct device *dev,
+				       struct device_attribute *attr,
+				       char *buf);
+
+struct strom_control_attributes {
+	u32 bc_kbyte_per_sec_rate;
+	u32 unknown_uc_kbyte_per_sec_rate;
+	u32 unreg_mc_kbyte_per_sec_rate;
+};
+
+struct prestera_storm_control {
+	struct prestera_switch *sw;
+	struct strom_control_attributes *attribute_values;
+};
+
+static DEVICE_ATTR(broadcast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static DEVICE_ATTR(unknown_unicast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static DEVICE_ATTR(unregistered_multicast_kbyte_per_sec_rate, SYSFS_ATTR_MODE,
+		   storm_control_attr_show, storm_control_attr_store);
+
+static struct attribute *prestera_sw_dev_attrs[] = {
+	&dev_attr_broadcast_kbyte_per_sec_rate.attr,
+	&dev_attr_unknown_unicast_kbyte_per_sec_rate.attr,
+	&dev_attr_unregistered_multicast_kbyte_per_sec_rate.attr,
+	NULL
+};
+
+static struct attribute_group prestera_sw_dev_attr_group = {
+	.name = "storm_control", /* we want them in subdirectory */
+	.attrs = prestera_sw_dev_attrs,
+};
+
+static ssize_t storm_control_attr_store(struct device *dev,
+					struct device_attribute *attr,
+					const char *buf, size_t size)
+{
+	struct prestera_port *port = dev_to_prestera_port(dev);
+	struct strom_control_attributes *sc_attr;
+	struct prestera_storm_control *sc;
+	u32 *attr_to_change = NULL;
+	u32 kbyte_per_sec_rate;
+	ssize_t ret = -EINVAL;
+	u32 storm_type;
+
+	if (!port)
+		return -EINVAL;
+
+	sc = port->sw->storm_control;
+	sc_attr = &sc->attribute_values[port->fp_id];
+
+	ret = kstrtou32(buf, 10, &kbyte_per_sec_rate);
+	if (ret)
+		return ret;
+
+	if (!strcmp(attr->attr.name, "broadcast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->bc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_BC;
+	}
+
+	if (!strcmp(attr->attr.name, "unknown_unicast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->unknown_uc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_UC_UNK;
+	}
+
+	if (!strcmp(attr->attr.name,
+		    "unregistered_multicast_kbyte_per_sec_rate")) {
+		attr_to_change = &sc_attr->unreg_mc_kbyte_per_sec_rate;
+		storm_type = MVSW_PORT_STORM_CTL_TYPE_MC;
+	}
+
+	if (!attr_to_change)
+		return -EINVAL;
+
+	if (kbyte_per_sec_rate != *attr_to_change)
+		ret = mvsw_pr_hw_port_storm_control_cfg_set(port, storm_type,
+							    kbyte_per_sec_rate);
+	else
+		return size;
+
+	if (ret)
+		return ret;
+
+	*attr_to_change = kbyte_per_sec_rate;
+
+	return size;
+}
+
+static ssize_t storm_control_attr_show(struct device *dev,
+				       struct device_attribute *attr,
+				       char *buf)
+{
+	struct prestera_port *port = dev_to_prestera_port(dev);
+	struct strom_control_attributes *sc_attr;
+	struct prestera_storm_control *sc;
+
+	if (!port)
+		return -EINVAL;
+
+	sc = port->sw->storm_control;
+
+	sc_attr = &sc->attribute_values[port->fp_id];
+
+	if (!strcmp(attr->attr.name, "broadcast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n", sc_attr->bc_kbyte_per_sec_rate);
+
+	if (!strcmp(attr->attr.name, "unknown_unicast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n",
+			       sc_attr->unknown_uc_kbyte_per_sec_rate);
+
+	if (!strcmp(attr->attr.name,
+		    "unregistered_multicast_kbyte_per_sec_rate"))
+		return sprintf(buf, "%u\n",
+			       sc_attr->unreg_mc_kbyte_per_sec_rate);
+
+	return -EINVAL;
+}
+
+int prestera_storm_control_init(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc;
+	struct prestera_port *port;
+	int err;
+
+	sc = kzalloc(sizeof(*sc), GFP_KERNEL);
+	if (!sc)
+		return -ENOMEM;
+
+	sc->attribute_values = kcalloc(sw->port_count,
+				       sizeof(*sc->attribute_values),
+				       GFP_KERNEL);
+	if (!sc->attribute_values) {
+		err = -ENOMEM;
+		goto err_values_alloca;
+	}
+
+	list_for_each_entry(port, &sw->port_list, list) {
+		err = sysfs_create_group(&port->net_dev->dev.kobj,
+					 &prestera_sw_dev_attr_group);
+		if (err) {
+			pr_err("Failed to create sysfs group for %s\n",
+			       dev_name(&port->net_dev->dev));
+			goto err_group_create;
+		}
+	}
+
+	sc->sw = sw;
+	sw->storm_control = sc;
+
+	return 0;
+
+err_group_create:
+	list_for_each_entry_continue_reverse(port, &sw->port_list, list) {
+		sysfs_remove_group(&port->net_dev->dev.kobj,
+				   &prestera_sw_dev_attr_group);
+	}
+	kfree(sc->attribute_values);
+err_values_alloca:
+	kfree(sc);
+	return err;
+}
+
+void prestera_storm_control_fini(struct prestera_switch *sw)
+{
+	struct prestera_storm_control *sc = sw->storm_control;
+	struct prestera_port *port;
+
+	list_for_each_entry(port, &sw->port_list, list)
+		sysfs_remove_group(&port->net_dev->dev.kobj,
+				   &prestera_sw_dev_attr_group);
+
+	kfree(sc->attribute_values);
+	kfree(sc);
+}
+
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h
new file mode 100644
index 0000000..cc54150
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_storm_control.h
@@ -0,0 +1,15 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+ *
+ * Copyright (c) 2020 Marvell International Ltd. All rights reserved.
+ *
+ */
+
+#ifndef _MVSW_PRESTERA_STORM_CONTROL_H_
+#define _MVSW_PRESTERA_STORM_CONTROL_H_
+
+#include "prestera.h"
+
+int prestera_storm_control_init(struct prestera_switch *sw);
+void prestera_storm_control_fini(struct prestera_switch *sw);
+
+#endif /* _MVSW_PRESTERA_STORM_CONTROL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
index 969daeb..d1e07e7 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_switchdev.c
@@ -17,7 +17,7 @@
 #define MVSW_PR_VID_ALL (0xffff)
 
 struct mvsw_pr_bridge {
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	u32 ageing_time;
 	struct list_head bridge_list;
 	bool bridge_8021q_exists;
@@ -78,7 +78,7 @@ mvsw_pr_bridge_device_find(const struct mvsw_pr_bridge *bridge,
 }
 
 static bool
-mvsw_pr_bridge_device_is_offloaded(const struct mvsw_pr_switch *sw,
+mvsw_pr_bridge_device_is_offloaded(const struct prestera_switch *sw,
 				   const struct net_device *br_dev)
 {
 	return !!mvsw_pr_bridge_device_find(sw->bridge, br_dev);
@@ -186,7 +186,7 @@ mvsw_pr_port_vlan_bridge_join(struct mvsw_pr_port_vlan *port_vlan,
 			      struct mvsw_pr_bridge_port *br_port,
 			      struct netlink_ext_ack *extack)
 {
-	struct mvsw_pr_port *port = port_vlan->mvsw_pr_port;
+	struct prestera_port *port = port_vlan->mvsw_pr_port;
 	struct mvsw_pr_bridge_vlan *br_vlan;
 	u16 vid = port_vlan->vid;
 	int err;
@@ -194,19 +194,19 @@ mvsw_pr_port_vlan_bridge_join(struct mvsw_pr_port_vlan *port_vlan,
 	if (port_vlan->bridge_port)
 		return 0;
 
-	err = mvsw_pr_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
+	err = prestera_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
 	if (err)
 		return err;
 
-	err = mvsw_pr_port_mc_flood_set(port, br_port->flags & BR_MCAST_FLOOD);
+	err = prestera_port_mc_flood_set(port, br_port->flags & BR_MCAST_FLOOD);
 	if (err)
 		return err;
 
-	err = mvsw_pr_port_learning_set(port, br_port->flags & BR_LEARNING);
+	err = prestera_port_learning_set(port, br_port->flags & BR_LEARNING);
 	if (err)
 		goto err_port_learning_set;
 
-	err = mvsw_pr_port_vid_stp_set(port, vid, br_port->stp_state);
+	err = prestera_port_vid_stp_set(port, vid, br_port->stp_state);
 	if (err)
 		goto err_port_vid_stp_set;
 
@@ -224,9 +224,9 @@ mvsw_pr_port_vlan_bridge_join(struct mvsw_pr_port_vlan *port_vlan,
 	return 0;
 
 err_bridge_vlan_get:
-	mvsw_pr_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
+	prestera_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
 err_port_vid_stp_set:
-	mvsw_pr_port_learning_set(port, false);
+	prestera_port_learning_set(port, false);
 err_port_learning_set:
 	return err;
 }
@@ -256,7 +256,7 @@ mvsw_pr_bridge_vlan_port_count_get(struct mvsw_pr_bridge_device *bridge_device,
 void
 mvsw_pr_port_vlan_bridge_leave(struct mvsw_pr_port_vlan *port_vlan)
 {
-	struct mvsw_pr_port *port = port_vlan->mvsw_pr_port;
+	struct prestera_port *port = port_vlan->mvsw_pr_port;
 	u32 mode = MVSW_PR_FDB_FLUSH_MODE_DYNAMIC;
 	struct mvsw_pr_bridge_vlan *br_vlan;
 	struct mvsw_pr_bridge_port *br_port;
@@ -271,21 +271,21 @@ mvsw_pr_port_vlan_bridge_leave(struct mvsw_pr_port_vlan *port_vlan)
 	br_vlan = mvsw_pr_bridge_vlan_find(br_port, vid);
 	last_port = port_count == 1;
 	if (last_vlan)
-		mvsw_pr_fdb_flush_port(port, mode);
+		prestera_fdb_flush_port(port, mode);
 	else if (last_port)
-		mvsw_pr_fdb_flush_vlan(port->sw, vid, mode);
+		prestera_fdb_flush_vlan(port->sw, vid, mode);
 	else
-		mvsw_pr_fdb_flush_port_vlan(port, vid, mode);
+		prestera_fdb_flush_port_vlan(port, vid, mode);
 
 	list_del(&port_vlan->bridge_vlan_node);
 	mvsw_pr_bridge_vlan_put(br_vlan);
-	mvsw_pr_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
+	prestera_port_vid_stp_set(port, vid, BR_STATE_FORWARDING);
 	mvsw_pr_bridge_port_put(port->sw->bridge, br_port);
 	port_vlan->bridge_port = NULL;
 }
 
 static int
-mvsw_pr_bridge_port_vlan_add(struct mvsw_pr_port *port,
+mvsw_pr_bridge_port_vlan_add(struct prestera_port *port,
 			     struct mvsw_pr_bridge_port *br_port,
 			     u16 vid, bool is_untagged, bool is_pvid,
 			     struct netlink_ext_ack *extack)
@@ -300,21 +300,21 @@ mvsw_pr_bridge_port_vlan_add(struct mvsw_pr_port *port,
 	else
 		pvid = port->pvid == vid ? 0 : port->pvid;
 
-	port_vlan = mvsw_pr_port_vlan_find_by_vid(port, vid);
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (port_vlan && port_vlan->bridge_port != br_port)
 		return -EEXIST;
 
 	if (!port_vlan) {
-		port_vlan = mvsw_pr_port_vlan_create(port, vid, is_untagged);
+		port_vlan = prestera_port_vlan_create(port, vid, is_untagged);
 		if (IS_ERR(port_vlan))
 			return PTR_ERR(port_vlan);
 	} else {
-		err = mvsw_pr_port_vlan_set(port, vid, true, is_untagged);
+		err = prestera_port_vlan_set(port, vid, true, is_untagged);
 		if (err)
 			goto err_port_vlan_set;
 	}
 
-	err = mvsw_pr_port_pvid_set(port, pvid);
+	err = prestera_port_pvid_set(port, pvid);
 	if (err)
 		goto err_port_pvid_set;
 
@@ -325,16 +325,16 @@ mvsw_pr_bridge_port_vlan_add(struct mvsw_pr_port *port,
 	return 0;
 
 err_port_vlan_bridge_join:
-	mvsw_pr_port_pvid_set(port, old_pvid);
+	prestera_port_pvid_set(port, old_pvid);
 err_port_pvid_set:
-	mvsw_pr_port_vlan_set(port, vid, false, false);
+	prestera_port_vlan_set(port, vid, false, false);
 err_port_vlan_set:
-	mvsw_pr_port_vlan_destroy(port_vlan);
+	prestera_port_vlan_destroy(port_vlan);
 
 	return err;
 }
 
-static int mvsw_pr_port_vlans_add(struct mvsw_pr_port *port,
+static int mvsw_pr_port_vlans_add(struct prestera_port *port,
 				  const struct switchdev_obj_port_vlan *vlan,
 				  struct switchdev_trans *trans,
 				  struct netlink_ext_ack *extack)
@@ -344,7 +344,7 @@ static int mvsw_pr_port_vlans_add(struct mvsw_pr_port *port,
 	struct net_device *orig_dev = vlan->obj.orig_dev;
 	struct mvsw_pr_bridge_port *br_port;
 	struct mvsw_pr_bridge_device *bridge_device;
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	u16 vid;
 
 	if (netif_is_bridge_master(orig_dev))
@@ -383,7 +383,7 @@ static int mvsw_pr_port_obj_add(struct net_device *dev,
 				struct netlink_ext_ack *extack)
 {
 	int err = 0;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	const struct switchdev_obj_port_vlan *vlan;
 
 	switch (obj->id) {
@@ -399,25 +399,25 @@ static int mvsw_pr_port_obj_add(struct net_device *dev,
 }
 
 static void
-mvsw_pr_bridge_port_vlan_del(struct mvsw_pr_port *port,
+mvsw_pr_bridge_port_vlan_del(struct prestera_port *port,
 			     struct mvsw_pr_bridge_port *br_port, u16 vid)
 {
 	u16 pvid = port->pvid == vid ? 0 : port->pvid;
 	struct mvsw_pr_port_vlan *port_vlan;
 
-	port_vlan = mvsw_pr_port_vlan_find_by_vid(port, vid);
+	port_vlan = prestera_port_vlan_find_by_vid(port, vid);
 	if (WARN_ON(!port_vlan))
 		return;
 
 	mvsw_pr_port_vlan_bridge_leave(port_vlan);
-	mvsw_pr_port_pvid_set(port, pvid);
-	mvsw_pr_port_vlan_destroy(port_vlan);
+	prestera_port_pvid_set(port, pvid);
+	prestera_port_vlan_destroy(port_vlan);
 }
 
-static int mvsw_pr_port_vlans_del(struct mvsw_pr_port *port,
+static int mvsw_pr_port_vlans_del(struct prestera_port *port,
 				  const struct switchdev_obj_port_vlan *vlan)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct net_device *orig_dev = vlan->obj.orig_dev;
 	struct mvsw_pr_bridge_port *br_port;
 	u16 vid;
@@ -442,7 +442,7 @@ static int mvsw_pr_port_obj_del(struct net_device *dev,
 				const struct switchdev_obj *obj)
 {
 	int err = 0;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	switch (obj->id) {
 	case SWITCHDEV_OBJ_ID_PORT_VLAN:
@@ -457,12 +457,12 @@ static int mvsw_pr_port_obj_del(struct net_device *dev,
 	return err;
 }
 
-static int mvsw_pr_port_attr_br_vlan_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_vlan_set(struct prestera_port *port,
 					 struct switchdev_trans *trans,
 					 struct net_device *orig_dev,
 					 bool vlan_enabled)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct mvsw_pr_bridge_device *bridge_device;
 
 	if (!switchdev_trans_ph_prepare(trans))
@@ -480,7 +480,7 @@ static int mvsw_pr_port_attr_br_vlan_set(struct mvsw_pr_port *port,
 	return -EINVAL;
 }
 
-static int mvsw_pr_port_attr_br_flags_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_flags_set(struct prestera_port *port,
 					  struct switchdev_trans *trans,
 					  struct net_device *orig_dev,
 					  unsigned long flags)
@@ -495,15 +495,15 @@ static int mvsw_pr_port_attr_br_flags_set(struct mvsw_pr_port *port,
 	if (!br_port)
 		return 0;
 
-	err = mvsw_pr_port_uc_flood_set(port, flags & BR_FLOOD);
+	err = prestera_port_uc_flood_set(port, flags & BR_FLOOD);
 	if (err)
 		return err;
 
-	err = mvsw_pr_port_mc_flood_set(port, flags & BR_MCAST_FLOOD);
+	err = prestera_port_mc_flood_set(port, flags & BR_MCAST_FLOOD);
 	if (err)
 		return err;
 
-	err = mvsw_pr_port_learning_set(port, flags & BR_LEARNING);
+	err = prestera_port_learning_set(port, flags & BR_LEARNING);
 	if (err)
 		return err;
 
@@ -511,12 +511,12 @@ static int mvsw_pr_port_attr_br_flags_set(struct mvsw_pr_port *port,
 	return 0;
 }
 
-static int mvsw_pr_port_attr_br_ageing_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_ageing_set(struct prestera_port *port,
 					   struct switchdev_trans *trans,
 					   unsigned long ageing_clock_t)
 {
 	int err;
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	unsigned long ageing_jiffies = clock_t_to_jiffies(ageing_clock_t);
 	u32 ageing_time = jiffies_to_msecs(ageing_jiffies);
 
@@ -528,7 +528,7 @@ static int mvsw_pr_port_attr_br_ageing_set(struct mvsw_pr_port *port,
 			return 0;
 	}
 
-	err = mvsw_pr_switch_ageing_set(sw, ageing_time);
+	err = prestera_switch_ageing_set(sw, ageing_time);
 	if (!err)
 		sw->bridge->ageing_time = ageing_time;
 
@@ -536,7 +536,7 @@ static int mvsw_pr_port_attr_br_ageing_set(struct mvsw_pr_port *port,
 }
 
 static int
-mvsw_pr_port_bridge_vlan_stp_set(struct mvsw_pr_port *port,
+mvsw_pr_port_bridge_vlan_stp_set(struct prestera_port *port,
 				 struct mvsw_pr_bridge_vlan *br_vlan,
 				 u8 state)
 {
@@ -546,13 +546,13 @@ mvsw_pr_port_bridge_vlan_stp_set(struct mvsw_pr_port *port,
 			    bridge_vlan_node) {
 		if (port_vlan->mvsw_pr_port != port)
 			continue;
-		return mvsw_pr_port_vid_stp_set(port, br_vlan->vid, state);
+		return prestera_port_vid_stp_set(port, br_vlan->vid, state);
 	}
 
 	return 0;
 }
 
-static int mvsw_pr_port_attr_stp_state_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_stp_state_set(struct prestera_port *port,
 					   struct switchdev_trans *trans,
 					   struct net_device *orig_dev,
 					   u8 state)
@@ -571,7 +571,7 @@ static int mvsw_pr_port_attr_stp_state_set(struct mvsw_pr_port *port,
 
 	if (!br_port->bridge_device->vlan_enabled) {
 		vid = br_port->bridge_device->bridge_id;
-		err = mvsw_pr_port_vid_stp_set(port, vid, state);
+		err = prestera_port_vid_stp_set(port, vid, state);
 		if (err)
 			goto err_port_bridge_stp_set;
 	} else {
@@ -596,17 +596,17 @@ static int mvsw_pr_port_attr_stp_state_set(struct mvsw_pr_port *port,
 	return err;
 
 err_port_bridge_stp_set:
-	mvsw_pr_port_vid_stp_set(port, vid, br_port->stp_state);
+	prestera_port_vid_stp_set(port, vid, br_port->stp_state);
 
 	return err;
 }
 
-static int mvsw_pr_port_attr_br_mc_disabled_set(struct mvsw_pr_port *port,
+static int mvsw_pr_port_attr_br_mc_disabled_set(struct prestera_port *port,
 						struct switchdev_trans *trans,
 						struct net_device *orig_dev,
 						bool mc_disabled)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct mvsw_pr_bridge_device *br_dev;
 	struct mvsw_pr_bridge_port *br_port;
 	bool enabled = !mc_disabled;
@@ -623,8 +623,8 @@ static int mvsw_pr_port_attr_br_mc_disabled_set(struct mvsw_pr_port *port,
 		return 0;
 
 	list_for_each_entry(br_port, &br_dev->port_list, bridge_device_node) {
-		err = mvsw_pr_port_mc_flood_set(netdev_priv(br_port->dev),
-						enabled);
+		err = prestera_port_mc_flood_set(netdev_priv(br_port->dev),
+						 enabled);
 		if (err)
 			return err;
 	}
@@ -639,7 +639,7 @@ static int mvsw_pr_port_obj_attr_set(struct net_device *dev,
 				     struct switchdev_trans *trans)
 {
 	int err = 0;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 
 	switch (attr->id) {
 	case SWITCHDEV_ATTR_ID_PORT_STP_STATE:
@@ -678,7 +678,7 @@ static int mvsw_pr_port_obj_attr_set(struct net_device *dev,
 	return err;
 }
 
-static void mvsw_fdb_offload_notify(struct mvsw_pr_port *port,
+static void mvsw_fdb_offload_notify(struct prestera_port *port,
 				    struct switchdev_notifier_fdb_info *info)
 {
 	struct switchdev_notifier_fdb_info send_info;
@@ -691,10 +691,10 @@ static void mvsw_fdb_offload_notify(struct mvsw_pr_port *port,
 }
 
 static int
-mvsw_pr_port_fdb_set(struct mvsw_pr_port *port,
+mvsw_pr_port_fdb_set(struct prestera_port *port,
 		     struct switchdev_notifier_fdb_info *fdb_info, bool adding)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct mvsw_pr_bridge_port *br_port;
 	struct mvsw_pr_bridge_device *bridge_device;
 	struct net_device *orig_dev = fdb_info->info.dev;
@@ -713,9 +713,9 @@ mvsw_pr_port_fdb_set(struct mvsw_pr_port *port,
 		vid = bridge_device->bridge_id;
 
 	if (adding)
-		err = mvsw_pr_fdb_add(port, fdb_info->addr, vid, false);
+		err = prestera_fdb_add(port, fdb_info->addr, vid, false);
 	else
-		err = mvsw_pr_fdb_del(port, fdb_info->addr, vid);
+		err = prestera_fdb_del(port, fdb_info->addr, vid);
 
 	return err;
 }
@@ -727,13 +727,13 @@ static void mvsw_pr_bridge_fdb_event_work(struct work_struct *work)
 	    container_of(work, struct mvsw_pr_event_work, work);
 	struct net_device *dev = switchdev_work->dev;
 	struct switchdev_notifier_fdb_info *fdb_info;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
 	rtnl_lock();
 	if (netif_is_vxlan(dev))
 		goto out;
 
-	port = mvsw_pr_port_dev_lower_find(dev);
+	port = prestera_port_dev_lower_find(dev);
 	if (!port)
 		goto out;
 
@@ -775,7 +775,7 @@ static int prestera_switchdev_event(struct notifier_block *unused,
 
 	if (event == SWITCHDEV_PORT_ATTR_SET) {
 		err = switchdev_handle_port_attr_set(net_dev, ptr,
-						     mvsw_pr_netdev_check,
+						     prestera_netdev_check,
 						     mvsw_pr_port_obj_attr_set);
 		return notifier_from_errno(err);
 	}
@@ -840,7 +840,7 @@ static int prestera_switchdev_blocking_event(struct notifier_block *unused,
 			err = -EOPNOTSUPP;
 		} else {
 			err = switchdev_handle_port_obj_add
-			    (net_dev, ptr, mvsw_pr_netdev_check,
+			    (net_dev, ptr, prestera_netdev_check,
 			     mvsw_pr_port_obj_add);
 		}
 		break;
@@ -849,13 +849,13 @@ static int prestera_switchdev_blocking_event(struct notifier_block *unused,
 			err = -EOPNOTSUPP;
 		} else {
 			err = switchdev_handle_port_obj_del
-			    (net_dev, ptr, mvsw_pr_netdev_check,
+			    (net_dev, ptr, prestera_netdev_check,
 			     mvsw_pr_port_obj_del);
 		}
 		break;
 	case SWITCHDEV_PORT_ATTR_SET:
 		err = switchdev_handle_port_attr_set
-		    (net_dev, ptr, mvsw_pr_netdev_check,
+		    (net_dev, ptr, prestera_netdev_check,
 		    mvsw_pr_port_obj_attr_set);
 		break;
 	default:
@@ -886,7 +886,7 @@ mvsw_pr_bridge_device_create(struct mvsw_pr_bridge *bridge,
 	if (vlan_enabled) {
 		bridge->bridge_8021q_exists = true;
 	} else {
-		err = mvsw_pr_8021d_bridge_create(bridge->sw, &bridge_id);
+		err = prestera_8021d_bridge_create(bridge->sw, &bridge_id);
 		if (err) {
 			kfree(bridge_device);
 			return ERR_PTR(err);
@@ -914,8 +914,8 @@ mvsw_pr_bridge_device_destroy(struct mvsw_pr_bridge *bridge,
 	if (bridge_device->vlan_enabled)
 		bridge->bridge_8021q_exists = false;
 	else
-		mvsw_pr_8021d_bridge_delete(bridge->sw,
-					    bridge_device->bridge_id);
+		prestera_8021d_bridge_delete(bridge->sw,
+					     bridge_device->bridge_id);
 
 	WARN_ON(!list_empty(&bridge_device->port_list));
 	kfree(bridge_device);
@@ -947,13 +947,13 @@ mvsw_pr_bridge_port_create(struct mvsw_pr_bridge_device *bridge_device,
 			   struct net_device *brport_dev)
 {
 	struct mvsw_pr_bridge_port *br_port;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 
 	br_port = kzalloc(sizeof(*br_port), GFP_KERNEL);
 	if (!br_port)
 		return NULL;
 
-	port = mvsw_pr_port_dev_lower_find(brport_dev);
+	port = prestera_port_dev_lower_find(brport_dev);
 
 	br_port->dev = brport_dev;
 	br_port->bridge_device = bridge_device;
@@ -1027,7 +1027,7 @@ static void mvsw_pr_bridge_port_put(struct mvsw_pr_bridge *bridge,
 static int
 mvsw_pr_bridge_8021q_port_join(struct mvsw_pr_bridge_device *bridge_device,
 			       struct mvsw_pr_bridge_port *br_port,
-			       struct mvsw_pr_port *port,
+			       struct prestera_port *port,
 			       struct netlink_ext_ack *extack)
 {
 	if (is_vlan_dev(br_port->dev)) {
@@ -1042,7 +1042,7 @@ mvsw_pr_bridge_8021q_port_join(struct mvsw_pr_bridge_device *bridge_device,
 static int
 mvsw_pr_bridge_8021d_port_join(struct mvsw_pr_bridge_device *bridge_device,
 			       struct mvsw_pr_bridge_port *br_port,
-			       struct mvsw_pr_port *port,
+			       struct prestera_port *port,
 			       struct netlink_ext_ack *extack)
 {
 	int err;
@@ -1052,19 +1052,19 @@ mvsw_pr_bridge_8021d_port_join(struct mvsw_pr_bridge_device *bridge_device,
 				   "Enslaving of a VLAN device is not supported");
 		return -ENOTSUPP;
 	}
-	err = mvsw_pr_8021d_bridge_port_add(port, bridge_device->bridge_id);
+	err = prestera_8021d_bridge_port_add(port, bridge_device->bridge_id);
 	if (err)
 		return err;
 
-	err = mvsw_pr_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
+	err = prestera_port_uc_flood_set(port, br_port->flags & BR_FLOOD);
 	if (err)
 		goto err_port_uc_flood_set;
 
-	err = mvsw_pr_port_mc_flood_set(port, br_port->flags & BR_MCAST_FLOOD);
+	err = prestera_port_mc_flood_set(port, br_port->flags & BR_MCAST_FLOOD);
 	if (err)
 		goto err_port_mc_flood_set;
 
-	err = mvsw_pr_port_learning_set(port, br_port->flags & BR_LEARNING);
+	err = prestera_port_learning_set(port, br_port->flags & BR_LEARNING);
 	if (err)
 		goto err_port_learning_set;
 
@@ -1074,21 +1074,21 @@ mvsw_pr_bridge_8021d_port_join(struct mvsw_pr_bridge_device *bridge_device,
 	return err;
 
 err_port_learning_set:
-	mvsw_pr_port_mc_flood_set(port, false);
+	prestera_port_mc_flood_set(port, false);
 err_port_mc_flood_set:
-	mvsw_pr_port_uc_flood_set(port, false);
+	prestera_port_uc_flood_set(port, false);
 err_port_uc_flood_set:
-	mvsw_pr_8021d_bridge_port_delete(port, bridge_device->bridge_id);
+	prestera_8021d_bridge_port_delete(port, bridge_device->bridge_id);
 	return err;
 }
 
-static int mvsw_pr_port_bridge_join(struct mvsw_pr_port *port,
+static int mvsw_pr_port_bridge_join(struct prestera_port *port,
 				    struct net_device *brport_dev,
 				    struct net_device *br_dev,
 				    struct netlink_ext_ack *extack)
 {
 	struct mvsw_pr_bridge_device *bridge_device;
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct mvsw_pr_bridge_port *br_port;
 	int err;
 
@@ -1123,26 +1123,26 @@ static int mvsw_pr_port_bridge_join(struct mvsw_pr_port *port,
 static void
 mvsw_pr_bridge_8021d_port_leave(struct mvsw_pr_bridge_device *bridge_device,
 				struct mvsw_pr_bridge_port *br_port,
-				struct mvsw_pr_port *port)
+				struct prestera_port *port)
 {
-	mvsw_pr_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
-	mvsw_pr_8021d_bridge_port_delete(port, bridge_device->bridge_id);
+	prestera_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
+	prestera_8021d_bridge_port_delete(port, bridge_device->bridge_id);
 }
 
 static void
 mvsw_pr_bridge_8021q_port_leave(struct mvsw_pr_bridge_device *bridge_device,
 				struct mvsw_pr_bridge_port *br_port,
-				struct mvsw_pr_port *port)
+				struct prestera_port *port)
 {
-	mvsw_pr_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
-	mvsw_pr_port_pvid_set(port, MVSW_PR_DEFAULT_VID);
+	prestera_fdb_flush_port(port, MVSW_PR_FDB_FLUSH_MODE_ALL);
+	prestera_port_pvid_set(port, MVSW_PR_DEFAULT_VID);
 }
 
-static void mvsw_pr_port_bridge_leave(struct mvsw_pr_port *port,
+static void mvsw_pr_port_bridge_leave(struct prestera_port *port,
 				      struct net_device *brport_dev,
 				      struct net_device *br_dev)
 {
-	struct mvsw_pr_switch *sw = port->sw;
+	struct prestera_switch *sw = port->sw;
 	struct mvsw_pr_bridge_device *bridge_device;
 	struct mvsw_pr_bridge_port *br_port;
 
@@ -1158,10 +1158,10 @@ static void mvsw_pr_port_bridge_leave(struct mvsw_pr_port *port,
 	else
 		mvsw_pr_bridge_8021d_port_leave(bridge_device, br_port, port);
 
-	mvsw_pr_port_learning_set(port, false);
-	mvsw_pr_port_uc_flood_set(port, false);
-	mvsw_pr_port_mc_flood_set(port, false);
-	mvsw_pr_port_vid_stp_set(port, MVSW_PR_VID_ALL, BR_STATE_FORWARDING);
+	prestera_port_learning_set(port, false);
+	prestera_port_uc_flood_set(port, false);
+	prestera_port_mc_flood_set(port, false);
+	prestera_port_vid_stp_set(port, MVSW_PR_VID_ALL, BR_STATE_FORWARDING);
 	mvsw_pr_bridge_port_put(sw->bridge, br_port);
 
 	/* Offload rif that was previosly disabled */
@@ -1171,7 +1171,8 @@ static void mvsw_pr_port_bridge_leave(struct mvsw_pr_port *port,
 }
 
 static bool
-prestera_lag_master_check(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
+prestera_lag_master_check(struct prestera_switch *sw,
+			  struct net_device *lag_dev,
 			  struct netdev_lag_upper_info *upper_info,
 			  struct netlink_ext_ack *ext_ack)
 {
@@ -1189,7 +1190,7 @@ prestera_lag_master_check(struct mvsw_pr_switch *sw, struct net_device *lag_dev,
 	return true;
 }
 
-static void mvsw_pr_port_lag_clean(struct mvsw_pr_port *port,
+static void mvsw_pr_port_lag_clean(struct prestera_port *port,
 				   struct net_device *lag_dev)
 {
 	struct net_device *br_dev = netdev_master_upper_dev_get(lag_dev);
@@ -1199,7 +1200,7 @@ static void mvsw_pr_port_lag_clean(struct mvsw_pr_port *port,
 
 	list_for_each_entry_safe(port_vlan, tmp, &port->vlans_list, list) {
 		mvsw_pr_port_vlan_bridge_leave(port_vlan);
-		mvsw_pr_port_vlan_destroy(port_vlan);
+		prestera_port_vlan_destroy(port_vlan);
 	}
 
 	if (netif_is_bridge_port(lag_dev))
@@ -1212,10 +1213,10 @@ static void mvsw_pr_port_lag_clean(struct mvsw_pr_port *port,
 		mvsw_pr_port_bridge_leave(port, upper_dev, br_dev);
 	}
 
-	mvsw_pr_port_pvid_set(port, MVSW_PR_DEFAULT_VID);
+	prestera_port_pvid_set(port, MVSW_PR_DEFAULT_VID);
 }
 
-static int mvsw_pr_port_lag_join(struct mvsw_pr_port *port,
+static int mvsw_pr_port_lag_join(struct prestera_port *port,
 				 struct net_device *lag_dev)
 {
 	u16 lag_id;
@@ -1233,7 +1234,7 @@ static int mvsw_pr_port_lag_join(struct mvsw_pr_port *port,
 	return 0;
 }
 
-static void mvsw_pr_port_lag_leave(struct mvsw_pr_port *port,
+static void mvsw_pr_port_lag_leave(struct prestera_port *port,
 				   struct net_device *lag_dev)
 {
 	mvsw_pr_router_lag_member_leave(port, lag_dev);
@@ -1249,10 +1250,10 @@ static int mvsw_pr_netdevice_port_upper_event(struct net_device *lower_dev,
 					      unsigned long event, void *ptr)
 {
 	struct netdev_notifier_changeupper_info *info;
-	struct mvsw_pr_port *port;
+	struct prestera_port *port;
 	struct netlink_ext_ack *extack;
 	struct net_device *upper_dev;
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	int err = 0;
 
 	port = netdev_priv(dev);
@@ -1331,14 +1332,14 @@ static int mvsw_pr_netdevice_port_lower_event(struct net_device *dev,
 {
 	struct netdev_notifier_changelowerstate_info *info = ptr;
 	struct netdev_lag_lower_state_info *lower_state_info;
-	struct mvsw_pr_port *port = netdev_priv(dev);
+	struct prestera_port *port = netdev_priv(dev);
 	bool enabled;
 
 	if (event != NETDEV_CHANGELOWERSTATE)
 		return 0;
 	if (!netif_is_lag_port(dev))
 		return 0;
-	if (!mvsw_pr_port_is_lag_member(port))
+	if (!prestera_port_is_lag_member(port))
 		return 0;
 
 	lower_state_info = info->lower_state_info;
@@ -1366,7 +1367,7 @@ static int mvsw_pr_netdevice_port_event(struct net_device *lower_dev,
 static int mvsw_pr_netdevice_bridge_event(struct net_device *br_dev,
 					  unsigned long event, void *ptr)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(br_dev);
+	struct prestera_switch *sw = prestera_switch_get(br_dev);
 	struct netdev_notifier_changeupper_info *info = ptr;
 	struct netlink_ext_ack *extack;
 	struct net_device *upper_dev;
@@ -1403,7 +1404,7 @@ static int mvsw_pr_netdevice_bridge_event(struct net_device *br_dev,
 static int mvsw_pr_netdevice_macvlan_event(struct net_device *macvlan_dev,
 					   unsigned long event, void *ptr)
 {
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(macvlan_dev);
+	struct prestera_switch *sw = prestera_switch_get(macvlan_dev);
 	struct netdev_notifier_changeupper_info *info = ptr;
 	struct netlink_ext_ack *extack;
 
@@ -1435,7 +1436,7 @@ static int mvsw_pr_netdevice_lag_event(struct net_device *lag_dev,
 	int err;
 
 	netdev_for_each_lower_dev(lag_dev, dev, iter) {
-		if (mvsw_pr_netdev_check(dev)) {
+		if (prestera_netdev_check(dev)) {
 			err = mvsw_pr_netdevice_port_event(lag_dev, dev, event,
 							   ptr);
 			if (err)
@@ -1450,7 +1451,7 @@ static int mvsw_pr_netdevice_vlan_event(struct net_device *vlan_dev,
 					unsigned long event, void *ptr)
 {
 	struct net_device *real_dev = vlan_dev_real_dev(vlan_dev);
-	struct mvsw_pr_switch *sw = mvsw_pr_switch_get(real_dev);
+	struct prestera_switch *sw = prestera_switch_get(real_dev);
 	struct netdev_notifier_changeupper_info *info = ptr;
 	struct netlink_ext_ack *extack;
 	struct net_device *upper_dev;
@@ -1486,17 +1487,17 @@ static int mvsw_pr_netdevice_event(struct notifier_block *nb,
 				   unsigned long event, void *ptr)
 {
 	struct net_device *dev = netdev_notifier_info_to_dev(ptr);
-	struct mvsw_pr_switch *sw;
+	struct prestera_switch *sw;
 	int err = 0;
 
-	sw = container_of(nb, struct mvsw_pr_switch, netdevice_nb);
+	sw = container_of(nb, struct prestera_switch, netdevice_nb);
 
 	if (event == NETDEV_PRE_CHANGEADDR ||
 	    event == NETDEV_CHANGEADDR)
 		err = mvsw_pr_netdevice_router_port_event(dev, event, ptr);
 	else if (mvsw_pr_is_vrf_event(event, ptr))
 		err = mvsw_pr_netdevice_vrf_event(dev, event, ptr);
-	else if (mvsw_pr_netdev_check(dev))
+	else if (prestera_netdev_check(dev))
 		err = mvsw_pr_netdevice_port_event(dev, dev, event, ptr);
 	else if (netif_is_bridge_master(dev))
 		err = mvsw_pr_netdevice_bridge_event(dev, event, ptr);
@@ -1510,18 +1511,18 @@ static int mvsw_pr_netdevice_event(struct notifier_block *nb,
 	return notifier_from_errno(err);
 }
 
-static int mvsw_pr_fdb_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_fdb_init(struct prestera_switch *sw)
 {
 	int err;
 
-	err = mvsw_pr_switch_ageing_set(sw, MVSW_PR_DEFAULT_AGEING_TIME);
+	err = prestera_switch_ageing_set(sw, MVSW_PR_DEFAULT_AGEING_TIME);
 	if (err)
 		return err;
 
 	return 0;
 }
 
-static int prestera_switchdev_init(struct mvsw_pr_switch *sw)
+static int prestera_switchdev_init(struct prestera_switch *sw)
 {
 	int err = 0;
 	struct prestera_switchdev *swdev;
@@ -1578,7 +1579,7 @@ static int prestera_switchdev_init(struct mvsw_pr_switch *sw)
 	return err;
 }
 
-static void prestera_switchdev_fini(struct mvsw_pr_switch *sw)
+static void prestera_switchdev_fini(struct prestera_switch *sw)
 {
 	if (!sw->switchdev)
 		return;
@@ -1593,7 +1594,7 @@ static void prestera_switchdev_fini(struct mvsw_pr_switch *sw)
 	kfree(sw->bridge);
 }
 
-static int mvsw_pr_netdev_init(struct mvsw_pr_switch *sw)
+static int mvsw_pr_netdev_init(struct prestera_switch *sw)
 {
 	int err = 0;
 
@@ -1605,13 +1606,13 @@ static int mvsw_pr_netdev_init(struct mvsw_pr_switch *sw)
 	return err;
 }
 
-static void mvsw_pr_netdev_fini(struct mvsw_pr_switch *sw)
+static void mvsw_pr_netdev_fini(struct prestera_switch *sw)
 {
 	if (sw->netdevice_nb.notifier_call)
 		unregister_netdevice_notifier(&sw->netdevice_nb);
 }
 
-int prestera_switchdev_register(struct mvsw_pr_switch *sw)
+int prestera_switchdev_register(struct prestera_switch *sw)
 {
 	int err;
 
@@ -1639,7 +1640,7 @@ int prestera_switchdev_register(struct mvsw_pr_switch *sw)
 	return err;
 }
 
-void prestera_switchdev_unregister(struct mvsw_pr_switch *sw)
+void prestera_switchdev_unregister(struct prestera_switch *sw)
 {
 	mvsw_pr_netdev_fini(sw);
 	mvsw_pr_router_fini(sw);
