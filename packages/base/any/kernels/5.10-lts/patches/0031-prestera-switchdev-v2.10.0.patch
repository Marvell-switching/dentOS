diff --git a/drivers/net/ethernet/marvell/prestera/Makefile b/drivers/net/ethernet/marvell/prestera/Makefile
index db531db..f158125 100644
--- a/drivers/net/ethernet/marvell/prestera/Makefile
+++ b/drivers/net/ethernet/marvell/prestera/Makefile
@@ -8,7 +8,7 @@ prestera-objs := prestera_main.o \
 	prestera_hw.o prestera_switchdev.o prestera_devlink.o prestera_fw_log.o \
 	prestera_rxtx.o prestera_dsa.o prestera_router.o \
 	prestera_acl.o prestera_flow.o prestera_flower.o prestera_matchall.o prestera_debugfs.o \
-	prestera_storm_control.o prestera_ct.o
+	prestera_storm_control.o prestera_ct.o prestera_ethtool.o
 
 prestera-$(CONFIG_PRESTERA_DEBUG) += prestera_log.o
 ccflags-$(CONFIG_PRESTERA_DEBUG) += -DCONFIG_MRVL_PRESTERA_DEBUG
diff --git a/drivers/net/ethernet/marvell/prestera/prestera.h b/drivers/net/ethernet/marvell/prestera/prestera.h
index 6228cfa..10f3f56 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera.h
@@ -55,11 +55,12 @@ struct prestera_flow_block_binding {
 
 struct prestera_flow_block {
 	struct list_head binding_list;
+	struct list_head template_list;
 	struct prestera_switch *sw;
 	unsigned int rule_count;
 	unsigned int disable_count;
 	struct net *net;
-	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl_ruleset *ruleset_zero;
 	struct flow_block_cb *block_cb;
 	u32 mall_prio;
 	u32 flower_min_prio;
@@ -113,6 +114,21 @@ struct mvsw_pr_port_caps {
 	u8 transceiver;
 };
 
+struct prestera_port_link_params {
+	u64 lmode_bmap;
+	u32 speed;
+	u8 duplex;
+	bool oper_state;
+	struct {
+		bool pause;
+		bool asym_pause;
+	} remote_fc;
+	struct {
+		u8 status;
+		u8 admin_mode;
+	} mdix;
+};
+
 struct prestera_port {
 	struct devlink_port dl_port;
 	struct net_device *net_dev;
@@ -123,9 +139,6 @@ struct prestera_port {
 	u16 fp_id;
 	u16 pvid;
 	bool autoneg;
-	bool hw_oper_state; /* RS (PCS) */
-	u32 hw_speed;
-	u8 hw_duplex;
 	u64 adver_link_modes;
 	u8 adver_fec;
 	u16 lag_id;
@@ -140,6 +153,8 @@ struct prestera_port {
 
 	struct phylink_config phy_config;
 	struct phylink *phy_link;
+
+	struct prestera_port_link_params link_params;
 };
 
 struct prestera_switchdev {
@@ -234,8 +249,6 @@ struct mvsw_pr_port_event {
 	u32 port_id;
 	struct {
 		u8 oper_state;
-		u8 duplex;
-		u32 speed;
 	} data;
 };
 
@@ -365,22 +378,33 @@ struct mvsw_pr_neigh_info {
 	bool connected; /* indicate, if mac/oif valid */
 };
 
-enum prestera_acl_rule_match_entry_type {
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE = 1,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE,
-	MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE
+enum prestera_acl_match_type {
+	PRESTERA_ACL_RULE_MATCH_TYPE_PCL_ID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_TYPE,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_DMAC_0,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_DMAC_1,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_SMAC_0,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ETH_SMAC_1,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_PROTO,
+	PRESTERA_ACL_RULE_MATCH_TYPE_SYS_PORT,
+	PRESTERA_ACL_RULE_MATCH_TYPE_SYS_DEV,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_IP_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_RANGE_SRC,
+	PRESTERA_ACL_RULE_MATCH_TYPE_L4_PORT_RANGE_DST,
+	PRESTERA_ACL_RULE_MATCH_TYPE_VLAN_ID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_VLAN_TPID,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ICMP_TYPE,
+	PRESTERA_ACL_RULE_MATCH_TYPE_ICMP_CODE,
+
+	__PRESTERA_ACL_RULE_MATCH_TYPE_MAX
+};
+
+struct prestera_acl_match {
+	__be32 key[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	__be32 mask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
 };
 
 enum prestera_acl_rule_action {
@@ -390,73 +414,40 @@ enum prestera_acl_rule_action {
 	MVSW_ACL_RULE_ACTION_POLICE,
 	MVSW_ACL_RULE_ACTION_NAT,
 	MVSW_ACL_RULE_ACTION_JUMP,
-	MVSW_ACL_RULE_ACTION_MANGLE
+	MVSW_ACL_RULE_ACTION_NH
 };
 
-/* Used for hw call */
-struct prestera_acl_hw_match_info {
-	enum prestera_acl_rule_match_entry_type type;
-	union {
-		struct {
-			u8 key, mask;
-		} u8;
-		struct {
-			u16 key, mask;
-		} u16;
-		struct {
-			u32 key, mask;
-		} u32;
-		struct {
-			u64 key, mask;
-		} u64;
-		struct {
-			u8 key[ETH_ALEN];
-			u8 mask[ETH_ALEN];
-		} mac;
-	};
+struct prestera_acl_action_jump {
+	u32 index;
 };
 
-/* Used for hw call */
-struct prestera_acl_hw_action_info {
-	enum prestera_acl_rule_action id;
-	union {
-		struct {
-			u64 rate;
-			u64 burst;
-		} police;
-		struct {
-			u8 l4_src_valid:1, l4_dst_valid:1,
-			   sip_valid:1, dip_valid:1;
-			__be16 l4_src;
-			__be16 l4_dst;
-			struct mvsw_pr_ip_addr sip;
-			struct mvsw_pr_ip_addr dip;
-			struct mvsw_pr_neigh_info n;
-		} mangle;
-		struct {
-			__be32 old_addr;
-			__be32 new_addr;
-			u32 port;
-			u32 dev;
-			u32 flags;
-		} nat;
-		struct {
-			u32 chain;
-		} jump;
-	};
+struct prestera_acl_action_trap {
+	u8 hw_tc;
 };
 
-/* TODO: match/action entries will be refactored to provide tie with neigh */
+struct prestera_acl_action_police {
+	u64 rate;
+	u64 burst;
+};
 
-struct prestera_acl_rule_match_entry {
-	struct list_head list;
-	struct prestera_acl_hw_match_info info;
+struct prestera_acl_action_nat {
+	__be32 old_addr;
+	__be32 new_addr;
+	u32 port;
+	u32 dev;
+	u32 flags;
 };
 
-struct prestera_acl_rule_action_entry {
-	struct list_head list;
-	struct prestera_acl_rule *rule;
-	struct prestera_acl_hw_action_info info;
+/* Used for hw call */
+struct prestera_acl_hw_action_info {
+	enum prestera_acl_rule_action id;
+	union {
+		struct prestera_acl_action_trap trap;
+		struct prestera_acl_action_police police;
+		u32 nh;
+		struct prestera_acl_action_nat nat;
+		struct prestera_acl_action_jump jump;
+	};
 };
 
 struct mvsw_pr_fib_key {
@@ -493,12 +484,20 @@ struct mvsw_pr_nh_neigh {
 	struct mvsw_pr_neigh_info info;
 	struct rhash_head ht_node; /* node of mvsw_pr_vr */
 	struct list_head nexthop_group_list;
+	struct list_head nh_mangle_entry_list;
 };
 
 struct mvsw_pr_nexthop_group_key {
 	struct mvsw_pr_nh_neigh_key neigh[MVSW_PR_NHGR_SIZE_MAX];
 };
 
+/* internal lock */
+void prestera_router_owq_lock(void);
+void prestera_router_owq_unlock(void);
+/* Must be called under rtnl_lock */
+void prestera_router_owq_flush(void);
+void prestera_router_owq_queue_work(struct work_struct *work);
+
 struct prestera_port *dev_to_prestera_port(struct device *dev);
 
 int prestera_switch_ageing_set(struct prestera_switch *sw, u32 ageing_time);
@@ -568,6 +567,13 @@ int mvsw_pr_flower_stats(struct prestera_switch *sw,
 			 struct flow_cls_offload *f);
 int prestera_flower_prio_get(struct prestera_flow_block *block,
 			     u32 *prio);
+int prestera_flower_tmplt_create(struct prestera_switch *sw,
+				 struct prestera_flow_block *block,
+				 struct flow_cls_offload *f);
+void prestera_flower_tmplt_destroy(struct prestera_switch *sw,
+				   struct prestera_flow_block *block,
+				   struct flow_cls_offload *f);
+void prestera_flower_template_cleanup(struct prestera_flow_block *block);
 
 /* prestera_matchall.c */
 int prestera_mall_replace(struct prestera_flow_block *block,
@@ -583,9 +589,6 @@ int prestera_setup_tc_block(struct prestera_port *port,
 /* prestera_acl.c */
 int prestera_acl_init(struct prestera_switch *sw);
 void prestera_acl_fini(struct prestera_switch *sw);
-struct prestera_flow_block *
-prestera_acl_block_create(struct prestera_switch *sw, struct net *net);
-void prestera_acl_block_destroy(struct prestera_flow_block *block);
 struct net *prestera_acl_block_net(struct prestera_flow_block *block);
 struct prestera_switch *
 prestera_acl_block_sw(struct prestera_flow_block *block);
@@ -593,47 +596,6 @@ unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block);
 void prestera_acl_block_disable_inc(struct prestera_flow_block *block);
 void prestera_acl_block_disable_dec(struct prestera_flow_block *block);
 bool prestera_acl_block_disabled(const struct prestera_flow_block *block);
-int prestera_acl_block_bind(struct prestera_switch *sw,
-			    struct prestera_flow_block *block,
-			    struct prestera_port *port);
-int prestera_acl_block_unbind(struct prestera_switch *sw,
-			      struct prestera_flow_block *block,
-			      struct prestera_port *port);
-struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_flow_block *block);
-struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_flow_block *block,
-			 unsigned long cookie, u32 chain_index);
-u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule);
-void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
-				    u32 priority);
-u8 prestera_acl_rule_hw_tc_get(struct prestera_acl_rule *rule);
-void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc);
-u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule);
-u8 prestera_acl_rule_hw_chain_id_get(const struct prestera_acl_rule *rule);
-struct list_head *
-prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule);
-u32 prestera_acl_rule_chain_get(struct prestera_acl_rule *rule);
-u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule);
-u8 prestera_acl_rule_match_len(struct prestera_acl_rule *rule);
-int prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_action_entry *entry);
-
-struct list_head *
-prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule);
-void prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_match_entry *entry);
-void prestera_acl_rule_destroy(struct prestera_acl_rule *rule);
-struct prestera_acl_rule *
-prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
-			 unsigned long cookie);
-int prestera_acl_rule_add(struct prestera_switch *sw,
-			  struct prestera_acl_rule *rule);
-void prestera_acl_rule_del(struct prestera_switch *sw,
-			   struct prestera_acl_rule *rule);
-int prestera_acl_rule_get_stats(struct prestera_switch *sw,
-				struct prestera_acl_rule *rule,
-				u64 *packets, u64 *bytes, u64 *last_use);
 void prestera_acl_block_prio_update(struct prestera_switch *sw,
 				    struct prestera_flow_block *block);
 
@@ -663,6 +625,9 @@ struct prestera_port *prestera_port_dev_lower_find(struct net_device *dev);
 
 struct prestera_port *prestera_port_find(u32 dev_hw_id, u32 port_hw_id);
 
+int prestera_port_autoneg_set(struct prestera_port *port, bool enable,
+			      u64 link_modes, u8 fec);
+
 /* prestera_router.c */
 int mvsw_pr_router_init(struct prestera_switch *sw);
 void mvsw_pr_router_fini(struct prestera_switch *sw);
@@ -692,6 +657,11 @@ int prestera_mp4_hash_set(const struct prestera_switch *sw, u8 hash_policy);
 struct mvsw_pr_nh_neigh *
 mvsw_pr_nh_neigh_find(struct prestera_switch *sw,
 		      struct mvsw_pr_nh_neigh_key *key);
+struct mvsw_pr_nh_neigh *
+mvsw_pr_nh_neigh_get(struct prestera_switch *sw,
+		     struct mvsw_pr_nh_neigh_key *key);
+void mvsw_pr_nh_neigh_put(struct prestera_switch *sw,
+			  struct mvsw_pr_nh_neigh *neigh);
 int prestera_util_kern_dip2nh_grp_key(struct prestera_switch *sw,
 				      u32 tb_id, struct mvsw_pr_ip_addr *addr,
 				      struct mvsw_pr_nexthop_group_key *res);
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.c b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
index 6dc7d75..c2a9d86 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_acl.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.c
@@ -11,11 +11,51 @@
 #include "prestera_ct.h"
 #include "prestera_acl.h"
 
+#define ACL_STATS_POLL_TIMEOUT_MS	(msecs_to_jiffies(10000))
+#define ACL_STATS_COUNT			(1024 * 8)
+#define ACL_STATS_BULK_SIZE		(512)
+#define ACL_STATS_BULK_COUNT		(ACL_STATS_COUNT / ACL_STATS_BULK_SIZE)
+#define ACL_KEYMASK_SIZE	\
+	(sizeof(__be32) * __PRESTERA_ACL_RULE_MATCH_TYPE_MAX)
+
+struct prestera_acl_ruleset_ht_key {
+	struct prestera_flow_block *block;
+	u32 chain_index;
+};
 
 struct prestera_acl_ruleset {
+	struct rhash_head ht_node; /* Member of acl HT */
+	struct prestera_acl_ruleset_ht_key ht_key;
 	struct rhashtable rule_ht;
-	struct prestera_switch *sw;
-	u16 id;
+	struct prestera_acl *acl;
+	unsigned long rule_count;
+	refcount_t refcount;
+	void *keymask;
+	bool offload;
+	u32 vtcam_id;
+	u16 pcl_id;
+	u32 index;
+};
+
+struct prestera_acl_uid_entry {
+	struct list_head list;
+	u8 id;
+};
+
+struct prestera_acl_vtcam {
+	struct list_head list;
+	__be32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	bool is_keymask_set;
+	refcount_t refcount;
+	u8 lookup;
+	u32 id;
+};
+
+static const struct rhashtable_params prestera_acl_ruleset_ht_params = {
+	.key_len = sizeof(struct prestera_acl_ruleset_ht_key),
+	.key_offset = offsetof(struct prestera_acl_ruleset, ht_key),
+	.head_offset = offsetof(struct prestera_acl_ruleset, ht_node),
+	.automatic_shrinking = true,
 };
 
 static const struct rhashtable_params prestera_acl_rule_ht_params = {
@@ -25,6 +65,57 @@ static const struct rhashtable_params prestera_acl_rule_ht_params = {
 	.automatic_shrinking = true,
 };
 
+static const struct rhashtable_params __prestera_nh_mangle_entry_ht_params = {
+	.key_offset  = offsetof(struct prestera_nh_mangle_entry, key),
+	.head_offset = offsetof(struct prestera_nh_mangle_entry, ht_node),
+	.key_len     = sizeof(struct prestera_nh_mangle_entry_key),
+	.automatic_shrinking = true,
+};
+
+static const struct rhashtable_params __prestera_acl_rule_entry_ht_params = {
+	.key_offset  = offsetof(struct prestera_acl_rule_entry, key),
+	.head_offset = offsetof(struct prestera_acl_rule_entry, ht_node),
+	.key_len     = sizeof(struct prestera_acl_rule_entry_key),
+	.automatic_shrinking = true,
+};
+
+static int acl_stats_bulk_refcount[ACL_STATS_BULK_COUNT];
+static struct mutex acl_stats_lock;
+
+static inline u32 prestera_acl_counter_to_bulk_id(u32 counter_id)
+{
+	return counter_id / ACL_STATS_BULK_SIZE;
+}
+
+static inline void prestera_acl_stats_refcount_inc(u32 counter_id)
+{
+	if (counter_id >= ACL_STATS_COUNT)
+		return;
+
+	acl_stats_bulk_refcount[prestera_acl_counter_to_bulk_id(counter_id)]++;
+}
+
+static inline void prestera_acl_stats_refcount_dec(u32 counter_id)
+{
+	if (counter_id >= ACL_STATS_COUNT)
+		return;
+
+	acl_stats_bulk_refcount[prestera_acl_counter_to_bulk_id(counter_id)]--;
+}
+
+static inline bool prestera_acl_stats_bulk_refcount_test(u32 bulk_id)
+{
+	return acl_stats_bulk_refcount[bulk_id] > 0;
+}
+
+static void prestera_acl_stats_clear(struct prestera_acl *acl, u32 counter_id)
+{
+	if (counter_id >= ACL_STATS_COUNT)
+		return;
+
+	memset(&acl->stats[counter_id], 0, sizeof(*acl->stats));
+}
+
 struct prestera_acl_nat_port *
 prestera_acl_nat_port_get(struct prestera_acl *acl, u32 port_hw_id,
 			  u32 port_dev_id)
@@ -77,27 +168,44 @@ prestera_acl_nat_port_create(struct prestera_acl *acl,
 }
 
 static struct prestera_acl_ruleset *
-prestera_acl_ruleset_create(struct prestera_switch *sw)
+prestera_acl_ruleset_create(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index)
 {
-	int err;
 	struct prestera_acl_ruleset *ruleset;
+	int err;
+	u8 uid;
 
 	ruleset = kzalloc(sizeof(*ruleset), GFP_KERNEL);
 	if (!ruleset)
 		return ERR_PTR(-ENOMEM);
 
+	ruleset->acl = acl;
+	ruleset->ht_key.block = block;
+	ruleset->ht_key.chain_index = chain_index;
+	refcount_set(&ruleset->refcount, 1);
+
 	err = rhashtable_init(&ruleset->rule_ht, &prestera_acl_rule_ht_params);
 	if (err)
 		goto err_rhashtable_init;
 
-	err = mvsw_pr_hw_acl_ruleset_create(sw, &ruleset->id);
+	err = prestera_acl_uid_new_get(acl, &uid);
 	if (err)
 		goto err_ruleset_create;
 
-	ruleset->sw = sw;
+	/* make pcl-id based on uid and chain */
+	ruleset->pcl_id = PRESTERA_ACL_PCL_ID_MAKE(uid, chain_index);
+	ruleset->index = uid;
+
+	err = rhashtable_insert_fast(&acl->ruleset_ht, &ruleset->ht_node,
+				     prestera_acl_ruleset_ht_params);
+	if (err)
+		goto err_ruleset_ht_insert;
 
 	return ruleset;
 
+err_ruleset_ht_insert:
+	prestera_acl_uid_release(acl, uid);
 err_ruleset_create:
 	rhashtable_destroy(&ruleset->rule_ht);
 err_rhashtable_init:
@@ -105,150 +213,247 @@ prestera_acl_ruleset_create(struct prestera_switch *sw)
 	return ERR_PTR(err);
 }
 
-static void prestera_acl_ruleset_destroy(struct prestera_acl_ruleset *ruleset)
+int prestera_acl_ruleset_keymask_set(struct prestera_acl_ruleset *ruleset,
+				     void *keymask)
 {
-	mvsw_pr_hw_acl_ruleset_del(ruleset->sw, ruleset->id);
-	rhashtable_destroy(&ruleset->rule_ht);
-	kfree(ruleset);
+	void *__keymask;
+
+	if (!keymask || !ruleset)
+		return -EINVAL;
+
+	__keymask = kmalloc(ACL_KEYMASK_SIZE, GFP_KERNEL);
+	if (!__keymask)
+		return -ENOMEM;
+
+	memcpy(__keymask, keymask, ACL_KEYMASK_SIZE);
+	ruleset->keymask = __keymask;
+
+	return 0;
 }
 
-void prestera_acl_block_prio_update(struct prestera_switch *sw,
-				    struct prestera_flow_block *block)
+int prestera_acl_ruleset_offload(struct prestera_acl_ruleset *ruleset)
 {
-	struct prestera_acl *acl = sw->acl;
-	struct prestera_acl_rule *rule;
-	u32 new_prio = UINT_MAX;
-	u32 prio;
+	struct prestera_acl_iface iface;
+	u32 vtcam_id;
+	int err;
 
-	list_for_each_entry(rule, &acl->rules, list) {
-		prio = prestera_acl_rule_priority_get(rule);
-		if (prio < new_prio)
-			new_prio = prio;
+	if (ruleset->offload)
+		return -EEXIST;
+
+	err = prestera_acl_vtcam_id_get(ruleset->acl,
+					ruleset->ht_key.chain_index,
+					ruleset->keymask, &vtcam_id);
+	if (err)
+		goto err_vtcam_create;
+
+	if (ruleset->ht_key.chain_index) {
+		/* for chain > 0, bind iface index to pcl-id to be able
+		 * to jump from any other ruleset to this one using the index.
+		 */
+		iface.index = ruleset->index;
+		iface.type = PRESTERA_ACL_IFACE_TYPE_INDEX;
+		err = prestera_hw_vtcam_iface_bind(ruleset->acl->sw, &iface,
+						   vtcam_id, ruleset->pcl_id);
+		if (err)
+			goto err_ruleset_bind;
 	}
 
-	block->flower_min_prio = new_prio;
+	ruleset->vtcam_id = vtcam_id;
+	ruleset->offload = true;
+	return 0;
+
+err_ruleset_bind:
+	prestera_acl_vtcam_id_put(ruleset->acl, ruleset->vtcam_id);
+err_vtcam_create:
+	return err;
 }
 
-struct prestera_flow_block *
-prestera_acl_block_create(struct prestera_switch *sw, struct net *net)
+static void prestera_acl_ruleset_destroy(struct prestera_acl_ruleset *ruleset)
 {
-	struct prestera_flow_block *block;
-
-	block = kzalloc(sizeof(*block), GFP_KERNEL);
-	if (!block)
-		return NULL;
-	INIT_LIST_HEAD(&block->binding_list);
-	block->net = net;
-	block->sw = sw;
-	block->mall_prio = UINT_MAX;
-	block->flower_min_prio = UINT_MAX;
+	struct prestera_acl *acl = ruleset->acl;
+	u8 uid = ruleset->pcl_id & PRESTERA_ACL_KEYMASK_PCL_ID_USER;
+	int err;
 
-	block->ruleset = prestera_acl_ruleset_create(sw);
-	if (IS_ERR(block->ruleset)) {
-		kfree(block);
-		return NULL;
+	rhashtable_remove_fast(&acl->ruleset_ht, &ruleset->ht_node,
+			       prestera_acl_ruleset_ht_params);
+
+	if (ruleset->offload) {
+		if (ruleset->ht_key.chain_index) {
+			struct prestera_acl_iface iface = {
+				.type = PRESTERA_ACL_IFACE_TYPE_INDEX,
+				.index = ruleset->index
+			};
+			err = prestera_hw_vtcam_iface_unbind(acl->sw, &iface,
+							     ruleset->vtcam_id);
+			WARN_ON(err);
+		}
+		WARN_ON(prestera_acl_vtcam_id_put(acl, ruleset->vtcam_id));
 	}
 
-	return block;
+	WARN_ON(prestera_acl_uid_release(acl, uid));
+
+	rhashtable_destroy(&ruleset->rule_ht);
+	kfree(ruleset->keymask);
+	kfree(ruleset);
 }
 
-void prestera_acl_block_destroy(struct prestera_flow_block *block)
+static struct prestera_acl_ruleset *
+__prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			      struct prestera_flow_block *block,
+			      u32 chain_index)
 {
-	prestera_acl_ruleset_destroy(block->ruleset);
-	WARN_ON(!list_empty(&block->binding_list));
-	kfree(block);
+	struct prestera_acl_ruleset_ht_key ht_key;
+
+	memset(&ht_key, 0, sizeof(ht_key));
+	ht_key.block = block;
+	ht_key.chain_index = chain_index;
+	return rhashtable_lookup_fast(&acl->ruleset_ht, &ht_key,
+				      prestera_acl_ruleset_ht_params);
 }
 
-static struct prestera_flow_block_binding *
-prestera_acl_block_lookup(struct prestera_flow_block *block,
-			  struct prestera_port *port)
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index)
 {
-	struct prestera_flow_block_binding *binding;
+	struct prestera_acl_ruleset *ruleset;
 
-	list_for_each_entry(binding, &block->binding_list, list)
-		if (binding->port == port)
-			return binding;
+	ruleset = __prestera_acl_ruleset_lookup(acl, block, chain_index);
+	if (!ruleset)
+		return ERR_PTR(-ENOENT);
 
-	return NULL;
+	refcount_inc(&ruleset->refcount);
+	return ruleset;
 }
 
-unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block)
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_get(struct prestera_acl *acl,
+			 struct prestera_flow_block *block,
+			 u32 chain_index)
 {
-	return block ? block->rule_count : 0;
+	struct prestera_acl_ruleset *ruleset;
+
+	ruleset = __prestera_acl_ruleset_lookup(acl, block, chain_index);
+	if (ruleset) {
+		refcount_inc(&ruleset->refcount);
+		return ruleset;
+	}
+
+	return prestera_acl_ruleset_create(acl, block, chain_index);
 }
 
-void prestera_acl_block_disable_inc(struct prestera_flow_block *block)
+void prestera_acl_ruleset_put(struct prestera_acl_ruleset *ruleset)
 {
-	if (block)
-		block->disable_count++;
+	if (!refcount_dec_and_test(&ruleset->refcount))
+		return;
+
+	prestera_acl_ruleset_destroy(ruleset);
 }
 
-void prestera_acl_block_disable_dec(struct prestera_flow_block *block)
+int prestera_acl_ruleset_bind(struct prestera_acl_ruleset *ruleset,
+			      struct prestera_port *port)
 {
-	if (block)
-		block->disable_count--;
+	struct prestera_acl_iface iface = {
+		.type = PRESTERA_ACL_IFACE_TYPE_PORT,
+		.port = port
+	};
+
+	return prestera_hw_vtcam_iface_bind(port->sw, &iface, ruleset->vtcam_id,
+					    ruleset->pcl_id);
 }
 
-bool prestera_acl_block_disabled(const struct prestera_flow_block *block)
+int prestera_acl_ruleset_unbind(struct prestera_acl_ruleset *ruleset,
+				struct prestera_port *port)
 {
-	return block->disable_count;
+	struct prestera_acl_iface iface = {
+		.type = PRESTERA_ACL_IFACE_TYPE_PORT,
+		.port = port
+	};
+
+	return prestera_hw_vtcam_iface_unbind(port->sw, &iface,
+					      ruleset->vtcam_id);
 }
 
-int prestera_acl_block_bind(struct prestera_switch *sw,
-			    struct prestera_flow_block *block,
-			    struct prestera_port *port)
+static int prestera_acl_ruleset_block_bind(struct prestera_acl_ruleset *ruleset,
+					   struct prestera_flow_block *block)
 {
 	struct prestera_flow_block_binding *binding;
 	int err;
 
-	if (WARN_ON(prestera_acl_block_lookup(block, port)))
-		return -EEXIST;
-
-	binding = kzalloc(sizeof(*binding), GFP_KERNEL);
-	if (!binding)
-		return -ENOMEM;
-	binding->span_id = PRESTERA_SPAN_INVALID_ID;
-	binding->port = port;
-
-	err = mvsw_pr_hw_acl_port_bind(port, block->ruleset->id);
-	if (err)
-		goto err_rules_bind;
-
-	list_add(&binding->list, &block->binding_list);
+	block->ruleset_zero = ruleset;
+	list_for_each_entry(binding, &block->binding_list, list) {
+		err = prestera_acl_ruleset_bind(ruleset, binding->port);
+		if (err)
+			goto rollback;
+	}
 	return 0;
 
-err_rules_bind:
-	kfree(binding);
+rollback:
+	list_for_each_entry_continue_reverse(binding, &block->binding_list,
+					     list)
+		err = prestera_acl_ruleset_unbind(ruleset, binding->port);
+	block->ruleset_zero = NULL;
+
 	return err;
 }
 
-int prestera_acl_block_unbind(struct prestera_switch *sw,
-			      struct prestera_flow_block *block,
-			      struct prestera_port *port)
+static void
+prestera_acl_ruleset_block_unbind(struct prestera_acl_ruleset *ruleset,
+				  struct prestera_flow_block *block)
 {
 	struct prestera_flow_block_binding *binding;
 
-	binding = prestera_acl_block_lookup(block, port);
-	if (!binding)
-		return -ENOENT;
+	list_for_each_entry(binding, &block->binding_list, list)
+		prestera_acl_ruleset_unbind(ruleset, binding->port);
+	block->ruleset_zero = NULL;
+}
+
+void prestera_acl_block_prio_update(struct prestera_switch *sw,
+				    struct prestera_flow_block *block)
+{
+	struct prestera_acl *acl = sw->acl;
+	struct prestera_acl_rule *rule;
+	u32 new_prio = UINT_MAX;
 
-	list_del(&binding->list);
+	list_for_each_entry(rule, &acl->rules, list) {
+		if (rule->priority < new_prio)
+			new_prio = rule->priority;
+	}
 
-	mvsw_pr_hw_acl_port_unbind(port, block->ruleset->id);
+	block->flower_min_prio = new_prio;
+}
 
-	kfree(binding);
-	return 0;
+unsigned int prestera_acl_block_rule_count(struct prestera_flow_block *block)
+{
+	return block ? block->rule_count : 0;
 }
 
-struct prestera_acl_ruleset *
-prestera_acl_block_ruleset_get(struct prestera_flow_block *block)
+void prestera_acl_block_disable_inc(struct prestera_flow_block *block)
 {
-	return block->ruleset;
+	if (block)
+		block->disable_count++;
+}
+
+void prestera_acl_block_disable_dec(struct prestera_flow_block *block)
+{
+	if (block)
+		block->disable_count--;
 }
 
-u16 prestera_acl_rule_ruleset_id_get(const struct prestera_acl_rule *rule)
+bool prestera_acl_block_disabled(const struct prestera_flow_block *block)
 {
-	return rule->block->ruleset->id;
+	return block->disable_count;
+}
+
+void
+prestera_acl_rule_keymask_pcl_id_set(struct prestera_acl_rule *rule, u16 pcl_id)
+{
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	__be16 pcl_id_mask = htons(PRESTERA_ACL_KEYMASK_PCL_ID);
+	__be16 pcl_id_key = htons(pcl_id);
+
+	rule_match_set(r_match->key, PCL_ID, pcl_id_key);
+	rule_match_set(r_match->mask, PCL_ID, pcl_id_mask);
 }
 
 struct net *prestera_acl_block_net(struct prestera_flow_block *block)
@@ -269,8 +474,18 @@ prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
 				      prestera_acl_rule_ht_params);
 }
 
+u32 prestera_acl_ruleset_index_get(const struct prestera_acl_ruleset *ruleset)
+{
+	return ruleset->index;
+}
+
+bool prestera_acl_ruleset_is_offload(struct prestera_acl_ruleset *ruleset)
+{
+	return ruleset->offload;
+}
+
 struct prestera_acl_rule *
-prestera_acl_rule_create(struct prestera_flow_block *block,
+prestera_acl_rule_create(struct prestera_acl_ruleset *ruleset,
 			 unsigned long cookie, u32 chain_index)
 {
 	struct prestera_acl_rule *rule;
@@ -279,61 +494,14 @@ prestera_acl_rule_create(struct prestera_flow_block *block,
 	if (!rule)
 		return ERR_PTR(-ENOMEM);
 
-	INIT_LIST_HEAD(&rule->match_list);
-	INIT_LIST_HEAD(&rule->action_list);
+	rule->ruleset = ruleset;
 	rule->cookie = cookie;
-	rule->block = block;
 	rule->chain_index = chain_index;
 	rule->hw_tc = PRESTERA_ACL_RULE_DEF_HW_TC;
 
-	return rule;
-}
-
-struct list_head *
-prestera_acl_rule_match_list_get(struct prestera_acl_rule *rule)
-{
-	return &rule->match_list;
-}
-
-static struct prestera_acl_rule_action_entry *
-prestera_acl_rule_action_lookup(struct prestera_acl_rule *rule,
-				enum prestera_acl_rule_action action)
-{
-	struct prestera_acl_rule_action_entry *a_entry;
-
-	list_for_each_entry(a_entry, &rule->action_list, list)
-		if (a_entry->info.id == action)
-			return a_entry;
+	refcount_inc(&ruleset->refcount);
 
-	return NULL;
-}
-
-struct list_head *
-prestera_acl_rule_action_list_get(struct prestera_acl_rule *rule)
-{
-	return &rule->action_list;
-}
-
-int prestera_acl_rule_action_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_action_entry *entry)
-{
-	struct prestera_acl_rule_action_entry *a_entry;
-
-	a_entry = kmalloc(sizeof(*a_entry), GFP_KERNEL);
-	if (!a_entry)
-		return -ENOMEM;
-
-	memcpy(a_entry, entry, sizeof(*entry));
-	list_add(&a_entry->list, &rule->action_list);
-	a_entry->rule = rule;
-
-	rule->n_actions++;
-	return 0;
-}
-
-u8 prestera_acl_rule_action_len(struct prestera_acl_rule *rule)
-{
-	return rule->n_actions;
+	return rule;
 }
 
 void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
@@ -349,11 +517,6 @@ prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
 	return test_bit(flag, &rule->attr.flags);
 }
 
-u32 prestera_acl_rule_priority_get(struct prestera_acl_rule *rule)
-{
-	return rule->priority;
-}
-
 void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
 				    u32 priority)
 {
@@ -369,23 +532,6 @@ void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc)
 {
 	rule->hw_tc = hw_tc;
 }
-void prestera_acl_rule_match_add(struct prestera_acl_rule *rule,
-				 struct prestera_acl_rule_match_entry *entry)
-{
-	list_add(&entry->list, &rule->match_list);
-	rule->n_matches++;
-}
-
-u8 prestera_acl_rule_match_len(struct prestera_acl_rule *rule)
-{
-	return rule->n_matches;
-}
-
-u32 prestera_acl_rule_chain_get(struct prestera_acl_rule *rule)
-{
-	/* TODO: chain (rule->chain_index) is not supported for user now */
-	return 0;
-}
 
 static int prestera_acl_nat_port_neigh_lookup(struct prestera_port *port,
 					      struct mvsw_pr_neigh_info *ni)
@@ -416,22 +562,14 @@ static int prestera_acl_nat_port_neigh_lookup(struct prestera_port *port,
 
 void prestera_acl_rule_destroy(struct prestera_acl_rule *rule)
 {
-	struct prestera_acl_rule_action_entry *a_entry;
-	struct prestera_acl_rule_match_entry *m_entry;
-	struct list_head *pos, *n;
-
-	list_for_each_safe(pos, n, &rule->match_list) {
-		m_entry = list_entry(pos, typeof(*m_entry), list);
-		list_del(pos);
-		kfree(m_entry);
-	}
-	list_for_each_safe(pos, n, &rule->action_list) {
-		a_entry = list_entry(pos, typeof(*a_entry), list);
-		list_del(pos);
-		kfree(a_entry);
-	}
 	if (rule->nat_port)
 		prestera_acl_nat_port_put(rule->nat_port);
+
+	if (rule->jump_ruleset)
+		/* release ruleset kept by jump action */
+		prestera_acl_ruleset_put(rule->jump_ruleset);
+
+	prestera_acl_ruleset_put(rule->ruleset);
 	kfree(rule);
 }
 
@@ -439,22 +577,26 @@ int prestera_acl_rule_add(struct prestera_switch *sw,
 			  struct prestera_acl_rule *rule)
 {
 	int err;
-	u32 rule_id;
-	struct prestera_acl_hw_match_info *matches = NULL;
-	struct prestera_acl_hw_action_info *actions = NULL;
+	struct prestera_acl_ruleset *ruleset = rule->ruleset;
+	struct prestera_flow_block *block = ruleset->ht_key.block;
 	struct prestera_flow_block_binding *binding;
 	struct prestera_acl_nat_port *nat_port;
 	struct mvsw_pr_neigh_info n_info;
-	u8 n_matches, n_actions, i;
-	struct prestera_acl_rule_action_entry *a_entry;
-	struct prestera_acl_rule_match_entry *m_entry;
+
+	err = rule_flag_test(rule, CT) && rule_flag_test(rule, GOTO) ?
+	      -ENOTSUPP : 0;
+	if (err)
+		goto err_sanity;
 
 	/* try to add rule to hash table first */
-	err = rhashtable_insert_fast(&rule->block->ruleset->rule_ht,
-				     &rule->ht_node,
+	err = rhashtable_insert_fast(&ruleset->rule_ht, &rule->ht_node,
 				     prestera_acl_rule_ht_params);
 	if (err)
-		return err;
+		goto err_ht_insert;
+
+	prestera_acl_rule_keymask_pcl_id_set(rule, ruleset->pcl_id);
+	rule->re_arg.vtcam_id = ruleset->vtcam_id;
+	rule->re_key.prio = rule->priority;
 
 	if (rule_flag_test(rule, CT)) {
 		err = prestera_ct_ft_offload_add_cb(sw, rule);
@@ -464,44 +606,18 @@ int prestera_acl_rule_add(struct prestera_switch *sw,
 		goto hw_handled;
 	}
 
-	if (rule_flag_test(rule, GOTO))
-		goto err_rule_add;
-
-	n_actions = prestera_acl_rule_action_len(rule);
-	n_matches = prestera_acl_rule_match_len(rule);
-	matches = kcalloc(n_matches, sizeof(*matches), GFP_KERNEL);
-	actions = kcalloc(n_actions, sizeof(*actions), GFP_KERNEL);
-	if (!matches || !actions)
+	rule->re = prestera_acl_rule_entry_find(sw->acl, &rule->re_key);
+	err = WARN_ON(rule->re) ? -EEXIST : 0;
+	if (err)
 		goto err_rule_add;
 
-	i = 0;
-	list_for_each_entry(m_entry, prestera_acl_rule_match_list_get(rule),
-			    list) {
-		matches[i] = m_entry->info;
-		i++;
-	}
-
-	i = 0;
-	list_for_each_entry(a_entry, prestera_acl_rule_action_list_get(rule),
-			    list) {
-		actions[i] = a_entry->info;
-		i++;
-	}
-
-	err = mvsw_pr_hw_acl_rule_add(sw,
-				      prestera_acl_rule_ruleset_id_get(rule),
-				      prestera_acl_rule_chain_get(rule),
-				      prestera_acl_rule_priority_get(rule),
-				      prestera_acl_rule_hw_tc_get(rule),
-				      n_matches, matches, n_actions, actions,
-				      &rule_id);
+	rule->re = prestera_acl_rule_entry_create(sw->acl, &rule->re_key,
+						  &rule->re_arg);
+	err = !rule->re ? -EINVAL : 0;
 	if (err)
 		goto err_rule_add;
 
-	rule->id = rule_id;
-
-	if (!prestera_acl_rule_action_lookup
-	    (rule, MVSW_ACL_RULE_ACTION_NAT))
+	if (!rule_flag_test(rule, NAT))
 		goto nat_port_neigh_not_found;
 
 	/* TODO: assign port to NAT here instead of doing this in
@@ -510,14 +626,15 @@ int prestera_acl_rule_add(struct prestera_switch *sw,
 	 * Get first interface bound to the block same as
 	 * in NAT action for now
 	 */
-	binding = list_first_entry(&rule->block->binding_list,
+	binding = list_first_entry(&block->binding_list,
 				   struct prestera_flow_block_binding, list);
 	nat_port = prestera_acl_nat_port_get(sw->acl, binding->port->hw_id,
 					     binding->port->dev_id);
 	if (!nat_port) {
 		nat_port = prestera_acl_nat_port_create(sw->acl, binding->port);
 		MVSW_LOG_INFO("NAT port created");
-		if (!nat_port)
+		err = !nat_port ? -EINVAL : 0;
+		if (err)
 			goto err_rule_add_nat;
 	}
 	rule->nat_port = nat_port;
@@ -538,39 +655,82 @@ int prestera_acl_rule_add(struct prestera_switch *sw,
 
 hw_handled:
 nat_port_neigh_not_found:
-	list_add_tail(&rule->list, &sw->acl->rules);
-	rule->block->rule_count++;
+	/* bind the block (all ports) to chain index 0, rest of
+	 * the chains are bound to goto action
+	 */
+	if (!ruleset->ht_key.chain_index && !ruleset->rule_count) {
+		err = prestera_acl_ruleset_block_bind(ruleset, block);
+		if (err)
+			goto err_acl_block_bind;
+	}
 
+	list_add_tail(&rule->list, &sw->acl->rules);
+	ruleset->ht_key.block->rule_count++;
+	ruleset->rule_count++;
 	return 0;
 
+err_acl_block_bind:
 err_rule_add_nat:
-	mvsw_pr_hw_acl_rule_del(sw, rule->chain_index, rule->id);
+	prestera_acl_rule_entry_destroy(sw->acl, rule->re);
 err_rule_add:
-	kfree(matches);
-	kfree(actions);
-	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
+	rule->re = NULL;
+	rhashtable_remove_fast(&ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
+err_ht_insert:
+err_sanity:
 	return err;
 }
 
 void prestera_acl_rule_del(struct prestera_switch *sw,
 			   struct prestera_acl_rule *rule)
 {
-	rhashtable_remove_fast(&rule->block->ruleset->rule_ht, &rule->ht_node,
+	struct prestera_acl_ruleset *ruleset = rule->ruleset;
+	struct prestera_flow_block *block = ruleset->ht_key.block;
+
+	rhashtable_remove_fast(&ruleset->rule_ht, &rule->ht_node,
 			       prestera_acl_rule_ht_params);
-	rule->block->rule_count--;
+	block->rule_count--;
+	ruleset->rule_count--;
 	list_del(&rule->list);
 
 	if (rule_flag_test(rule, CT)) {
 		prestera_ct_ft_offload_del_cb(sw, rule);
 	} else {
-		/* TODO: use prestera_acl_rule_chain_get ? */
-		mvsw_pr_hw_acl_rule_del(sw, rule->chain_index, rule->id);
-		prestera_acl_block_prio_update(sw, rule->block);
+		prestera_acl_rule_entry_destroy(sw->acl, rule->re);
+		prestera_acl_block_prio_update(sw, block);
 	}
+
+	/* unbind block (all ports) */
+	if (!ruleset->ht_key.chain_index && !ruleset->rule_count)
+		prestera_acl_ruleset_block_unbind(ruleset, block);
 }
 
-int prestera_acl_rule_get_stats(struct prestera_switch *sw,
+static void prestera_acl_rule_stats_update(struct work_struct *work)
+{
+	struct delayed_work *dl_work =
+		container_of(work, struct delayed_work, work);
+	struct prestera_acl *acl =
+		container_of(dl_work, struct prestera_acl,
+			     stats_dw);
+	int bulk_id, idx;
+
+	for (bulk_id = 0; bulk_id < ACL_STATS_BULK_COUNT; bulk_id++) {
+		if (!prestera_acl_stats_bulk_refcount_test(bulk_id))
+			continue;
+
+		idx = bulk_id * ACL_STATS_BULK_SIZE;
+
+		mutex_lock(&acl_stats_lock);
+		mvsw_pr_hw_acl_rule_stats_get(acl->sw, idx,
+					      ACL_STATS_BULK_SIZE,
+					      &acl->stats[idx]);
+		mutex_unlock(&acl_stats_lock);
+	}
+
+	schedule_delayed_work(&acl->stats_dw, ACL_STATS_POLL_TIMEOUT_MS);
+}
+
+int prestera_acl_rule_get_stats(struct prestera_acl *acl,
 				struct prestera_acl_rule *rule,
 				u64 *packets, u64 *bytes, u64 *last_use)
 {
@@ -578,15 +738,9 @@ int prestera_acl_rule_get_stats(struct prestera_switch *sw,
 	u64 current_bytes;
 	int err;
 
-	if (rule_flag_test(rule, CT)) {
-		*last_use = jiffies;
-		*packets = 0;
-		*bytes = 0;
-		return 0;
-	}
-
-	err = mvsw_pr_hw_acl_rule_stats_get(sw, rule->id, &current_packets,
-					    &current_bytes);
+	err = prestera_acl_rule_entry_util_stats(acl, rule->re,
+						 &current_packets,
+						 &current_bytes);
 	if (err)
 		return err;
 
@@ -597,34 +751,598 @@ int prestera_acl_rule_get_stats(struct prestera_switch *sw,
 	return 0;
 }
 
+/* HW objects infrastructure */
+static struct prestera_nh_mangle_entry *
+__prestera_nh_mangle_entry_find(struct prestera_switch *sw,
+				struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+
+	e = rhashtable_lookup_fast(&sw->acl->nh_mangle_entry_ht, key,
+				   __prestera_nh_mangle_entry_ht_params);
+	return IS_ERR(e) ? NULL : e;
+}
+
+static void
+__prestera_nh_mangle_entry_destroy(struct prestera_switch *sw,
+				   struct prestera_nh_mangle_entry *e)
+{
+	rhashtable_remove_fast(&sw->acl->nh_mangle_entry_ht, &e->ht_node,
+			       __prestera_nh_mangle_entry_ht_params);
+	list_del(&e->nh_neigh_head);
+	mvsw_pr_nh_neigh_put(sw, e->n);
+	WARN_ON(prestera_hw_nh_mangle_del(sw, e->hw_id));
+	kfree(e);
+}
+
+int prestera_nh_mangle_entry_set(struct prestera_switch *sw,
+				 struct prestera_nh_mangle_entry *e)
+{
+	return prestera_hw_nh_mangle_set(sw, e->hw_id,
+					 e->key.mangle.l4_src_valid,
+					 e->key.mangle.l4_src,
+					 e->key.mangle.l4_dst_valid,
+					 e->key.mangle.l4_dst,
+					 e->key.mangle.sip_valid,
+					 e->key.mangle.sip,
+					 e->key.mangle.dip_valid,
+					 e->key.mangle.dip,
+					 e->n->info);
+}
+
+static struct prestera_nh_mangle_entry *
+__prestera_nh_mangle_entry_create(struct prestera_switch *sw,
+				  struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+	int err;
+
+	e = kzalloc(sizeof(*e), GFP_KERNEL);
+	if (!e)
+		goto err_kzalloc;
+
+	memcpy(&e->key, key, sizeof(*key));
+	e->n = mvsw_pr_nh_neigh_get(sw, &e->key.n);
+	if (!e->n)
+		goto err_nh_get;
+
+	list_add(&e->nh_neigh_head, &e->n->nh_mangle_entry_list);
+
+	err = prestera_hw_nh_mangle_add(sw, &e->hw_id);
+	if (err)
+		goto err_hw_add;
+
+	err = prestera_nh_mangle_entry_set(sw, e);
+	if (err)
+		goto err_set;
+
+	err = rhashtable_insert_fast(&sw->acl->nh_mangle_entry_ht, &e->ht_node,
+				     __prestera_nh_mangle_entry_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	return e;
+
+err_ht_insert:
+err_set:
+	WARN_ON(prestera_hw_nh_mangle_del(sw, e->hw_id));
+err_hw_add:
+	list_del(&e->nh_neigh_head);
+	mvsw_pr_nh_neigh_put(sw, e->n);
+err_nh_get:
+	kfree(e);
+err_kzalloc:
+	return NULL;
+}
+
+static void prestera_nh_mangle_entry_put(struct prestera_switch *sw,
+					 struct prestera_nh_mangle_entry *e)
+{
+	if (!e->ref_cnt)
+		__prestera_nh_mangle_entry_destroy(sw, e);
+}
+
+static struct prestera_nh_mangle_entry *
+prestera_nh_mangle_entry_get(struct prestera_switch *sw,
+			     struct prestera_nh_mangle_entry_key *key)
+{
+	struct prestera_nh_mangle_entry *e;
+
+	e = __prestera_nh_mangle_entry_find(sw, key);
+	if (!e)
+		e = __prestera_nh_mangle_entry_create(sw, key);
+
+	return e;
+}
+
+bool prestera_nh_mangle_entry_util_hw_state(struct prestera_switch *sw,
+					    struct prestera_nh_mangle_entry *e)
+{
+	int err;
+
+	/* Antijitter
+	 * Prevent situation, when we read state of nh_grp twice in short time,
+	 * and state bit is still cleared on second call. So just stuck active
+	 * state for MVSW_PR_NH_ACTIVE_JIFFER_FILTER, after last occurred.
+	 */
+	if (!time_before(jiffies, e->is_active_hw_cache_kick +
+			msecs_to_jiffies(MVSW_PR_NH_ACTIVE_JIFFER_FILTER))) {
+		err = prestera_hw_nh_mangle_get(sw, e->hw_id,
+						&e->is_active_hw_cache);
+		if (err) {
+			MVSW_LOG_ERROR("Failed to get nh_mangle %pI4n hw_state",
+				       &e->key.n.addr.u.ipv4);
+			return false;
+		}
+
+		e->is_active_hw_cache_kick = jiffies;
+	}
+
+	return e->is_active_hw_cache;
+}
+
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_find(struct prestera_acl *acl,
+			     struct prestera_acl_rule_entry_key *key)
+{
+	struct prestera_acl_rule_entry *e;
+
+	e = rhashtable_lookup_fast(&acl->acl_rule_entry_ht, key,
+				   __prestera_acl_rule_entry_ht_params);
+	return IS_ERR(e) ? NULL : e;
+}
+
+static int __prestera_acl_rule_entry2hw_del(struct prestera_switch *sw,
+					    struct prestera_acl_rule_entry *e)
+{
+	return prestera_hw_vtcam_rule_del(sw, e->vtcam_id, e->hw_id);
+}
+
+static int __prestera_acl_rule_entry2hw_add(struct prestera_switch *sw,
+					    struct prestera_acl_rule_entry *e)
+{
+	struct prestera_acl_hw_action_info act_hw[PRESTERA_ACL_ACTION_MAX];
+	int act_num;
+
+	memset(&act_hw, 0, sizeof(act_hw));
+	act_num = 0;
+
+	/* accept */
+	if (e->accept.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_ACCEPT;
+		act_num++;
+	}
+	/* drop */
+	if (e->drop.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_DROP;
+		act_num++;
+	}
+	/* trap */
+	if (e->trap.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_TRAP;
+		act_hw[act_num].trap = e->trap.i;
+		act_num++;
+	}
+	/* police */
+	if (e->police.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_POLICE;
+		act_hw[act_num].police = e->police.i;
+		act_num++;
+	}
+	/* nat */
+	if (e->nat.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_NAT;
+		act_hw[act_num].nat = e->nat.i;
+		act_num++;
+	}
+	/* jump */
+	if (e->jump.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_JUMP;
+		act_hw[act_num].jump = e->jump.i;
+		act_num++;
+	}
+	/* nh */
+	if (e->nh.valid) {
+		act_hw[act_num].id = MVSW_ACL_RULE_ACTION_NH;
+		act_hw[act_num].nh = e->nh.e->hw_id;
+		act_num++;
+	}
+
+	return prestera_hw_vtcam_rule_add(sw, e->vtcam_id, e->key.prio,
+					  e->key.match.key, e->key.match.mask,
+					  act_hw, act_num, &e->hw_id,
+					  &e->counter_id);
+}
+
+static void
+__prestera_acl_rule_entry_act_destruct(struct prestera_switch *sw,
+				       struct prestera_acl_rule_entry *e)
+{
+	/* nh */
+	if (e->nh.valid) {
+		e->nh.e->ref_cnt--;
+		prestera_nh_mangle_entry_put(sw, e->nh.e);
+	}
+}
+
+int prestera_acl_rule_entry_set(struct prestera_acl *acl,
+				struct prestera_acl_rule_entry *e,
+				bool enable)
+{
+	return prestera_hw_vtcam_rule_set(acl->sw, e->vtcam_id, e->hw_id,
+					  enable);
+}
+
+void prestera_acl_rule_entry_destroy(struct prestera_acl *acl,
+				     struct prestera_acl_rule_entry *e)
+{
+	rhashtable_remove_fast(&acl->acl_rule_entry_ht, &e->ht_node,
+			       __prestera_acl_rule_entry_ht_params);
+	WARN_ON(__prestera_acl_rule_entry2hw_del(acl->sw, e));
+	__prestera_acl_rule_entry_act_destruct(acl->sw, e);
+	prestera_acl_stats_refcount_dec(e->counter_id);
+	kfree(e);
+}
+
+static int
+__prestera_acl_rule_entry_act_construct(struct prestera_switch *sw,
+					struct prestera_acl_rule_entry *e,
+					struct prestera_acl_rule_entry_arg *arg)
+{
+	/* accept */
+	e->accept.valid = arg->accept.valid;
+	/* drop */
+	e->drop.valid = arg->drop.valid;
+	/* trap */
+	e->trap.valid = arg->trap.valid;
+	e->trap.i = arg->trap.i;
+	/* police */
+	e->police.valid = arg->police.valid;
+	e->police.i = arg->police.i;
+	/* nat */
+	e->nat.valid = arg->nat.valid;
+	e->nat.i = arg->nat.i;
+	/* jump */
+	e->jump.valid = arg->jump.valid;
+	e->jump.i = arg->jump.i;
+	/* nh */
+	if (arg->nh.valid) {
+		e->nh.e = prestera_nh_mangle_entry_get(sw, &arg->nh.k);
+		if (!e->nh.e)
+			goto err_out;
+
+		e->nh.e->ref_cnt++;
+		e->nh.valid = 1;
+	}
+
+	return 0;
+
+err_out:
+	__prestera_acl_rule_entry_act_destruct(sw, e);
+	return -EINVAL;
+}
+
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_create(struct prestera_acl *acl,
+			       struct prestera_acl_rule_entry_key *key,
+			       struct prestera_acl_rule_entry_arg *arg)
+{
+	struct prestera_acl_rule_entry *e;
+	int err;
+
+	e = kzalloc(sizeof(*e), GFP_KERNEL);
+	if (!e)
+		goto err_kzalloc;
+
+	memcpy(&e->key, key, sizeof(*key));
+	e->vtcam_id = arg->vtcam_id;
+	err = __prestera_acl_rule_entry_act_construct(acl->sw, e, arg);
+	if (err)
+		goto err_act_construct;
+
+	err = __prestera_acl_rule_entry2hw_add(acl->sw, e);
+	if (err)
+		goto err_hw_add;
+
+	err = rhashtable_insert_fast(&acl->acl_rule_entry_ht, &e->ht_node,
+				     __prestera_acl_rule_entry_ht_params);
+	if (err)
+		goto err_ht_insert;
+
+	prestera_acl_stats_clear(acl, e->counter_id);
+	prestera_acl_stats_refcount_inc(e->counter_id);
+
+	return e;
+
+err_ht_insert:
+	WARN_ON(__prestera_acl_rule_entry2hw_del(acl->sw, e));
+err_hw_add:
+	__prestera_acl_rule_entry_act_destruct(acl->sw, e);
+err_act_construct:
+	kfree(e);
+err_kzalloc:
+	return NULL;
+}
+
+/* Can be executed without rtnl_lock().
+ * So pay attention when something changing.
+ */
+int prestera_acl_rule_entry_util_stats(struct prestera_acl *acl,
+				       struct prestera_acl_rule_entry *e,
+				       u64 *packets, u64 *bytes)
+{
+	if (e->counter_id >= ACL_STATS_COUNT) {
+		*packets = 0;
+		*bytes = 0;
+		return 0;
+	}
+
+	mutex_lock(&acl_stats_lock);
+	*packets = acl->stats[e->counter_id].packets;
+	*bytes = acl->stats[e->counter_id].bytes;
+
+	prestera_acl_stats_clear(acl, e->counter_id);
+	mutex_unlock(&acl_stats_lock);
+
+	return 0;
+}
+
+int prestera_acl_uid_new_get(struct prestera_acl *acl, u8 *uid)
+{
+	struct prestera_acl_uid_entry *uid_entry;
+
+	uid_entry = list_first_entry_or_null(&acl->uid.free_list,
+					     typeof(*uid_entry), list);
+	if (uid_entry) {
+		list_del(&uid_entry->list);
+		*uid = uid_entry->id;
+		kfree(uid_entry);
+		return 0;
+	}
+
+	if (!(acl->uid.next + 1))
+		/* max number reached */
+		return -ENOENT;
+
+	*uid = acl->uid.next++;
+	return 0;
+}
+
+int prestera_acl_uid_release(struct prestera_acl *acl, u8 id)
+{
+	struct prestera_acl_uid_entry *uid_entry;
+
+	if (!(id < acl->uid.next))
+		return -EINVAL;
+
+	uid_entry = kmalloc(sizeof(*uid_entry), GFP_KERNEL);
+	if (!uid_entry)
+		return -ENOMEM;
+
+	uid_entry->id = id;
+	list_add_rcu(&uid_entry->list, &acl->uid.free_list);
+
+	return 0;
+}
+
+static void prestera_acl_uid_destroy(struct prestera_acl *acl)
+{
+	struct prestera_acl_uid_entry *uid_entry;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &acl->uid.free_list) {
+		uid_entry = list_entry(pos, typeof(*uid_entry), list);
+		list_del(&uid_entry->list);
+		kfree(uid_entry);
+	}
+}
+
+static int __prestera_acl_vtcam_id_try_fit(struct prestera_acl *acl, u8 lookup,
+					   void *keymask, u32 *vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	int i;
+
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (lookup != vtcam->lookup)
+			continue;
+
+		if (!keymask && !vtcam->is_keymask_set)
+			goto vtcam_found;
+
+		if (!(keymask && vtcam->is_keymask_set))
+			continue;
+
+		/* try to fit with vtcam keymask */
+		for (i = 0; i < __PRESTERA_ACL_RULE_MATCH_TYPE_MAX; i++) {
+			__be32 __keymask = ((__be32 *)keymask)[i];
+
+			if (!__keymask)
+				/* vtcam keymask in not interested */
+				continue;
+
+			if (__keymask & ~vtcam->keymask[i])
+				/* keymask does not fit the vtcam keymask */
+				break;
+		}
+
+		if (i == __PRESTERA_ACL_RULE_MATCH_TYPE_MAX)
+			/* keymask fits vtcam keymask, return it */
+			goto vtcam_found;
+	}
+
+	/* nothing is found */
+	return -ENOENT;
+
+vtcam_found:
+	refcount_inc(&vtcam->refcount);
+	*vtcam_id = vtcam->id;
+	return 0;
+}
+
+int prestera_acl_vtcam_id_get(struct prestera_acl *acl, u8 lookup,
+			      void *keymask, u32 *vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	u32 new_vtcam_id;
+	int err;
+
+	/* find the vtcam that suits keymask. We do not expect to have
+	 * a big number of vtcams, so, the list type for vtcam list is
+	 * fine for now
+	 */
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (lookup != vtcam->lookup)
+			continue;
+
+		if (!keymask && !vtcam->is_keymask_set) {
+			refcount_inc(&vtcam->refcount);
+			goto vtcam_found;
+		}
+
+		if (keymask && vtcam->is_keymask_set &&
+		    !memcmp(keymask, vtcam->keymask, sizeof(vtcam->keymask))) {
+			refcount_inc(&vtcam->refcount);
+			goto vtcam_found;
+		}
+	}
+
+	/* vtcam not found, try to create new one */
+	vtcam = kzalloc(sizeof(*vtcam), GFP_KERNEL);
+	if (!vtcam)
+		return -ENOMEM;
+
+	err = prestera_hw_vtcam_create(acl->sw, lookup, keymask, &new_vtcam_id);
+	if (err) {
+		kfree(vtcam);
+
+		/* cannot create new, try to fit into existing vtcam */
+		if (__prestera_acl_vtcam_id_try_fit(acl, lookup,
+						    keymask, &new_vtcam_id))
+			return err;
+
+		*vtcam_id = new_vtcam_id;
+		return 0;
+	}
+
+	vtcam->id = new_vtcam_id;
+	vtcam->lookup = lookup;
+	if (keymask) {
+		memcpy(vtcam->keymask, keymask, sizeof(vtcam->keymask));
+		vtcam->is_keymask_set = true;
+	}
+	refcount_set(&vtcam->refcount, 1);
+	list_add_rcu(&vtcam->list, &acl->vtcam_list);
+
+vtcam_found:
+	*vtcam_id = vtcam->id;
+	return 0;
+}
+
+int prestera_acl_vtcam_id_put(struct prestera_acl *acl, u32 vtcam_id)
+{
+	struct prestera_acl_vtcam *vtcam;
+	int err;
+
+	list_for_each_entry(vtcam, &acl->vtcam_list, list) {
+		if (vtcam_id != vtcam->id)
+			continue;
+
+		if (!refcount_dec_and_test(&vtcam->refcount))
+			return 0;
+
+		err = prestera_hw_vtcam_destroy(acl->sw, vtcam->id);
+		if (err) {
+			refcount_set(&vtcam->refcount, 1);
+			return err;
+		}
+
+		list_del(&vtcam->list);
+		kfree(vtcam);
+		return 0;
+	}
+
+	return -ENOENT;
+}
+
 int prestera_acl_init(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl;
+	int err;
 
 	acl = kzalloc(sizeof(*acl), GFP_KERNEL);
 	if (!acl)
 		return -ENOMEM;
 
-	acl->ct_priv = prestera_ct_init(sw);
-	if (IS_ERR(acl->ct_priv)) {
-		kfree(acl);
-		return PTR_ERR(acl->ct_priv);
-	}
+	acl->stats = kzalloc(sizeof(*acl->stats) * ACL_STATS_COUNT,
+			     GFP_KERNEL);
+	if (!acl->stats)
+		return -ENOMEM;
 
+	acl->sw = sw;
+	mutex_init(&acl_stats_lock);
 	INIT_LIST_HEAD(&acl->rules);
 	INIT_LIST_HEAD(&acl->nat_port_list);
+	INIT_LIST_HEAD(&acl->vtcam_list);
+	INIT_LIST_HEAD(&acl->uid.free_list);
+	INIT_DELAYED_WORK(&acl->stats_dw, prestera_acl_rule_stats_update);
+
+	err = rhashtable_init(&acl->acl_rule_entry_ht,
+			      &__prestera_acl_rule_entry_ht_params);
+	if (err)
+		goto err_acl_rule_entry_ht_init;
+
+	err = rhashtable_init(&acl->nh_mangle_entry_ht,
+			      &__prestera_nh_mangle_entry_ht_params);
+	if (err)
+		goto err_nh_mangle_entry_ht_init;
+
+	err = rhashtable_init(&acl->ruleset_ht,
+			      &prestera_acl_ruleset_ht_params);
+	if (err)
+		goto err_ruleset_ht_init;
+
+	acl->ct_priv = prestera_ct_init(acl);
+	if (IS_ERR(acl->ct_priv)) {
+		err = PTR_ERR(acl->ct_priv);
+		goto err_ct_init;
+	}
+
 	sw->acl = acl;
-	acl->sw = sw;
+
+	schedule_delayed_work(&acl->stats_dw, ACL_STATS_POLL_TIMEOUT_MS);
 
 	return 0;
+
+err_ct_init:
+	rhashtable_destroy(&acl->ruleset_ht);
+err_ruleset_ht_init:
+	rhashtable_destroy(&acl->nh_mangle_entry_ht);
+err_nh_mangle_entry_ht_init:
+	rhashtable_destroy(&acl->acl_rule_entry_ht);
+err_acl_rule_entry_ht_init:
+	kfree(acl);
+	return err;
 }
 
 void prestera_acl_fini(struct prestera_switch *sw)
 {
 	struct prestera_acl *acl = sw->acl;
 
+	cancel_delayed_work_sync(&acl->stats_dw);
+	mutex_destroy(&acl_stats_lock);
+
+	prestera_ct_clean(acl->ct_priv);
+	prestera_acl_uid_destroy(acl);
+
+	WARN_ON(!list_empty(&acl->vtcam_list));
 	WARN_ON(!list_empty(&acl->nat_port_list));
 	WARN_ON(!list_empty(&acl->rules));
-	prestera_ct_clean(acl->ct_priv);
+
+	rhashtable_destroy(&acl->ruleset_ht);
+	rhashtable_destroy(&acl->nh_mangle_entry_ht);
+	rhashtable_destroy(&acl->acl_rule_entry_ht);
+
+	kfree(acl->stats);
 	kfree(acl);
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_acl.h b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
index a76ae1e..fc695e2 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_acl.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_acl.h
@@ -8,26 +8,173 @@
 #define _PRESTERA_ACL_H_
 
 #include <linux/types.h>
+#include "prestera_ct.h"
 
 #define PRESTERA_ACL_RULE_DEF_HW_TC		3
 #define PRESTERA_ACL_RULE_DEF_HW_CHAIN_ID	0
-#define PRESTERA_ACL_RULESET_ALL		0xff
+
+#define PRESTERA_ACL_KEYMASK_PCL_ID		0x3FF
+#define PRESTERA_ACL_KEYMASK_PCL_ID_USER	0xFF
+#define PRESTERA_ACL_KEYMASK_PCL_ID_CHAIN	0x0300
+#define PRESTERA_ACL_PCL_ID_MAKE(uid, chain_id)			\
+	(((uid) & PRESTERA_ACL_KEYMASK_PCL_ID_USER) |		\
+	(((chain_id) << 8) & PRESTERA_ACL_KEYMASK_PCL_ID_CHAIN))
 
 #define rule_flag_set(rule, flag) \
 	prestera_acl_rule_flag_set(rule, PRESTERA_ACL_RULE_FLAG_##flag)
 #define rule_flag_test(rule, flag) \
 	prestera_acl_rule_flag_test(rule, PRESTERA_ACL_RULE_FLAG_##flag)
 
+#define rule_match_set_n(match_p, type, val_p, size)		\
+	memcpy(&(match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type],	\
+	       val_p, size)
+#define rule_match_set(match_p, type, val)			\
+	memcpy(&(match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type],	\
+	       &(val), sizeof(val))
+#define rule_match_set_u32(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       htonl(val))
+#define rule_match_set_u16(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       (__force __be32)htons(val))
+#define rule_match_set_u8(match_p, type, val)			\
+	((match_p)[PRESTERA_ACL_RULE_MATCH_TYPE_##type] =	\
+	       (__force __be32)(val))
+#define rule_match_get_u32(match_p, type)			\
+	(match_p[PRESTERA_ACL_RULE_MATCH_TYPE_##type])
+
+#define MVSW_PR_NH_ACTIVE_JIFFER_FILTER 3000 /* ms */
+#define PRESTERA_ACL_RULE_DEF_HW_TC	3
+#define MVSW_ACL_RULE_DEF_HW_CHAIN_ID	0
+#define MVSW_ACL_RULESET_ALL		0xff
+
+#define PRESTERA_ACL_ACTION_MAX 8
+
+/* HW objects infrastructure */
+struct prestera_mangle_cfg {
+	u8 l4_src_valid:1, l4_dst_valid:1,
+	   sip_valid:1, dip_valid:1;
+	__be16 l4_src;
+	__be16 l4_dst;
+	struct mvsw_pr_ip_addr sip;
+	struct mvsw_pr_ip_addr dip;
+};
+
+/* TODO: Move mangle_entry to router ? */
+struct prestera_nh_mangle_entry {
+	struct rhash_head ht_node; /* node of prestera_router */
+	struct prestera_nh_mangle_entry_key {
+		struct prestera_mangle_cfg mangle;
+		struct mvsw_pr_nh_neigh_key n;
+	} key;
+	struct mvsw_pr_nh_neigh *n;
+	u32 hw_id;
+	unsigned long is_active_hw_cache_kick; /* jiffies */
+	bool is_active_hw_cache;
+	u32 ref_cnt;
+	struct list_head nh_neigh_head;
+};
+
+struct prestera_acl_rule_entry {
+	struct rhash_head ht_node; /* node of prestera_sw */
+	struct prestera_acl_rule_entry_key {
+		u32 prio;
+		struct prestera_acl_match match;
+	} key;
+	u32 hw_id;
+	u32 vtcam_id;
+	u32 counter_id;
+	/* This struct seems to be dublicate of arg, but purpose is to pass
+	 * in cfg objet keys, resolve them and save object links here.
+	 * E.g. chain can be link to object, when chain_id just key in cfg.
+	 */
+	struct {
+		struct {
+			u8 valid:1;
+		} accept, drop;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_trap i;
+		} trap;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_police i;
+		} police;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_nat i;
+		} nat;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_jump i;
+		} jump;
+		struct {
+			u8 valid:1;
+			struct prestera_nh_mangle_entry *e; /* entry */
+		} nh;
+	};
+};
+
+/* This struct (arg) used only to be passed as parameter for
+ * acl_rule_entry_create. Must be flat. Can contain object keys, which will be
+ * resolved to object links, before saving to acl_rule_entry struct
+ */
+struct prestera_acl_rule_entry_arg {
+	u32 vtcam_id;
+	struct {
+		struct {
+			u8 valid:1;
+		} accept, drop;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_trap i;
+		} trap;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_police i;
+		} police;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_nat i;
+		} nat;
+		struct {
+			u8 valid:1;
+			struct prestera_acl_action_jump i;
+		} jump;
+		struct {
+			u8 valid:1;
+			struct prestera_nh_mangle_entry_key k; /* key */
+		} nh;
+	};
+};
+
 enum {
 	PRESTERA_ACL_RULE_FLAG_CT,
-	PRESTERA_ACL_RULE_FLAG_GOTO
+	PRESTERA_ACL_RULE_FLAG_GOTO,
+	PRESTERA_ACL_RULE_FLAG_NAT
+};
+
+struct prestera_acl_stats {
+	u64 packets;
+	u64 bytes;
 };
 
 struct prestera_acl {
 	struct prestera_switch *sw;
 	struct list_head nat_port_list;
+	struct list_head vtcam_list;
 	struct list_head rules;
+	struct rhashtable ruleset_ht;
+	struct rhashtable acl_rule_entry_ht;
+	/* TODO: move nh_mangle_entry_ht to router ? */
+	struct rhashtable nh_mangle_entry_ht;
 	struct prestera_ct_priv *ct_priv;
+	struct delayed_work stats_dw;
+	struct prestera_acl_stats *stats;
+	struct {
+		struct list_head free_list;
+		u8 next;
+	} uid;
 };
 
 struct prestera_acl_nat_port {
@@ -44,18 +191,30 @@ struct prestera_acl_rule_attr {
 struct prestera_acl_rule {
 	struct rhash_head ht_node; /* Member of acl HT */
 	struct list_head list;
-	struct list_head match_list;
-	struct list_head action_list;
-	struct prestera_flow_block *block;
 	struct prestera_acl_nat_port *nat_port;
 	struct prestera_acl_rule_attr attr;
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl_ruleset *jump_ruleset;
 	unsigned long cookie;
 	u32 chain_index;
 	u32 priority;
-	u8 n_actions;
-	u8 n_matches;
 	u8 hw_tc;
-	u32 id;
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_rule_entry *re;
+};
+
+enum {
+	PRESTERA_ACL_IFACE_TYPE_PORT,
+	PRESTERA_ACL_IFACE_TYPE_INDEX
+};
+
+struct prestera_acl_iface {
+	u8 type;
+	union {
+		struct prestera_port *port;
+		u32 index;
+	};
 };
 
 void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
@@ -63,5 +222,72 @@ void prestera_acl_rule_flag_set(struct prestera_acl_rule *rule,
 bool
 prestera_acl_rule_flag_test(const struct prestera_acl_rule *rule,
 			    unsigned long flag);
+struct prestera_acl_rule *
+prestera_acl_rule_create(struct prestera_acl_ruleset *ruleset,
+			 unsigned long cookie, u32 chain_index);
+void prestera_acl_rule_priority_set(struct prestera_acl_rule *rule,
+				    u32 priority);
+u8 prestera_acl_rule_hw_tc_get(struct prestera_acl_rule *rule);
+void prestera_acl_rule_hw_tc_set(struct prestera_acl_rule *rule, u8 hw_tc);
+u8 prestera_acl_rule_hw_chain_id_get(const struct prestera_acl_rule *rule);
+void prestera_acl_rule_destroy(struct prestera_acl_rule *rule);
+struct prestera_acl_rule *
+prestera_acl_rule_lookup(struct prestera_acl_ruleset *ruleset,
+			 unsigned long cookie);
+int prestera_acl_rule_add(struct prestera_switch *sw,
+			  struct prestera_acl_rule *rule);
+void prestera_acl_rule_del(struct prestera_switch *sw,
+			   struct prestera_acl_rule *rule);
+int prestera_acl_rule_get_stats(struct prestera_acl *acl,
+				struct prestera_acl_rule *rule,
+				u64 *packets, u64 *bytes, u64 *last_use);
+
+int prestera_nh_mangle_entry_set(struct prestera_switch *sw,
+				 struct prestera_nh_mangle_entry *e);
+bool prestera_nh_mangle_entry_util_hw_state(struct prestera_switch *sw,
+					    struct prestera_nh_mangle_entry *e);
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_find(struct prestera_acl *acl,
+			     struct prestera_acl_rule_entry_key *key);
+void prestera_acl_rule_entry_destroy(struct prestera_acl *acl,
+				     struct prestera_acl_rule_entry *e);
+struct prestera_acl_rule_entry *
+prestera_acl_rule_entry_create(struct prestera_acl *acl,
+			       struct prestera_acl_rule_entry_key *key,
+			       struct prestera_acl_rule_entry_arg *arg);
+int prestera_acl_rule_entry_util_stats(struct prestera_acl *acl,
+				       struct prestera_acl_rule_entry *e,
+				       u64 *packets, u64 *bytes);
+int prestera_acl_rule_entry_set(struct prestera_acl *acl,
+				struct prestera_acl_rule_entry *e,
+				bool enable);
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_get(struct prestera_acl *acl,
+			 struct prestera_flow_block *block,
+			 u32 chain_index);
+struct prestera_acl_ruleset *
+prestera_acl_ruleset_lookup(struct prestera_acl *acl,
+			    struct prestera_flow_block *block,
+			    u32 chain_index);
+int prestera_acl_ruleset_keymask_set(struct prestera_acl_ruleset *ruleset,
+				     void *keymask);
+int prestera_acl_ruleset_offload(struct prestera_acl_ruleset *ruleset);
+u32 prestera_acl_ruleset_index_get(const struct prestera_acl_ruleset *ruleset);
+bool prestera_acl_ruleset_is_offload(struct prestera_acl_ruleset *ruleset);
+void prestera_acl_ruleset_put(struct prestera_acl_ruleset *ruleset);
+int prestera_acl_ruleset_bind(struct prestera_acl_ruleset *ruleset,
+			      struct prestera_port *port);
+int prestera_acl_ruleset_unbind(struct prestera_acl_ruleset *ruleset,
+				struct prestera_port *port);
+void
+prestera_acl_rule_keymask_pcl_id_set(struct prestera_acl_rule *rule,
+				     u16 pcl_id);
+
+int prestera_acl_uid_new_get(struct prestera_acl *acl, u8 *uid);
+int prestera_acl_uid_release(struct prestera_acl *acl, u8 uid);
+
+int prestera_acl_vtcam_id_get(struct prestera_acl *acl, u8 lookup,
+			      void *keymask, u32 *vtcam_id);
+int prestera_acl_vtcam_id_put(struct prestera_acl *acl, u32 vtcam_id);
 
 #endif /* _PRESTERA_ACL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.c b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
index ea05aae..0d4d726 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_ct.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.c
@@ -27,32 +27,41 @@ enum mangle_act_mask {
 
 struct prestera_ct_tuple {
 	u16 zone;
-	u16 ruleset;
-	u32 prio;
-	u8 n_matches;
-	struct prestera_acl_hw_match_info match[PRESTERA_ACL_CT_MATCHES];
-	struct prestera_acl_hw_action_info act;
-	u32 rule_id;
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_rule_entry *re;
 };
 
 struct prestera_ct_priv {
-	struct prestera_switch *sw;
+	struct prestera_acl *acl;
 	struct rhashtable zone_ht;
-	u32 trap_hw_rule_id;
-	u32 access_hw_rule_id;
+	struct prestera_acl_rule_entry *re;
+	u32 vtcam_id;
+	u16 pcl_id;
+	u32 index;
 };
 
 struct prestera_ct_entry {
 	struct rhash_head node;
 	unsigned long cookie;
 	struct prestera_ct_tuple tuple;
+	volatile struct {
+		u64 lastuse, packets, bytes;
+	} stats; /* cache */
 };
 
 struct prestera_ct_ft {
 	struct rhash_head node;
 	u16 zone;
-	struct net *net;
+	/* refcount used to detect,
+	 *  when we need to call nf_flow_table_offload_del_cb.
+	 * In other words - when we doing unsubscribe
+	 */
 	refcount_t refcount;
+	/* holdcount used to detect, that there is one or more events
+	 *  is waiting to be handled in workqueue
+	 */
+	refcount_t holdcount;
 	struct prestera_ct_priv *ct_priv;
 	struct nf_flowtable *nf_ft;
 	struct rhashtable ct_entries_ht;
@@ -72,40 +81,91 @@ static const struct rhashtable_params ct_zone_ht_params = {
 	.automatic_shrinking = true,
 };
 
-static int __prestera_ct_hw_chain_init(struct prestera_ct_priv *priv)
+static struct prestera_ct_ft *
+prestera_ct_ft_get(struct prestera_ct_priv *ct_priv,
+		   u16 zone, struct nf_flowtable *nf_ft);
+static void prestera_ct_ft_hold(struct prestera_ct_ft *ft);
+static void prestera_ct_ft_release(struct prestera_ct_ft *ft);
+static void prestera_ct_ft_put(struct prestera_ct_ft *ft);
+
+/* Lock just ct entries.
+ * For operations, which can be executed without rtnl_lock. E.g. stats.
+ */
+static DEFINE_MUTEX(prestera_ct_entries_lock);
+
+static int prestera_ct_chain_init(struct prestera_ct_priv *priv)
 {
+	struct prestera_acl_rule_entry_key re_key;
+	struct prestera_acl_rule_entry_arg re_arg;
+	struct prestera_acl_iface iface;
+	u16 pcl_id;
 	int err;
-	struct prestera_acl_hw_action_info action_info;
-
-	action_info.id = MVSW_ACL_RULE_ACTION_TRAP;
-	err = mvsw_pr_hw_acl_rule_add(priv->sw, PRESTERA_ACL_RULESET_ALL,
-				      PRESTERA_ACL_CT_CHAIN,
-				      PRESTERA_ACL_CT_TRAP_PRIO,
-				      PRESTERA_ACL_RULE_DEF_HW_TC,
-				      0, NULL, 1, &action_info,
-				      &priv->trap_hw_rule_id);
+	u8 uid;
+
+	err = prestera_acl_uid_new_get(priv->acl, &uid);
 	if (err)
-		goto err_hw_acl_add_trap;
-
-	action_info.id = MVSW_ACL_RULE_ACTION_ACCEPT;
-	err = mvsw_pr_hw_acl_rule_add(priv->sw, PRESTERA_ACL_RULESET_ALL,
-				      0, PRESTERA_ACL_CT_TRAP_PRIO,
-				      PRESTERA_ACL_RULE_DEF_HW_TC,
-				      0, NULL, 1, &action_info,
-				      &priv->access_hw_rule_id);
+		return err;
+
+	/* create vtcam with specific keymask/template */
+	memset(&re_key, 0, sizeof(re_key));
+	rule_match_set_u16(re_key.match.mask, PCL_ID,
+			   PRESTERA_ACL_KEYMASK_PCL_ID);
+	rule_match_set_u16(re_key.match.mask, ETH_TYPE, 0xFFFF);
+	rule_match_set_u8(re_key.match.mask, IP_PROTO, 0xFF);
+	rule_match_set_u32(re_key.match.mask, IP_SRC, 0xFFFFFFFF);
+	rule_match_set_u32(re_key.match.mask, IP_DST, 0xFFFFFFFF);
+	rule_match_set_u16(re_key.match.mask, L4_PORT_SRC, 0xFFFF);
+	rule_match_set_u16(re_key.match.mask, L4_PORT_DST, 0xFFFF);
+
+	err = prestera_acl_vtcam_id_get(priv->acl, PRESTERA_ACL_CT_CHAIN,
+					re_key.match.mask, &priv->vtcam_id);
 	if (err)
-		goto err_hw_acl_add_access;
+		goto err_vtcam_create;
+
+	/* make pcl-id based on uid and chain */
+	pcl_id = PRESTERA_ACL_PCL_ID_MAKE(uid, PRESTERA_ACL_CT_CHAIN);
 
+	/* bind iface index to pcl-id to be able to jump to this from
+	 * any other rules.
+	 */
+	iface.index = uid;
+	iface.type = PRESTERA_ACL_IFACE_TYPE_INDEX;
+	err = prestera_hw_vtcam_iface_bind(priv->acl->sw, &iface,
+					   priv->vtcam_id, pcl_id);
+	if (err)
+		goto err_rule_entry_bind;
+
+	memset(&re_key, 0, sizeof(re_key));
+	re_key.prio = PRESTERA_ACL_CT_TRAP_PRIO;
+	rule_match_set_u16(re_key.match.key, PCL_ID, pcl_id);
+	rule_match_set_u16(re_key.match.mask, PCL_ID,
+			   PRESTERA_ACL_KEYMASK_PCL_ID);
+
+	memset(&re_arg, 0, sizeof(re_arg));
+	re_arg.trap.valid = 1;
+	re_arg.trap.i.hw_tc = PRESTERA_ACL_RULE_DEF_HW_TC;
+	re_arg.vtcam_id = priv->vtcam_id;
+
+	priv->re = prestera_acl_rule_entry_create(priv->acl, &re_key, &re_arg);
+	if (!priv->re) {
+		err = -EINVAL;
+		goto err_rule_entry_create;
+	}
+
+	priv->pcl_id = pcl_id;
+	priv->index = uid;
 	return 0;
 
-err_hw_acl_add_access:
-	mvsw_pr_hw_acl_rule_del(priv->sw, PRESTERA_ACL_CT_CHAIN,
-				priv->trap_hw_rule_id);
-err_hw_acl_add_trap:
-	return -EINVAL;
+err_rule_entry_create:
+	prestera_hw_vtcam_iface_unbind(priv->acl->sw, &iface, priv->vtcam_id);
+err_rule_entry_bind:
+	prestera_acl_vtcam_id_put(priv->acl, priv->vtcam_id);
+err_vtcam_create:
+	prestera_acl_uid_release(priv->acl, uid);
+	return err;
 }
 
-struct prestera_ct_priv *prestera_ct_init(struct prestera_switch *sw)
+struct prestera_ct_priv *prestera_ct_init(struct prestera_acl *acl)
 {
 	struct prestera_ct_priv *ct_priv;
 
@@ -114,9 +174,9 @@ struct prestera_ct_priv *prestera_ct_init(struct prestera_switch *sw)
 		return ERR_PTR(-ENOMEM);
 
 	rhashtable_init(&ct_priv->zone_ht, &ct_zone_ht_params);
-	ct_priv->sw = sw;
+	ct_priv->acl = acl;
 
-	if (__prestera_ct_hw_chain_init(ct_priv))
+	if (prestera_ct_chain_init(ct_priv))
 		return ERR_PTR(-EINVAL);
 
 	return ct_priv;
@@ -124,9 +184,15 @@ struct prestera_ct_priv *prestera_ct_init(struct prestera_switch *sw)
 
 void prestera_ct_clean(struct prestera_ct_priv *ct_priv)
 {
+	u8 uid = ct_priv->pcl_id & PRESTERA_ACL_KEYMASK_PCL_ID_USER;
+
 	if (!ct_priv)
 		return;
 
+	prestera_acl_rule_entry_destroy(ct_priv->acl, ct_priv->re);
+	prestera_acl_vtcam_id_put(ct_priv->acl, ct_priv->vtcam_id);
+	prestera_acl_uid_release(ct_priv->acl, uid);
+
 	rhashtable_destroy(&ct_priv->zone_ht);
 	kfree(ct_priv);
 }
@@ -213,9 +279,8 @@ prestera_ct_get_ct_metadata_action(struct flow_rule *flow_rule)
 	return NULL;
 }
 
-static int
-prestera_ct_flow_rule_to_tuple(struct flow_rule *rule, struct net *net,
-			       struct prestera_ct_tuple *tuple)
+static int __flow_rule2prestera_acl_match(struct flow_rule *rule,
+					  struct prestera_acl_match *r_match)
 {
 	struct flow_match_ipv4_addrs ipv4_match;
 	struct flow_match_ports ports_match;
@@ -234,14 +299,12 @@ prestera_ct_flow_rule_to_tuple(struct flow_rule *rule, struct net *net,
 		return -EOPNOTSUPP;
 
 	flow_rule_match_ipv4_addrs(rule, &ipv4_match);
-	tuple->match[0].type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC;
-	tuple->match[0].u32.mask = -1;
-	memcpy(&tuple->match[0].u32.key, &ipv4_match.key->src, sizeof(u32));
-	/* Match 1 must be dst ! */
-	tuple->match[1].type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST;
-	tuple->match[1].u32.mask = -1;
-	memcpy(&tuple->match[1].u32.key, &ipv4_match.key->dst, sizeof(u32));
-	tuple->n_matches = 2;
+
+	rule_match_set(r_match->key, IP_SRC, ipv4_match.key->src);
+	rule_match_set(r_match->mask, IP_SRC, ipv4_match.mask->src);
+
+	rule_match_set(r_match->key, IP_DST, ipv4_match.key->dst);
+	rule_match_set(r_match->mask, IP_DST, ipv4_match.mask->dst);
 
 	if (!flow_rule_match_key(rule, FLOW_DISSECTOR_KEY_PORTS))
 		return -EOPNOTSUPP;
@@ -250,15 +313,15 @@ prestera_ct_flow_rule_to_tuple(struct flow_rule *rule, struct net *net,
 	switch (ip_proto) {
 	case IPPROTO_TCP:
 	case IPPROTO_UDP:
-		tuple->match[2].type =
-			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC;
-		tuple->match[2].u16.mask = -1;
-		tuple->match[2].u16.key = ntohs(ports_match.key->src);
-		tuple->match[3].type =
-			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST;
-		tuple->match[3].u16.mask = -1;
-		tuple->match[3].u16.key = ntohs(ports_match.key->dst);
-		tuple->n_matches = 4;
+		rule_match_set(r_match->key,
+			       L4_PORT_SRC, ports_match.key->src);
+		rule_match_set(r_match->mask,
+			       L4_PORT_SRC, ports_match.mask->src);
+
+		rule_match_set(r_match->key,
+			       L4_PORT_DST, ports_match.key->dst);
+		rule_match_set(r_match->mask,
+			       L4_PORT_DST, ports_match.mask->dst);
 		break;
 	default:
 		return -EOPNOTSUPP;
@@ -273,16 +336,14 @@ prestera_ct_flow_rule_to_tuple(struct flow_rule *rule, struct net *net,
 	return 0;
 }
 
-static int
-prestera_ct_flow_rule_to_tuple_nat(struct flow_rule *rule,
-				   struct prestera_ct_tuple *tuple)
+static int __flow_rule2prestera_mangle_cfg(struct flow_rule *rule,
+					   struct prestera_mangle_cfg *mc)
 {
 	struct flow_action *flow_action = &rule->action;
 	struct flow_action_entry *act;
 	u32 offset, val;
 	int i;
 
-	tuple->act.id = MVSW_ACL_RULE_ACTION_MANGLE;
 	flow_action_for_each(i, act, flow_action) {
 		if (act->id != FLOW_ACTION_MANGLE)
 			continue;
@@ -292,33 +353,35 @@ prestera_ct_flow_rule_to_tuple_nat(struct flow_rule *rule,
 		switch (act->mangle.htype) {
 		case FLOW_ACT_MANGLE_HDR_TYPE_IP4:
 			if (offset == offsetof(struct iphdr, saddr)) {
-				tuple->act.mangle.sip.u.ipv4 = cpu_to_be32(val);
-				tuple->act.mangle.sip_valid = true;
+				mc->sip.u.ipv4 =
+					cpu_to_be32(val);
+				mc->sip_valid = true;
 			} else if (offset == offsetof(struct iphdr, daddr)) {
-				tuple->act.mangle.dip.u.ipv4 = cpu_to_be32(val);
-				tuple->act.mangle.dip_valid = true;
+				mc->dip.u.ipv4 =
+					cpu_to_be32(val);
+				mc->dip_valid = true;
 			} else {
 				return -EOPNOTSUPP;
 			}
 			break;
 		case FLOW_ACT_MANGLE_HDR_TYPE_TCP:
 			if (offset == offsetof(struct tcphdr, source)) {
-				tuple->act.mangle.l4_src = cpu_to_be16(val);
-				tuple->act.mangle.l4_src_valid = true;
+				mc->l4_src = cpu_to_be16(val);
+				mc->l4_src_valid = true;
 			} else if (offset == offsetof(struct tcphdr, dest)) {
-				tuple->act.mangle.l4_dst = cpu_to_be16(val);
-				tuple->act.mangle.l4_dst_valid = true;
+				mc->l4_dst = cpu_to_be16(val);
+				mc->l4_dst_valid = true;
 			} else {
 				return -EOPNOTSUPP;
 			}
 			break;
 		case FLOW_ACT_MANGLE_HDR_TYPE_UDP:
 			if (offset == offsetof(struct udphdr, source)) {
-				tuple->act.mangle.l4_src = cpu_to_be16(val);
-				tuple->act.mangle.l4_src_valid = true;
+				mc->l4_src = cpu_to_be16(val);
+				mc->l4_src_valid = true;
 			} else if (offset == offsetof(struct udphdr, dest)) {
-				tuple->act.mangle.l4_dst = cpu_to_be16(val);
-				tuple->act.mangle.l4_dst_valid = true;
+				mc->l4_dst = cpu_to_be16(val);
+				mc->l4_dst_valid = true;
 			} else {
 				return -EOPNOTSUPP;
 			}
@@ -336,14 +399,14 @@ static int __prestera_ct_tuple_get_nh(struct prestera_switch *sw,
 {
 	struct mvsw_pr_ip_addr ip;
 	struct mvsw_pr_nexthop_group_key nh_grp_key;
-	struct mvsw_pr_nh_neigh *n;
+	struct prestera_mangle_cfg *mc;
 
-	/* Match 1 must be dst ! See prestera_ct_flow_rule_to_tuple() */
+	mc = &tuple->re_arg.nh.k.mangle;
 	memset(&ip, 0, sizeof(ip));
 	memcpy(&ip.u.ipv4,
-	       tuple->act.mangle.sip_valid ?
-	       (void *)&tuple->match[1].u32.key :
-	       (void *)&tuple->act.mangle.dip.u.ipv4,
+	       mc->sip_valid ?
+	       (void *)&rule_match_get_u32(tuple->re_key.match.key, IP_DST) :
+	       (void *)&mc->dip.u.ipv4,
 	       sizeof(ip.u.ipv4));
 
 	/* TODO: VRF */
@@ -352,43 +415,37 @@ static int __prestera_ct_tuple_get_nh(struct prestera_switch *sw,
 					      &nh_grp_key) != 1)
 		return -ENOTSUPP;
 
-	n = mvsw_pr_nh_neigh_find(sw, &nh_grp_key.neigh[0]);
-	if (!n) {
-		memset(&tuple->act.mangle.n, 0, sizeof(tuple->act.mangle.n));
-		return 0;
-	}
-
-	tuple->act.mangle.n = n->info;
+	tuple->re_arg.nh.k.n = nh_grp_key.neigh[0];
 
 	return 0;
 }
 
-static int __prestera_ct_tuple2acl_add(struct prestera_switch *sw,
+static int __prestera_ct_tuple2acl_add(struct prestera_acl *acl,
 				       struct prestera_ct_tuple *tuple)
 {
-	return mvsw_pr_hw_acl_rule_add(sw,
-				       tuple->ruleset,
-				       PRESTERA_ACL_CT_CHAIN,
-				       tuple->prio,
-				       PRESTERA_ACL_RULE_DEF_HW_TC,
-				       tuple->n_matches, &tuple->match[0], 1,
-				       &tuple->act, &tuple->rule_id);
+	tuple->re = prestera_acl_rule_entry_find(acl, &tuple->re_key);
+	if (tuple->re) {
+		tuple->re = NULL;
+		return -EEXIST;
+	}
+
+	tuple->re = prestera_acl_rule_entry_create(acl, &tuple->re_key,
+						   &tuple->re_arg);
+	if (!tuple->re)
+		return -EINVAL;
+
+	return 0;
 }
 
 static int
-prestera_ct_block_flow_offload_add(struct prestera_ct_ft *ft,
-				   struct flow_cls_offload *flow)
+__prestera_ct_block_flow_offload_add(struct prestera_ct_ft *ft,
+				     unsigned long cookie, u32 prio,
+				     struct prestera_acl_match r_match,
+				     struct prestera_mangle_cfg mc)
 {
-	struct flow_rule *flow_rule = flow_cls_offload_flow_rule(flow);
-	struct flow_action_entry *meta_action;
-	unsigned long cookie = flow->cookie;
 	struct prestera_ct_entry *entry;
 	int err;
 
-	meta_action = prestera_ct_get_ct_metadata_action(flow_rule);
-	if (!meta_action)
-		return -EOPNOTSUPP;
-
 	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
 				       ct_entry_ht_params);
 	if (entry)
@@ -399,25 +456,27 @@ prestera_ct_block_flow_offload_add(struct prestera_ct_ft *ft,
 		return -ENOMEM;
 
 	entry->tuple.zone = ft->zone;
-	entry->cookie = flow->cookie;
-	entry->tuple.prio = flow->common.prio;
-	/* Match everyting for CT lookup. FIXME */
-	entry->tuple.ruleset = PRESTERA_ACL_RULESET_ALL;
-
-	err = prestera_ct_flow_rule_to_tuple(flow_rule, ft->net, &entry->tuple);
-	if (err)
-		goto err_set;
-
-	err = prestera_ct_flow_rule_to_tuple_nat(flow_rule, &entry->tuple);
-	if (err)
-		goto err_set;
-
-	err = __prestera_ct_tuple_get_nh(ft->ct_priv->sw, &entry->tuple);
+	entry->cookie = cookie;
+	entry->tuple.re_key.prio = prio;
+	entry->tuple.re_arg.vtcam_id = ft->ct_priv->vtcam_id;
+
+	/* set pcl-id for this rule */
+	rule_match_set_u16(entry->tuple.re_key.match.key,
+			   PCL_ID, ft->ct_priv->pcl_id);
+	rule_match_set_u16(entry->tuple.re_key.match.mask,
+			   PCL_ID, PRESTERA_ACL_KEYMASK_PCL_ID);
+
+	entry->tuple.re_key.match = r_match;
+	/* Do we need sanity check before "valid = 1" ? */
+	entry->tuple.re_arg.nh.valid = 1;
+	entry->tuple.re_arg.nh.k.mangle = mc;
+
+	err = __prestera_ct_tuple_get_nh(ft->ct_priv->acl->sw, &entry->tuple);
 	if (err)
 		goto err_set;
 
 	/* HW offload */
-	err = __prestera_ct_tuple2acl_add(ft->ct_priv->sw, &entry->tuple);
+	err = __prestera_ct_tuple2acl_add(ft->ct_priv->acl, &entry->tuple);
 	if (err)
 		goto err_set;
 
@@ -429,19 +488,18 @@ prestera_ct_block_flow_offload_add(struct prestera_ct_ft *ft,
 	return 0;
 
 err_insert:
-	/* HW remove*/
+	prestera_acl_rule_entry_destroy(ft->ct_priv->acl, entry->tuple.re);
 
 err_set:
 	kfree(entry);
+	/* TODO: Error message ? */
 	return err;
 }
 
 static int
-prestera_ct_block_flow_offload_del(struct prestera_ct_ft *ft,
-				   struct flow_cls_offload *flow)
+__prestera_ct_block_flow_offload_del(struct prestera_ct_ft *ft,
+				     unsigned long cookie)
 {
-	int err;
-	unsigned long cookie = flow->cookie;
 	struct prestera_ct_entry *entry;
 
 	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
@@ -449,44 +507,130 @@ prestera_ct_block_flow_offload_del(struct prestera_ct_ft *ft,
 	if (!entry)
 		return -ENOENT;
 
-	err = mvsw_pr_hw_acl_rule_del(ft->ct_priv->sw, PRESTERA_ACL_CT_CHAIN,
-				      entry->tuple.rule_id);
-	if (err)
-		MVSW_LOG_ERROR("mvsw_pr_hw_acl_rule_del failed err = %d", err);
-
+	prestera_acl_rule_entry_destroy(ft->ct_priv->acl, entry->tuple.re);
 	rhashtable_remove_fast(&ft->ct_entries_ht,
 			       &entry->node, ct_entry_ht_params);
 	kfree(entry);
 	return 0;
 }
 
-static void
-prestera_ct_flow_stats_query_cached(u64 *bytes, u64 *packets, u64 *lastuse)
-{
-	/* TODO: add HW stats instead */
-	*bytes = 128;
-	*packets = 1;
-	*lastuse = jiffies;
-}
-
+/* Can be executed without rtnl_lock().
+ * So pay attention when something changing.
+ */
 static int
 prestera_ct_block_flow_offload_stats(struct prestera_ct_ft *ft,
 				     struct flow_cls_offload *f)
 {
 	unsigned long cookie = f->cookie;
 	struct prestera_ct_entry *entry;
-	u64 lastuse, packets, bytes;
+	u64 packets, bytes;
+	int err = 0;
+
+	mutex_lock(&prestera_ct_entries_lock);
 
 	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
 				       ct_entry_ht_params);
-	if (!entry)
-		return -ENOENT;
+	err = entry ? 0 : -ENOENT;
+	if (err)
+		goto out;
+
+	err = prestera_acl_rule_entry_util_stats(ft->ct_priv->acl,
+						 entry->tuple.re,
+						 &packets, &bytes);
+	if (err)
+		goto out;
 
-	prestera_ct_flow_stats_query_cached(&bytes, &packets, &lastuse);
-	flow_stats_update(&f->stats, bytes, packets, 0, lastuse,
+	if (packets != entry->stats.packets || bytes != entry->stats.bytes) {
+		entry->stats.packets = packets;
+		entry->stats.bytes = bytes;
+		entry->stats.lastuse = jiffies;
+	}
+
+	flow_stats_update(&f->stats,
+			  entry->stats.bytes,
+			  entry->stats.packets,
+			  0,
+			  entry->stats.lastuse,
 			  FLOW_ACTION_HW_STATS_DELAYED);
 
-	return 0;
+out:
+	mutex_unlock(&prestera_ct_entries_lock);
+	return err;
+}
+
+/* Can be executed without rtnl_lock().
+ * So pay attention when something changing.
+ */
+static int
+prestera_ct_block_flow_offload_try_enable(struct prestera_ct_ft *ft,
+					  struct flow_cls_offload *f)
+{
+	unsigned long cookie = f->cookie;
+	struct prestera_ct_entry *entry;
+	int err;
+
+	mutex_lock(&prestera_ct_entries_lock);
+
+	entry = rhashtable_lookup_fast(&ft->ct_entries_ht, &cookie,
+				       ct_entry_ht_params);
+	if (!entry) {
+		err = -ENOENT;
+		goto err_enable;
+	}
+
+	/* if entry already exists, just enable it */
+	err = prestera_acl_rule_entry_set(ft->ct_priv->acl,
+					  entry->tuple.re, true);
+err_enable:
+	mutex_unlock(&prestera_ct_entries_lock);
+	return err;
+}
+
+struct prestera_ct_flow_work {
+	struct work_struct work;
+	enum flow_cls_command command;
+	struct prestera_ct_ft *ft;
+	unsigned long cookie; /* add/del */
+	u32 prio; /* add */
+	struct prestera_acl_match r_match; /* add */
+	struct prestera_mangle_cfg mc; /* add */
+};
+
+static void __prestera_ct_flow_event_work(struct work_struct *work)
+{
+	int err;
+	struct prestera_ct_flow_work *ct_work =
+		container_of(work, struct prestera_ct_flow_work, work);
+
+	prestera_router_owq_lock();
+	mutex_lock(&prestera_ct_entries_lock);
+
+	switch (ct_work->command) {
+	case FLOW_CLS_REPLACE:
+		err = __prestera_ct_block_flow_offload_add(ct_work->ft,
+							   ct_work->cookie,
+							   ct_work->prio,
+							   ct_work->r_match,
+							   ct_work->mc);
+		/* Don't print error. (when there are too much sessions) */
+		break;
+	case FLOW_CLS_DESTROY:
+		err = __prestera_ct_block_flow_offload_del(ct_work->ft,
+							   ct_work->cookie);
+		/* Don't print error. (when ct is not offloaded due to leak
+		 * of memory... kernel still try to remove tuple)
+		 */
+		break;
+	default:
+		WARN_ON(true);
+		break;
+	}
+
+	/* out */
+	prestera_ct_ft_release(ct_work->ft);
+	mutex_unlock(&prestera_ct_entries_lock);
+	prestera_router_owq_unlock();
+	kfree(ct_work);
 }
 
 static int
@@ -495,28 +639,70 @@ prestera_ct_block_flow_offload(enum tc_setup_type type, void *type_data,
 {
 	struct flow_cls_offload *f = type_data;
 	struct prestera_ct_ft *ft = cb_priv;
+	struct flow_rule *flow_rule = flow_cls_offload_flow_rule(f);
+	struct prestera_ct_flow_work *ct_work;
+	int status = 0;
+	int err;
 
 	if (type != TC_SETUP_CLSFLOWER)
 		return -EOPNOTSUPP;
 
 	switch (f->command) {
 	case FLOW_CLS_REPLACE:
-		return prestera_ct_block_flow_offload_add(ft, f);
+		/* NOTE: maybe it makes sense to have separate rhash like
+		 *       ct_wip_entries_ht when entries are not offloaded yet
+		 *       but are in progress to be added. In this case we can
+		 *       check this and do not scedule the wq again to offload
+		 *       the same ct entry.
+		 */
+		status = prestera_ct_block_flow_offload_try_enable(ft, f);
+		if (!status)
+			/* ct entry is enabled, so return hw-offloaded */
+			break;
+		/*  FALLTHRU */
 	case FLOW_CLS_DESTROY:
-		return prestera_ct_block_flow_offload_del(ft, f);
+		ct_work = kzalloc(sizeof(*ct_work), GFP_ATOMIC);
+		if (!ct_work)
+			return -ENOMEM;
+
+		ct_work->command = f->command;
+		ct_work->ft = ft;
+		prestera_ct_ft_hold(ft);
+		ct_work->cookie = f->cookie;
+
+		if (f->command == FLOW_CLS_REPLACE) {
+			if (!prestera_ct_get_ct_metadata_action(flow_rule))
+				return -EOPNOTSUPP;
+
+			ct_work->prio = f->common.prio;
+			err = __flow_rule2prestera_acl_match(flow_rule,
+							     &ct_work->r_match);
+			if (err)
+				return err;
+			err = __flow_rule2prestera_mangle_cfg(flow_rule,
+							      &ct_work->mc);
+			if (err)
+				return err;
+		}
+
+		INIT_WORK(&ct_work->work, __prestera_ct_flow_event_work);
+		prestera_router_owq_queue_work(&ct_work->work);
+		break;
 	case FLOW_CLS_STATS:
-		return prestera_ct_block_flow_offload_stats(ft, f);
-	default:
+		err = prestera_ct_block_flow_offload_stats(ft, f);
+		if (err)
+			return err;
 		break;
+	default:
+		return -EOPNOTSUPP;
 	}
 
-	return -EOPNOTSUPP;
+	return status;
 }
 
 static struct prestera_ct_ft *
-__prestera_ct_ft_offload_add_cb(struct prestera_ct_priv *ct_priv,
-				u16 zone, struct nf_flowtable *nf_ft,
-				struct net *net)
+prestera_ct_ft_get(struct prestera_ct_priv *ct_priv,
+		   u16 zone, struct nf_flowtable *nf_ft)
 {
 	struct prestera_ct_ft *ft;
 	int err;
@@ -533,11 +719,11 @@ __prestera_ct_ft_offload_add_cb(struct prestera_ct_priv *ct_priv,
 		return ERR_PTR(-ENOMEM);
 
 	/* ft->net = read_pnet(&nf_ft->net); */
-	ft->net = net;
 	ft->zone = zone;
 	ft->nf_ft = nf_ft;
 	ft->ct_priv = ct_priv;
 	refcount_set(&ft->refcount, 1);
+	refcount_set(&ft->holdcount, 1);
 
 	err = rhashtable_init(&ft->ct_entries_ht, &ct_entry_ht_params);
 	if (err)
@@ -564,55 +750,77 @@ __prestera_ct_ft_offload_add_cb(struct prestera_ct_priv *ct_priv,
 	return ERR_PTR(err);
 }
 
+/* Used for workqeue */
+static void prestera_ct_ft_hold(struct prestera_ct_ft *ft)
+{
+	refcount_inc(&ft->holdcount);
+}
+
+static void __prestera_ct_flush_ft_entry(void *ptr, void *arg)
+{
+	struct prestera_ct_priv *ct_priv = arg;
+	struct prestera_ct_entry *entry = ptr;
+
+	prestera_acl_rule_entry_destroy(ct_priv->acl, entry->tuple.re);
+	kfree(entry);
+}
+
+/* Used for workqeue */
+static void prestera_ct_ft_release(struct prestera_ct_ft *ft)
+{
+	if (refcount_dec_and_test(&ft->holdcount)) {
+		/* paranoia */
+		WARN_ON(refcount_read(&ft->refcount));
+		rhashtable_free_and_destroy(&ft->ct_entries_ht,
+					    __prestera_ct_flush_ft_entry,
+					    ft->ct_priv);
+		kfree(ft);
+	}
+}
+
+static void prestera_ct_ft_put(struct prestera_ct_ft *ft)
+{
+	if (!refcount_dec_and_test(&ft->refcount))
+		return;
+
+	/* Remove from search results (rhtable) first. */
+	rhashtable_remove_fast(&ft->ct_priv->zone_ht, &ft->node,
+			       ct_zone_ht_params);
+	nf_flow_table_offload_del_cb(ft->nf_ft,
+				     prestera_ct_block_flow_offload, ft);
+	prestera_ct_ft_release(ft);
+}
+
 /* Add gateway rule in def chain and add TRAP rule in CT chain */
 static int __prestera_ct_rule2gateway(struct prestera_switch *sw,
 				      struct prestera_acl_rule *rule)
 {
-	int err;
-	u8 n_matches, i;
-	struct prestera_acl_rule_match_entry *m_entry;
-	struct prestera_acl_hw_match_info *match_info;
-	struct prestera_acl_hw_action_info action_info;
-
-	n_matches = prestera_acl_rule_match_len(rule);
-	match_info = kcalloc(n_matches, sizeof(*match_info), GFP_KERNEL);
-	if (!match_info)
-		goto err_kzalloc_match;
-
-	i = 0;
-	list_for_each_entry(m_entry,
-			    prestera_acl_rule_match_list_get(rule),
-			    list) {
-		match_info[i] = m_entry->info;
-		i++;
-	}
+	struct prestera_ct_priv *ct_priv = sw->acl->ct_priv;
 
-	action_info.id = MVSW_ACL_RULE_ACTION_JUMP;
-	action_info.jump.chain = PRESTERA_ACL_CT_CHAIN;
+	/* TODO: fill this in flower parse */
 
-	err = mvsw_pr_hw_acl_rule_add(sw,
-				      prestera_acl_rule_ruleset_id_get(rule),
-				      prestera_acl_rule_chain_get(rule),
-				      prestera_acl_rule_priority_get(rule),
-				      prestera_acl_rule_hw_tc_get(rule),
-				      n_matches, match_info, 1, &action_info,
-				      &rule->id);
-	if (err)
-		goto err_hw_acl_add_gw;
+	/* just update the action for this rule */
+	rule->re_arg.jump.valid = 1;
+	rule->re_arg.jump.i.index = ct_priv->index;
 
-	return 0;
+	rule->re = prestera_acl_rule_entry_find(sw->acl, &rule->re_key);
+	if (WARN_ON(rule->re)) {
+		rule->re = NULL;
+		return -EEXIST;
+	}
+
+	rule->re = prestera_acl_rule_entry_create(sw->acl, &rule->re_key,
+						  &rule->re_arg);
+	if (!rule->re)
+		return -EINVAL;
 
-err_hw_acl_add_gw:
-	kfree(match_info);
-err_kzalloc_match:
-	return -EINVAL;
+	return 0;
 }
 
 int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
 				  struct prestera_acl_rule *rule)
 {
 	struct prestera_ct_attr *ct_attr;
-	struct prestera_ct_ft *ct_ft;
 	int err;
 
 	ct_attr = &rule->attr.ct_attr;
@@ -620,11 +828,11 @@ int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
 	if (ct_attr->ct_action & TCA_CT_ACT_CLEAR)
 		return -EOPNOTSUPP;
 
-	ct_ft = __prestera_ct_ft_offload_add_cb(sw->acl->ct_priv, ct_attr->zone,
-						ct_attr->nf_ft,
-						rule->block->net);
-	if (IS_ERR(ct_ft))
-		return PTR_ERR(ct_ft);
+	ct_attr->ft = prestera_ct_ft_get(sw->acl->ct_priv,
+					 ct_attr->zone,
+					 ct_attr->nf_ft);
+	if (IS_ERR(ct_attr->ft))
+		return PTR_ERR(ct_attr->ft);
 
 	err = __prestera_ct_rule2gateway(sw, rule);
 	if (err) {
@@ -632,56 +840,22 @@ int prestera_ct_ft_offload_add_cb(struct prestera_switch *sw,
 		return err;
 	}
 
-	ct_attr->ft = ct_ft;
 	return 0;
 }
 
-static void
-prestera_ct_del_ft_entry(struct prestera_ct_priv *ct_priv,
-			 struct prestera_ct_entry *entry)
-{
-	int err;
-
-	err = mvsw_pr_hw_acl_rule_del(ct_priv->sw, PRESTERA_ACL_CT_CHAIN,
-				      entry->tuple.rule_id);
-	if (err)
-		MVSW_LOG_ERROR("mvsw_pr_hw_acl_rule_del failed err = %d", err);
-}
-
-static void prestera_ct_flush_ft_entry(void *ptr, void *arg)
-{
-	struct prestera_ct_priv *ct_priv = arg;
-	struct prestera_ct_entry *entry = ptr;
-
-	prestera_ct_del_ft_entry(ct_priv, entry);
-	kfree(entry);
-}
-
 void prestera_ct_ft_offload_del_cb(struct prestera_switch *sw,
 				   struct prestera_acl_rule *rule)
 {
 	struct prestera_ct_attr *ct_attr;
 	struct prestera_ct_ft *ft;
 	struct prestera_ct_priv *ct_priv;
-	int err;
 
 	ct_attr = &rule->attr.ct_attr;
 	ft = ct_attr->ft;
 	ct_priv = sw->acl->ct_priv;
 
-	err = mvsw_pr_hw_acl_rule_del(sw, prestera_acl_rule_chain_get(rule),
-				      rule->id);
-	if (err)
-		MVSW_LOG_ERROR("mvsw_pr_hw_acl_rule_del failed err = %d", err);
+	if (rule->re)
+		prestera_acl_rule_entry_destroy(ct_priv->acl, rule->re);
 
-	if (!refcount_dec_and_test(&ft->refcount))
-		return;
-
-	nf_flow_table_offload_del_cb(ft->nf_ft,
-				     prestera_ct_block_flow_offload, ft);
-	rhashtable_free_and_destroy(&ft->ct_entries_ht,
-				    prestera_ct_flush_ft_entry, ct_priv);
-	rhashtable_remove_fast(&ct_priv->zone_ht, &ft->node, ct_zone_ht_params);
-
-	kfree(ft);
+	prestera_ct_ft_put(ft);
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ct.h b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
index c86c9a4..1a1342b 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_ct.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ct.h
@@ -23,7 +23,7 @@ struct prestera_ct_attr {
 	struct nf_flowtable *nf_ft;
 };
 
-struct prestera_ct_priv *prestera_ct_init(struct prestera_switch *sw);
+struct prestera_ct_priv *prestera_ct_init(struct prestera_acl *acl);
 void prestera_ct_clean(struct prestera_ct_priv *ct_priv);
 
 /* match & action */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
index fa7a46f..9f9d4fe 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_devlink.c
@@ -5,6 +5,7 @@
 #include <linux/version.h>
 
 #include "prestera_devlink.h"
+#include "prestera_hw.h"
 
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(5, 8, 0)
 /* All driver-specific traps must be documented in
@@ -36,6 +37,15 @@ enum {
 	DEVLINK_PRESTERA_TRAP_ID_SSH,
 	DEVLINK_PRESTERA_TRAP_ID_TELNET,
 	DEVLINK_PRESTERA_TRAP_ID_ICMP,
+	DEVLINK_PRESTERA_TRAP_ID_MET_RED,
+	DEVLINK_PRESTERA_TRAP_ID_IP_SIP_IS_ZERO,
+	DEVLINK_PRESTERA_TRAP_ID_IP_UC_DIP_DA_MISMATCH,
+	DEVLINK_PRESTERA_TRAP_ID_ILLEGAL_IPV4_HDR,
+	DEVLINK_PRESTERA_TRAP_ID_ILLEGAL_IP_ADDR,
+	DEVLINK_PRESTERA_TRAP_ID_INVALID_SA,
+	DEVLINK_PRESTERA_TRAP_ID_LOCAL_PORT,
+	DEVLINK_PRESTERA_TRAP_ID_PORT_NO_VLAN,
+	DEVLINK_PRESTERA_TRAP_ID_RXDMA_DROP,
 };
 
 #define DEVLINK_PRESTERA_TRAP_NAME_ARP_BC \
@@ -86,6 +96,24 @@ enum {
 	"telnet"
 #define DEVLINK_PRESTERA_TRAP_NAME_ICMP \
 	"icmp"
+#define DEVLINK_PRESTERA_TRAP_NAME_RXDMA_DROP \
+	"rxdma_drop"
+#define DEVLINK_PRESTERA_TRAP_NAME_PORT_NO_VLAN \
+	"port_no_vlan"
+#define DEVLINK_PRESTERA_TRAP_NAME_LOCAL_PORT \
+	"local_port"
+#define DEVLINK_PRESTERA_TRAP_NAME_INVALID_SA \
+	"invalid_sa"
+#define DEVLINK_PRESTERA_TRAP_NAME_ILLEGAL_IP_ADDR \
+	"illegal_ip_addr"
+#define DEVLINK_PRESTERA_TRAP_NAME_ILLEGAL_IPV4_HDR \
+	"illegal_ipv4_hdr"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_UC_DIP_DA_MISMATCH \
+	"ip_uc_dip_da_mismatch"
+#define DEVLINK_PRESTERA_TRAP_NAME_IP_SIP_IS_ZERO \
+	"ip_sip_is_zero"
+#define DEVLINK_PRESTERA_TRAP_NAME_MET_RED \
+	"met_red"
 
 struct prestera_trap {
 	struct devlink_trap trap;
@@ -127,6 +155,12 @@ struct prestera_trap_data {
 			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
 			    PRESTERA_TRAP_METADATA)
 
+#define PRESTERA_TRAP_DRIVER_DROP(_id, _group_id)			      \
+	DEVLINK_TRAP_DRIVER(DROP, DROP, DEVLINK_PRESTERA_TRAP_ID_##_id,	      \
+			    DEVLINK_PRESTERA_TRAP_NAME_##_id,		      \
+			    DEVLINK_TRAP_GROUP_GENERIC_ID_##_group_id,	      \
+			    PRESTERA_TRAP_METADATA)
+
 static const struct devlink_trap_group prestera_trap_groups_arr[] = {
 	/* No policer is associated with following groups (policerid == 0)*/
 	DEVLINK_TRAP_GROUP_GENERIC(L2_DROPS, 0),
@@ -144,6 +178,7 @@ static const struct devlink_trap_group prestera_trap_groups_arr[] = {
 	DEVLINK_TRAP_GROUP_GENERIC(DHCP, 0),
 	DEVLINK_TRAP_GROUP_GENERIC(BGP, 0),
 	DEVLINK_TRAP_GROUP_GENERIC(LOCAL_DELIVERY, 0),
+	DEVLINK_TRAP_GROUP_GENERIC(BUFFER_DROPS, 0),
 };
 
 /* Initialize trap list, as well as associate CPU code with them. */
@@ -273,6 +308,43 @@ static struct prestera_trap prestera_trap_items_arr[] = {
 		.trap = PRESTERA_TRAP_DRIVER_CONTROL(ICMP, LOCAL_DELIVERY),
 		.cpu_code = 209,
 	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(RXDMA_DROP, BUFFER_DROPS),
+		.cpu_code = 37,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(PORT_NO_VLAN, L2_DROPS),
+		.cpu_code = 39,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(LOCAL_PORT, L2_DROPS),
+		.cpu_code = 56,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(INVALID_SA, L2_DROPS),
+		.cpu_code = 60,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(ILLEGAL_IP_ADDR, L3_DROPS),
+		.cpu_code = 136,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(ILLEGAL_IPV4_HDR, L3_DROPS),
+		.cpu_code = 137,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(IP_UC_DIP_DA_MISMATCH,
+						  L3_DROPS),
+		.cpu_code = 138,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(IP_SIP_IS_ZERO, L3_DROPS),
+		.cpu_code = 145,
+	},
+	{
+		.trap = PRESTERA_TRAP_DRIVER_DROP(MET_RED, BUFFER_DROPS),
+		.cpu_code = 185,
+	},
 };
 #endif
 
@@ -288,6 +360,10 @@ static int prestera_trap_action_set(struct devlink *devlink,
 
 static int prestera_devlink_traps_register(struct prestera_switch *sw);
 
+static int prestera_drop_counter_get(struct devlink *devlink,
+				     const struct devlink_trap *trap,
+				     u64 *p_drops);
+
 static int prestera_dl_info_get(struct devlink *dl,
 				struct devlink_info_req *req,
 				struct netlink_ext_ack *extack)
@@ -314,6 +390,7 @@ static const struct devlink_ops prestera_dl_ops = {
 	.info_get = prestera_dl_info_get,
 	.trap_init = prestera_trap_init,
 	.trap_action_set = prestera_trap_action_set,
+	.trap_drop_counter_get = prestera_drop_counter_get,
 };
 
 struct prestera_switch *prestera_devlink_alloc(void)
@@ -533,6 +610,25 @@ static int prestera_trap_action_set(struct devlink *devlink,
 	return -ENOTSUPP;
 }
 
+static int prestera_drop_counter_get(struct devlink *devlink,
+				     const struct devlink_trap *trap,
+				     u64 *p_drops)
+{
+	struct prestera_switch *sw = devlink_priv(devlink);
+	enum prestera_hw_cpu_code_cnt_t cpu_code_type =
+		PRESTERA_HW_CPU_CODE_CNT_TYPE_DROP;
+	struct prestera_trap *prestera_trap =
+		container_of(trap, struct prestera_trap, trap);
+	int ret;
+
+	ret = prestera_hw_cpu_code_counters_get(sw, prestera_trap->cpu_code,
+						cpu_code_type, p_drops);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
 static void prestera_devlink_traps_fini(struct prestera_switch *sw)
 {
 	struct prestera_trap_data *trap_data = sw->trap_data;
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
index d2969fc..ba54cb3 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_drv_ver.h
@@ -12,7 +12,7 @@
 #define PRESTERA_DRV_VER_MAJOR	2
 #define PRESTERA_DRV_VER_MINOR	0
 #define PRESTERA_DRV_VER_PATCH	0
-#define PRESTERA_DRV_VER_EXTRA	-v2.9.0
+#define PRESTERA_DRV_VER_EXTRA	-v2.10.0
 
 #define PRESTERA_DRV_VER \
 		__stringify(PRESTERA_DRV_VER_MAJOR)  "." \
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c
new file mode 100644
index 0000000..c823299
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.c
@@ -0,0 +1,921 @@
+// SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0
+/* Copyright (c) 2019-2021 Marvell International Ltd. All rights reserved */
+
+#include <linux/ethtool.h>
+#include <linux/kernel.h>
+#include <linux/netdevice.h>
+
+#include "prestera_ethtool.h"
+#include "prestera.h"
+#include "prestera_hw.h"
+
+static const char prestera_driver_kind[] = "prestera";
+
+#define PORT_STATS_CNT	(sizeof(struct mvsw_pr_port_stats) / sizeof(u64))
+#define PORT_STATS_IDX(name) \
+	(offsetof(struct mvsw_pr_port_stats, name) / sizeof(u64))
+#define PORT_STATS_FIELD(name)	\
+	[PORT_STATS_IDX(name)] = __stringify(name)
+
+struct prestera_link_mode {
+	enum ethtool_link_mode_bit_indices eth_mode;
+	u32 speed;
+	u64 pr_mask;
+	u8 duplex;
+	u8 port_type;
+};
+
+static const struct prestera_link_mode
+prestera_link_modes[MVSW_LINK_MODE_MAX] = {
+	[MVSW_LINK_MODE_10baseT_Half_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Half_BIT,
+		.speed = 10,
+		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Half_BIT,
+		.duplex = MVSW_PORT_DUPLEX_HALF,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_10baseT_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Full_BIT,
+		.speed = 10,
+		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_100baseT_Half_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Half_BIT,
+		.speed = 100,
+		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Half_BIT,
+		.duplex = MVSW_PORT_DUPLEX_HALF,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_100baseT_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Full_BIT,
+		.speed = 100,
+		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_1000baseT_Half_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Half_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Half_BIT,
+		.duplex = MVSW_PORT_DUPLEX_HALF,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_1000baseT_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Full_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_1000baseX_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_1000baseX_Full_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseX_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_1000baseKX_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_1000baseKX_Full_BIT,
+		.speed = 1000,
+		.pr_mask = 1 << MVSW_LINK_MODE_1000baseKX_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_2500baseX_Full_BIT] = {
+		.eth_mode =  ETHTOOL_LINK_MODE_2500baseX_Full_BIT,
+		.speed = 2500,
+		.pr_mask = 1 << MVSW_LINK_MODE_2500baseX_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+	},
+	[MVSW_LINK_MODE_10GbaseKR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_10000baseKR_Full_BIT,
+		.speed = 10000,
+		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseKR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_10GbaseSR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_10000baseSR_Full_BIT,
+		.speed = 10000,
+		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseSR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_10GbaseLR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_10000baseLR_Full_BIT,
+		.speed = 10000,
+		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseLR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_20GbaseKR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_20000baseKR2_Full_BIT,
+		.speed = 20000,
+		.pr_mask = 1 << MVSW_LINK_MODE_20GbaseKR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_25GbaseCR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_25000baseCR_Full_BIT,
+		.speed = 25000,
+		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseCR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	},
+	[MVSW_LINK_MODE_25GbaseKR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_25000baseKR_Full_BIT,
+		.speed = 25000,
+		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseKR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_25GbaseSR_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_25000baseSR_Full_BIT,
+		.speed = 25000,
+		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseSR_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_40GbaseKR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_40000baseKR4_Full_BIT,
+		.speed = 40000,
+		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseKR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_40GbaseCR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_40000baseCR4_Full_BIT,
+		.speed = 40000,
+		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseCR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	},
+	[MVSW_LINK_MODE_40GbaseSR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_40000baseSR4_Full_BIT,
+		.speed = 40000,
+		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseSR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_50GbaseCR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_50000baseCR2_Full_BIT,
+		.speed = 50000,
+		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseCR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	},
+	[MVSW_LINK_MODE_50GbaseKR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_50000baseKR2_Full_BIT,
+		.speed = 50000,
+		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseKR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_50GbaseSR2_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_50000baseSR2_Full_BIT,
+		.speed = 50000,
+		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseSR2_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_100GbaseKR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_100000baseKR4_Full_BIT,
+		.speed = 100000,
+		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseKR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_TP,
+	},
+	[MVSW_LINK_MODE_100GbaseSR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_100000baseSR4_Full_BIT,
+		.speed = 100000,
+		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseSR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_FIBRE,
+	},
+	[MVSW_LINK_MODE_100GbaseCR4_Full_BIT] = {
+		.eth_mode = ETHTOOL_LINK_MODE_100000baseCR4_Full_BIT,
+		.speed = 100000,
+		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseCR4_Full_BIT,
+		.duplex = MVSW_PORT_DUPLEX_FULL,
+		.port_type = MVSW_PORT_TYPE_DA,
+	}
+};
+
+struct prestera_fec {
+	u32 eth_fec;
+	enum ethtool_link_mode_bit_indices eth_mode;
+	u8 pr_fec;
+};
+
+static const struct prestera_fec prestera_fec_caps[MVSW_PORT_FEC_MAX] = {
+	[MVSW_PORT_FEC_OFF_BIT] = {
+		.eth_fec = ETHTOOL_FEC_OFF,
+		.eth_mode = ETHTOOL_LINK_MODE_FEC_NONE_BIT,
+		.pr_fec = 1 << MVSW_PORT_FEC_OFF_BIT,
+	},
+	[MVSW_PORT_FEC_BASER_BIT] = {
+		.eth_fec = ETHTOOL_FEC_BASER,
+		.eth_mode = ETHTOOL_LINK_MODE_FEC_BASER_BIT,
+		.pr_fec = 1 << MVSW_PORT_FEC_BASER_BIT,
+	},
+	[MVSW_PORT_FEC_RS_BIT] = {
+		.eth_fec = ETHTOOL_FEC_RS,
+		.eth_mode = ETHTOOL_LINK_MODE_FEC_RS_BIT,
+		.pr_fec = 1 << MVSW_PORT_FEC_RS_BIT,
+	}
+};
+
+struct prestera_port_type {
+	enum ethtool_link_mode_bit_indices eth_mode;
+	u8 eth_type;
+};
+
+static const struct prestera_port_type
+prestera_port_types[MVSW_PORT_TYPE_MAX] = {
+	[MVSW_PORT_TYPE_NONE] = {
+		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
+		.eth_type = PORT_NONE,
+	},
+	[MVSW_PORT_TYPE_TP] = {
+		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
+		.eth_type = PORT_TP,
+	},
+	[MVSW_PORT_TYPE_AUI] = {
+		.eth_mode = ETHTOOL_LINK_MODE_AUI_BIT,
+		.eth_type = PORT_AUI,
+	},
+	[MVSW_PORT_TYPE_MII] = {
+		.eth_mode = ETHTOOL_LINK_MODE_MII_BIT,
+		.eth_type = PORT_MII,
+	},
+	[MVSW_PORT_TYPE_FIBRE] = {
+		.eth_mode = ETHTOOL_LINK_MODE_FIBRE_BIT,
+		.eth_type = PORT_FIBRE,
+	},
+	[MVSW_PORT_TYPE_BNC] = {
+		.eth_mode = ETHTOOL_LINK_MODE_BNC_BIT,
+		.eth_type = PORT_BNC,
+	},
+	[MVSW_PORT_TYPE_DA] = {
+		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
+		.eth_type = PORT_TP,
+	},
+	[MVSW_PORT_TYPE_OTHER] = {
+		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
+		.eth_type = PORT_OTHER,
+	}
+};
+
+static const char prestera_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
+	PORT_STATS_FIELD(good_octets_received),
+	PORT_STATS_FIELD(bad_octets_received),
+	PORT_STATS_FIELD(mac_trans_error),
+	PORT_STATS_FIELD(broadcast_frames_received),
+	PORT_STATS_FIELD(multicast_frames_received),
+	PORT_STATS_FIELD(frames_64_octets),
+	PORT_STATS_FIELD(frames_65_to_127_octets),
+	PORT_STATS_FIELD(frames_128_to_255_octets),
+	PORT_STATS_FIELD(frames_256_to_511_octets),
+	PORT_STATS_FIELD(frames_512_to_1023_octets),
+	PORT_STATS_FIELD(frames_1024_to_max_octets),
+	PORT_STATS_FIELD(excessive_collision),
+	PORT_STATS_FIELD(multicast_frames_sent),
+	PORT_STATS_FIELD(broadcast_frames_sent),
+	PORT_STATS_FIELD(fc_sent),
+	PORT_STATS_FIELD(fc_received),
+	PORT_STATS_FIELD(buffer_overrun),
+	PORT_STATS_FIELD(undersize),
+	PORT_STATS_FIELD(fragments),
+	PORT_STATS_FIELD(oversize),
+	PORT_STATS_FIELD(jabber),
+	PORT_STATS_FIELD(rx_error_frame_received),
+	PORT_STATS_FIELD(bad_crc),
+	PORT_STATS_FIELD(collisions),
+	PORT_STATS_FIELD(late_collision),
+	PORT_STATS_FIELD(unicast_frames_received),
+	PORT_STATS_FIELD(unicast_frames_sent),
+	PORT_STATS_FIELD(sent_multiple),
+	PORT_STATS_FIELD(sent_deferred),
+	PORT_STATS_FIELD(good_octets_sent),
+};
+
+static void prestera_modes_to_eth(unsigned long *eth_modes, u64 link_modes,
+				  u8 fec, u8 type)
+{
+	u32 mode;
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask & link_modes) == 0)
+			continue;
+		if (type != MVSW_PORT_TYPE_NONE &&
+		    prestera_link_modes[mode].port_type != type)
+			continue;
+		__set_bit(prestera_link_modes[mode].eth_mode, eth_modes);
+	}
+
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if ((prestera_fec_caps[mode].pr_fec & fec) == 0)
+			continue;
+		__set_bit(prestera_fec_caps[mode].eth_mode, eth_modes);
+	}
+}
+
+static void prestera_port_remote_cap_cache(struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+
+	if (!params->oper_state)
+		return;
+
+	if (!params->lmode_bmap)
+		if (mvsw_pr_hw_port_remote_cap_get(port, &params->lmode_bmap))
+			netdev_warn(port->net_dev,
+				    "Remote link caps get failed %d",
+				    port->caps.transceiver);
+
+	if (!params->remote_fc.pause && !params->remote_fc.asym_pause) {
+		bool *pause = &params->remote_fc.pause;
+		bool *asym_pause = &params->remote_fc.asym_pause;
+
+		if (mvsw_pr_hw_port_remote_fc_get(port, pause, asym_pause)) {
+			netdev_warn(port->net_dev, "Remote FC caps get failed");
+			*pause = *asym_pause = false;
+		}
+	}
+}
+
+static void prestera_port_mdix_cache(struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+
+	if (!params->oper_state)
+		return;
+
+	if (params->mdix.status == ETH_TP_MDI_INVALID ||
+	    params->mdix.admin_mode == ETH_TP_MDI_INVALID) {
+		if (mvsw_pr_hw_port_mdix_get(port, &params->mdix.status,
+					     &params->mdix.admin_mode)) {
+			netdev_warn(port->net_dev, "MDIX params get failed");
+			params->mdix.status = ETH_TP_MDI_INVALID;
+			params->mdix.admin_mode = ETH_TP_MDI_INVALID;
+		}
+	}
+}
+
+static void prestera_port_link_mode_cache(struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+
+	if (!params->oper_state)
+		return;
+
+	if (params->speed == SPEED_UNKNOWN ||
+	    params->duplex == DUPLEX_UNKNOWN) {
+		u32 mode;
+
+		if (mvsw_pr_hw_port_link_mode_get(port, &mode) ||
+		    mode >= MVSW_LINK_MODE_MAX) {
+			params->speed = SPEED_UNKNOWN;
+			params->duplex = DUPLEX_UNKNOWN;
+		} else {
+			const struct prestera_link_mode *pr_mode =
+				prestera_link_modes;
+
+			params->duplex =
+				pr_mode[mode].duplex == MVSW_PORT_DUPLEX_FULL ?
+					DUPLEX_FULL : DUPLEX_HALF;
+			params->speed = prestera_link_modes[mode].speed;
+		}
+	}
+}
+
+static void prestera_port_mdix_get(struct ethtool_link_ksettings *ecmd,
+				   struct prestera_port *port)
+{
+	prestera_port_mdix_cache(port);
+
+	ecmd->base.eth_tp_mdix = port->link_params.mdix.status;
+	ecmd->base.eth_tp_mdix_ctrl = port->link_params.mdix.admin_mode;
+}
+
+static void prestera_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
+					 struct prestera_port *port)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+	bool asym_pause;
+	bool pause;
+	u64 bitmap;
+
+	prestera_port_remote_cap_cache(port);
+
+	bitmap = params->lmode_bmap;
+
+	prestera_modes_to_eth(ecmd->link_modes.lp_advertising,
+			      bitmap, 0, MVSW_PORT_TYPE_NONE);
+
+	if (!bitmap_empty(ecmd->link_modes.lp_advertising,
+			  __ETHTOOL_LINK_MODE_MASK_NBITS)) {
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Autoneg);
+	}
+
+	pause = params->remote_fc.pause;
+	asym_pause = params->remote_fc.asym_pause;
+
+	if (pause)
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Pause);
+	if (asym_pause)
+		ethtool_link_ksettings_add_link_mode(ecmd,
+						     lp_advertising,
+						     Asym_Pause);
+}
+
+static int prestera_port_link_mode_set(struct prestera_port *port,
+				       u32 speed, u8 duplex, u8 type)
+{
+	u32 new_mode = MVSW_LINK_MODE_MAX;
+	u32 mode;
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if (speed != prestera_link_modes[mode].speed)
+			continue;
+		if (duplex != prestera_link_modes[mode].duplex)
+			continue;
+		if (!(prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes))
+			continue;
+		if (type != prestera_link_modes[mode].port_type)
+			continue;
+
+		new_mode = mode;
+		break;
+	}
+
+	if (new_mode == MVSW_LINK_MODE_MAX) {
+		netdev_err(port->net_dev, "Unsupported speed/duplex requested");
+		return -EINVAL;
+	}
+
+	return mvsw_pr_hw_port_link_mode_set(port, new_mode);
+}
+
+static int prestera_port_speed_duplex_set(const struct ethtool_link_ksettings
+					  *ecmd, struct prestera_port *port)
+{
+	int err;
+	u8 duplex;
+	u32 speed;
+	u32 curr_mode;
+
+	err = mvsw_pr_hw_port_link_mode_get(port, &curr_mode);
+	if (err || curr_mode >= MVSW_LINK_MODE_MAX)
+		return -EINVAL;
+
+	if (ecmd->base.duplex != DUPLEX_UNKNOWN)
+		duplex = ecmd->base.duplex == DUPLEX_FULL ?
+			 MVSW_PORT_DUPLEX_FULL : MVSW_PORT_DUPLEX_HALF;
+	else
+		duplex = prestera_link_modes[curr_mode].duplex;
+
+	if (ecmd->base.speed != SPEED_UNKNOWN)
+		speed = ecmd->base.speed;
+	else
+		speed = prestera_link_modes[curr_mode].speed;
+
+	return prestera_port_link_mode_set(port, speed, duplex,
+					   port->caps.type);
+}
+
+static void prestera_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
+				      struct prestera_port *port)
+{
+	ecmd->base.autoneg = port->autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
+
+	prestera_modes_to_eth(ecmd->link_modes.supported,
+			      port->caps.supp_link_modes,
+			      port->caps.supp_fec,
+			      port->caps.type);
+
+	if (port->caps.type != MVSW_PORT_TYPE_TP)
+		return;
+
+	ethtool_link_ksettings_add_link_mode(ecmd, supported, Autoneg);
+
+	if (!netif_running(port->net_dev))
+		return;
+
+	if (port->autoneg) {
+		prestera_modes_to_eth(ecmd->link_modes.advertising,
+				      port->adver_link_modes,
+				      port->adver_fec,
+				      port->caps.type);
+		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
+						     Autoneg);
+	} else if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
+		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
+						     Autoneg);
+}
+
+static int prestera_modes_from_eth(struct prestera_port *port,
+				   const unsigned long *advertising,
+				   const unsigned long *supported,
+				   u64 *link_modes, u8 *fec)
+{
+	struct ethtool_link_ksettings curr = {};
+	u32 mode;
+
+	ethtool_link_ksettings_zero_link_mode(&curr, supported);
+	ethtool_link_ksettings_zero_link_mode(&curr, advertising);
+
+	prestera_port_autoneg_get(&curr, port);
+
+	if (linkmode_equal(advertising, curr.link_modes.advertising)) {
+		*link_modes = port->adver_link_modes;
+		*fec = port->adver_fec;
+		return 0;
+	}
+
+	if (!linkmode_subset(advertising, supported)) {
+		netdev_err(port->net_dev, "Unsupported link mode requested");
+		return -EINVAL;
+	}
+
+	*link_modes  = 0;
+	*fec = 0;
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if (!test_bit(prestera_link_modes[mode].eth_mode, advertising))
+			continue;
+		if (prestera_link_modes[mode].port_type != port->caps.type)
+			continue;
+		*link_modes |= prestera_link_modes[mode].pr_mask;
+	}
+
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if (!test_bit(prestera_fec_caps[mode].eth_mode, advertising))
+			continue;
+		*fec |= prestera_fec_caps[mode].pr_fec;
+	}
+
+	if (*link_modes == 0 && *fec == 0) {
+		netdev_err(port->net_dev, "No link modes requested");
+		return -EINVAL;
+	}
+	if (*link_modes == 0)
+		*link_modes = port->adver_link_modes;
+	if (*fec == 0)
+		*fec = port->adver_fec ? port->adver_fec :
+					 BIT(MVSW_PORT_FEC_OFF_BIT);
+
+	return 0;
+}
+
+static void prestera_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
+					 struct prestera_port *port)
+{
+	u32 mode;
+	u8 ptype;
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes) == 0)
+			continue;
+		ptype = prestera_link_modes[mode].port_type;
+		__set_bit(prestera_port_types[ptype].eth_mode,
+			  ecmd->link_modes.supported);
+	}
+}
+
+static void prestera_port_link_mode_get(struct ethtool_link_ksettings *ecmd,
+					struct prestera_port *port)
+{
+	prestera_port_link_mode_cache(port);
+
+	ecmd->base.speed = port->link_params.speed;
+	ecmd->base.duplex = port->link_params.duplex;
+}
+
+static void prestera_port_get_drvinfo(struct net_device *dev,
+				      struct ethtool_drvinfo *drvinfo)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	struct prestera_switch *sw = port->sw;
+
+	strlcpy(drvinfo->driver, prestera_driver_kind, sizeof(drvinfo->driver));
+	strlcpy(drvinfo->bus_info, dev_name(sw->dev->dev),
+		sizeof(drvinfo->bus_info));
+	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),
+		 "%d.%d.%d",
+		 sw->dev->fw_rev.maj,
+		 sw->dev->fw_rev.min,
+		 sw->dev->fw_rev.sub);
+}
+
+static void prestera_port_type_get(struct ethtool_link_ksettings *ecmd,
+				   struct prestera_port *port)
+{
+	if (port->caps.type < MVSW_PORT_TYPE_MAX)
+		ecmd->base.port = prestera_port_types[port->caps.type].eth_type;
+	else
+		ecmd->base.port = PORT_OTHER;
+}
+
+static int prestera_port_type_set(const struct ethtool_link_ksettings *ecmd,
+				  struct prestera_port *port)
+{
+	int err;
+	u32 type, mode;
+	u32 new_mode = MVSW_LINK_MODE_MAX;
+
+	for (type = 0; type < MVSW_PORT_TYPE_MAX; type++) {
+		if (prestera_port_types[type].eth_type == ecmd->base.port &&
+		    test_bit(prestera_port_types[type].eth_mode,
+			     ecmd->link_modes.supported)) {
+			break;
+		}
+	}
+
+	if (type == port->caps.type)
+		return 0;
+
+	if (type != port->caps.type && ecmd->base.autoneg == AUTONEG_ENABLE)
+		return -EINVAL;
+
+	if (type == MVSW_PORT_TYPE_MAX) {
+		pr_err("Unsupported port type requested\n");
+		return -EINVAL;
+	}
+
+	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
+		if ((prestera_link_modes[mode].pr_mask &
+		    port->caps.supp_link_modes) &&
+		    type == prestera_link_modes[mode].port_type) {
+			new_mode = mode;
+		}
+	}
+
+	if (new_mode < MVSW_LINK_MODE_MAX)
+		err = mvsw_pr_hw_port_link_mode_set(port, new_mode);
+	else
+		err = -EINVAL;
+
+	if (!err) {
+		port->caps.type = type;
+		port->autoneg = false;
+	}
+
+	return err;
+}
+
+static int prestera_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
+				  struct prestera_port *port)
+{
+	if (ecmd->base.eth_tp_mdix_ctrl != ETH_TP_MDI_INVALID &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
+	    port->caps.type == MVSW_PORT_TYPE_TP)
+		return mvsw_pr_hw_port_mdix_set(port,
+						ecmd->base.eth_tp_mdix_ctrl);
+	return 0;
+}
+
+static int prestera_port_get_link_ksettings(struct net_device *dev,
+					    struct ethtool_link_ksettings *ecmd)
+{
+	struct prestera_port *port = netdev_priv(dev);
+
+	/* Dirty hook: Deinit ecmd.
+	 * It caused by suspicious phylink_ethtool_ksettings_get()
+	 * implementation, which can left "kset" uninitialized, when there is no
+	 * SFP plugged
+	 */
+	ethtool_link_ksettings_zero_link_mode(ecmd, supported);
+	ethtool_link_ksettings_zero_link_mode(ecmd, advertising);
+	ethtool_link_ksettings_zero_link_mode(ecmd, lp_advertising);
+	ecmd->base.speed = SPEED_UNKNOWN;
+	ecmd->base.duplex = DUPLEX_UNKNOWN;
+#ifdef CONFIG_PHYLINK
+	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
+		return phylink_ethtool_ksettings_get(port->phy_link, ecmd);
+#endif /* CONFIG_PHYLINK */
+
+	prestera_port_supp_types_get(ecmd, port);
+
+	prestera_port_autoneg_get(ecmd, port);
+
+	if (port->autoneg && netif_carrier_ok(dev) &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
+		prestera_port_remote_cap_get(ecmd, port);
+
+	if (netif_carrier_ok(dev))
+		prestera_port_link_mode_get(ecmd, port);
+
+	prestera_port_type_get(ecmd, port);
+
+	if (port->caps.type == MVSW_PORT_TYPE_TP &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
+		prestera_port_mdix_get(ecmd, port);
+
+	return 0;
+}
+
+static int prestera_port_set_link_ksettings(struct net_device *dev,
+					    const struct ethtool_link_ksettings
+					    *ecmd)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	u64 adver_modes = 0;
+	u8 adver_fec = 0;
+	int err;
+
+#ifdef CONFIG_PHYLINK
+	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
+		return phylink_ethtool_ksettings_set(port->phy_link, ecmd);
+#endif /* CONFIG_PHYLINK */
+
+	err = prestera_port_type_set(ecmd, port);
+	if (err)
+		return err;
+
+	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER) {
+		err = prestera_port_mdix_set(ecmd, port);
+		if (err)
+			return err;
+	}
+
+	if (ecmd->base.autoneg == AUTONEG_ENABLE) {
+		if (prestera_modes_from_eth(port, ecmd->link_modes.advertising,
+					    ecmd->link_modes.supported,
+					    &adver_modes, &adver_fec))
+			return -EINVAL;
+		if (!port->autoneg && !adver_modes)
+			adver_modes = port->caps.supp_link_modes;
+	} else {
+		adver_modes = port->adver_link_modes;
+		adver_fec = port->adver_fec;
+	}
+
+	err = prestera_port_autoneg_set(port,
+					ecmd->base.autoneg == AUTONEG_ENABLE,
+					adver_modes, adver_fec);
+	if (err)
+		return err;
+
+	if (ecmd->base.autoneg == AUTONEG_DISABLE) {
+		err = prestera_port_speed_duplex_set(ecmd, port);
+		if (err)
+			return err;
+	}
+
+	return 0;
+}
+
+static int prestera_port_nway_reset(struct net_device *dev)
+{
+	struct prestera_port *port = netdev_priv(dev);
+
+	if (netif_running(dev) &&
+	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
+	    port->caps.type == MVSW_PORT_TYPE_TP)
+		return mvsw_pr_hw_port_autoneg_restart(port);
+
+	return -EINVAL;
+}
+
+static int prestera_port_get_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	u32 mode;
+	u8 active;
+	int err;
+
+	err = mvsw_pr_hw_port_fec_get(port, &active);
+	if (err)
+		return err;
+
+	fecparam->fec = 0;
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if ((prestera_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
+			continue;
+		fecparam->fec |= prestera_fec_caps[mode].eth_fec;
+	}
+
+	if (active < MVSW_PORT_FEC_MAX)
+		fecparam->active_fec = prestera_fec_caps[active].eth_fec;
+	else
+		fecparam->active_fec = ETHTOOL_FEC_AUTO;
+
+	return 0;
+}
+
+static int prestera_port_set_fecparam(struct net_device *dev,
+				      struct ethtool_fecparam *fecparam)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	u8 fec, active;
+	u32 mode;
+	int err;
+
+	if (port->autoneg) {
+		netdev_err(dev, "FEC set is not allowed while autoneg is on\n");
+		return -EINVAL;
+	}
+
+	err = mvsw_pr_hw_port_fec_get(port, &active);
+	if (err)
+		return err;
+
+	fec = MVSW_PORT_FEC_MAX;
+	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
+		if ((prestera_fec_caps[mode].eth_fec & fecparam->fec) &&
+		    (prestera_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
+			fec = mode;
+			break;
+		}
+	}
+
+	if (fec == active)
+		return 0;
+
+	if (fec == MVSW_PORT_FEC_MAX) {
+		netdev_err(dev, "Unsupported FEC requested");
+		return -EINVAL;
+	}
+
+	return mvsw_pr_hw_port_fec_set(port, fec);
+}
+
+static int prestera_port_get_sset_count(struct net_device *dev, int sset)
+{
+	switch (sset) {
+	case ETH_SS_STATS:
+		return PORT_STATS_CNT;
+	default:
+		return -EOPNOTSUPP;
+	}
+}
+
+static void prestera_port_get_ethtool_stats(struct net_device *dev,
+					    struct ethtool_stats *stats,
+					    u64 *data)
+{
+	struct prestera_port *port = netdev_priv(dev);
+	struct mvsw_pr_port_stats *port_stats = &port->cached_hw_stats.stats;
+
+	memcpy((u8 *)data, port_stats, sizeof(*port_stats));
+}
+
+static void prestera_port_get_strings(struct net_device *dev,
+				      u32 stringset, u8 *data)
+{
+	if (stringset != ETH_SS_STATS)
+		return;
+
+	memcpy(data, *prestera_port_cnt_name, sizeof(prestera_port_cnt_name));
+}
+
+void prestera_ethtool_port_state_changed(struct prestera_port *port,
+					 struct mvsw_pr_port_event *evt)
+{
+	struct prestera_port_link_params *params = &port->link_params;
+
+	params->oper_state = evt->data.oper_state;
+
+	if (params->oper_state) {
+		if (port->autoneg && netif_carrier_ok(port->net_dev) &&
+		    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
+			prestera_port_remote_cap_cache(port);
+
+		if (netif_carrier_ok(port->net_dev))
+			prestera_port_link_mode_cache(port);
+
+		if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
+		    port->caps.type == MVSW_PORT_TYPE_TP)
+			prestera_port_mdix_cache(port);
+	} else {
+		params->remote_fc.pause = false;
+		params->remote_fc.asym_pause = false;
+		params->lmode_bmap = 0;
+		params->speed = SPEED_UNKNOWN;
+		params->duplex = DUPLEX_UNKNOWN;
+		params->mdix.status = ETH_TP_MDI_INVALID;
+		params->mdix.admin_mode = ETH_TP_MDI_INVALID;
+	}
+}
+
+const struct ethtool_ops prestera_ethtool_ops = {
+	.get_drvinfo = prestera_port_get_drvinfo,
+	.get_link_ksettings = prestera_port_get_link_ksettings,
+	.set_link_ksettings = prestera_port_set_link_ksettings,
+	.get_fecparam = prestera_port_get_fecparam,
+	.set_fecparam = prestera_port_set_fecparam,
+	.get_sset_count = prestera_port_get_sset_count,
+	.get_strings = prestera_port_get_strings,
+	.get_ethtool_stats = prestera_port_get_ethtool_stats,
+	.get_link = ethtool_op_get_link,
+	.nway_reset = prestera_port_nway_reset
+};
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h
new file mode 100644
index 0000000..7b4efe9
--- /dev/null
+++ b/drivers/net/ethernet/marvell/prestera/prestera_ethtool.h
@@ -0,0 +1,16 @@
+/* SPDX-License-Identifier: BSD-3-Clause OR GPL-2.0 */
+/* Copyright (c) 2019-2020 Marvell International Ltd. All rights reserved. */
+
+#ifndef __PRESTERA_ETHTOOL_H_
+#define __PRESTERA_ETHTOOL_H_
+
+#include <linux/ethtool.h>
+
+#include "prestera.h"
+
+extern const struct ethtool_ops prestera_ethtool_ops;
+
+void prestera_ethtool_port_state_changed(struct prestera_port *port,
+					 struct mvsw_pr_port_event *evt);
+
+#endif /* _PRESTERA_ETHTOOL_H_ */
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flow.c b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
index 2869bd0..74cfd5f 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_flow.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flow.c
@@ -8,12 +8,18 @@
 #include <linux/netdevice.h>
 
 #include "prestera.h"
+#include "prestera_acl.h"
 
 static LIST_HEAD(prestera_block_cb_list);
 
 static int prestera_flow_block_mall_cb(struct prestera_flow_block *block,
 				       struct tc_cls_matchall_offload *f)
 {
+	if (f->common.chain_index != 0) {
+		NL_SET_ERR_MSG(f->common.extack, "Only chain 0 is supported");
+		return -EOPNOTSUPP;
+	}
+
 	switch (f->command) {
 	case TC_CLSMATCHALL_REPLACE:
 		return prestera_mall_replace(block, f);
@@ -30,9 +36,6 @@ static int prestera_flow_block_flower_cb(struct prestera_flow_block *block,
 {
 	struct prestera_switch *sw = prestera_acl_block_sw(block);
 
-	if (f->common.chain_index != 0)
-		return -EOPNOTSUPP;
-
 	switch (f->command) {
 	case FLOW_CLS_REPLACE:
 		return mvsw_pr_flower_replace(sw, block, f);
@@ -41,6 +44,11 @@ static int prestera_flow_block_flower_cb(struct prestera_flow_block *block,
 		return 0;
 	case FLOW_CLS_STATS:
 		return mvsw_pr_flower_stats(sw, block, f);
+	case FLOW_CLS_TMPLT_CREATE:
+		return prestera_flower_tmplt_create(sw, block, f);
+	case FLOW_CLS_TMPLT_DESTROY:
+		prestera_flower_tmplt_destroy(sw, block, f);
+		return 0;
 	default:
 		return -EOPNOTSUPP;
 	}
@@ -64,11 +72,106 @@ static int prestera_flow_block_cb(enum tc_setup_type type,
 	}
 }
 
+static void prestera_flow_block_destroy(void *cb_priv)
+{
+	struct prestera_flow_block *block = cb_priv;
+
+	prestera_flower_template_cleanup(block);
+
+	WARN_ON(!list_empty(&block->template_list));
+	WARN_ON(!list_empty(&block->binding_list));
+
+	kfree(block);
+}
+
 static void prestera_flow_block_release(void *cb_priv)
 {
 	struct prestera_flow_block *block = cb_priv;
 
-	prestera_acl_block_destroy(block);
+	prestera_flow_block_destroy(block);
+}
+
+static inline bool
+prestera_flow_block_is_bound(const struct prestera_flow_block *block)
+{
+	return block->ruleset_zero;
+}
+
+static struct prestera_flow_block_binding *
+prestera_flow_block_lookup(struct prestera_flow_block *block,
+			   struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+
+	list_for_each_entry(binding, &block->binding_list, list)
+		if (binding->port == port)
+			return binding;
+
+	return NULL;
+}
+
+static int prestera_flow_block_bind(struct prestera_flow_block *block,
+				    struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+	int err;
+
+	binding = kzalloc(sizeof(*binding), GFP_KERNEL);
+	if (!binding)
+		return -ENOMEM;
+
+	binding->span_id = PRESTERA_SPAN_INVALID_ID;
+	binding->port = port;
+
+	if (prestera_flow_block_is_bound(block)) {
+		err = prestera_acl_ruleset_bind(block->ruleset_zero, port);
+		if (err)
+			goto err_ruleset_bind;
+	}
+
+	list_add(&binding->list, &block->binding_list);
+	return 0;
+
+err_ruleset_bind:
+	kfree(binding);
+	return err;
+}
+
+static int prestera_flow_block_unbind(struct prestera_flow_block *block,
+				      struct prestera_port *port)
+{
+	struct prestera_flow_block_binding *binding;
+
+	binding = prestera_flow_block_lookup(block, port);
+	if (!binding)
+		return -ENOENT;
+
+	list_del(&binding->list);
+
+	if (prestera_flow_block_is_bound(block))
+		prestera_acl_ruleset_unbind(block->ruleset_zero, port);
+
+	kfree(binding);
+	return 0;
+}
+
+static struct prestera_flow_block *
+prestera_flow_block_create(struct prestera_switch *sw, struct net *net)
+{
+	struct prestera_flow_block *block;
+
+	block = kzalloc(sizeof(*block), GFP_KERNEL);
+	if (!block)
+		return NULL;
+
+	INIT_LIST_HEAD(&block->binding_list);
+	INIT_LIST_HEAD(&block->template_list);
+	block->net = net;
+	block->sw = sw;
+	block->mall_prio = UINT_MAX;
+	block->flower_min_prio = UINT_MAX;
+
+	return block;
 }
 
 static struct prestera_flow_block *
@@ -82,7 +185,7 @@ prestera_flow_block_get(struct prestera_switch *sw,
 	block_cb = flow_block_cb_lookup(f->block,
 					prestera_flow_block_cb, sw);
 	if (!block_cb) {
-		block = prestera_acl_block_create(sw, f->net);
+		block = prestera_flow_block_create(sw, f->net);
 		if (!block)
 			return ERR_PTR(-ENOMEM);
 
@@ -90,7 +193,7 @@ prestera_flow_block_get(struct prestera_switch *sw,
 					       sw, block,
 					       prestera_flow_block_release);
 		if (IS_ERR(block_cb)) {
-			prestera_acl_block_destroy(block);
+			prestera_flow_block_destroy(block);
 			return ERR_CAST(block_cb);
 		}
 
@@ -114,7 +217,7 @@ static void prestera_flow_block_put(struct prestera_flow_block *block)
 		return;
 
 	flow_block_cb_free(block_cb);
-	prestera_acl_block_destroy(block);
+	prestera_flow_block_destroy(block);
 }
 
 static int prestera_setup_tc_block_bind(struct prestera_port *port,
@@ -142,7 +245,7 @@ static int prestera_setup_tc_block_bind(struct prestera_port *port,
 		disable_block = true;
 	}
 
-	err = prestera_acl_block_bind(sw, block, port);
+	err = prestera_flow_block_bind(block, port);
 	if (err)
 		goto err_block_bind;
 
@@ -159,7 +262,6 @@ static int prestera_setup_tc_block_bind(struct prestera_port *port,
 
 err_block_bind:
 	prestera_flow_block_put(block);
-
 	return err;
 }
 
@@ -171,8 +273,7 @@ static void prestera_setup_tc_block_unbind(struct prestera_port *port,
 	struct flow_block_cb *block_cb;
 	int err;
 
-	block_cb = flow_block_cb_lookup(f->block,
-					prestera_flow_block_cb, sw);
+	block_cb = flow_block_cb_lookup(f->block, prestera_flow_block_cb, sw);
 	if (!block_cb)
 		return;
 
@@ -183,15 +284,16 @@ static void prestera_setup_tc_block_unbind(struct prestera_port *port,
 
 	prestera_mall_destroy(block);
 
-	err = prestera_acl_block_unbind(sw, block, port);
+	err = prestera_flow_block_unbind(block, port);
 	if (err)
-		goto error;
+		goto err_flow_block_unbind;
 
 	if (!flow_block_cb_decref(block_cb)) {
 		flow_block_cb_remove(block_cb, f);
 		list_del(&block_cb->driver_list);
 	}
-error:
+
+err_flow_block_unbind:
 	port->flow_block = NULL;
 }
 
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_flower.c b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
index bad77f4..6b03d8c 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_flower.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_flower.c
@@ -11,41 +11,112 @@
 
 #define PRESTERA_DEFAULT_TC_NUM	8
 
+struct prestera_flower_template {
+	struct prestera_acl_ruleset *ruleset;
+	struct list_head list;
+	u32 chain_index;
+};
+
+void prestera_flower_template_cleanup(struct prestera_flow_block *block)
+{
+	struct prestera_flower_template *template;
+	struct list_head *pos, *n;
+
+	/* put the reference to all rulesets kept in tmpl create */
+	list_for_each_safe(pos, n, &block->template_list) {
+		template = list_entry(pos, typeof(*template), list);
+		prestera_acl_ruleset_put(template->ruleset);
+		list_del(&template->list);
+		kfree(template);
+	}
+}
+
+static int
+prestera_flower_parse_goto_action(struct prestera_flow_block *block,
+				  struct prestera_acl_rule *rule,
+				  u32 chain_index,
+				  const struct flow_action_entry *act)
+{
+	struct prestera_acl_ruleset *ruleset;
+
+	if (act->chain_index <= chain_index)
+		/* we can jump only forward */
+		return -EINVAL;
+
+	if (rule->re_arg.jump.valid)
+		return -EEXIST;
+
+	ruleset = prestera_acl_ruleset_get(block->sw->acl, block,
+					   act->chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	rule->re_arg.jump.valid = 1;
+	rule->re_arg.jump.i.index = prestera_acl_ruleset_index_get(ruleset);
+
+	rule->jump_ruleset = ruleset;
+
+	return 0;
+}
+
 static int mvsw_pr_flower_parse_actions(struct prestera_flow_block *block,
 					struct prestera_acl_rule *rule,
 					struct flow_action *flow_action,
+					u32 chain_index,
 					struct netlink_ext_ack *extack)
 {
 	const struct flow_action_entry *act;
 	struct prestera_flow_block_binding *binding;
-	struct prestera_acl_rule_action_entry a_entry;
 	int err, i;
 
+	/* whole struct (rule->re_arg) must be initialized with 0 */
 	if (!flow_action_has_entries(flow_action))
 		return 0;
 
 	flow_action_for_each(i, act, flow_action) {
-		memset(&a_entry, 0, sizeof(a_entry));
-
 		switch (act->id) {
 		case FLOW_ACTION_ACCEPT:
-			a_entry.info.id = MVSW_ACL_RULE_ACTION_ACCEPT;
+			if (rule->re_arg.accept.valid)
+				return -EEXIST;
+
+			rule->re_arg.accept.valid = 1;
 			break;
 		case FLOW_ACTION_DROP:
-			a_entry.info.id = MVSW_ACL_RULE_ACTION_DROP;
+			if (rule->re_arg.drop.valid)
+				return -EEXIST;
+
+			rule->re_arg.drop.valid = 1;
 			break;
 		case FLOW_ACTION_TRAP:
-			a_entry.info.id = MVSW_ACL_RULE_ACTION_TRAP;
+			if (rule->re_arg.trap.valid)
+				return -EEXIST;
+
+			rule->re_arg.trap.valid = 1;
+			rule->re_arg.trap.i.hw_tc =
+				prestera_acl_rule_hw_tc_get(rule);
 			break;
 		case FLOW_ACTION_POLICE:
-			a_entry.info.id = MVSW_ACL_RULE_ACTION_POLICE;
-			a_entry.info.police.rate = act->police.rate_bytes_ps;
-			a_entry.info.police.burst = act->police.burst;
+			if (rule->re_arg.police.valid)
+				return -EEXIST;
+
+			rule->re_arg.police.valid = 1;
+			rule->re_arg.police.i.rate =
+				act->police.rate_bytes_ps;
+			rule->re_arg.police.i.burst = act->police.burst;
 			break;
 		case FLOW_ACTION_GOTO:
+			err = prestera_flower_parse_goto_action(block, rule,
+								chain_index,
+								act);
+			if (err)
+				return err;
+
 			rule_flag_set(rule, GOTO);
 			break;
 		case FLOW_ACTION_NAT:
+			if (rule->re_arg.nat.valid)
+				return -EEXIST;
+
 			if (~act->nat.mask) {
 				NL_SET_ERR_MSG_MOD(extack,
 						   "Netmask is not supported");
@@ -57,20 +128,25 @@ static int mvsw_pr_flower_parse_actions(struct prestera_flow_block *block,
 				     "All-zero IP address isn't supported");
 				return -EOPNOTSUPP;
 			}
-			a_entry.info.id = MVSW_ACL_RULE_ACTION_NAT;
-			a_entry.info.nat.old_addr = act->nat.old_addr;
-			a_entry.info.nat.new_addr = act->nat.new_addr;
-			a_entry.info.nat.flags = act->nat.flags;
 
-			/* get first interface bound to the block */
+			rule->re_arg.nat.valid = 1;
+			rule->re_arg.nat.i.old_addr = act->nat.old_addr;
+			rule->re_arg.nat.i.new_addr = act->nat.new_addr;
+			rule->re_arg.nat.i.flags = act->nat.flags;
+
+			/* TODO: move this to the rule_add() */
 			binding = list_first_entry
 			    (&block->binding_list,
 			     struct prestera_flow_block_binding, list);
-			a_entry.info.nat.dev = binding->port->dev_id;
-			a_entry.info.nat.port = binding->port->hw_id;
+			rule->re_arg.nat.i.dev = binding->port->dev_id;
+			rule->re_arg.nat.i.port = binding->port->hw_id;
+			rule_flag_set(rule, NAT);
 			break;
 		case FLOW_ACTION_CT:
 			/* TODO: check ct nat commit */
+			if (rule_flag_test(rule, CT))
+				return -EEXIST;
+
 			err = prestera_ct_parse_action(act, rule, extack);
 			if (err)
 				return err;
@@ -82,9 +158,6 @@ static int mvsw_pr_flower_parse_actions(struct prestera_flow_block *block,
 			pr_err("Unsupported action\n");
 			return -EOPNOTSUPP;
 		}
-		err = prestera_acl_rule_action_add(rule, &a_entry);
-		if (err)
-			return err;
 	}
 
 	return 0;
@@ -95,10 +168,11 @@ static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
 				     struct prestera_flow_block *block)
 {
 	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
-	struct prestera_acl_rule_match_entry *m_entry;
+	struct prestera_acl_match *r_match = &rule->re_key.match;
 	struct prestera_port *port;
 	struct net_device *ingress_dev;
 	struct flow_match_meta match;
+	__be16 key, mask;
 
 	flow_rule_match_meta(f_rule, &match);
 	if (match.mask->ingress_ifindex != 0xFFFFFFFF) {
@@ -122,15 +196,15 @@ static int mvsw_pr_flower_parse_meta(struct prestera_acl_rule *rule,
 	}
 	port = netdev_priv(ingress_dev);
 
-	/* add port key,mask */
-	m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-	if (!m_entry)
-		return -ENOMEM;
+	mask = htons(0x1FFF);
+	key = htons(port->hw_id);
+	rule_match_set(r_match->key, SYS_PORT, key);
+	rule_match_set(r_match->mask, SYS_PORT, mask);
 
-	m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT;
-	m_entry->info.u64.key = port->hw_id | ((u64)port->dev_id << 32);
-	m_entry->info.u64.mask = ~(u64)0;
-	prestera_acl_rule_match_add(rule, m_entry);
+	mask = htons(0x1FF);
+	key = htons(port->dev_id);
+	rule_match_set(r_match->key, SYS_DEV, key);
+	rule_match_set(r_match->mask, SYS_DEV, mask);
 
 	return 0;
 }
@@ -141,9 +215,9 @@ static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 {
 	struct flow_rule *f_rule = flow_cls_offload_flow_rule(f);
 	struct flow_dissector *dissector = f_rule->match.dissector;
-	struct prestera_acl_rule_match_entry *m_entry;
-	u16 n_proto_mask = 0;
-	u16 n_proto_key = 0;
+	struct prestera_acl_match *r_match = &rule->re_key.match;
+	__be16 n_proto_mask = 0;
+	__be16 n_proto_key = 0;
 	u16 addr_type = 0;
 	u8 ip_proto = 0;
 	u32 hwtc = 0;
@@ -203,33 +277,19 @@ static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 		struct flow_match_basic match;
 
 		flow_rule_match_basic(f_rule, &match);
-		n_proto_key = ntohs(match.key->n_proto);
-		n_proto_mask = ntohs(match.mask->n_proto);
+		n_proto_key = match.key->n_proto;
+		n_proto_mask = match.mask->n_proto;
 
-		if (n_proto_key == ETH_P_ALL) {
+		if (ntohs(match.key->n_proto) == ETH_P_ALL) {
 			n_proto_key = 0;
 			n_proto_mask = 0;
 		}
 
-		/* add eth type key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE;
-		m_entry->info.u16.key = n_proto_key;
-		m_entry->info.u16.mask = n_proto_mask;
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		/* add ip proto key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO;
-		m_entry->info.u8.key = match.key->ip_proto;
-		m_entry->info.u8.mask = match.mask->ip_proto;
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, ETH_TYPE, n_proto_key);
+		rule_match_set(r_match->mask, ETH_TYPE, n_proto_mask);
+
+		rule_match_set(r_match->key, IP_PROTO, match.key->ip_proto);
+		rule_match_set(r_match->mask, IP_PROTO, match.mask->ip_proto);
 		ip_proto = match.key->ip_proto;
 	}
 
@@ -238,29 +298,27 @@ static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_eth_addrs(f_rule, &match);
 
-		/* add ethernet dst key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC;
-		memcpy(&m_entry->info.mac.key,
-		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry->info.mac.mask,
-		       &match.mask->dst, sizeof(match.mask->dst));
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		/* add ethernet src key,mask */
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC;
-		memcpy(&m_entry->info.mac.key,
-		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry->info.mac.mask,
-		       &match.mask->src, sizeof(match.mask->src));
-		prestera_acl_rule_match_add(rule, m_entry);
+		/* DA key, mask */
+		rule_match_set_n(r_match->key,
+				 ETH_DMAC_0, &match.key->dst[0], 4);
+		rule_match_set_n(r_match->key,
+				 ETH_DMAC_1, &match.key->dst[4], 2);
+
+		rule_match_set_n(r_match->mask,
+				 ETH_DMAC_0, &match.mask->dst[0], 4);
+		rule_match_set_n(r_match->mask,
+				 ETH_DMAC_1, &match.mask->dst[4], 2);
+
+		/* SA key, mask */
+		rule_match_set_n(r_match->key,
+				 ETH_SMAC_0, &match.key->src[0], 4);
+		rule_match_set_n(r_match->key,
+				 ETH_SMAC_1, &match.key->src[4], 2);
+
+		rule_match_set_n(r_match->mask,
+				 ETH_SMAC_0, &match.mask->src[0], 4);
+		rule_match_set_n(r_match->mask,
+				 ETH_SMAC_1, &match.mask->src[4], 2);
 	}
 
 	if (addr_type == FLOW_DISSECTOR_KEY_IPV4_ADDRS) {
@@ -268,27 +326,11 @@ static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_ipv4_addrs(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC;
-		memcpy(&m_entry->info.u32.key,
-		       &match.key->src, sizeof(match.key->src));
-		memcpy(&m_entry->info.u32.mask,
-		       &match.mask->src, sizeof(match.mask->src));
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST;
-		memcpy(&m_entry->info.u32.key,
-		       &match.key->dst, sizeof(match.key->dst));
-		memcpy(&m_entry->info.u32.mask,
-		       &match.mask->dst, sizeof(match.mask->dst));
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, IP_SRC, match.key->src);
+		rule_match_set(r_match->mask, IP_SRC, match.mask->src);
+
+		rule_match_set(r_match->key, IP_DST, match.key->dst);
+		rule_match_set(r_match->mask, IP_DST, match.mask->dst);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_PORTS)) {
@@ -303,49 +345,34 @@ static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_ports(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC;
-		m_entry->info.u16.key = ntohs(match.key->src);
-		m_entry->info.u16.mask = ntohs(match.mask->src);
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST;
-		m_entry->info.u16.key = ntohs(match.key->dst);
-		m_entry->info.u16.mask = ntohs(match.mask->dst);
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, L4_PORT_SRC, match.key->src);
+		rule_match_set(r_match->mask, L4_PORT_SRC, match.mask->src);
+
+		rule_match_set(r_match->key, L4_PORT_DST, match.key->dst);
+		rule_match_set(r_match->mask, L4_PORT_DST, match.mask->dst);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_PORTS_RANGE)) {
 		struct flow_match_ports_range match;
+		__be32 tp_key, tp_mask;
 
 		flow_rule_match_ports_range(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->info.type =
-			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC;
-		m_entry->info.u32.key = ntohs(match.key->tp_min.src) |
-				(u32)ntohs(match.key->tp_max.src) << 16;
-		m_entry->info.u32.mask = ntohs(match.mask->tp_min.src) |
-				(u32)ntohs(match.mask->tp_max.src) << 16;
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->info.type =
-			MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST;
-		m_entry->info.u32.key = ntohs(match.key->tp_min.dst) |
-				(u32)ntohs(match.key->tp_max.dst) << 16;
-		m_entry->info.u32.mask = ntohs(match.mask->tp_min.dst) |
-				(u32)ntohs(match.mask->tp_max.dst) << 16;
-		prestera_acl_rule_match_add(rule, m_entry);
+		/* src port range (min, max) */
+		tp_key = htonl(ntohs(match.key->tp_min.src) |
+			       (ntohs(match.key->tp_max.src) << 16));
+		tp_mask = htonl(ntohs(match.mask->tp_min.src) |
+				(ntohs(match.mask->tp_max.src) << 16));
+		rule_match_set(r_match->key, L4_PORT_RANGE_SRC, tp_key);
+		rule_match_set(r_match->mask, L4_PORT_RANGE_SRC, tp_mask);
+
+		/* dst port range (min, max) */
+		tp_key = htonl(ntohs(match.key->tp_min.dst) |
+			       (ntohs(match.key->tp_max.dst) << 16));
+		tp_mask = htonl(ntohs(match.mask->tp_min.dst) |
+				(ntohs(match.mask->tp_max.dst) << 16));
+		rule_match_set(r_match->key, L4_PORT_RANGE_DST, tp_key);
+		rule_match_set(r_match->mask, L4_PORT_RANGE_DST, tp_mask);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_VLAN)) {
@@ -354,23 +381,15 @@ static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 		flow_rule_match_vlan(f_rule, &match);
 
 		if (match.mask->vlan_id != 0) {
-			m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-			if (!m_entry)
-				return -ENOMEM;
-			m_entry->info.type =
-				MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID;
-			m_entry->info.u16.key = match.key->vlan_id;
-			m_entry->info.u16.mask = match.mask->vlan_id;
-			prestera_acl_rule_match_add(rule, m_entry);
+			__be16 key = cpu_to_be16(match.key->vlan_id);
+			__be16 mask = cpu_to_be16(match.mask->vlan_id);
+
+			rule_match_set(r_match->key, VLAN_ID, key);
+			rule_match_set(r_match->mask, VLAN_ID, mask);
 		}
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID;
-		m_entry->info.u16.key = ntohs(match.key->vlan_tpid);
-		m_entry->info.u16.mask = ntohs(match.mask->vlan_tpid);
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, VLAN_TPID, match.key->vlan_tpid);
+		rule_match_set(r_match->mask, VLAN_TPID, match.mask->vlan_tpid);
 	}
 
 	if (flow_rule_match_key(f_rule, FLOW_DISSECTOR_KEY_ICMP)) {
@@ -378,24 +397,15 @@ static int mvsw_pr_flower_parse(struct prestera_flow_block *block,
 
 		flow_rule_match_icmp(f_rule, &match);
 
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE;
-		m_entry->info.u8.key = match.key->type;
-		m_entry->info.u8.mask = match.mask->type;
-		prestera_acl_rule_match_add(rule, m_entry);
-
-		m_entry = kmalloc(sizeof(*m_entry), GFP_KERNEL);
-		if (!m_entry)
-			return -ENOMEM;
-		m_entry->info.type = MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE;
-		m_entry->info.u8.key = match.key->code;
-		m_entry->info.u8.mask = match.mask->code;
-		prestera_acl_rule_match_add(rule, m_entry);
+		rule_match_set(r_match->key, ICMP_TYPE, match.key->type);
+		rule_match_set(r_match->mask, ICMP_TYPE, match.mask->type);
+
+		rule_match_set(r_match->key, ICMP_CODE, match.key->code);
+		rule_match_set(r_match->mask, ICMP_CODE, match.mask->code);
 	}
 
 	return mvsw_pr_flower_parse_actions(block, rule, &f->rule->action,
+					    f->common.chain_index,
 					    f->common.extack);
 }
 
@@ -438,6 +448,8 @@ int mvsw_pr_flower_replace(struct prestera_switch *sw,
 			   struct prestera_flow_block *block,
 			   struct flow_cls_offload *f)
 {
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl *acl = sw->acl;
 	struct prestera_acl_rule *rule;
 	int err;
 
@@ -445,14 +457,27 @@ int mvsw_pr_flower_replace(struct prestera_switch *sw,
 	if (err)
 		return err;
 
-	rule = prestera_acl_rule_create(block, f->cookie,
+	ruleset = prestera_acl_ruleset_get(acl, block, f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	/* increments the ruleset reference */
+	rule = prestera_acl_rule_create(ruleset, f->cookie,
 					f->common.chain_index);
-	if (IS_ERR(rule))
-		return PTR_ERR(rule);
+	if (IS_ERR(rule)) {
+		err = PTR_ERR(rule);
+		goto err_rule_create;
+	}
 
 	err = mvsw_pr_flower_parse(block, rule, f);
 	if (err)
-		goto err_flower_parse;
+		goto err_rule_add;
+
+	if (!prestera_acl_ruleset_is_offload(ruleset)) {
+		err = prestera_acl_ruleset_offload(ruleset);
+		if (err)
+			goto err_ruleset_offload;
+	}
 
 	err = prestera_acl_rule_add(sw, rule);
 	if (err)
@@ -460,11 +485,14 @@ int mvsw_pr_flower_replace(struct prestera_switch *sw,
 
 	prestera_flower_prio_update(block, f->common.prio);
 
+	prestera_acl_ruleset_put(ruleset);
 	return 0;
 
+err_ruleset_offload:
 err_rule_add:
-err_flower_parse:
 	prestera_acl_rule_destroy(rule);
+err_rule_create:
+	prestera_acl_ruleset_put(ruleset);
 	return err;
 }
 
@@ -472,36 +500,128 @@ void mvsw_pr_flower_destroy(struct prestera_switch *sw,
 			    struct prestera_flow_block *block,
 			    struct flow_cls_offload *f)
 {
+	struct prestera_acl_ruleset *ruleset;
 	struct prestera_acl_rule *rule;
 
-	rule = prestera_acl_rule_lookup(prestera_acl_block_ruleset_get(block),
-					f->cookie);
+	ruleset = prestera_acl_ruleset_lookup(sw->acl, block,
+					      f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return;
+
+	rule = prestera_acl_rule_lookup(ruleset, f->cookie);
 	if (rule) {
 		prestera_acl_rule_del(sw, rule);
 		prestera_acl_rule_destroy(rule);
 	}
+	prestera_acl_ruleset_put(ruleset);
+}
+
+int prestera_flower_tmplt_create(struct prestera_switch *sw,
+				 struct prestera_flow_block *block,
+				 struct flow_cls_offload *f)
+{
+	struct prestera_flower_template *template;
+	struct prestera_acl_ruleset *ruleset;
+	struct prestera_acl_rule rule;
+	int err;
+
+	memset(&rule, 0, sizeof(rule));
+	err = mvsw_pr_flower_parse(block, &rule, f);
+	if (err)
+		return err;
+
+	template = kmalloc(sizeof(*template), GFP_KERNEL);
+	if (!template) {
+		err = -ENOMEM;
+		goto err_malloc;
+	}
+
+	prestera_acl_rule_keymask_pcl_id_set(&rule, 0);
+	ruleset = prestera_acl_ruleset_get(sw->acl, block,
+					   f->common.chain_index);
+	if (IS_ERR_OR_NULL(ruleset)) {
+		err = -EINVAL;
+		goto err_ruleset_get;
+	}
+
+	/* preserve keymask/template to this ruleset */
+	err = prestera_acl_ruleset_keymask_set(ruleset, rule.re_key.match.mask);
+	if (err)
+		goto err_ruleset_offload;
+
+	/* skip error, as it is not possible to reject template operation,
+	 * so, keep the reference to the ruleset for rules to be added
+	 * to that ruleset later. In case of offload fail, the ruleset
+	 * will be offloaded again during adding a new rule. Also,
+	 * unlikly possble that ruleset is already offloaded at this staage.
+	 */
+	prestera_acl_ruleset_offload(ruleset);
+
+	/* keep the reference to the ruleset */
+	template->ruleset = ruleset;
+	template->chain_index = f->common.chain_index;
+	list_add_rcu(&template->list, &block->template_list);
+	return 0;
+
+err_ruleset_offload:
+	prestera_acl_ruleset_put(ruleset);
+err_ruleset_get:
+	kfree(template);
+err_malloc:
+	MVSW_LOG_ERROR("Create chain template failed");
+	return err;
+}
+
+void prestera_flower_tmplt_destroy(struct prestera_switch *sw,
+				   struct prestera_flow_block *block,
+				   struct flow_cls_offload *f)
+{
+	struct prestera_flower_template *template;
+	struct list_head *pos, *n;
+
+	list_for_each_safe(pos, n, &block->template_list) {
+		template = list_entry(pos, typeof(*template), list);
+		if (template->chain_index == f->common.chain_index) {
+			/* put the reference to the ruleset kept in create */
+			prestera_acl_ruleset_put(template->ruleset);
+			list_del(&template->list);
+			kfree(template);
+			return;
+		}
+	}
 }
 
 int mvsw_pr_flower_stats(struct prestera_switch *sw,
 			 struct prestera_flow_block *block,
 			 struct flow_cls_offload *f)
 {
+	struct prestera_acl_ruleset *ruleset;
 	struct prestera_acl_rule *rule;
 	u64 packets;
 	u64 lastuse;
 	u64 bytes;
 	int err;
 
-	rule = prestera_acl_rule_lookup(prestera_acl_block_ruleset_get(block),
-					f->cookie);
-	if (!rule)
-		return -EINVAL;
+	ruleset = prestera_acl_ruleset_lookup(sw->acl, block,
+					      f->common.chain_index);
+	if (IS_ERR(ruleset))
+		return PTR_ERR(ruleset);
+
+	rule = prestera_acl_rule_lookup(ruleset, f->cookie);
+	if (!rule) {
+		err = -EINVAL;
+		goto err_rule_get_stats;
+	}
 
-	err = prestera_acl_rule_get_stats(sw, rule, &packets, &bytes, &lastuse);
+	err = prestera_acl_rule_get_stats(sw->acl, rule, &packets,
+					  &bytes, &lastuse);
 	if (err)
-		return err;
+		goto err_rule_get_stats;
 
 	flow_stats_update(&f->stats, bytes, packets, 0, lastuse,
-			  FLOW_ACTION_HW_STATS_IMMEDIATE);
-	return 0;
+			  FLOW_ACTION_HW_STATS_DELAYED);
+
+err_rule_get_stats:
+	prestera_acl_ruleset_put(ruleset);
+	return err;
 }
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.c b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
index b2161d1..0a9578b 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.c
@@ -10,6 +10,7 @@
 
 #include "prestera.h"
 #include "prestera_hw.h"
+#include "prestera_acl.h"
 #include "prestera_log.h"
 #include "prestera_fw_log.h"
 #include "prestera_rxtx.h"
@@ -57,13 +58,15 @@ enum mvsw_msg_type {
 	MVSW_MSG_TYPE_BRIDGE_PORT_ADD = 0x402,
 	MVSW_MSG_TYPE_BRIDGE_PORT_DELETE = 0x403,
 
-	MVSW_MSG_TYPE_ACL_RULE_ADD = 0x500,
-	MVSW_MSG_TYPE_ACL_RULE_DELETE = 0x501,
 	MVSW_MSG_TYPE_ACL_RULE_STATS_GET = 0x510,
-	MVSW_MSG_TYPE_ACL_RULESET_CREATE = 0x520,
-	MVSW_MSG_TYPE_ACL_RULESET_DELETE = 0x521,
-	MVSW_MSG_TYPE_ACL_PORT_BIND = 0x530,
-	MVSW_MSG_TYPE_ACL_PORT_UNBIND = 0x531,
+
+	MVSW_MSG_TYPE_VTCAM_CREATE = 0x540,
+	MVSW_MSG_TYPE_VTCAM_DESTROY = 0x541,
+	MVSW_MSG_TYPE_VTCAM_RULE_ADD = 0x550,
+	MVSW_MSG_TYPE_VTCAM_RULE_DELETE = 0x551,
+	MVSW_MSG_TYPE_VTCAM_RULE_SET = 0x552,
+	MVSW_MSG_TYPE_VTCAM_IFACE_BIND = 0x560,
+	MVSW_MSG_TYPE_VTCAM_IFACE_UNBIND = 0x561,
 
 	MVSW_MSG_TYPE_ROUTER_RIF_CREATE = 0x600,
 	MVSW_MSG_TYPE_ROUTER_RIF_DELETE = 0x601,
@@ -97,6 +100,11 @@ enum mvsw_msg_type {
 
 	MVSW_MSG_TYPE_NAT_PORT_NEIGH_UPDATE = 0X1200,
 
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_ADD = 0X1211,
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_SET = 0X1212,
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_DEL = 0X1213,
+	MVSW_MSG_TYPE_NAT_NH_MANGLE_GET = 0X1214,
+
 	MVSW_MSG_TYPE_CPU_CODE_COUNTERS_GET = 0x2000,
 
 	MVSW_MSG_TYPE_ACK = 0x10000,
@@ -108,7 +116,6 @@ enum mvsw_msg_port_attr {
 	MVSW_MSG_PORT_ATTR_OPER_STATE = 2,
 	MVSW_MSG_PORT_ATTR_MTU = 3,
 	MVSW_MSG_PORT_ATTR_MAC = 4,
-	MVSW_MSG_PORT_ATTR_SPEED = 5,
 	MVSW_MSG_PORT_ATTR_ACCEPT_FRAME_TYPE = 6,
 	MVSW_MSG_PORT_ATTR_LEARNING = 7,
 	MVSW_MSG_PORT_ATTR_FLOOD = 8,
@@ -119,7 +126,6 @@ enum mvsw_msg_port_attr {
 	MVSW_MSG_PORT_ATTR_TYPE = 13,
 	MVSW_MSG_PORT_ATTR_FEC = 14,
 	MVSW_MSG_PORT_ATTR_AUTONEG = 15,
-	MVSW_MSG_PORT_ATTR_DUPLEX = 16,
 	MVSW_MSG_PORT_ATTR_STATS = 17,
 	MVSW_MSG_PORT_ATTR_MDIX = 18,
 	MVSW_MSG_PORT_ATTR_AUTONEG_RESTART = 19,
@@ -375,22 +381,41 @@ struct mvsw_msg_nh {
 	u8 mac[ETH_ALEN];
 } __packed;
 
+struct mvsw_msg_nh_mangle_info {
+	u8 l4_src_valid:1, l4_dst_valid:1,
+	   sip_valid:1, dip_valid:1;
+	__be16 l4_src;
+	__be16 l4_dst;
+	__be32 sip;
+	__be32 dip;
+	struct mvsw_msg_nh nh;
+} __packed __aligned(4);
+
+struct mvsw_msg_nh_mangle_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 nh_id;
+	struct mvsw_msg_nh_mangle_info info;
+} __packed __aligned(4);
+
+struct mvsw_msg_nh_mangle_ret {
+	struct mvsw_msg_ret ret;
+	u32 nh_id;
+	struct mvsw_msg_nh_mangle_info info;
+} __packed __aligned(4);
+
 struct mvsw_msg_acl_action {
 	u32 id;
 	union {
 		struct {
+			u8 hw_tc;
+		} __packed trap;
+		struct {
 			u64 rate;
 			u64 burst;
 		} __packed police;
 		struct {
-			u8 l4_src_valid:1, l4_dst_valid:1,
-			   sip_valid:1, dip_valid:1;
-			__be16 l4_src;
-			__be16 l4_dst;
-			__be32 sip;
-			__be32 dip;
-			struct mvsw_msg_nh nh;
-		} __packed mangle;
+			u32 nh_id;
+		} __packed nh;
 		struct {
 			__be32 old_addr;
 			__be32 new_addr;
@@ -399,75 +424,73 @@ struct mvsw_msg_acl_action {
 			u32 flags;
 		} __packed nat;
 		struct {
-			u32 chain;
+			u32 index;
 		} __packed jump;
 	};
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_match {
-	u32 type;
-	union {
-		struct {
-			u8 key;
-			u8 mask;
-		} __packed u8;
-		struct {
-			u16 key;
-			u16 mask;
-		} __packed u16;
-		struct {
-			u32 key;
-			u32 mask;
-		} __packed u32;
-		struct {
-			u64 key;
-			u64 mask;
-		} __packed u64;
-		struct {
-			u8 key[ETH_ALEN];
-			u8 mask[ETH_ALEN];
-		} __packed mac;
-	} keymask;
+struct mvsw_msg_vtcam_create_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	u8 lookup;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_rule_cmd {
+struct mvsw_msg_vtcam_destroy_cmd {
 	struct mvsw_msg_cmd cmd;
-	u32 id;
-	u32 priority;
-	u16 ruleset_id;
-	u8 chain_id;
-	u8 hw_tc;
-	u8 n_actions;
-	u8 n_matches;
-	u32 chain;
+	u32 vtcam_id;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_rule_ret {
-	struct mvsw_msg_ret ret;
-	u32 id;
+struct mvsw_msg_vtcam_rule_add_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 key[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	u32 keymask[__PRESTERA_ACL_RULE_MATCH_TYPE_MAX];
+	u32 vtcam_id;
+	u32 prio;
+	u8 n_act;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_rule_stats_ret {
-	struct mvsw_msg_ret ret;
-	u64 packets;
-	u64 bytes;
+struct mvsw_msg_vtcam_rule_cmd {
+	struct mvsw_msg_cmd cmd;
+	u32 vtcam_id;
+	u32 id;
+	bool enable;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_ruleset_bind_cmd {
+struct mvsw_msg_vtcam_bind_cmd {
 	struct mvsw_msg_cmd cmd;
-	u32 port;
-	u32 dev;
-	u16 ruleset_id;
+	union {
+		struct {
+			u32 hw_id;
+			u32 dev_id;
+		} __packed port;
+		u32 index;
+	};
+	u32 vtcam_id;
+	u16 pcl_id;
+	u8 type;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_ruleset_cmd {
+struct mvsw_msg_vtcam_ret {
+	struct mvsw_msg_ret ret;
+	u32 vtcam_id;
+	u32 rule_id;
+	u32 counter_id;
+} __packed __aligned(4);
+
+struct mvsw_msg_acl_rule_stats_cmd {
 	struct mvsw_msg_cmd cmd;
-	u16 id;
+	u32 start_idx;
+	u32 count;
 } __packed __aligned(4);
 
-struct mvsw_msg_acl_ruleset_ret {
+struct mvsw_msg_acl_stats {
+	u64 packets;
+	u64 bytes;
+} __packed;
+
+struct mvsw_msg_acl_rule_stats_ret {
 	struct mvsw_msg_ret ret;
-	u16 id;
+	struct mvsw_msg_acl_stats stats[0];
 } __packed __aligned(4);
 
 struct mvsw_msg_nat_port_cmd {
@@ -517,8 +540,6 @@ struct mvsw_msg_event_fdb {
 
 struct mvsw_msg_event_port_param {
 	u8 oper_state;
-	u8 duplex;
-	u32 speed;
 } __packed __aligned(4);
 
 struct mvsw_msg_event_port {
@@ -673,32 +694,50 @@ static int mvsw_pr_cmd_qid_by_req_type(enum mvsw_msg_type type)
 	(__er);							\
 })
 
-#define __fw_send_req_resp(_switch, _type, _req, _req_size,	\
-_response, _wait)						\
+#define __fw_send_req_resp(_switch, _type, _request, _req_size,	\
+_response, _resp_size, _wait)					\
 ({								\
 	int __e;						\
 	typeof(_switch) __sw = (_switch);			\
-	typeof(_req) __req = (_req);				\
+	typeof(_request) __req = (_request);			\
 	typeof(_response) __resp = (_response);			\
-	__req->cmd.type = (_type);				\
+	typeof(_type) __type = (_type);				\
+	__req->cmd.type = (__type);				\
 	__e = __sw->dev->send_req(__sw->dev,			\
-		mvsw_pr_cmd_qid_by_req_type(_type),		\
+		mvsw_pr_cmd_qid_by_req_type(__type),		\
 		(u8 *)__req, _req_size,				\
-		(u8 *)__resp, sizeof(*__resp),			\
+		(u8 *)__resp, _resp_size,			\
 		_wait);						\
 	if (!__e)						\
 		__e = fw_check_resp(__resp);			\
 	(__e);							\
 })
 
+#define fw_send_nreq_nresp(_sw, _t, _req, _req_size, _resp, _resp_size)	\
+	__fw_send_req_resp(_sw, _t, _req, _req_size, _resp, _resp_size, 0)
+
 #define fw_send_nreq_resp(_sw, _t, _req, _req_size, _resp)	\
-	__fw_send_req_resp(_sw, _t, _req, _req_size, _resp, 0)
+({								\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _req, _req_size,		\
+			    _res, sizeof(*_res), 0));		\
+})
 
-#define fw_send_req_resp(_sw, _t, _req, _resp)	\
-	__fw_send_req_resp(_sw, _t, _req, sizeof(*_req), _resp, 0)
+#define fw_send_req_resp(_sw, _t, _req, _resp)			\
+({								\
+	typeof(_req) _re = (_req);				\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _re, sizeof(*_re),		\
+			    _res, sizeof(*_res), 0));		\
+})
 
 #define fw_send_req_resp_wait(_sw, _t, _req, _resp, _wait)	\
-	__fw_send_req_resp(_sw, _t, _req, sizeof(*_req), _resp, _wait)
+({								\
+	typeof(_req) _re = (_req);				\
+	typeof(_resp) _res = (_resp);				\
+	(__fw_send_req_resp(_sw, _t, _re, sizeof(*_re),		\
+			    _res, sizeof(*_res), _wait));	\
+})
 
 #define fw_send_req(_sw, _t, _req)	\
 ({							\
@@ -715,6 +754,9 @@ struct mvsw_fw_event_handler {
 	void *arg;
 };
 
+static void prestera_hw_remote_fc_to_eth(u8 fc, bool *pause, bool *asym_pause);
+static u8 mvsw_mdix_to_eth(u8 mode);
+
 static void mvsw_pr_fw_keepalive_wd_work_fn(struct work_struct *work)
 {
 	struct delayed_work *dl_work =
@@ -743,13 +785,11 @@ static int fw_parse_port_evt(u8 *msg, struct mvsw_pr_event *evt)
 
 	evt->port_evt.port_id = hw_evt->port_id;
 
-	if (evt->id == MVSW_PORT_EVENT_STATE_CHANGED) {
+	if (evt->id == MVSW_PORT_EVENT_STATE_CHANGED)
 		evt->port_evt.data.oper_state = hw_evt->param.oper_state;
-		evt->port_evt.data.duplex = hw_evt->param.duplex;
-		evt->port_evt.data.speed = hw_evt->param.speed;
-	} else {
+	else
 		return -EINVAL;
-	}
+
 	return 0;
 }
 
@@ -1203,26 +1243,6 @@ int mvsw_pr_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state)
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_STP_PORT_SET, &req);
 }
 
-int mvsw_pr_hw_port_speed_get(const struct prestera_port *port, u32 *speed)
-{
-	struct mvsw_msg_port_attr_ret resp;
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_SPEED,
-		.port = port->hw_id,
-		.dev = port->dev_id
-	};
-	int err;
-
-	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-			       &req, &resp);
-	if (err)
-		return err;
-
-	*speed = resp.param.speed;
-
-	return err;
-}
-
 int mvsw_pr_hw_port_uc_flood_set(const struct prestera_port *port, bool flood)
 {
 	struct mvsw_msg_port_attr_cmd req = {
@@ -1394,6 +1414,27 @@ static u8 mvsw_mdix_from_eth(u8 mode)
 	return MVSW_PORT_TP_NA;
 }
 
+static void prestera_hw_remote_fc_to_eth(u8 fc, bool *pause, bool *asym_pause)
+{
+	switch (fc) {
+	case MVSW_FC_SYMMETRIC:
+		*pause = true;
+		*asym_pause = false;
+		break;
+	case MVSW_FC_ASYMMETRIC:
+		*pause = false;
+		*asym_pause = true;
+		break;
+	case MVSW_FC_SYMM_ASYMM:
+		*pause = true;
+		*asym_pause = true;
+		break;
+	default:
+		*pause = false;
+		*asym_pause = false;
+	};
+}
+
 int mvsw_pr_hw_port_mdix_get(const struct prestera_port *port, u8 *status,
 			     u8 *admin_mode)
 {
@@ -1513,26 +1554,6 @@ int mvsw_pr_hw_port_autoneg_set(const struct prestera_port *port,
 	return fw_send_req(port->sw, MVSW_MSG_TYPE_PORT_ATTR_SET, &req);
 }
 
-int mvsw_pr_hw_port_duplex_get(const struct prestera_port *port, u8 *duplex)
-{
-	struct mvsw_msg_port_attr_ret resp;
-	struct mvsw_msg_port_attr_cmd req = {
-		.attr = MVSW_MSG_PORT_ATTR_DUPLEX,
-		.port = port->hw_id,
-		.dev = port->dev_id
-	};
-	int err;
-
-	err = fw_send_req_resp(port->sw, MVSW_MSG_TYPE_PORT_ATTR_GET,
-			       &req, &resp);
-	if (err)
-		return err;
-
-	*duplex = resp.param.duplex;
-
-	return err;
-}
-
 int mvsw_pr_hw_port_stats_get(const struct prestera_port *port,
 			      struct mvsw_pr_port_stats *stats)
 {
@@ -2062,101 +2083,34 @@ int mvsw_pr_hw_port_remote_fc_get(const struct prestera_port *port,
 	if (err)
 		return err;
 
-	switch (resp.param.fc) {
-	case MVSW_FC_SYMMETRIC:
-		*pause = true;
-		*asym_pause = false;
-		break;
-	case MVSW_FC_ASYMMETRIC:
-		*pause = false;
-		*asym_pause = true;
-		break;
-	case MVSW_FC_SYMM_ASYMM:
-		*pause = true;
-		*asym_pause = true;
-		break;
-	default:
-		*pause = false;
-		*asym_pause = false;
-	};
+	prestera_hw_remote_fc_to_eth(resp.param.fc, pause, asym_pause);
 
 	return err;
 }
 
 /* ACL API */
-int mvsw_pr_hw_acl_ruleset_create(const struct prestera_switch *sw,
-				  u16 *ruleset_id)
-{
-	int err;
-	struct mvsw_msg_acl_ruleset_ret resp;
-	struct mvsw_msg_acl_ruleset_cmd req;
-
-	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_ACL_RULESET_CREATE,
-			       &req, &resp);
-	if (err)
-		return err;
-
-	*ruleset_id = resp.id;
-	return 0;
-}
-
-int mvsw_pr_hw_acl_ruleset_del(const struct prestera_switch *sw,
-			       u16 ruleset_id)
-{
-	struct mvsw_msg_acl_ruleset_cmd req = {
-		.id = ruleset_id,
-	};
-
-	return fw_send_req(sw, MVSW_MSG_TYPE_ACL_RULESET_DELETE, &req);
-}
-
 static int acl_rule_add_put_action(struct mvsw_msg_acl_action *action,
 				   struct prestera_acl_hw_action_info *info)
 {
-	int err;
-
 	action->id = info->id;
 
 	switch (info->id) {
 	case MVSW_ACL_RULE_ACTION_ACCEPT:
 	case MVSW_ACL_RULE_ACTION_DROP:
-	case MVSW_ACL_RULE_ACTION_TRAP:
 		/* just rule action id, no specific data */
 		break;
+	case MVSW_ACL_RULE_ACTION_TRAP:
+		action->trap.hw_tc = info->trap.hw_tc;
+		break;
 	case MVSW_ACL_RULE_ACTION_JUMP:
-		action->jump.chain = info->jump.chain;
+		action->jump.index = info->jump.index;
 		break;
 	case MVSW_ACL_RULE_ACTION_POLICE:
 		action->police.rate = info->police.rate;
 		action->police.burst = info->police.burst;
 		break;
-	case MVSW_ACL_RULE_ACTION_MANGLE:
-		/* TODO: trap on AGENT side ? */
-		if (!info->mangle.n.connected) {
-			action->id = MVSW_ACL_RULE_ACTION_TRAP;
-			break;
-		}
-		action->mangle.l4_src_valid =
-			info->mangle.l4_src_valid;
-		action->mangle.l4_dst_valid =
-			info->mangle.l4_dst_valid;
-		action->mangle.sip_valid =
-			info->mangle.sip_valid;
-		action->mangle.dip_valid =
-			info->mangle.dip_valid;
-		action->mangle.l4_src = info->mangle.l4_src;
-		action->mangle.l4_dst = info->mangle.l4_dst;
-		action->mangle.sip = info->mangle.sip.u.ipv4;
-		if (WARN_ON(info->mangle.dip.v != MVSW_PR_IPV4) ||
-		    WARN_ON(info->mangle.sip.v != MVSW_PR_IPV4))
-			return -ENOTSUPP;
-		action->mangle.dip = info->mangle.dip.u.ipv4;
-		err = mvsw_pr_iface_to_msg(&info->mangle.n.iface,
-					   &action->mangle.nh.oif);
-		if (err)
-			return -EINVAL;
-		memcpy(&action->mangle.nh.mac[0], &info->mangle.n.ha[0],
-		       ETH_ALEN);
+	case MVSW_ACL_RULE_ACTION_NH:
+		action->nh.nh_id = info->nh;
 		break;
 	case MVSW_ACL_RULE_ACTION_NAT:
 		action->nat.old_addr = info->nat.old_addr;
@@ -2172,175 +2126,124 @@ static int acl_rule_add_put_action(struct mvsw_msg_acl_action *action,
 	return 0;
 }
 
-static int acl_rule_add_put_match(struct mvsw_msg_acl_match *match,
-				  struct prestera_acl_hw_match_info *info)
-{
-	match->type = info->type;
-
-	switch (info->type) {
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_TYPE:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_SRC:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_DST:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_ID:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_VLAN_TPID:
-		match->keymask.u16.key = info->u16.key;
-		match->keymask.u16.mask = info->u16.mask;
-		break;
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_TYPE:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ICMP_CODE:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_PROTO:
-		match->keymask.u8.key = info->u8.key;
-		match->keymask.u8.mask = info->u8.mask;
-		break;
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_SMAC:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_ETH_DMAC:
-		memcpy(match->keymask.mac.key,
-		       info->mac.key,
-		       sizeof(match->keymask.mac.key));
-		memcpy(match->keymask.mac.mask,
-		       info->mac.mask,
-		       sizeof(match->keymask.mac.mask));
-		break;
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_SRC:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_IP_DST:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_SRC:
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_L4_PORT_RANGE_DST:
-		match->keymask.u32.key = info->u32.key;
-		match->keymask.u32.mask = info->u32.mask;
-		break;
-	case MVSW_ACL_RULE_MATCH_ENTRY_TYPE_PORT:
-		match->keymask.u64.key = info->u64.key;
-		match->keymask.u64.mask = info->u64.mask;
-		break;
-	default:
-		return -EINVAL;
-	}
-
-	return 0;
-}
-
-int mvsw_pr_hw_acl_rule_add(const struct prestera_switch *sw,
-			    u16 ruleset, u8 chain, u32 prio, u8 tc,
-			    u8 n_matches,
-			    struct prestera_acl_hw_match_info *matches,
-			    u8 n_actions,
-			    struct prestera_acl_hw_action_info *actions,
-			    u32 *rule_id)
+int mvsw_pr_hw_acl_rule_stats_get(const struct prestera_switch *sw,
+				  u32 start_idx, u32 len,
+				  struct prestera_acl_stats *stats)
 {
-	struct mvsw_msg_acl_action *actions_msg;
-	struct mvsw_msg_acl_match *matches_msg;
-	struct mvsw_msg_acl_rule_ret resp;
-	struct mvsw_msg_acl_rule_cmd *req;
-	void *buff;
-	u32 size;
-	int err;
-	u8 i;
-
-	size = sizeof(*req) + sizeof(*actions_msg) * n_actions +
-		sizeof(*matches_msg) * n_matches;
+	struct mvsw_msg_acl_rule_stats_ret *resp;
+	struct mvsw_msg_acl_rule_stats_cmd req = {
+		.start_idx = start_idx,
+		.count = len,
+	};
+	size_t size = sizeof(*resp) + sizeof(*resp->stats) * len;
+	int err, i;
 
-	buff = kzalloc(size, GFP_KERNEL);
-	if (!buff)
+	resp = kmalloc(size, GFP_KERNEL);
+	if (!resp)
 		return -ENOMEM;
 
-	req = buff;
-	actions_msg = buff + sizeof(*req);
-	matches_msg = buff + sizeof(*req) + sizeof(*actions_msg) * n_actions;
-	req->n_matches = n_matches;
-	req->n_actions = n_actions;
-
-	/* put acl matches into the message */
-	for (i = 0; i < n_matches; i++) {
-		err = acl_rule_add_put_match(&matches_msg[i], &matches[i]);
-		if (err)
-			goto free_buff;
-	}
-
-	/* put acl actions into the message */
-	for (i = 0; i < n_actions; i++) {
-		err = acl_rule_add_put_action(&actions_msg[i], &actions[i]);
-		if (err)
-			goto free_buff;
-	}
-
-	req->ruleset_id = ruleset;
-	req->chain = chain;
-	req->priority = prio;
-	req->hw_tc = tc;
-
-	err = fw_send_nreq_resp(sw, MVSW_MSG_TYPE_ACL_RULE_ADD, req,
-				size, &resp);
+	err = fw_send_nreq_nresp(sw, MVSW_MSG_TYPE_ACL_RULE_STATS_GET,
+				 &req, sizeof(req), resp, size);
 	if (err)
 		goto free_buff;
 
-	*rule_id = resp.id;
+	for (i = 0; i < len; i++) {
+		stats[i].packets += resp->stats[i].packets;
+		stats[i].bytes += resp->stats[i].bytes;
+	}
+
 free_buff:
-	kfree(buff);
+	kfree(resp);
 	return err;
 }
 
-int mvsw_pr_hw_acl_rule_del(const struct prestera_switch *sw,
-			    u32 chain, u32 rule_id)
+int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
+				      unsigned char *mac)
 {
-	struct mvsw_msg_acl_rule_cmd req = {
-		.chain = chain,
-		.id = rule_id
+	struct mvsw_msg_nat_port_cmd req = {
+		.port = port->hw_id,
+		.dev = port->dev_id,
 	};
-
-	return fw_send_req(sw, MVSW_MSG_TYPE_ACL_RULE_DELETE, &req);
+	memcpy(req.neigh_mac, mac, sizeof(req.neigh_mac));
+	return fw_send_req(port->sw, MVSW_MSG_TYPE_NAT_PORT_NEIGH_UPDATE,
+			   &req);
 }
 
-int mvsw_pr_hw_acl_rule_stats_get(const struct prestera_switch *sw, u32 rule_id,
-				  u64 *packets, u64 *bytes)
+int prestera_hw_nh_mangle_add(const struct prestera_switch *sw, u32 *nh_id)
 {
+	struct mvsw_msg_nh_mangle_cmd req;
+	struct mvsw_msg_nh_mangle_ret resp;
 	int err;
-	struct mvsw_msg_acl_rule_stats_ret resp;
-	struct mvsw_msg_acl_rule_cmd req = {
-		.id = rule_id
-	};
 
-	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_ACL_RULE_STATS_GET,
-			       &req, &resp);
+	memset(&req, 0, sizeof(req));
+	memset(&resp, 0, sizeof(resp));
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_ADD, &req,
+			       &resp);
 	if (err)
 		return err;
 
-	*packets = resp.packets;
-	*bytes = resp.bytes;
+	*nh_id = resp.nh_id;
 	return 0;
 }
 
-int mvsw_pr_hw_acl_port_bind(const struct prestera_port *port, u16 ruleset_id)
+int prestera_hw_nh_mangle_del(const struct prestera_switch *sw, u32 nh_id)
 {
-	struct mvsw_msg_acl_ruleset_bind_cmd req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.ruleset_id = ruleset_id,
-	};
+	struct mvsw_msg_nh_mangle_cmd req;
 
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_ACL_PORT_BIND, &req);
+	memset(&req, 0, sizeof(req));
+	req.nh_id = nh_id;
+	return fw_send_req(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_DEL, &req);
 }
 
-int mvsw_pr_hw_acl_port_unbind(const struct prestera_port *port, u16 ruleset_id)
+int prestera_hw_nh_mangle_set(const struct prestera_switch *sw, u32 nh_id,
+			      bool l4_src_valid, __be16 l4_src,
+			      bool l4_dst_valid, __be16 l4_dst,
+			      bool sip_valid, struct mvsw_pr_ip_addr sip,
+			      bool dip_valid, struct mvsw_pr_ip_addr dip,
+			      struct mvsw_pr_neigh_info nh)
 {
-	struct mvsw_msg_acl_ruleset_bind_cmd req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-		.ruleset_id = ruleset_id,
-	};
+	struct mvsw_msg_nh_mangle_cmd req;
+	int err;
+
+	if (sip.v != MVSW_PR_IPV4 || dip.v != MVSW_PR_IPV4)
+		return -EINVAL;
 
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_ACL_PORT_UNBIND, &req);
+	memset(&req, 0, sizeof(req));
+	req.nh_id = nh_id;
+	req.info.l4_src_valid = l4_src_valid;
+	req.info.l4_dst_valid = l4_dst_valid;
+	req.info.sip_valid = sip_valid;
+	req.info.dip_valid = dip_valid;
+	req.info.l4_src = l4_src;
+	req.info.l4_dst = l4_dst;
+	req.info.sip = sip.u.ipv4;
+	req.info.dip = dip.u.ipv4;
+	req.info.nh.is_active = nh.connected;
+	memcpy(&req.info.nh.mac, nh.ha, ETH_ALEN);
+	err = mvsw_pr_iface_to_msg(&nh.iface, &req.info.nh.oif);
+	if (err)
+		return err;
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_SET, &req);
 }
 
-int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
-				      unsigned char *mac)
+int prestera_hw_nh_mangle_get(const struct prestera_switch *sw, u32 nh_id,
+			      bool *is_active)
 {
-	struct mvsw_msg_nat_port_cmd req = {
-		.port = port->hw_id,
-		.dev = port->dev_id,
-	};
-	memcpy(req.neigh_mac, mac, sizeof(req.neigh_mac));
-	return fw_send_req(port->sw, MVSW_MSG_TYPE_NAT_PORT_NEIGH_UPDATE,
-			   &req);
+	struct mvsw_msg_nh_mangle_cmd req;
+	struct mvsw_msg_nh_mangle_ret resp;
+	int err;
+
+	memset(&req, 0, sizeof(req));
+	req.nh_id = nh_id;
+	memset(&resp, 0, sizeof(resp));
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_NAT_NH_MANGLE_GET, &req,
+			       &resp);
+	if (err)
+		return err;
+
+	*is_active = resp.info.nh.is_active;
+	return 0;
 }
 
 int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id)
@@ -2461,3 +2364,146 @@ prestera_hw_cpu_code_counters_get(const struct prestera_switch *sw, u8 code,
 
 	return 0;
 }
+
+int prestera_hw_vtcam_create(const struct prestera_switch *sw,
+			     u8 lookup, const u32 *keymask, u32 *vtcam_id)
+{
+	int err;
+	struct mvsw_msg_vtcam_ret resp;
+	struct mvsw_msg_vtcam_create_cmd req = {
+		.lookup = lookup,
+	};
+
+	if (keymask)
+		memcpy(req.keymask, keymask, sizeof(req.keymask));
+	else
+		memset(req.keymask, 0, sizeof(req.keymask));
+
+	err = fw_send_req_resp(sw, MVSW_MSG_TYPE_VTCAM_CREATE, &req, &resp);
+	if (err)
+		return err;
+
+	*vtcam_id = resp.vtcam_id;
+	return 0;
+}
+
+int prestera_hw_vtcam_destroy(const struct prestera_switch *sw, u32 vtcam_id)
+{
+	struct mvsw_msg_vtcam_destroy_cmd req = {
+		.vtcam_id = vtcam_id,
+	};
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_DESTROY, &req);
+}
+
+int prestera_hw_vtcam_rule_add(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 prio, void *key, void *keymask,
+			       struct prestera_acl_hw_action_info *act,
+			       u8 n_act, u32 *rule_id, u32 *counter_id)
+{
+	struct mvsw_msg_acl_action *actions_msg;
+	struct mvsw_msg_vtcam_rule_add_cmd *req;
+	struct mvsw_msg_vtcam_ret resp;
+	void *buff;
+	u32 size;
+	int err;
+	u8 i;
+
+	size = sizeof(*req) + sizeof(*actions_msg) * n_act;
+
+	buff = kzalloc(size, GFP_KERNEL);
+	if (!buff)
+		return -ENOMEM;
+
+	req = buff;
+	req->n_act = n_act;
+	actions_msg = buff + sizeof(*req);
+
+	/* put acl matches into the message */
+	memcpy(req->key, key, sizeof(req->key));
+	memcpy(req->keymask, keymask, sizeof(req->keymask));
+
+	/* put acl actions into the message */
+	for (i = 0; i < n_act; i++) {
+		err = acl_rule_add_put_action(&actions_msg[i], &act[i]);
+		if (err)
+			goto free_buff;
+	}
+
+	req->vtcam_id = vtcam_id;
+	req->prio = prio;
+
+	err = fw_send_nreq_resp(sw, MVSW_MSG_TYPE_VTCAM_RULE_ADD, req,
+				size, &resp);
+	if (err)
+		goto free_buff;
+
+	*counter_id = resp.counter_id;
+	*rule_id = resp.rule_id;
+free_buff:
+	kfree(buff);
+	return err;
+	return 0;
+}
+
+int prestera_hw_vtcam_rule_set(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id, bool enable)
+{
+	struct mvsw_msg_vtcam_rule_cmd req = {
+		.vtcam_id = vtcam_id,
+		.enable = enable,
+		.id = rule_id
+	};
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_RULE_SET, &req);
+}
+
+int prestera_hw_vtcam_rule_del(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id)
+{
+	struct mvsw_msg_vtcam_rule_cmd req = {
+		.vtcam_id = vtcam_id,
+		.id = rule_id
+	};
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_RULE_DELETE, &req);
+}
+
+int prestera_hw_vtcam_iface_bind(const struct prestera_switch *sw,
+				 struct prestera_acl_iface *iface,
+				 u32 vtcam_id, u16 pcl_id)
+{
+	struct mvsw_msg_vtcam_bind_cmd req = {
+		.vtcam_id = vtcam_id,
+		.type = iface->type,
+		.pcl_id = pcl_id
+	};
+
+	if (iface->type == PRESTERA_ACL_IFACE_TYPE_PORT) {
+		req.port.dev_id = iface->port->dev_id;
+		req.port.hw_id = iface->port->hw_id;
+	} else {
+		req.index = iface->index;
+	}
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_IFACE_BIND, &req);
+}
+
+int prestera_hw_vtcam_iface_unbind(const struct prestera_switch *sw,
+				   struct prestera_acl_iface *iface,
+				   u32 vtcam_id)
+{
+	struct mvsw_msg_vtcam_bind_cmd req = {
+		.vtcam_id = vtcam_id,
+		.type = iface->type,
+	};
+
+	if (iface->type == PRESTERA_ACL_IFACE_TYPE_PORT) {
+		req.port.dev_id = iface->port->dev_id;
+		req.port.hw_id = iface->port->hw_id;
+	} else {
+		req.index = iface->index;
+	}
+
+	return fw_send_req(sw, MVSW_MSG_TYPE_VTCAM_IFACE_UNBIND, &req);
+}
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_hw.h b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
index f844f8d..4432d1e 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_hw.h
+++ b/drivers/net/ethernet/marvell/prestera/prestera_hw.h
@@ -135,6 +135,7 @@ enum {
 	MVSW_FW_LOG_LIB_PPU,
 	MVSW_FW_LOG_LIB_EXACT_MATCH_MANAGER,
 	MVSW_FW_LOG_LIB_MAC_SEC,
+	MVSW_FW_LOG_LIB_PTP_MANAGER,
 	MVSW_FW_LOG_LIB_ALL,
 
 	MVSW_FW_LOG_LIB_MAX
@@ -168,6 +169,8 @@ struct mvsw_pr_port_caps;
 struct prestera_acl_rule;
 struct mvsw_pr_iface;
 struct mvsw_pr_neigh_info;
+struct prestera_acl_stats;
+struct prestera_acl_iface;
 
 enum mvsw_pr_event_type;
 struct mvsw_pr_event;
@@ -194,7 +197,6 @@ int mvsw_pr_hw_port_mac_get(const struct prestera_port *port, char *mac);
 int mvsw_pr_hw_port_accept_frame_type_set(const struct prestera_port *port,
 					  enum mvsw_pr_accept_frame_type type);
 int mvsw_pr_hw_port_learning_set(const struct prestera_port *port, bool enable);
-int mvsw_pr_hw_port_speed_get(const struct prestera_port *port, u32 *speed);
 int mvsw_pr_hw_port_uc_flood_set(const struct prestera_port *port, bool flood);
 int mvsw_pr_hw_port_mc_flood_set(const struct prestera_port *port, bool flood);
 int mvsw_pr_hw_port_cap_get(const struct prestera_port *port,
@@ -208,7 +210,6 @@ int mvsw_pr_hw_port_fec_get(const struct prestera_port *port, u8 *fec);
 int mvsw_pr_hw_port_fec_set(const struct prestera_port *port, u8 fec);
 int mvsw_pr_hw_port_autoneg_set(const struct prestera_port *port,
 				bool autoneg, u64 link_modes, u8 fec);
-int mvsw_pr_hw_port_duplex_get(const struct prestera_port *port, u8 *duplex);
 int mvsw_pr_hw_port_stats_get(const struct prestera_port *port,
 			      struct mvsw_pr_port_stats *stats);
 int mvsw_pr_hw_port_link_mode_get(const struct prestera_port *port,
@@ -257,28 +258,42 @@ int mvsw_pr_hw_bridge_port_delete(const struct prestera_port *port,
 int mvsw_pr_hw_port_vid_stp_set(struct prestera_port *port, u16 vid, u8 state);
 
 /* ACL API */
-int mvsw_pr_hw_acl_ruleset_create(const struct prestera_switch *sw,
-				  u16 *ruleset_id);
-int mvsw_pr_hw_acl_ruleset_del(const struct prestera_switch *sw,
-			       u16 ruleset_id);
-int mvsw_pr_hw_acl_rule_add(const struct prestera_switch *sw,
-			    u16 ruleset, u8 chain, u32 prio, u8 tc,
-			    u8 n_matches,
-			    struct prestera_acl_hw_match_info *matches,
-			    u8 n_actions,
-			    struct prestera_acl_hw_action_info *actions,
-			    u32 *rule_id);
-int mvsw_pr_hw_acl_rule_del(const struct prestera_switch *sw,
-			    u32 chain, u32 rule_id);
-int mvsw_pr_hw_acl_rule_stats_get(const struct prestera_switch *sw, u32 rule_id,
-				  u64 *packets, u64 *bytes);
-int mvsw_pr_hw_acl_port_bind(const struct prestera_port *port, u16 ruleset_id);
-int mvsw_pr_hw_acl_port_unbind(const struct prestera_port *port,
-			       u16 ruleset_id);
+int mvsw_pr_hw_acl_rule_stats_get(const struct prestera_switch *sw,
+				  u32 start_idx, u32 len,
+				  struct prestera_acl_stats *stats);
+
+/* vTCAM API */
+int prestera_hw_vtcam_create(const struct prestera_switch *sw,
+			     u8 lookup, const u32 *keymask, u32 *vtcam_id);
+int prestera_hw_vtcam_rule_add(const struct prestera_switch *sw, u32 vtcam_id,
+			       u32 prio, void *key, void *keymask,
+			       struct prestera_acl_hw_action_info *act,
+			       u8 n_act, u32 *rule_id, u32 *counter_id);
+int prestera_hw_vtcam_rule_set(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id, bool enable);
+int prestera_hw_vtcam_rule_del(const struct prestera_switch *sw,
+			       u32 vtcam_id, u32 rule_id);
+int prestera_hw_vtcam_destroy(const struct prestera_switch *sw, u32 vtcam_id);
+int prestera_hw_vtcam_iface_bind(const struct prestera_switch *sw,
+				 struct prestera_acl_iface *iface,
+				 u32 vtcam_id, u16 pcl_id);
+int prestera_hw_vtcam_iface_unbind(const struct prestera_switch *sw,
+				   struct prestera_acl_iface *iface,
+				   u32 vtcam_id);
 
 /* NAT API */
 int prestera_hw_nat_port_neigh_update(const struct prestera_port *port,
 				      unsigned char *mac);
+int prestera_hw_nh_mangle_add(const struct prestera_switch *sw, u32 *nh_id);
+int prestera_hw_nh_mangle_del(const struct prestera_switch *sw, u32 nh_id);
+int prestera_hw_nh_mangle_set(const struct prestera_switch *sw, u32 nh_id,
+			      bool l4_src_valid, __be16 l4_src,
+			      bool l4_dst_valid, __be16 l4_dst,
+			      bool sip_valid, struct mvsw_pr_ip_addr sip,
+			      bool dip_valid, struct mvsw_pr_ip_addr dip,
+			      struct mvsw_pr_neigh_info nh);
+int prestera_hw_nh_mangle_get(const struct prestera_switch *sw, u32 nh_id,
+			      bool *is_active);
 
 /* SPAN API */
 int prestera_hw_span_get(const struct prestera_port *port, u8 *span_id);
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_main.c b/drivers/net/ethernet/marvell/prestera/prestera_main.c
index ebb7742..da5b8e0 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_main.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_main.c
@@ -24,6 +24,7 @@
 #include "prestera_hw.h"
 #include "prestera_debugfs.h"
 #include "prestera_devlink.h"
+#include "prestera_ethtool.h"
 #include "prestera_dsa.h"
 #include "prestera_rxtx.h"
 #include "prestera_drv_ver.h"
@@ -35,30 +36,15 @@ static u8 trap_policer_profile = 1;
 #define PRESTERA_MAC_ADDR_OFFSET 4
 
 #define PORT_STATS_CACHE_TIMEOUT_MS	(msecs_to_jiffies(1000))
-#define PORT_STATS_CNT	(sizeof(struct mvsw_pr_port_stats) / sizeof(u64))
-#define PORT_STATS_IDX(name) \
-	(offsetof(struct mvsw_pr_port_stats, name) / sizeof(u64))
-#define PORT_STATS_FIELD(name)	\
-	[PORT_STATS_IDX(name)] = __stringify(name)
 
 static struct list_head switches_registered;
 
-static const char prestera_driver_kind[] = "prestera";
 static const char prestera_driver_name[] = "mvsw_switchdev";
 
 #define prestera_dev(sw)	((sw)->dev->dev)
-#define prestera_dev_name(sw)	dev_name((sw)->dev->dev)
 
 static struct workqueue_struct *prestera_wq;
 
-struct prestera_link_mode {
-	enum ethtool_link_mode_bit_indices eth_mode;
-	u32 speed;
-	u64 pr_mask;
-	u8 duplex;
-	u8 port_type;
-};
-
 struct prestera_span_entry {
 	struct list_head list;
 	struct prestera_port *port;
@@ -71,282 +57,6 @@ struct prestera_span {
 	struct list_head entries;
 };
 
-static const struct prestera_link_mode
-prestera_link_modes[MVSW_LINK_MODE_MAX] = {
-	[MVSW_LINK_MODE_10baseT_Half_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Half_BIT,
-		.speed = 10,
-		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Half_BIT,
-		.duplex = MVSW_PORT_DUPLEX_HALF,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_10baseT_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_10baseT_Full_BIT,
-		.speed = 10,
-		.pr_mask = 1 << MVSW_LINK_MODE_10baseT_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_100baseT_Half_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Half_BIT,
-		.speed = 100,
-		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Half_BIT,
-		.duplex = MVSW_PORT_DUPLEX_HALF,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_100baseT_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_100baseT_Full_BIT,
-		.speed = 100,
-		.pr_mask = 1 << MVSW_LINK_MODE_100baseT_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_1000baseT_Half_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Half_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Half_BIT,
-		.duplex = MVSW_PORT_DUPLEX_HALF,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_1000baseT_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_1000baseT_Full_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseT_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_1000baseX_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_1000baseX_Full_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseX_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_1000baseKX_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_1000baseKX_Full_BIT,
-		.speed = 1000,
-		.pr_mask = 1 << MVSW_LINK_MODE_1000baseKX_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_2500baseX_Full_BIT] = {
-		.eth_mode =  ETHTOOL_LINK_MODE_2500baseX_Full_BIT,
-		.speed = 2500,
-		.pr_mask = 1 << MVSW_LINK_MODE_2500baseX_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-	},
-	[MVSW_LINK_MODE_10GbaseKR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_10000baseKR_Full_BIT,
-		.speed = 10000,
-		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseKR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_10GbaseSR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_10000baseSR_Full_BIT,
-		.speed = 10000,
-		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseSR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_10GbaseLR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_10000baseLR_Full_BIT,
-		.speed = 10000,
-		.pr_mask = 1 << MVSW_LINK_MODE_10GbaseLR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_20GbaseKR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_20000baseKR2_Full_BIT,
-		.speed = 20000,
-		.pr_mask = 1 << MVSW_LINK_MODE_20GbaseKR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_25GbaseCR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_25000baseCR_Full_BIT,
-		.speed = 25000,
-		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseCR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	},
-	[MVSW_LINK_MODE_25GbaseKR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_25000baseKR_Full_BIT,
-		.speed = 25000,
-		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseKR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_25GbaseSR_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_25000baseSR_Full_BIT,
-		.speed = 25000,
-		.pr_mask = 1 << MVSW_LINK_MODE_25GbaseSR_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_40GbaseKR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_40000baseKR4_Full_BIT,
-		.speed = 40000,
-		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseKR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_40GbaseCR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_40000baseCR4_Full_BIT,
-		.speed = 40000,
-		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseCR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	},
-	[MVSW_LINK_MODE_40GbaseSR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_40000baseSR4_Full_BIT,
-		.speed = 40000,
-		.pr_mask = 1 << MVSW_LINK_MODE_40GbaseSR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_50GbaseCR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_50000baseCR2_Full_BIT,
-		.speed = 50000,
-		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseCR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	},
-	[MVSW_LINK_MODE_50GbaseKR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_50000baseKR2_Full_BIT,
-		.speed = 50000,
-		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseKR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_50GbaseSR2_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_50000baseSR2_Full_BIT,
-		.speed = 50000,
-		.pr_mask = 1 << MVSW_LINK_MODE_50GbaseSR2_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_100GbaseKR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_100000baseKR4_Full_BIT,
-		.speed = 100000,
-		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseKR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_TP,
-	},
-	[MVSW_LINK_MODE_100GbaseSR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_100000baseSR4_Full_BIT,
-		.speed = 100000,
-		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseSR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_FIBRE,
-	},
-	[MVSW_LINK_MODE_100GbaseCR4_Full_BIT] = {
-		.eth_mode = ETHTOOL_LINK_MODE_100000baseCR4_Full_BIT,
-		.speed = 100000,
-		.pr_mask = 1 << MVSW_LINK_MODE_100GbaseCR4_Full_BIT,
-		.duplex = MVSW_PORT_DUPLEX_FULL,
-		.port_type = MVSW_PORT_TYPE_DA,
-	}
-};
-
-struct prestera_fec {
-	u32 eth_fec;
-	enum ethtool_link_mode_bit_indices eth_mode;
-	u8 pr_fec;
-};
-
-static const struct prestera_fec prestera_fec_caps[MVSW_PORT_FEC_MAX] = {
-	[MVSW_PORT_FEC_OFF_BIT] = {
-		.eth_fec = ETHTOOL_FEC_OFF,
-		.eth_mode = ETHTOOL_LINK_MODE_FEC_NONE_BIT,
-		.pr_fec = 1 << MVSW_PORT_FEC_OFF_BIT,
-	},
-	[MVSW_PORT_FEC_BASER_BIT] = {
-		.eth_fec = ETHTOOL_FEC_BASER,
-		.eth_mode = ETHTOOL_LINK_MODE_FEC_BASER_BIT,
-		.pr_fec = 1 << MVSW_PORT_FEC_BASER_BIT,
-	},
-	[MVSW_PORT_FEC_RS_BIT] = {
-		.eth_fec = ETHTOOL_FEC_RS,
-		.eth_mode = ETHTOOL_LINK_MODE_FEC_RS_BIT,
-		.pr_fec = 1 << MVSW_PORT_FEC_RS_BIT,
-	}
-};
-
-struct prestera_port_type {
-	enum ethtool_link_mode_bit_indices eth_mode;
-	u8 eth_type;
-};
-
-static const struct prestera_port_type
-prestera_port_types[MVSW_PORT_TYPE_MAX] = {
-	[MVSW_PORT_TYPE_NONE] = {
-		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
-		.eth_type = PORT_NONE,
-	},
-	[MVSW_PORT_TYPE_TP] = {
-		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
-		.eth_type = PORT_TP,
-	},
-	[MVSW_PORT_TYPE_AUI] = {
-		.eth_mode = ETHTOOL_LINK_MODE_AUI_BIT,
-		.eth_type = PORT_AUI,
-	},
-	[MVSW_PORT_TYPE_MII] = {
-		.eth_mode = ETHTOOL_LINK_MODE_MII_BIT,
-		.eth_type = PORT_MII,
-	},
-	[MVSW_PORT_TYPE_FIBRE] = {
-		.eth_mode = ETHTOOL_LINK_MODE_FIBRE_BIT,
-		.eth_type = PORT_FIBRE,
-	},
-	[MVSW_PORT_TYPE_BNC] = {
-		.eth_mode = ETHTOOL_LINK_MODE_BNC_BIT,
-		.eth_type = PORT_BNC,
-	},
-	[MVSW_PORT_TYPE_DA] = {
-		.eth_mode = ETHTOOL_LINK_MODE_TP_BIT,
-		.eth_type = PORT_TP,
-	},
-	[MVSW_PORT_TYPE_OTHER] = {
-		.eth_mode = __ETHTOOL_LINK_MODE_MASK_NBITS,
-		.eth_type = PORT_OTHER,
-	}
-};
-
-static const char prestera_port_cnt_name[PORT_STATS_CNT][ETH_GSTRING_LEN] = {
-	PORT_STATS_FIELD(good_octets_received),
-	PORT_STATS_FIELD(bad_octets_received),
-	PORT_STATS_FIELD(mac_trans_error),
-	PORT_STATS_FIELD(broadcast_frames_received),
-	PORT_STATS_FIELD(multicast_frames_received),
-	PORT_STATS_FIELD(frames_64_octets),
-	PORT_STATS_FIELD(frames_65_to_127_octets),
-	PORT_STATS_FIELD(frames_128_to_255_octets),
-	PORT_STATS_FIELD(frames_256_to_511_octets),
-	PORT_STATS_FIELD(frames_512_to_1023_octets),
-	PORT_STATS_FIELD(frames_1024_to_max_octets),
-	PORT_STATS_FIELD(excessive_collision),
-	PORT_STATS_FIELD(multicast_frames_sent),
-	PORT_STATS_FIELD(broadcast_frames_sent),
-	PORT_STATS_FIELD(fc_sent),
-	PORT_STATS_FIELD(fc_received),
-	PORT_STATS_FIELD(buffer_overrun),
-	PORT_STATS_FIELD(undersize),
-	PORT_STATS_FIELD(fragments),
-	PORT_STATS_FIELD(oversize),
-	PORT_STATS_FIELD(jabber),
-	PORT_STATS_FIELD(rx_error_frame_received),
-	PORT_STATS_FIELD(bad_crc),
-	PORT_STATS_FIELD(collisions),
-	PORT_STATS_FIELD(late_collision),
-	PORT_STATS_FIELD(unicast_frames_received),
-	PORT_STATS_FIELD(unicast_frames_sent),
-	PORT_STATS_FIELD(sent_multiple),
-	PORT_STATS_FIELD(sent_deferred),
-	PORT_STATS_FIELD(good_octets_sent),
-};
-
 struct prestera_port *dev_to_prestera_port(struct device *dev)
 {
 	struct net_device *net_dev;
@@ -606,22 +316,6 @@ static int prestera_set_features(struct net_device *dev,
 	return 0;
 }
 
-static void prestera_port_get_drvinfo(struct net_device *dev,
-				      struct ethtool_drvinfo *drvinfo)
-{
-	struct prestera_port *port = netdev_priv(dev);
-	struct prestera_switch *sw = port->sw;
-
-	strlcpy(drvinfo->driver, prestera_driver_kind, sizeof(drvinfo->driver));
-	strlcpy(drvinfo->bus_info, prestera_dev_name(sw),
-		sizeof(drvinfo->bus_info));
-	snprintf(drvinfo->fw_version, sizeof(drvinfo->fw_version),
-		 "%d.%d.%d",
-		 sw->dev->fw_rev.maj,
-		 sw->dev->fw_rev.min,
-		 sw->dev->fw_rev.sub);
-}
-
 static const struct net_device_ops prestera_netdev_ops = {
 	.ndo_open = prestera_port_open,
 	.ndo_stop = prestera_port_close,
@@ -681,292 +375,8 @@ struct prestera_switch *prestera_switch_get(struct net_device *dev)
 	return port ? port->sw : NULL;
 }
 
-static void prestera_modes_to_eth(unsigned long *eth_modes, u64 link_modes,
-				  u8 fec, u8 type)
-{
-	u32 mode;
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((prestera_link_modes[mode].pr_mask & link_modes) == 0)
-			continue;
-		if (type != MVSW_PORT_TYPE_NONE &&
-		    prestera_link_modes[mode].port_type != type)
-			continue;
-		__set_bit(prestera_link_modes[mode].eth_mode, eth_modes);
-	}
-
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((prestera_fec_caps[mode].pr_fec & fec) == 0)
-			continue;
-		__set_bit(prestera_fec_caps[mode].eth_mode, eth_modes);
-	}
-}
-
-static void prestera_port_autoneg_get(struct ethtool_link_ksettings *ecmd,
-				      struct prestera_port *port)
-{
-	ecmd->base.autoneg = port->autoneg ? AUTONEG_ENABLE : AUTONEG_DISABLE;
-
-	prestera_modes_to_eth(ecmd->link_modes.supported,
-			      port->caps.supp_link_modes,
-			      port->caps.supp_fec,
-			      port->caps.type);
-
-	if (port->caps.type != MVSW_PORT_TYPE_TP)
-		return;
-
-	ethtool_link_ksettings_add_link_mode(ecmd, supported, Autoneg);
-
-	if (!netif_running(port->net_dev))
-		return;
-
-	if (port->autoneg) {
-		prestera_modes_to_eth(ecmd->link_modes.advertising,
-				      port->adver_link_modes,
-				      port->adver_fec,
-				      port->caps.type);
-		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
-						     Autoneg);
-	} else if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
-		ethtool_link_ksettings_add_link_mode(ecmd, advertising,
-						     Autoneg);
-}
-
-static int prestera_modes_from_eth(struct prestera_port *port,
-				   const unsigned long *advertising,
-				   const unsigned long *supported,
-				   u64 *link_modes, u8 *fec)
-{
-	struct ethtool_link_ksettings curr = {};
-	u32 mode;
-
-	ethtool_link_ksettings_zero_link_mode(&curr, supported);
-	ethtool_link_ksettings_zero_link_mode(&curr, advertising);
-
-	prestera_port_autoneg_get(&curr, port);
-
-	if (linkmode_equal(advertising, curr.link_modes.advertising)) {
-		*link_modes = port->adver_link_modes;
-		*fec = port->adver_fec;
-		return 0;
-	}
-
-	if (!linkmode_subset(advertising, supported)) {
-		netdev_err(port->net_dev, "Unsupported link mode requested");
-		return -EINVAL;
-	}
-
-	*link_modes  = 0;
-	*fec = 0;
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if (!test_bit(prestera_link_modes[mode].eth_mode, advertising))
-			continue;
-		if (prestera_link_modes[mode].port_type != port->caps.type)
-			continue;
-		*link_modes |= prestera_link_modes[mode].pr_mask;
-	}
-
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if (!test_bit(prestera_fec_caps[mode].eth_mode, advertising))
-			continue;
-		*fec |= prestera_fec_caps[mode].pr_fec;
-	}
-
-	if (*link_modes == 0 && *fec == 0) {
-		netdev_err(port->net_dev, "No link modes requested");
-		return -EINVAL;
-	}
-	if (*link_modes == 0)
-		*link_modes = port->adver_link_modes;
-	if (*fec == 0)
-		*fec = port->adver_fec ? port->adver_fec :
-					 BIT(MVSW_PORT_FEC_OFF_BIT);
-
-	return 0;
-}
-
-static void prestera_port_supp_types_get(struct ethtool_link_ksettings *ecmd,
-					 struct prestera_port *port)
-{
-	u32 mode;
-	u8 ptype;
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((prestera_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes) == 0)
-			continue;
-		ptype = prestera_link_modes[mode].port_type;
-		__set_bit(prestera_port_types[ptype].eth_mode,
-			  ecmd->link_modes.supported);
-	}
-}
-
-static void prestera_port_speed_get(struct ethtool_link_ksettings *ecmd,
-				    struct prestera_port *port)
-{
-	u32 speed;
-	int err;
-
-	err = mvsw_pr_hw_port_speed_get(port, &speed);
-	ecmd->base.speed = !err ? speed : SPEED_UNKNOWN;
-}
-
-static int prestera_port_link_mode_set(struct prestera_port *port,
-				       u32 speed, u8 duplex, u8 type)
-{
-	u32 new_mode = MVSW_LINK_MODE_MAX;
-	u32 mode;
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if (speed != prestera_link_modes[mode].speed)
-			continue;
-		if (duplex != prestera_link_modes[mode].duplex)
-			continue;
-		if (!(prestera_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes))
-			continue;
-		if (type != prestera_link_modes[mode].port_type)
-			continue;
-
-		new_mode = mode;
-		break;
-	}
-
-	if (new_mode == MVSW_LINK_MODE_MAX) {
-		netdev_err(port->net_dev, "Unsupported speed/duplex requested");
-		return -EINVAL;
-	}
-
-	return mvsw_pr_hw_port_link_mode_set(port, new_mode);
-}
-
-static int prestera_port_speed_duplex_set(const struct ethtool_link_ksettings
-					  *ecmd, struct prestera_port *port)
-{
-	int err;
-	u8 duplex;
-	u32 speed;
-	u32 curr_mode;
-
-	err = mvsw_pr_hw_port_link_mode_get(port, &curr_mode);
-	if (err || curr_mode >= MVSW_LINK_MODE_MAX)
-		return -EINVAL;
-
-	if (ecmd->base.duplex != DUPLEX_UNKNOWN)
-		duplex = ecmd->base.duplex == DUPLEX_FULL ?
-			 MVSW_PORT_DUPLEX_FULL : MVSW_PORT_DUPLEX_HALF;
-	else
-		duplex = prestera_link_modes[curr_mode].duplex;
-
-	if (ecmd->base.speed != SPEED_UNKNOWN)
-		speed = ecmd->base.speed;
-	else
-		speed = prestera_link_modes[curr_mode].speed;
-
-	return prestera_port_link_mode_set(port, speed, duplex,
-					   port->caps.type);
-}
-
-static u8 prestera_port_type_get(struct prestera_port *port)
-{
-	if (port->caps.type < MVSW_PORT_TYPE_MAX)
-		return prestera_port_types[port->caps.type].eth_type;
-	return PORT_OTHER;
-}
-
-static int prestera_port_type_set(const struct ethtool_link_ksettings *ecmd,
-				  struct prestera_port *port)
-{
-	int err;
-	u32 type, mode;
-	u32 new_mode = MVSW_LINK_MODE_MAX;
-
-	for (type = 0; type < MVSW_PORT_TYPE_MAX; type++) {
-		if (prestera_port_types[type].eth_type == ecmd->base.port &&
-		    test_bit(prestera_port_types[type].eth_mode,
-			     ecmd->link_modes.supported)) {
-			break;
-		}
-	}
-
-	if (type == port->caps.type)
-		return 0;
-
-	if (type != port->caps.type && ecmd->base.autoneg == AUTONEG_ENABLE)
-		return -EINVAL;
-
-	if (type == MVSW_PORT_TYPE_MAX) {
-		pr_err("Unsupported port type requested\n");
-		return -EINVAL;
-	}
-
-	for (mode = 0; mode < MVSW_LINK_MODE_MAX; mode++) {
-		if ((prestera_link_modes[mode].pr_mask &
-		    port->caps.supp_link_modes) &&
-		    type == prestera_link_modes[mode].port_type) {
-			new_mode = mode;
-		}
-	}
-
-	if (new_mode < MVSW_LINK_MODE_MAX)
-		err = mvsw_pr_hw_port_link_mode_set(port, new_mode);
-	else
-		err = -EINVAL;
-
-	if (!err) {
-		port->caps.type = type;
-		port->autoneg = false;
-	}
-
-	return err;
-}
-
-static void prestera_port_remote_cap_get(struct ethtool_link_ksettings *ecmd,
-					 struct prestera_port *port)
-{
-	u64 bitmap;
-	bool pause;
-	bool asym_pause;
-
-	if (!mvsw_pr_hw_port_remote_cap_get(port, &bitmap)) {
-		prestera_modes_to_eth(ecmd->link_modes.lp_advertising,
-				      bitmap, 0, MVSW_PORT_TYPE_NONE);
-
-		if (!bitmap_empty(ecmd->link_modes.lp_advertising,
-				  __ETHTOOL_LINK_MODE_MASK_NBITS)) {
-			ethtool_link_ksettings_add_link_mode(ecmd,
-							     lp_advertising,
-							     Autoneg);
-		}
-	}
-
-	if (mvsw_pr_hw_port_remote_fc_get(port, &pause, &asym_pause))
-		return;
-	if (pause)
-		ethtool_link_ksettings_add_link_mode(ecmd,
-						     lp_advertising,
-						     Pause);
-	if (asym_pause)
-		ethtool_link_ksettings_add_link_mode(ecmd,
-						     lp_advertising,
-						     Asym_Pause);
-}
-
-static void prestera_port_duplex_get(struct ethtool_link_ksettings *ecmd,
-				     struct prestera_port *port)
-{
-	u8 duplex;
-
-	if (!mvsw_pr_hw_port_duplex_get(port, &duplex)) {
-		ecmd->base.duplex = duplex == MVSW_PORT_DUPLEX_FULL ?
-				    DUPLEX_FULL : DUPLEX_HALF;
-	} else {
-		ecmd->base.duplex = DUPLEX_UNKNOWN;
-	}
-}
-
-static int prestera_port_autoneg_set(struct prestera_port *port, bool enable,
-				     u64 link_modes, u8 fec)
+int prestera_port_autoneg_set(struct prestera_port *port, bool enable,
+			      u64 link_modes, u8 fec)
 {
 	if (port->caps.type != MVSW_PORT_TYPE_TP)
 		return enable ? -EINVAL : 0;
@@ -984,232 +394,6 @@ static int prestera_port_autoneg_set(struct prestera_port *port, bool enable,
 	return 0;
 }
 
-static int prestera_port_nway_reset(struct net_device *dev)
-{
-	struct prestera_port *port = netdev_priv(dev);
-
-	if (netif_running(dev) &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
-	    port->caps.type == MVSW_PORT_TYPE_TP)
-		return mvsw_pr_hw_port_autoneg_restart(port);
-
-	return -EINVAL;
-}
-
-static int prestera_port_mdix_set(const struct ethtool_link_ksettings *ecmd,
-				  struct prestera_port *port)
-{
-	if (ecmd->base.eth_tp_mdix_ctrl != ETH_TP_MDI_INVALID &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER &&
-	    port->caps.type == MVSW_PORT_TYPE_TP)
-		return mvsw_pr_hw_port_mdix_set(port,
-						ecmd->base.eth_tp_mdix_ctrl);
-	return 0;
-}
-
-static int prestera_port_get_link_ksettings(struct net_device *dev,
-					    struct ethtool_link_ksettings *ecmd)
-{
-	struct prestera_port *port = netdev_priv(dev);
-
-	/* Dirty hook: Deinit ecmd.
-	 * It caused by suspicious phylink_ethtool_ksettings_get()
-	 * implementation, which can left "kset" uninitialized, when there is no
-	 * SFP plugged
-	 */
-	ethtool_link_ksettings_zero_link_mode(ecmd, supported);
-	ethtool_link_ksettings_zero_link_mode(ecmd, advertising);
-	ethtool_link_ksettings_zero_link_mode(ecmd, lp_advertising);
-	ecmd->base.speed = SPEED_UNKNOWN;
-	ecmd->base.duplex = DUPLEX_UNKNOWN;
-#ifdef CONFIG_PHYLINK
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
-		return phylink_ethtool_ksettings_get(port->phy_link, ecmd);
-#endif /* CONFIG_PHYLINK */
-
-	prestera_port_supp_types_get(ecmd, port);
-
-	prestera_port_autoneg_get(ecmd, port);
-
-	if (port->autoneg && netif_carrier_ok(dev) &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
-		prestera_port_remote_cap_get(ecmd, port);
-
-	if (netif_carrier_ok(dev)) {
-		prestera_port_speed_get(ecmd, port);
-		prestera_port_duplex_get(ecmd, port);
-	} else {
-		ecmd->base.speed = SPEED_UNKNOWN;
-		ecmd->base.duplex = DUPLEX_UNKNOWN;
-	}
-
-	ecmd->base.port = prestera_port_type_get(port);
-
-	if (port->caps.type == MVSW_PORT_TYPE_TP &&
-	    port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER)
-		mvsw_pr_hw_port_mdix_get(port, &ecmd->base.eth_tp_mdix,
-					 &ecmd->base.eth_tp_mdix_ctrl);
-
-	return 0;
-}
-
-static int prestera_port_set_link_ksettings(struct net_device *dev,
-					    const struct ethtool_link_ksettings
-					    *ecmd)
-{
-	struct prestera_port *port = netdev_priv(dev);
-	u64 adver_modes = 0;
-	u8 adver_fec = 0;
-	int err;
-
-#ifdef CONFIG_PHYLINK
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_SFP)
-		return phylink_ethtool_ksettings_set(port->phy_link, ecmd);
-#endif /* CONFIG_PHYLINK */
-
-	err = prestera_port_type_set(ecmd, port);
-	if (err)
-		return err;
-
-	if (port->caps.transceiver == MVSW_PORT_TRANSCEIVER_COPPER) {
-		err = prestera_port_mdix_set(ecmd, port);
-		if (err)
-			return err;
-	}
-
-	if (ecmd->base.autoneg == AUTONEG_ENABLE) {
-		if (prestera_modes_from_eth(port, ecmd->link_modes.advertising,
-					    ecmd->link_modes.supported,
-					    &adver_modes, &adver_fec))
-			return -EINVAL;
-		if (!port->autoneg && !adver_modes)
-			adver_modes = port->caps.supp_link_modes;
-	} else {
-		adver_modes = port->adver_link_modes;
-		adver_fec = port->adver_fec;
-	}
-
-	err = prestera_port_autoneg_set(port,
-					ecmd->base.autoneg == AUTONEG_ENABLE,
-					adver_modes, adver_fec);
-	if (err)
-		return err;
-
-	if (ecmd->base.autoneg == AUTONEG_DISABLE) {
-		err = prestera_port_speed_duplex_set(ecmd, port);
-		if (err)
-			return err;
-	}
-
-	return 0;
-}
-
-static int prestera_port_get_fecparam(struct net_device *dev,
-				      struct ethtool_fecparam *fecparam)
-{
-	struct prestera_port *port = netdev_priv(dev);
-	u32 mode;
-	u8 active;
-	int err;
-
-	err = mvsw_pr_hw_port_fec_get(port, &active);
-	if (err)
-		return err;
-
-	fecparam->fec = 0;
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((prestera_fec_caps[mode].pr_fec & port->caps.supp_fec) == 0)
-			continue;
-		fecparam->fec |= prestera_fec_caps[mode].eth_fec;
-	}
-
-	if (active < MVSW_PORT_FEC_MAX)
-		fecparam->active_fec = prestera_fec_caps[active].eth_fec;
-	else
-		fecparam->active_fec = ETHTOOL_FEC_AUTO;
-
-	return 0;
-}
-
-static int prestera_port_set_fecparam(struct net_device *dev,
-				      struct ethtool_fecparam *fecparam)
-{
-	struct prestera_port *port = netdev_priv(dev);
-	u8 fec, active;
-	u32 mode;
-	int err;
-
-	if (port->autoneg) {
-		netdev_err(dev, "FEC set is not allowed while autoneg is on\n");
-		return -EINVAL;
-	}
-
-	err = mvsw_pr_hw_port_fec_get(port, &active);
-	if (err)
-		return err;
-
-	fec = MVSW_PORT_FEC_MAX;
-	for (mode = 0; mode < MVSW_PORT_FEC_MAX; mode++) {
-		if ((prestera_fec_caps[mode].eth_fec & fecparam->fec) &&
-		    (prestera_fec_caps[mode].pr_fec & port->caps.supp_fec)) {
-			fec = mode;
-			break;
-		}
-	}
-
-	if (fec == active)
-		return 0;
-
-	if (fec == MVSW_PORT_FEC_MAX) {
-		netdev_err(dev, "Unsupported FEC requested");
-		return -EINVAL;
-	}
-
-	return mvsw_pr_hw_port_fec_set(port, fec);
-}
-
-static void prestera_port_get_ethtool_stats(struct net_device *dev,
-					    struct ethtool_stats *stats,
-					    u64 *data)
-{
-	struct prestera_port *port = netdev_priv(dev);
-	struct mvsw_pr_port_stats *port_stats = &port->cached_hw_stats.stats;
-
-	memcpy((u8 *)data, port_stats, sizeof(*port_stats));
-}
-
-static void prestera_port_get_strings(struct net_device *dev,
-				      u32 stringset, u8 *data)
-{
-	if (stringset != ETH_SS_STATS)
-		return;
-
-	memcpy(data, *prestera_port_cnt_name, sizeof(prestera_port_cnt_name));
-}
-
-static int prestera_port_get_sset_count(struct net_device *dev, int sset)
-{
-	switch (sset) {
-	case ETH_SS_STATS:
-		return PORT_STATS_CNT;
-	default:
-		return -EOPNOTSUPP;
-	}
-}
-
-static const struct ethtool_ops prestera_ethtool_ops = {
-	.get_drvinfo = prestera_port_get_drvinfo,
-	.get_link_ksettings = prestera_port_get_link_ksettings,
-	.set_link_ksettings = prestera_port_set_link_ksettings,
-	.get_fecparam = prestera_port_get_fecparam,
-	.set_fecparam = prestera_port_set_fecparam,
-	.get_sset_count = prestera_port_get_sset_count,
-	.get_strings = prestera_port_get_strings,
-	.get_ethtool_stats = prestera_port_get_ethtool_stats,
-	.get_link = ethtool_op_get_link,
-	.nway_reset = prestera_port_nway_reset
-};
-
 int prestera_port_learning_set(struct prestera_port *port, bool learn)
 {
 	return mvsw_pr_hw_port_learning_set(port, learn);
@@ -1425,16 +609,15 @@ static void prestera_mac_pcs_get_state(struct phylink_config *config,
 	struct net_device *ndev = to_net_dev(config->dev);
 	struct prestera_port *port = netdev_priv(ndev);
 
-	state->link = port->hw_oper_state;
+	state->link = port->link_params.oper_state;
 	state->pause = 0;
 
-	if (port->hw_oper_state) {
+	if (port->link_params.oper_state) {
 		/* AN is completed, when port is up */
 		state->an_complete = port->autoneg;
 
-		state->speed = port->hw_speed;
-		state->duplex = (port->hw_duplex == MVSW_PORT_DUPLEX_FULL) ?
-					DUPLEX_FULL : DUPLEX_HALF;
+		state->speed = port->link_params.speed;
+		state->duplex = port->link_params.duplex;
 	} else {
 		state->an_complete = false;
 		state->speed = SPEED_UNKNOWN;
@@ -2160,7 +1343,21 @@ static int prestera_clear_ports(struct prestera_switch *sw)
 
 		cancel_delayed_work_sync(&port->cached_hw_stats.caching_dw);
 		prestera_devlink_port_clear(port);
-		unregister_netdev(net_dev);
+	}
+
+	rtnl_lock();
+	list_for_each_safe(pos, n, &sw->port_list) {
+		port = list_entry(pos, typeof(*port), list);
+		net_dev = port->net_dev;
+
+		unregister_netdevice(net_dev);
+	}
+	rtnl_unlock();
+
+	list_for_each_safe(pos, n, &sw->port_list) {
+		port = list_entry(pos, typeof(*port), list);
+		net_dev = port->net_dev;
+
 #ifdef CONFIG_PHYLINK
 		if (port->phy_link)
 			phylink_destroy(port->phy_link);
@@ -2187,13 +1384,12 @@ static void prestera_port_handle_event(struct prestera_switch *sw,
 
 	caching_dw = &port->cached_hw_stats.caching_dw;
 
+	prestera_ethtool_port_state_changed(port, &evt->port_evt);
+
 	switch (evt->id) {
 	case MVSW_PORT_EVENT_STATE_CHANGED:
-		port->hw_oper_state = evt->port_evt.data.oper_state;
 
-		if (port->hw_oper_state) {
-			port->hw_duplex = evt->port_evt.data.duplex;
-			port->hw_speed = evt->port_evt.data.speed;
+		if (port->link_params.oper_state) {
 #ifdef CONFIG_PHYLINK
 			if (port->caps.transceiver ==
 			    MVSW_PORT_TRANSCEIVER_SFP)
@@ -2207,8 +1403,6 @@ static void prestera_port_handle_event(struct prestera_switch *sw,
 			if (!delayed_work_pending(caching_dw))
 				queue_delayed_work(prestera_wq, caching_dw, 0);
 		} else {
-			port->hw_duplex = 0;
-			port->hw_speed = 0;
 #ifdef CONFIG_PHYLINK
 			if (port->caps.transceiver ==
 			    MVSW_PORT_TRANSCEIVER_SFP)
@@ -2472,6 +1666,7 @@ static int prestera_init(struct prestera_switch *sw)
 	prestera_rxtx_switch_fini(sw);
 err_rxtx_init:
 err_ports_init:
+	prestera_devlink_unregister(sw);
 	prestera_clear_ports(sw);
 err_devl_reg:
 	prestera_switchdev_unregister(sw);
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_matchall.c b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
index 54ce5d4..7221fc7 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_matchall.c
@@ -100,11 +100,6 @@ int prestera_mall_replace(struct prestera_flow_block *block,
 		return -EOPNOTSUPP;
 	}
 
-	if (f->common.chain_index) {
-		NL_SET_ERR_MSG(f->common.extack, "Only chain 0 is supported");
-		return -EOPNOTSUPP;
-	}
-
 	act = &f->rule->action.entries[0];
 
 	if (act->id != FLOW_ACTION_MIRRED)
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_pci.c b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
index 79321cd..07731b0 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_pci.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_pci.c
@@ -16,7 +16,7 @@
 #define PRESTERA_FW_FILENAME	"marvell/mvsw_prestera_fw.img"
 
 #define PRESTERA_SUPP_FW_MAJ_VER	2
-#define PRESTERA_SUPP_FW_MIN_VER	9
+#define PRESTERA_SUPP_FW_MIN_VER	10
 #define PRESTERA_SUPP_FW_PATCH_VER	0
 
 #define prestera_wait(cond, waitms) \
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_router.c b/drivers/net/ethernet/marvell/prestera/prestera_router.c
index 7145b10..7fa87ea 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_router.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_router.c
@@ -21,12 +21,13 @@
 #include <linux/rhashtable.h>
 
 #include "prestera.h"
+#include "prestera_ct.h"
+#include "prestera_acl.h"
 #include "prestera_hw.h"
 #include "prestera_log.h"
 
 #define MVSW_PR_IMPLICITY_RESOLVE_DEAD_NEIGH
 #define MVSW_PR_NH_PROBE_INTERVAL 5000 /* ms */
-#define MVSW_PR_NH_ACTIVE_JIFFER_FILTER 3000 /* ms */
 #define MVSW_PR_NHGR_UNUSED (0)
 #define MVSW_PR_NHGR_DROP (0xFFFFFFFF)
 
@@ -160,11 +161,13 @@ static const struct rhashtable_params __mvsw_pr_nexthop_group_ht_params = {
 };
 
 static struct workqueue_struct *mvsw_r_wq;
+
+/* TODO: this should be moved to router struct. */
 static struct workqueue_struct *mvsw_r_owq;
 
 static DEFINE_MUTEX(mvsw_owq_mutex_wip); /* owq function is in progress */
 static bool mvsw_owq_flushing;
-static void mvsw_owq_lock(void)
+void prestera_router_owq_lock(void)
 {
 	while (true) {
 		if (!mutex_trylock(&mvsw_owq_mutex_wip))
@@ -181,7 +184,7 @@ static void mvsw_owq_lock(void)
 	}
 }
 
-static void mvsw_owq_unlock(void)
+void prestera_router_owq_unlock(void)
 {
 	if (!READ_ONCE(mvsw_owq_flushing))
 		rtnl_unlock();
@@ -190,7 +193,7 @@ static void mvsw_owq_unlock(void)
 }
 
 /* Must be called under rtnl_lock */
-static void mvsw_owq_flush(void)
+void prestera_router_owq_flush(void)
 {
 	/* Sanity check */
 	if (rtnl_trylock())
@@ -207,6 +210,11 @@ static void mvsw_owq_flush(void)
 	mutex_unlock(&mvsw_owq_mutex_wip);
 }
 
+void prestera_router_owq_queue_work(struct work_struct *work)
+{
+	queue_work(mvsw_r_owq, work);
+}
+
 static const unsigned char mvsw_pr_mac_mask[ETH_ALEN] = {
 	0xff, 0xff, 0xff, 0xff, 0xfc, 0x00
 };
@@ -1475,7 +1483,7 @@ static void mvsw_pr_router_neigh_event_work(struct work_struct *work)
 	struct neighbour *n = net_work->n;
 
 	/* neigh - its not hw related object. It stored only in kernel. So... */
-	mvsw_owq_lock();
+	prestera_router_owq_lock();
 
 	if (sw->router->aborted)
 		goto out;
@@ -1484,7 +1492,7 @@ static void mvsw_pr_router_neigh_event_work(struct work_struct *work)
 
 out:
 	neigh_release(n);
-	mvsw_owq_unlock();
+	prestera_router_owq_unlock();
 	kfree(net_work);
 }
 
@@ -1515,7 +1523,7 @@ static int mvsw_pr_router_netevent_event(struct notifier_block *nb,
 		net_work->n = n;
 		net_work->sw = router->sw;
 		INIT_WORK(&net_work->work, mvsw_pr_router_neigh_event_work);
-		queue_work(mvsw_r_owq, &net_work->work);
+		prestera_router_owq_queue_work(&net_work->work);
 	}
 
 	return NOTIFY_DONE;
@@ -1962,7 +1970,7 @@ static int mvsw_pr_inetaddr_event(struct notifier_block *nb,
 	int err = 0;
 
 	/* Wait until previously created works finished (e.g. neigh events) */
-	mvsw_owq_flush();
+	prestera_router_owq_flush();
 	/* NETDEV_UP event is handled by mvsw_pr_inetaddr_valid_event */
 	if (event == NETDEV_UP)
 		goto out;
@@ -2000,7 +2008,7 @@ int mvsw_pr_inetaddr_valid_event(struct notifier_block *unused,
 		goto out;
 
 	/* Wait until previously created works finished (e.g. neigh events) */
-	mvsw_owq_flush();
+	prestera_router_owq_flush();
 
 	if (ipv4_is_multicast(ivi->ivi_addr))
 		return notifier_from_errno(-EINVAL);
@@ -2091,6 +2099,7 @@ __mvsw_pr_nh_neigh_create(struct prestera_switch *sw,
 	neigh->key.rif->ref_cnt++;
 	neigh->info.connected = false;
 	INIT_LIST_HEAD(&neigh->nexthop_group_list);
+	INIT_LIST_HEAD(&neigh->nh_mangle_entry_list);
 	err = rhashtable_insert_fast(&sw->router->nh_neigh_ht,
 				     &neigh->ht_node,
 				     __mvsw_pr_nh_neigh_ht_params);
@@ -2118,7 +2127,7 @@ mvsw_pr_nh_neigh_find(struct prestera_switch *sw,
 	return IS_ERR(nh_neigh) ? NULL : nh_neigh;
 }
 
-static struct mvsw_pr_nh_neigh *
+struct mvsw_pr_nh_neigh *
 mvsw_pr_nh_neigh_get(struct prestera_switch *sw,
 		     struct mvsw_pr_nh_neigh_key *key)
 {
@@ -2131,10 +2140,11 @@ mvsw_pr_nh_neigh_get(struct prestera_switch *sw,
 	return neigh;
 }
 
-static void mvsw_pr_nh_neigh_put(struct prestera_switch *sw,
-				 struct mvsw_pr_nh_neigh *neigh)
+void mvsw_pr_nh_neigh_put(struct prestera_switch *sw,
+			  struct mvsw_pr_nh_neigh *neigh)
 {
-	if (list_empty(&neigh->nexthop_group_list))
+	if (list_empty(&neigh->nexthop_group_list) &&
+	    list_empty(&neigh->nh_mangle_entry_list))
 		__mvsw_pr_nh_neigh_destroy(sw, neigh);
 }
 
@@ -2144,6 +2154,7 @@ static int mvsw_pr_nh_neigh_set(struct prestera_switch *sw,
 {
 	struct mvsw_pr_nh_neigh_head *nh_head;
 	struct mvsw_pr_nexthop_group *nh_grp;
+	struct prestera_nh_mangle_entry *nm;
 	int err;
 
 	list_for_each_entry(nh_head, &neigh->nexthop_group_list, head) {
@@ -2153,6 +2164,12 @@ static int mvsw_pr_nh_neigh_set(struct prestera_switch *sw,
 			return err;
 	}
 
+	list_for_each_entry(nm, &neigh->nh_mangle_entry_list, nh_neigh_head) {
+		err = prestera_nh_mangle_entry_set(sw, nm);
+		if (err)
+			return err;
+	}
+
 	return 0;
 }
 
@@ -2167,15 +2184,23 @@ mvsw_pr_nh_neigh_util_hw_state(struct prestera_switch *sw,
 {
 	bool state;
 	struct mvsw_pr_nh_neigh_head *nh_head, *tmp;
+	struct prestera_nh_mangle_entry  *nm, *nm_tmp;
 
 	state = false;
 	list_for_each_entry_safe(nh_head, tmp,
 				 &nh_neigh->nexthop_group_list, head) {
 		state = mvsw_pr_nexthop_group_util_hw_state(sw, nh_head->this);
 		if (state)
-			break;
+			goto out;
+	}
+	list_for_each_entry_safe(nm, nm_tmp, &nh_neigh->nh_mangle_entry_list,
+				 nh_neigh_head) {
+		state = prestera_nh_mangle_entry_util_hw_state(sw, nm);
+		if (state)
+			goto out;
 	}
 
+out:
 	return state;
 }
 
@@ -2541,7 +2566,7 @@ static void mvsw_pr_router_fib4_event_work(struct work_struct *work)
 	struct prestera_switch *sw = fib_work->sw;
 	int err;
 
-	mvsw_owq_lock();
+	prestera_router_owq_lock();
 
 	if (sw->router->aborted)
 		goto out;
@@ -2574,7 +2599,7 @@ static void mvsw_pr_router_fib4_event_work(struct work_struct *work)
 	dev_err(sw->dev->dev, "Abort. HW routing offloading disabled");
 out:
 	fib_info_put(fib_work->fen_info.fi);
-	mvsw_owq_unlock();
+	prestera_router_owq_unlock();
 	kfree(fib_work);
 }
 
@@ -2585,7 +2610,7 @@ static void mvsw_pr_router_nh_update_event_work(struct work_struct *work)
 	struct prestera_switch *sw = fib_work->sw;
 	struct fib_nh *fib_nh = fib_work->fnh_info.fib_nh;
 
-	mvsw_owq_lock();
+	prestera_router_owq_lock();
 
 	if (sw->router->aborted)
 		goto out;
@@ -2596,7 +2621,7 @@ static void mvsw_pr_router_nh_update_event_work(struct work_struct *work)
 
 out:
 	fib_info_put(fib_nh->nh_parent);
-	mvsw_owq_unlock();
+	prestera_router_owq_unlock();
 	kfree(fib_work);
 	return;
 }
@@ -2652,7 +2677,7 @@ static int mvsw_pr_router_fib_event(struct notifier_block *nb,
 		fib_work->event = event;
 		fib_work->sw = router->sw;
 		INIT_WORK(&fib_work->work, mvsw_pr_router_fib4_event_work);
-		queue_work(mvsw_r_owq, &fib_work->work);
+		prestera_router_owq_queue_work(&fib_work->work);
 		break;
 	case FIB_EVENT_NH_DEL:
 		/* Set down nh as fast as possible */
@@ -2672,7 +2697,7 @@ static int mvsw_pr_router_fib_event(struct notifier_block *nb,
 		fib_work->event = event;
 		fib_work->sw = router->sw;
 		INIT_WORK(&fib_work->work, mvsw_pr_router_nh_update_event_work);
-		queue_work(mvsw_r_owq, &fib_work->work);
+		prestera_router_owq_queue_work(&fib_work->work);
 		break;
 	default:
 		return NOTIFY_DONE;
@@ -2801,7 +2826,7 @@ int mvsw_pr_netdevice_vrf_event(struct net_device *dev, unsigned long event,
 	if (!sw || netif_is_macvlan(dev))
 		return 0;
 
-	mvsw_owq_flush();
+	prestera_router_owq_flush();
 
 	switch (event) {
 	case NETDEV_PRECHANGEUPPER:
diff --git a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
index acbad5a..c3bd399 100644
--- a/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
+++ b/drivers/net/ethernet/marvell/prestera/prestera_rxtx.c
@@ -700,8 +700,10 @@ int prestera_rxtx_switch_init(struct prestera_switch *sw)
 	}
 
 	sw->rxtx = kzalloc(sizeof(*sw->rxtx), GFP_KERNEL);
-	if (!sw->rxtx)
+	if (!sw->rxtx) {
+		err = -ENOMEM;
 		goto err_rxtx_alloc;
+	}
 
 	sdma = &sw->rxtx->sdma;
 
